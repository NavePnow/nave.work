{"pages":[{"title":"MARL","text":"","link":"/MARL/index.html"},{"title":"JavaScript","text":"","link":"/JavaScript/index.html"},{"title":"FakeNews","text":"","link":"/FakeNews/index.html"},{"title":"NLP","text":"","link":"/NLP/index.html"},{"title":"Python","text":"","link":"/Python/index.html"},{"title":"RL","text":"","link":"/RL/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"gallery","text":".hexo-image-steam-lazy {display:none;}.hexo-img-stream{width:90%;max-width:1210px;margin:3% auto}div.hexo-img-stream figure{background:#fefefe;box-shadow:0 1px 2px rgba(34,25,25,0.4);margin:0 0.05% 3%;padding:3%;padding-bottom:10px;display:inline-block;max-width:32%}div.hexo-img-stream figure img{border-bottom:1px solid #ccc;padding-bottom:15px;margin-bottom:5px}div.hexo-img-stream figure figcaption{font-size:.9rem;color:#444;line-height:1.5;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;}div.hexo-img-stream small{font-size:1rem;float:right;text-transform:uppercase;color:#aaa}div.hexo-img-stream small a{color:#666;text-decoration:none;transition:.4s color}@media screen and (max-width:950px){.hexo-img-stream{column-gap:0}} [Cover 1] [Cover 2] [Cover 3] [Cover 4] [Cover 5] [Cover 6] [Dorm 1] [Dorm 2] [Goodbye] $('img.hexo-image-steam-lazy').lazyload({ effect:'fadeIn' });","link":"/gallery/index.html"},{"title":"about","text":"nave.work My lovely blog About me è¿˜æ´»ç€ã€‚ æœ¬ç§‘ CS ä¸“ä¸šï¼Œä¸çŸ¥é“æ˜¯ä¸æ˜¯çŸ¥åçš„985é™¢æ ¡ï¼Œç›®å‰å¤§å››ï¼ŒGTç‹—ï¼Œé¢„è®¡ç¾å¦ç»§ç»­ CSï¼Œ12.1æœ€åä¸€æ¬¡æ‰˜ï¼Œå†æ‹¼ä¸€æŠŠäº‰å–å‰ä¸‰åã€‚æƒ³å»LA, å»æ„Ÿå—ä¸€ä¸‹ LALALAND çš„æ°›å›´ï¼Œå½“ç„¶æ¯•ä¸šä¹‹å‰æœ‰å¾ˆå¤šæ‰“ç®—ï¼Œæ¢ä¸€ä¸ªç”µè„‘ï¼Œä¹°ä¸€ä¸ªå¾®å•ï¼Œå»å¾ˆå¤šå¾ˆå¤šåœ°æ–¹ã€‚ã€‚åœ°å€ä¹‹æ‰€ä»¥å†™å°æ¹¾æ˜¯å› ä¸ºæˆ‘å¯¹å¥¹ï¼Œçˆ±çš„æ·±æ²‰ã€‚ ä¸è¦å¯¹æˆ‘æœ‰æœŸå¾…ã€‚ About website æ€»è¦è¯•ç€ç•™ä¸‹äº›ä¸œè¥¿ï¼Œå°±åƒ Remember me é‡Œé¢æåˆ°çš„ï¼ŒäººçœŸçš„ä¼šéšç€æ—¶é—´å’Œè®°å¿†æ…¢æ…¢æ¶ˆé€ï¼Œæ‰€ä»¥æˆ‘è¦è®°ä¸‹æ¥ï¼Œå³ä½¿æ˜¯éœé‚£é—´æºœèµ°çš„æ¢¦ï¼Œæˆ‘ä¹Ÿè¦è®°ä¸‹æ¥ï¼Œè¿˜è®°å¾—æœ‰ä¸€æ¬¡æ‰˜ç¦è€ƒå‰æˆ‘æ¢¦è§ä½ äº†ï¼Œæµç€æ³ªæ‹¿èµ·æ‰‹æœºèµ¶å¿«è®°ä¸‹æ¢¦é‡Œçš„äº‹æƒ…ï¼Œå“ªæ€•ä¸€å¥è¯ï¼Œä¸€ä¸ªå¾®ç¬‘ã€‚æˆ‘ä¼šå¿˜è®°ï¼Œä½†ä¸œè¥¿ä¸€æ—¦æ”¾åˆ°ç½‘ä¸Šï¼Œä»–å°±æ°¸è¿œä¸ä¼šä¸¢å¤±ï¼Œå°±åƒæ¼‚æµç“¶ä¸€æ ·ï¼Œå³ä½¿çœ‹ä¸è§ä»–åœ¨å“ªé‡Œï¼Œä½†ä½ çŸ¥é“ï¼Œå®ƒç¡®ç¡®å®å®å­˜åœ¨åœ¨è¿™ä¸ªç‰©ç†ä¸–ç•Œé‡Œã€‚ ä¸è¦æ‰‹æ‡’ï¼Œçœ‹å®Œä¸€æœ¬ä¹¦ï¼Œçœ‹å®Œä¸€ä¸ªç”µå½±ï¼Œå’Œä»–äººçš„ç¾å¥½é‚‚é€…ï¼Œå€¼å¾—å›å¿†çš„ä¸œè¥¿éƒ½å€¼å¾—è®©ä½ åŠ¨åŠ¨æ‰‹è®°å½•ä¸‹æ¥ï¼Œå³ä½¿ä»¥åå¿˜è®°äº†ï¼Œä¹Ÿå¯ä»¥ç¿»å‡ºæ¥ï¼Œè¯´ï¼Œä½ çœ‹ï¼Œæˆ‘è¿˜æœ‰è¿™æ ·çš„æ•…äº‹å‘¢ã€‚ Build: Hexo + Icarus + Travis CI + Github pages Image Hosting: Github + Tencent Cloud COS Thumbnail library: UNPLASH PHOTO DNS + SSL : Cloudflare Some tips about hexo Save original README.md (navepnow.github.io) after each update touch source/README.md echo &quot;skip_render: - README.md&quot; &gt;&gt; _config.yml Use LaTex in my blog https://www.jianshu.com/p/68e6f82d88b7 DO NOT PRESS SPACE CASUALLY WHILE WRITING","link":"/about/index.html"},{"title":"search","text":"","link":"/search/index.html"},{"title":"tags","text":"","link":"/tags/index.html"},{"title":"æ—§çš„æ–‡","text":"","link":"/%E6%97%A7%E7%9A%84%E6%96%87/index.html"},{"title":"æ—§çš„æ¢¦","text":"","link":"/%E6%97%A7%E7%9A%84%E6%A2%A6/index.html"}],"posts":[{"title":"Dec 15, 2018","text":"å¤ªç¾å¥½äº†â€¦ç¾å¥½çš„æˆ‘æƒ³å“­ã€‚ ä»¿ä½›è¿™ä¸ªæ¢¦â€¦ä»æˆ‘å…¥ç¡â€¦å°±å¼€å§‹äº†â€¦ä¸€ç›´åˆ°â€¦å¥¹è¯´ï¼šå’±ä»¬è¦åšä¸€è¾ˆå­çš„å¥½å…„å¼Ÿå•Šã€‚ç°åœ¨8:27ï¼Œæˆ‘é†’äº†ï¼Œä¸€åˆ‡åˆå›åˆ°äº†ç°å®ã€‚ æ¢¦çš„åŸå‹ï¼Œå¾ˆåƒæˆ‘å’Œæˆ‘å‰å¥³å‹çš„æ•…äº‹ã€‚æ¢¦é‡Œçš„é‚£ä¸ªå¥³å­©ï¼Œå¥½æƒ³ç°å®ä¸­çš„ç¡®å­˜åœ¨ï¼Œè€Œä¸”é¢éƒ¨è½®å»“é‚£ä¹ˆæ¸…æ™°ï¼Œæˆ‘æ˜¯é‚£ä¹ˆç†Ÿæ‚‰ã€‚å¥¹æœ‰ç”·æœ‹å‹çš„ï¼Œä½†ä»æ¢¦çš„å¼€å§‹ï¼Œæˆ‘å°±æ²¡æœ‰è§åˆ°ä»–çš„ç”·æœ‹å‹ã€‚ä¹‹å‰å¬äººè¯´ï¼Œæ‰€æœ‰äººéƒ½ä¸è®°å¾—æ¢¦æ˜¯æ€ä¹ˆå¼€å§‹çš„ï¼Œæˆ‘åªè®°å¾—ï¼Œæ¢¦æ˜¯åœ¨ä¸€é—´æ•™å®¤å¼€å§‹çš„ï¼Œå¥¹ååœ¨æˆ‘åé¢ï¼Œé‚£å ‚å®¢è¯¾ï¼Œå› ä¸ºè€å¸ˆçš„å°å»ºè¿·ä¿¡ï¼Œæˆ‘å’Œè€å¸ˆåµäº†èµ·æ¥ï¼ˆç”±äºæ¢¦é‡Œçš„å…ƒç´ å®åœ¨å¤ªå¤šäº†ï¼Œæˆ‘åªèƒ½æŒ‘é‡è¦çš„å…ƒç´ å»è®²ï¼‰åæ¥ä¸çŸ¥æ€ä¹ˆçš„ï¼Œä¸‹è¯¾äº†ï¼Œæˆ‘å°±å’Œé‚£ä¸ªå¥³ç”Ÿï¼Œä¸€å—èµ°äº†å‡ºæ¥ï¼Œæˆ‘è¿˜è®°å¾—é‚£ä¸€å¤©ï¼Œæˆ‘ä»¬å»äº†æ˜Ÿå·´å…‹ï¼Œå»äº†å¾ˆå¤šåƒçš„åœ°æ–¹ï¼Œä½†æ¯ä¸€æ¬¡ï¼Œéƒ½æ˜¯æˆ‘å»æ‰¾çš„å¥¹ï¼Œä»¿ä½›å¥¹æ‰æ˜¯ç›®çš„åœ°ï¼Œè€Œæˆ‘ï¼Œåªæ˜¯ä¸€ä¸ªå¥”è·‘è€…ï¼Œè€Œä¸”æ¯æ¬¡éƒ½æ˜¯æˆ‘çœ‹ç€å¥¹åƒï¼Œæˆ‘ä¸€å£ä¹Ÿæ²¡æœ‰åƒä¸‹å»ã€‚æˆ‘è®°å¾—æœ€æ¸…æ¥šçš„ä¸€ä¸ªæ¡¥æ®µï¼Œæ˜¯æˆ‘ä»¬å»åƒä¸²ï¼Œåº—ä¸å¤§ï¼Œåœ¨äºŒæ¥¼ï¼Œä¸€æ¥¼æ˜¯å¥èº«å™¨æï¼ŒåŒæ ·æ˜¯å‡ºç°åœ¨æˆ‘ç”Ÿå‘½é‡Œçš„å…ƒç´ ã€‚æˆ‘è®°å¾—å¾ˆæ¸…æ¥šï¼Œå¥¹å¸¦äº†å¥¹ä¸¤ä¸ªæœ‹å‹ï¼Œè€Œå¥¹ä¸¤ä¸ªæœ‹å‹éƒ½è¯¯ä»¥ä¸ºï¼Œæˆ‘æ˜¯å¥¹çš„ç”·æœ‹å‹ï¼Œè€Œå¥¹ä¹Ÿä¸æ…Œä¸å¿™åœ°è§£é‡Šï¼Œè¿ç¬‘å®¹éƒ½å¥½å¥½çœ‹ã€‚é‚£ä¸€å¤©è¿‡å¾—å¥½å¿«ï¼Œä»ä¸€å®¶åº—é¢å‡ºæ¥ï¼Œå¤©å·²ç»é»‘äº†ï¼Œæˆ‘è¯´ï¼Œæˆ‘é€ä½ å›å»å§ï¼Œä¹‹ååœ¨è·¯è¾¹æ‰«äº†ä¸€è¾†ç”µåŠ¨è½¦ï¼ˆæ ¡å›­é‡Œå…±äº«ç”µåŠ¨è½¦çš„å…ƒç´ ï¼‰ï¼Œå¥¹ååœ¨åé¢ï¼Œæˆ‘å¸¦ç€å¥¹ï¼Œå½“æ—¶çš„æˆ‘ï¼Œè™½è¯´ä¸æƒ³å’Œå¥¹å¤„æˆå…„å¼Ÿï¼Œä½†å¥¹æœ‰ç”·æœ‹å‹ã€‚æˆ‘çš„åˆæ‹ï¼Œæˆ‘ä¹Ÿæ˜¯ä½œä¸ºç¬¬ä¸‰è€…ï¼Œä½†åœ¨ç°å®ç”Ÿæ´»ä¸­ï¼Œæˆ‘æœ€ç»ˆï¼Œè¿½åˆ°äº†é‚£ä¸ªå¥³ç”Ÿï¼Œä½†åœ¨æ¢¦é‡Œï¼Œæ˜¯é‚£ä¸ªå¥³ç”Ÿå…ˆå¼€çš„å£ï¼šå’±ä»¬è¦åšä¸€è¾ˆå­çš„å¥½å…„å¼Ÿå•Šã€‚æˆ‘å¾ˆæ¸…æ¥šçš„è®°å¾—ï¼Œå½“æ—¶çš„æˆ‘ï¼Œéª‘ç€ç”µåŠ¨è½¦ï¼Œä¸€å¥è¯ä¹Ÿè¯´ä¸å‡ºæ¥ï¼Œå“½å’½ç€ï¼Œæˆ‘å¤šå¸Œæœ›æˆ‘èº«è¾¹çš„é‚£ä¸ªäººï¼Œæ˜¯ä½ ã€‚å¯¹ä¸èµ·ï¼Œæ˜¯æˆ‘å¤šæƒ³äº†ã€‚æˆ‘é†’äº†ã€‚","link":"/Dec-15-2018.html"},{"title":"æŸ³çƒˆçš„éŸ³ä¹ä¸“è¾‘","text":"æ˜¨å¤©åœ¨ç½‘ä¸Šå¶ç„¶é—´çœ‹åˆ°äº†ä¸€ä¸ªå¸–å­ï¼Œåå­—æ˜¯ã€ŠæŸ³çƒˆçš„éŸ³ä¹ä¸“è¾‘ã€‹ï¼Œä¸æµ·å¯…å’Œé«˜é‡‘é“¶ä¸»æ¼”ï¼Œä¹ä¸€çœ‹åå­—ï¼Œæ„Ÿè§‰æ˜¯è·Ÿå¥‡è¿¹å”±ç‰‡è¡Œä¸€æ ·çš„ç”·å¥³ä¸»å› ä¸ºéŸ³ä¹åœ¨ä¸€èµ·çš„æ•…äº‹ï¼Œè€Œä¸”ä¸æµ·å¯…å’Œé«˜é‡‘é“¶ä¸¤ä½æ¼”å‘˜æˆ‘è›®å–œæ¬¢ï¼Œæ­£å¥½ä¹Ÿå¥½ä¹…æ²¡çœ‹çˆ±æƒ…ç‰‡äº†ï¼Œå°±ç›´æ¥åœ¨ç½‘ä¸Šæ‰¾äº†èµ„æºã€‚ä¸è¿‡è¯´çœŸçš„ï¼Œå‡Œæ™¨ 1 ç‚¹å¼€å§‹ï¼Œçœ‹å®Œç”µå½±åˆåœ¨ bç«™ä¸Šçœ‹äº†é«˜é‡‘é“¶çš„è§†é¢‘ï¼Œç²‰äº†é«˜é‡‘é“¶çš„ insï¼Œä¸€ç›´æåˆ°äº† 5 ç‚¹é’Ÿï¼Œç®—æ˜¯ 22 å²ç”Ÿæ—¥è‡ªå·±ç»™è‡ªå·±çš„ä¸€ä»½â€œå¤§ç¤¼â€å§(çˆ†è‚çš„å¼€å§‹) è®²çœŸï¼Œæˆ‘çœ‹åˆ«äººè¯„ä»·è¿™éƒ¨ç”µå½±ï¼Œå“­çš„éƒ½å·²ç»ä¸è¡Œäº†ï¼Œæˆ‘å…¨ç¨‹çœ‹ä¸‹æ¥ï¼Œè¿˜çœŸçš„æ²¡æœ‰å“­ï¼Œæ„Ÿè§‰æ²¡æœ‰ã€Šç°åœ¨å»è§ä½ ã€‹é‚£ä¹ˆå‚¬æ³ªï¼Œä¸çŸ¥é“æ˜¯ä¸æ˜¯æˆ‘çš„æƒ…æ„Ÿæ®†å°½ï¼Œå·²ç»ä½“ä¼šä¸åˆ°è¿™ç§çˆ±æƒ…å¸¦æ¥çš„ç—›è‹¦ä¸æ¸©æš–äº†ã€‚ä¸€ä¸ªæ˜¯è¢«äººè¯¯ä¼šçŠ¯ä¸‹ä¼°è®¡è°‹æ€ç½ªè¿›å…¥å°‘ç®¡æ‰€çœ‹ä¼¼è¾ˆå­å°±å·²ç»æ²¡æœ‰ä»»ä½•å¸Œæœ›çš„ä¸æµ·å¯…é¥°æ¼”çš„è§’è‰²ï¼ˆå¯¹ä¸ä½äº†ï¼Œæˆ‘å¯¹åå­—å®åœ¨ä¸æ•æ„Ÿï¼‰ï¼Œä¸€ä¸ªæ˜¯åˆ»è‹¦å­¦ä¹ æƒ³æ‰¾ä¸€ä»½å·¥ä½œä½†é‡åˆ°ç»æµå±æœºéš¾ä»¥ç”Ÿå­˜çš„é«˜é‡‘é“¶é¥°æ¼”çš„è§’è‰²ï¼Œä¸¤ä¸ªäººçš„ç›¸é‡æ˜¯åœ¨ä¸æµ·å¯…å‡ºç‹±çš„å½“å¤©ï¼Œå› ä¸ºéŸ©å›½å¥½åƒæœ‰å‡ºç‹±å°±ä¸€å®šè¦åƒè±†è…çš„åŸå› ï¼Œä»–è¿›åˆ°äº†é«˜é‡‘é“¶æ‰“å·¥çš„é¢åŒ…åº—é‡Œï¼Œè¯¢é—®æ˜¯å¦æœ‰è±†åˆ¶å“ï¼Œè¿™ä¸€å¤©ä¹Ÿæ°å¥½æ˜¯æŸ³çƒˆçš„éŸ³ä¹ä¸“è¾‘å¼€æ’­çš„ç¬¬ä¸€å¤©ï¼š1994å¹´ 10 æœˆ 1 æ—¥ï¼Œä¸€åˆ‡éƒ½æ˜¯æ–°çš„å¼€å§‹ï¼Œä¸æµ·å¯…æŠ±ç€å¯¹ç”Ÿæ´»æ–°çš„æœŸè®¸ï¼Œåœ¨è¿™å®¶åº—åšèµ·äº†å…¼èŒï¼Œä»¿ä½›å¿™ç¢Œç€å¿™ç¢Œç€å°±å¯ä»¥å¿˜è®°ä¹‹å‰çš„ç—›è‹¦ï¼Œä½†ç”µå½±æ˜¯ä¸å…è®¸è¿™æ ·çš„ï¼Œå¥½çš„ç”Ÿæ´»èŠ‚å¥è¢«ä»–ä¸€èµ·å‡ºç‹±çš„æœ‹å‹æ‰“ç ´ï¼Œä¸€èµ·å‡ºå»å–é…’ç»“æœå’Œåˆ«äººå‘ç”Ÿäº†å£è§’ï¼Œç”Ÿæ´»å†æ¬¡å°†ä»–ä»¬æ‰“å›åŸå½¢ï¼Œè¿™ä¸€èµ°å°±æ˜¯ 3 å¹´ï¼Œå†æ¬¡çš„é‡é€¢è¿˜æ˜¯å‘ç”Ÿåœ¨é¢åŒ…åº—å‰ï¼Œçªç„¶çš„å¶é‡è®©é‡‘é«˜é“¶é‡æ‹¾å¿ƒä¸­çš„èŠ±ç«ï¼Œå¯ç¬¬äºŒå¤©ï¼Œä¸æµ·å¯…å°±è¦æœå½¹äº†ã€‚æ·±å¤œçš„å¥¹æ‰“å¼€ç”µè„‘ï¼Œç»™ä¸æµ·å¯…æ³¨å†Œäº†ç”µé‚®ï¼Œæƒ³ä»–åœ¨å†›é˜Ÿçš„æ—¶å€™ï¼Œä¹Ÿå¯ä»¥æ­£å¸¸æ¥å¾€ï¼Œç»“æœï¼Œæœ€ç»ˆçš„ç”µé‚®çš„å¯†ç å´å¿˜è®°å‘Šè¯‰äº†ä»–ã€‚æœå½¹çš„é‚£ä¹ˆé•¿æ—¶é—´é‡Œï¼Œé‚®ç®±é‡Œåªæœ‰é«˜é‡‘é“¶çš„æ¥ä¿¡ï¼Œæ²¡æœ‰ä¸€å°æ˜¯æœ‰å›å¤çš„ã€‚ä¸æµ·å¯…åœ¨ä¼‘å‡çš„æ—¶å€™ï¼Œæœ‰å»è¿‡é«˜é‡‘é“¶ä¹‹å‰ç§Ÿæˆ¿å­çš„åœ°æ–¹ï¼Œå¾ˆèªæ˜çš„çŒœåˆ°äº†é‚®ç®±çš„å¯†ç ï¼Œä¸¤äººçš„ç¬¬ä¸‰æ¬¡ç›¸é‡ï¼Œè¿™æ—¶æ—¶é—´åˆ°äº† 2000 å¹´ã€‚ä»¿ä½›æ˜¯æ—¶é—´åœ¨æ‰å¼„ä¸¤ä¸ªäººï¼Œä¸æµ·å¯…åšå…¼èŒçš„åœ°æ–¹å‡ºç°äº†é—®é¢˜ï¼Œçº¦å®šçš„ç”µè¯æ—¶é—´å¥¹è¢«æ”¾äº†é¸½å­ï¼Œè€Œé«˜é‡‘é“¶è‡ªå·±ä¹Ÿå› ä¸ºå¾ˆå¤šçš„ä¸å¦‚æ„çš„åœ°æ–¹è€Œæ¥è¿‘å´©æºƒï¼Œä¸å¦‚æ„çš„å·¥ä½œï¼Œæ— èŠè€Œå˜ˆæ‚çš„ç¯å¢ƒéƒ½è®©å¥¹æ— æ—¶æ— åˆ»ä¸åœ¨æ€€ç–‘è‡ªå·±å­˜åœ¨çš„ä»·å€¼ï¼Œé‚£å¤©æ™šä¸Šï¼Œå¥¹å“­ç€å‘äº†æœ€åçš„ä¸€å°é‚®ä»¶ï¼Œè¯´ç€â€œæˆ‘ä¹Ÿä¼šåœ¨æœ‰å¥½äº‹å‘ç”Ÿçš„æ—¶å€™ï¼Œå†è”ç³»ä½ â€ï¼Œç”µé‚®é‚£å¤´çš„ä»–ï¼Œä¹Ÿæ˜¯å¯¹ç”Ÿæ´»æŠ±ç€æ€€ç–‘çš„æ€åº¦ï¼ŒçŠ¹è±«çš„æ‰“ä¸‹çš„å­—æœ€åä¹Ÿåªå­˜åœ¨äºåƒåœ¾ç®±ä¸­ï¼Œå°±è¿™æ ·ï¼Œä¸¤äººå†æ¬¡å¤±å»äº†è”ç³»ã€‚æ—¶é—´åˆ°äº† 2005 å¹´ï¼Œé«˜é‡‘é“¶æ‰¾åˆ°äº†è‡ªå·±å¦‚æ„çš„ç¼–è¾‘å·¥ä½œï¼Œè€Œä¸”è·å¾—äº†æ»¡æ„çš„æˆå°±ï¼Œä¸æµ·å¯…ä¹Ÿå’Œåˆ«äººä¸€èµ·ï¼Œåšèµ·äº†æ‘„å½±ç›¸å…³çš„åˆ›ä¸šå·¥ä½œï¼Œå·§çš„æ˜¯ï¼Œä¸¤äººçš„å·¥ä½œå®¤å°±æ˜¯ 1 å±‚å’Œ 2 å±‚çš„å…³ç³»ï¼Œäºæ˜¯ï¼Œå†æ¬¡çš„ç›¸é€¢é‡æ–°å‹¾èµ·äº†ä»–ä»¬å¯¹äºå¾€äº‹çš„å›å¿†ã€‚åŒå±…ç”Ÿæ´»ï¼Œä¸€èµ·åšé¥­ï¼Œçœ‹ä¹¦ï¼Œç¡è§‰ï¼Œåˆ†äº«ç”Ÿæ´»ï¼Œä½†ä¸­é—´æœ‰ä¸€ä¸ªç»†èŠ‚ï¼Œæˆ‘å½“æ—¶çœ‹çœŸçš„æ²¡æœ‰åœ¨æ„ï¼Œçœ‹äº†åˆ«äººçš„è¯„è®ºï¼Œæˆ‘æ‰å‘ç°çš„ã€‚å½“æ—¶é«˜é‡‘é“¶å¯¹ä¸æµ·å¯…è¯´ï¼šâ€œæˆ‘ä»¬ç»“å©šå§â€ï¼Œé¢å¯¹çªç„¶çš„é—®é¢˜ï¼Œä»–ä¸€å®šæ˜¯æ²¡æœ‰åšå¥½å‡†å¤‡çš„ï¼Œè‡ªå·±æ— æ³•äº†å´çš„è¿‡å»å’Œä¸ç¡®å®šçš„æœªæ¥ï¼Œå“ªä¸€æ ·éƒ½æ— æ³•ç»™å¥¹ä¸€ä¸ªç¡®å®šçš„ç­”æ¡ˆï¼Œå”¯æœ‰å¤œé‡Œæ·±æ·±åœ°æ‹¥æŠ±æ‰èƒ½ç»™äºˆä»–å’Œå¥¹çŸ­æš‚çš„å®‰å…¨æ„Ÿã€‚ç”Ÿæ´»çš„å†·æ°´å†æ¬¡å€’ç»™äº†ä¸æµ·å¯…ï¼Œæ­»å»çš„æœ‹å‹çš„ 10 å¹´ç¥­åˆ°æ¥äº†ï¼Œä½œä¸ºâ€œä¸»çŠ¯â€çš„ä»–ç«™åœ¨æœ‹å‹å®¶çš„é—¨å£ï¼Œå£å£å£°å£°è¯´è‡ªå·±å¹¶æ²¡æœ‰é‚£ä¹ˆåšï¼Œè¿æ¥çš„å´æ˜¯ä¸€å¥â€œå°±ç®—çŸ¥é“ä¹Ÿä¸çŸ¥é“â€ï¼Œè¿™ä¸ªä¸–ç•Œä»¿ä½›æ€»è¦å»ç»™æ¯ä¸€ä»¶ä¸å¥½çš„äº‹æƒ…æ‰¾åˆ°ä¸€ä¸ªçœ‹ä¼¼åˆç†çš„ç†ç”±ï¼Œå³ä½¿å¤§å®¶éƒ½æ²¡æœ‰è¶³å¤Ÿçš„ç†ç”±å»ç›¸ä¿¡è¿™æ˜¯çœŸçš„ï¼Œä»¿ä½›æ˜¯ä¸ºäº†å¡«è¡¥äººä»¬å¿ƒä¸­çš„åˆ›ä¼¤ï¼Œä¹Ÿç®—æ˜¯ä¸€ç§æ…°è—‰äº†ã€‚è¿™ä¸ªäº‹æƒ…ä¹Ÿæ°å¥½è¢«é‡‘é«˜é“¶çŸ¥é“äº†ï¼Œåœ¨ä¸æµ·å¯…çœ¼é‡Œï¼Œä»–åªå¸Œæœ›å¥¹èƒ½è®°ä½ 1994 å¹´ä¹‹åçš„è‡ªå·±ï¼Œå› ä¸ºè¿‡å»çš„äº‹æƒ…å”¯æœ‰å°‘æ•°äººç†è§£ä»–ï¼Œæ›´å¤šçš„äººæ˜¯ä¸å¸Œæœ›ä»–èƒ½é¡ºåˆ©çš„æ´»åœ¨è¿™ä¸ªä¸–ç•Œä¸Šçš„ï¼Œå³ä½¿ä»–æœ‰å¤šåŠªåŠ›å»æ”¹å˜è‡ªå·±ã€‚å› ä¸ºåˆ›ä¸šèµ„é‡‘ä¸è¶³ï¼Œä»–è¦æ¬ç¦»å’Œé‡‘é«˜é“¶ä¸€èµ·å·¥ä½œçš„åœ°æ–¹ï¼Œè€Œä¸”å¥¹çš„ä¸Šå¸çš„æ²¹æ€§éªšæ‰°æœ‰ä¸€ç§ä¸å¯æŠ—åŠ›ï¼Œè®©ä¸æµ·å¯…è§‰å¾—å¥¹ä¼šè·Ÿä¸Šå¸ä¸€èµ·ç”Ÿæ´»ã€‚æˆ‘ç¬¬ä¸€éçœ‹çš„æ—¶å€™ï¼Œé«˜é‡‘é“¶ä¸Šäº†ä¸Šå¸çš„è½¦çœŸçš„ä»¥ä¸ºä»–ä¿©åœ¨ä¸€èµ·äº†ï¼Œåé¢çœ‹äº†å½±è¯„æ‰çŸ¥é“ä»–ä»¬æ˜¯ä¸€å—å»çœ‹äº†æ–°çš„åº—é¢è®¾è®¡ï¼Œæ˜¯ä¸ºäº†å·¥ä½œï¼Œæˆ‘ä¹Ÿç®—æ˜¯é•¿ç–äº†ä¸€å£æ°”ã€‚è€Œé‚£ä¸€æ®µä¸æµ·å¯…è¿½æ±½è½¦çš„æ¡¥æ®µï¼Œä»¿ä½›æ˜¯ç‚¹ç‡ƒäº†å¥¹å¿ƒä¸­ä»æœ‰ä½™æ¸©ä½†å¿«ç‡ƒçƒ§æ®†å°½çš„ç«è‹—ï¼Œå’Œé˜¿å§¨åœ¨ä¸€èµ·çš„è°ˆè¯ä¹Ÿè®©å¥¹ç›¸ä¿¡äº†ä»–çš„éš¾å¤„ä»¥åŠæƒ³è¦åŠªåŠ›ç”Ÿæ´»çš„æ„¿æœ›ã€‚å†ä¸€æ¬¡ä¹Ÿæ˜¯ç”µå½±æœ€åçš„ä¸€ä¸ªæ¡¥æ®µï¼Œå‘ç”Ÿåœ¨äº†æŸ³çƒˆæ¼”æ’­å®¤çš„å¤–é¢ï¼Œé«˜é‡‘é“¶åœ¨ç”µå°èŠ‚ç›®é‡Œé¢å¬åˆ°äº†è‡ªå·±çš„åå­—ï¼Œæ€»æœ‰ä¸€ç§å£°éŸ³å‘Šè¯‰å¥¹ä¸æµ·å¯…å°±åœ¨ç”µå°çš„å½•åˆ¶ç°åœºï¼Œäºæ˜¯ï¼Œç”µå½±çš„æœ€åï¼Œéš”ç€ä¸€é¢ç»ç’ƒï¼Œä¸€ä¸ªæ˜¯ 10 å¹´éƒ½ä»–å¦ˆæ²¡æœ‰ä»»ä½•å˜åŒ–ç”šè‡³æ›´åŠ å¹´è½»çš„ä¸æµ·å¯…ï¼Œä¸€ä¸ªæ˜¯æ‹¥æœ‰ç¨³å®šå·¥ä½œåˆæ¼‚äº®çš„é«˜é‡‘é“¶ã€‚ ç”µå½±çš„é¢˜ç›®æ˜¯ä¸€æ¡£ç”µå°èŠ‚ç›®ï¼Œä¸¤äººå› ä¸ºç”µå°èŠ‚ç›®çš„å¼€å§‹è€Œç›¸é‡ï¼Œå› ä¸ºç”µå°çš„äº’è¯‰æ–°ç”Ÿï¼Œåˆå› ä¸ºç”µå°è€Œé‡æ–°ç›¸é€¢ã€‚ç”µå½±ä¸­çš„ bgm ç”¨çš„ä¹Ÿéƒ½æ˜¯åŒæ—¶ä»£éŸ©å›½çš„çˆ±æƒ…éŸ³ä¹ï¼Œé‚£é¦– Fin.K.Lçš„æ°¸æ’çš„çˆ±ä¸€æƒ³èµ·æ¥ï¼Œçœ¼æ³ªçœŸçš„å·®ç‚¹å°±å¿ä¸ä½äº†ã€‚ç”µå½±çœ‹å®Œåˆçœ‹äº†ä¸€éä»–ä»¬ä¸¤ä¸ªåœ¨ Begin Again3 ä¸Šçš„è¡¨æ¼”ï¼Œå—“éŸ³çœŸçš„ç»äº†ã€‚10 å¹´æ–­æ–­ç»­ç»­çš„ç›¸é‡ï¼Œéƒ½æ˜¯åŠªåŠ›ç”Ÿæ´»çš„æ ·å­ï¼Œéƒ½æ˜¯å¯¹çˆ±æƒ…å……æ»¡äº†å¸Œæœ›ï¼ŒçœŸçš„å¾ˆä¸é”™çš„çˆ±æƒ…ç”µå½±ã€‚æœ€åæ¨ä¸€é¦–ä»Šå¤©æ·˜çš„æ­Œä½œä¸ºç»“å°¾ï¼Œé‡‘å…‰çŸ³çš„ã€Šä¸‰åå²ä¹‹é™…ã€‹","link":"/10-04-2019-%E6%9F%B3%E7%83%88%E7%9A%84%E9%9F%B3%E4%B9%90%E4%B8%93%E8%BE%91.html"},{"title":"Dec 27, 2017","text":"æ˜¨å¤©åœ¨æ¢¦é‡Œï¼Œæ¢¦è§å§¥å¨˜å› ä¸ºå¤ªç˜¦ï¼Œè¥å…»ä¸è‰¯è€ŒåŒç›®å¤±æ˜ï¼Œæˆ‘ååœ¨æ¡Œå‰ï¼Œå“­äº†ï¼Œæˆ–è®¸æ˜¯æ¢¦å¢ƒå¤ªè¿‡äºçœŸå®ï¼Œå“­é†’äº†æ³ªè¿˜æ˜¯æ­¢ä¸ä½ã€‚æˆ‘åäº†èµ·æ¥ï¼Œç”¨æ¯›å·¾æ“¦æ“¦æ³ªï¼Œä½†å†ä¹Ÿç¡ä¸ç€äº†ã€‚ è¿™ä¸€å¹´ç»å†äº†å¤ªå¤šâ€¦å¦‚æ„çš„â€¦ä¸é¡ºçš„â€¦ç”Ÿæ­»ç¦»åˆ«ä¹Ÿåªä¸è¿‡æ˜¯åŠä¸ªæ˜ŸæœŸçš„äº‹ã€‚å¸Œæœ›å§¥å¨˜èƒ½å¤šåƒç‚¹è‚‰ï¼Œåˆ«å†é‚£ä¹ˆç˜¦äº†ï¼Œå¸Œæœ›è¿œæ–¹çš„ä½ ï¼Œä¹Ÿèƒ½ç…§é¡¾å¥½è‡ªå·±ï¼Œç´¯äº†å°±è¹²ä¸‹æ¥ç»™è‡ªå·±ä¸€ä¸ªå¤§å¤§çš„æ‹¥æŠ±ï¼Œå‘Šè¯‰è‡ªå·±æˆ‘è¿˜è¡Œã€‚","link":"/Dec-27-2017.html"},{"title":"Cest la vie - Sep 24, 2019","text":"ä»Šå¤©è¿˜åœ¨è·Ÿæˆ‘ä»¬ç­ä¸€èµ·å‡ºå›½çš„äººä¸€èµ·èŠå¤©ï¼Œçªç„¶æœ‰ä¸€ç§ä½œä¸ºå€¾å¬è€…çš„æ„Ÿè§‰ã€‚æˆ‘ä»¬ç­å…¶å®è¿˜æœ‰å¦å¤–ä¸€ä¸ªå¸…æ°”å°ä¼™å­ï¼Œæœ¬æ¥è¦å‡ºå›½ï¼ŒèŠ±äº†2å¹´æ—¶é—´è€ƒè‹±è¯­ï¼Œ GTè€ƒäº†å‡ºæ¥ï¼Œæœ€åé€‰æ‹©äº†ä¿ç ”ï¼Œé€‰æ‹©äº†ç¡¬ä»¶ï¼Œé€‰æ‹©äº†å›½å…‰çš„ç›´åšã€‚å½“æ—¶å¬åˆ°è¿™ä¸ªæ¶ˆæ¯ï¼Œå…¶å®æˆ‘æœ‰æƒ³åˆ°ä»–çš„å¥³æœ‹å‹è¯¶ï¼Œæœ‰å¯èƒ½æ˜¯ä¸ºäº†çˆ±æƒ…ï¼Ÿä»Šå¤©å’Œè¿™ä¸ªå“¥ä»¬èŠå¤©ï¼Œå¥½åƒæœ‰ç‚¹ç¡®è®¤äº†è¿™ä¸ªæ¶ˆæ¯ï¼Œç„¶åè¿™å“¥ä»¬å°±é—®æˆ‘å…³äºå¥³æœ‹å‹ï¼Œå‡ºå›½çš„å„ç§ä¸ç¡®å®šæ€§ã€‚æˆ–è®¸æ˜¯å› ä¸ºç¡¬ä»¶æ¡ä»¶ï¼Ÿä»–è¯´ä»–ä¸ä¼šåœ¨é‚£è¾¹æ‰¾çš„ï¼Œæƒ³è¦åœ¨å›½å†…å¸¦ä¸€ä¸ªè¿‡å»ï¼Œä½†åˆæ€•ä¹‹åè‡ªå·±æ”¾å¼ƒè¿™æ®µçˆ±æƒ…ï¼Œç„¶åå°±æŠŠé—®é¢˜æŠ›ç»™æˆ‘äº†ï¼Œæˆ‘å•·ä¸ªçŸ¥é“å’¯ï¼Œéšç¼˜å§ï¼Ÿå…¶å®æˆ‘æœ‰ä¸€æ¡è·¯çš„é€‰æ‹©æ˜¯ï¼Œè¯»å®Œmasterå·¥ä½œï¼Œç„¶åå»æ–°åŠ å¡ï¼ŒæŠŠå­©å­è½æˆ·åœ¨é‚£é‡Œï¼Œä½†è¿™ä¸ªæ—…ç¨‹ç¼ºå¤±äº†å¦å¤–ä¸€ä¸ªäººï¼Œè¯´çœŸçš„ï¼Œæˆ‘ä¹Ÿä¸çŸ¥é“å¥¹èƒ½åœ¨å“ªé‡Œè¢«æˆ‘é‡åˆ°ï¼Œæ„¿æ„ä¸æ„¿æ„å»æ–°åŠ å¡ï¼Œå¥¹å®¶é‡Œæ„¿æ„ä¸æ„¿æ„è®©å¥¹è·Ÿæˆ‘å»æ–°åŠ å¡ï¼›æˆ–è€…è¯´æˆ‘æœ‰æƒ³æ³•è¦è¯»åšï¼Œé‚£ä»¥åçš„æ—¥å­å¯å°±è¦æ›´åŠ æƒ³æ¸…æ¥šäº†ï¼Œå½“ç„¶æˆ‘æ†§æ†¬ç€lalalandé‡Œé¢ç°å®çš„çˆ±æƒ…æ•…äº‹ï¼Œèƒ½é‡åˆ°ä¸èƒ½é‡åˆ°å°±ä¸¤è¯´äº†ã€‚é‚£å“¥ä»¬ä¹Ÿæ˜¯æŒºä¸å®¹æ˜“çš„ï¼Œè‡ªå·±èƒŒäº†å€ºï¼Œæƒ³åˆ°ç¾å¸è¯»phdå›æœ¬ï¼Œä½†åˆæ€•è‡ªå·±è¯»å®Œå›æ¥30+ï¼Œçœ‹åˆ°è‡ªå·±çš„åå­—å‡ºç°åœ¨éè¯šå‹¿æ‰°çš„åå•é‡Œï¼Œèµ„æ–™é‡Œå†™ç€ç¾å›½è®¡ç®—æœºåšå£«çš„é‚£ç§ã€‚æˆ‘è¿˜è®°å¾—å¾ˆæ¸…æ¥šï¼Œæˆ‘ä»¬ä¿©ä¹‹å‰èŠè¿‡è¿™ä¸œè¥¿ï¼Œå¤§ä¸‰çš„æ—¶å€™ï¼Œä»–å½“æ—¶è¿˜æ˜¯ä¸€è„¸ä¸åœ¨ä¹ï¼Œä»¿ä½›æ˜¯æ¢¦ä¸­äººï¼Œè¯¯ä»¥ä¸ºè‡ªå·±æ‰¾åˆ°äº†æ‰€æœ‰å¯è¡Œçš„é“è·¯ã€‚è¯»å®Œå¤§å­¦ï¼Œå¤§å®¶éƒ½å„å¥”ä¸œè¥¿äº†å•Šï¼Œç»“å©šç”Ÿå­©ï¼Œå°±ä»¿ä½›æ˜¯ç´§ç®å’’ä¸€èˆ¬ï¼Œæ°¸è¿œå»ä¸æ‰ï¼Œæå¾—ä½ æ­»å»æ´»æ¥ã€‚æ˜¨å¤©åˆšçœ‹äº†ä¸ƒæ¯›çš„æ–‡ç« ï¼Œå¿ƒæƒ³çœŸæœ‰è¿™æ ·çš„å©†å©†å•Šï¼Œå§æ§½ï¼Œè¦æ˜¯æˆ‘å¦ˆè¿™æ ·ï¼Œç›´æ¥è®©å¥¹æ»šå¥½äº†ã€‚è¯è¯´å›æ¥ï¼Œé’±ï¼Œçˆ±æƒ…ï¼Œç”Ÿæ´»ï¼Œè¿˜æœ‰æœ‹å‹ï¼Œå“ªä¸ªæ˜¯å¯ä»¥å‰²èˆçš„å‘¢ï¼Œéƒ½æ†§æ†¬ç€ç”œç”œçš„æ‹çˆ±ï¼Œè¯´ä¸å®šäº²äº²æŠ±æŠ±ä¹‹åå‚¬å€ºçš„ç”µè¯å°±æ¥äº†ã€‚æ´»åˆ°è¿™ä¹ˆå¤§ï¼ŒçœŸå°±æ˜¯èŠ±çˆ¶æ¯çš„é’±ï¼Œæˆ‘æƒ³ä½œä¸ºçˆ¶æ¯ï¼Œè¿™æˆ–è®¸å°±æ˜¯æ•™è‚²æŠ•èµ„å§ï¼Œé«˜æŠ•å…¥ï¼Œé«˜é£é™©çš„é‚£ç§ã€‚ç”Ÿæ´»å•Šï¼Œè°ä¸æ˜¯æ·Œç€ä¸€æ‘Šæµ‘æ°´è‰°éš¾å‰è¡Œå‘¢ï¼Œå½“ç„¶æœ‰é‚£ç§å‡ºç”Ÿå°±æ¯”åˆ«äººæœ‰æ›´å¤šçš„èµ„æºï¼Œæˆ¿äº§åŠ èº«ï¼Œæˆ‘æ˜¯æ²¡æœ‰æœºä¼šï¼Œæˆ‘å­©å„¿ï¼Ÿå…ˆæœ‰ä¸ªå­©å­å†è¯´å§ã€‚å½“ä»–è¯´åˆ°ä»–å®¶é‡Œå¯¹ä»–å‡ºå›½æ€åº¦çš„æ—¶å€™ï¼ˆå›½å†…ä¿ç ”å¤šå¥½ï¼Œå·¥ä½œè¯»åšå¨¶å¦»ç”Ÿå­ï¼Œå®‰å®‰ç¨³ç¨³ï¼Œè°è®©ä½ é€‰æ‹©è¿™æ¡è·¯äº†ï¼‰ï¼Œæˆ‘æƒ³åˆ°äº†å¤§å†°çš„ä¹¦ä¸­è¯´åˆ°çš„ï¼Œå¹´è½»äººï¼Œè¶æœ‰æ´»åŠ›ï¼Œå¤šé—¯ä¸€é—¯ï¼Œå¤šä½“éªŒè‡ªå·±æƒ³è¦çš„ç”Ÿæ´»ï¼Œæ˜¯å•Šï¼Œå¯å¦‚æœå¤±è´¥äº†ï¼ŒçœŸçš„å°±å¤´ç ´è¡€æµï¼Œè½æ—¥é»„èŠ±èˆ¬æ¨¡æ ·äº†ã€‚æœ‹å‹ï¼ŒåŠ æ²¹å•Šï¼Œæˆ‘çœŸçš„ä¸çŸ¥é“è¯¥æ€ä¹ˆåŠï¼Œæˆ‘ä¹Ÿæ²¡ç»å†è¿‡ï¼Œæ‰€ä»¥æˆ‘æ²¡ç»™ä½ ä¸€ä¸ªæ˜ç¡®çš„ç­”å¤ï¼Œåˆ°åº•æ˜¯é€‰æ‹©åœ¨å›½å†…è¿˜æ˜¯å›½å¤–ã€‚ä½†æ€»å½’ï¼Œè¿™å°±æ˜¯ç”Ÿæ´»å•Šï¼Œä»¥æ¢¦ä¸ºé©¬ï¼Œéšå¤„å¯æ –ï¼Ÿç°åœ¨1:42äº†ï¼Œæ‰‹æœºæ‰“å­—æ˜¯çœŸçš„æäººï¼Œæˆ‘ä¹Ÿç¡äº†ã€‚æ™šå®‰ã€‚","link":"/Cest-la-vie-Sep-24-2019.html"},{"title":"Fake News å­¦ä¹ ç¬”è®°ï¼ˆä¸‰ï¼‰Bert è´Ÿé‡‡æ · Transformer","text":"ä½¿ç”¨ Google Bert å®ç° Word-Embedding (ç”±äºç»„å†…åˆ†å·¥ï¼Œæˆ‘å’Œå¦å¤–ä¸€ä½åŒå­¦è´Ÿè´£æ–‡å­—å¤„ç†éƒ¨åˆ†ï¼Œæ‰€ä»¥è¿™é‡Œä¸»è¦ä»‹ç»å¯¹äº Google Bert çš„å­¦ä¹ è¿‡ç¨‹ä»¥åŠå¯¹äºæ–‡å­—å¤„ç†çš„ä¸€äº›ç»†èŠ‚) idea: 1. å°† cleaned åçš„æ–‡æœ¬è¿›è¡Œæå–ï¼Œå¦‚æœ len(text)ä¸º 0ï¼Œåˆ æ‰ label 2. ä½¿ç”¨å­¦ä¹ ç¬”è®°äºŒä¸­æåˆ°çš„stemming lemmatizingæŠ€æœ¯ï¼Œå¯¹æ–‡æœ¬è¿›è¡Œå¤„ç†(ä¸çŸ¥é“ç»“æœæ€ä¹ˆæ ·) 3. to be continued è´Ÿé‡‡æ · è´Ÿé‡‡æ ·é€šè¿‡ä½¿æ¯ä¸€ä¸ªè®­ç»ƒæ ·æœ¬ä»…ä»…æ”¹å˜ä¸€å°éƒ¨åˆ†çš„æƒé‡è€Œä¸æ˜¯æ‰€æœ‰æƒé‡ã€‚ä¹Ÿå°±æ˜¯å¯¹æ­£ç¡®çš„ä¸€ä¸ªè¾“å‡ºå•è¯upï¼Œé€‰æ‹©5-20ä¸ªä¸æ­£ç¡®çš„å•è¯lowã€‚åœ¨ Bert ä¸­ï¼Œé¦–å…ˆç»™å®šçš„ä¸€ä¸ªå¥å­ï¼Œä¸‹ä¸€å¥å­æ­£ä¾‹ï¼ˆæ­£ç¡®è¯ï¼‰ï¼Œéšæœºé‡‡æ ·ä¸€å¥è´Ÿä¾‹ï¼ˆéšæœºé‡‡æ ·è¯ï¼‰,å¥å­çº§ä¸Šæ¥åšäºŒåˆ†ç±»ï¼ˆå³åˆ¤æ–­å¥å­æ˜¯å½“å‰å¥å­çš„ä¸‹ä¸€å¥è¿˜æ˜¯å™ªå£°ï¼‰ï¼Œç±»ä¼¼word2vecçš„å•è¯çº§è´Ÿé‡‡æ ·ã€‚ Transformer æ¨¡å‹ç»“æ„ The Transformer Architecture å¦‚å›¾æ‰€ç¤ºï¼Œå·¦è¾¹ä¸ºencoderï¼Œå³è¾¹ä¸º decoderï¼Œå…·æœ‰é«˜å¹¶è¡Œæ€§çš„ç‰¹ç‚¹æŠ±æ­‰ï¼Œç°é˜¶æ®µæœ¬äººèƒ½åŠ›æœ‰é™ï¼Œæ ¹æœ¬çœ‹ä¸æ‡‚ï¼Œåæ­£ç‰›é€¼å°±å®Œäº‹äº†ï¼Œæ”¾ä¸Š linkï¼Œä¸‡ä¸€ä»¥åå›çœ‹å‘¢ã€‚ Transformer arch. ### multi-head attention: å°†ä¸€ä¸ªè¯çš„vectoråˆ‡åˆ†æˆhä¸ªç»´åº¦ï¼Œæ±‚attentionç›¸ä¼¼åº¦æ—¶æ¯ä¸ªhç»´åº¦è®¡ç®—ã€‚ç”±äºå•è¯æ˜ å°„åœ¨é«˜ç»´ç©ºé—´ä½œä¸ºå‘é‡å½¢å¼ï¼Œæ¯ä¸€ç»´ç©ºé—´éƒ½å¯ä»¥å­¦åˆ°ä¸åŒçš„ç‰¹å¾ï¼Œç›¸é‚»ç©ºé—´æ‰€å­¦ç»“æœæ›´ç›¸ä¼¼ï¼Œç›¸è¾ƒäºå…¨ä½“ç©ºé—´æ”¾åˆ°ä¸€èµ·å¯¹åº”æ›´åŠ åˆç†ã€‚æ¯”å¦‚å¯¹äºvector-size=512çš„è¯å‘é‡ï¼Œå–h=8ï¼Œæ¯64ä¸ªç©ºé—´åšä¸€ä¸ªattentionï¼Œå­¦åˆ°ç»“æœæ›´ç»†åŒ–ã€‚ ### self-attentionï¼š æ¯ä¸ªè¯ä½çš„è¯éƒ½å¯ä»¥æ— è§†æ–¹å‘å’Œè·ç¦»ï¼Œæœ‰æœºä¼šç›´æ¥å’Œå¥å­ä¸­çš„æ¯ä¸ªè¯encodingã€‚æ¯”å¦‚ä¸‹é¢è¿™ä¸ªå¥å­ï¼Œæ¯ä¸ªå•è¯å’ŒåŒå¥å…¶ä»–å•è¯ä¹‹é—´éƒ½æœ‰ä¸€æ¡è¾¹ä½œä¸ºè”ç³»ï¼Œè¾¹çš„é¢œè‰²è¶Šæ·±è¡¨æ˜è”ç³»è¶Šå¼ºï¼Œè€Œä¸€èˆ¬æ„ä¹‰æ¨¡ç³Šçš„è¯è¯­æ‰€è¿çš„è¾¹éƒ½æ¯”è¾ƒæ·±ã€‚æ¯”å¦‚ï¼šlawï¼Œapplicationï¼Œmissingï¼Œopinionã€‚ã€‚ã€‚ ### position encoding: å› ä¸ºtransformeræ—¢æ²¡æœ‰RNNçš„recurrenceä¹Ÿæ²¡æœ‰CNNçš„convolutionï¼Œä½†åºåˆ—é¡ºåºä¿¡æ¯å¾ˆé‡è¦ï¼Œæ¯”å¦‚ä½ æ¬ æˆ‘100ä¸‡æ˜å¤©è¦è¿˜å’Œæˆ‘æ¬ ä½ 100ä¸‡æ˜å¤©è¦è¿˜çš„å«ä¹‰æˆªç„¶ä¸åŒã€‚ã€‚ã€‚ transformerè®¡ç®—tokençš„ä½ç½®ä¿¡æ¯è¿™é‡Œä½¿ç”¨æ­£å¼¦æ³¢ï¼Œç±»ä¼¼æ¨¡æ‹Ÿä¿¡å·ä¼ æ’­å‘¨æœŸæ€§å˜åŒ–ã€‚è¿™æ ·çš„å¾ªç¯å‡½æ•°å¯ä»¥ä¸€å®šç¨‹åº¦ä¸Šå¢åŠ æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ ä½†BERTç›´æ¥è®­ç»ƒä¸€ä¸ªposition embeddingæ¥ä¿ç•™ä½ç½®ä¿¡æ¯ï¼Œæ¯ä¸ªä½ç½®éšæœºåˆå§‹åŒ–ä¸€ä¸ªå‘é‡ï¼ŒåŠ å…¥æ¨¡å‹è®­ç»ƒï¼Œæœ€åå°±å¾—åˆ°ä¸€ä¸ªåŒ…å«ä½ç½®ä¿¡æ¯çš„embeddingï¼ˆç®€å•ç²—æš´ã€‚ã€‚ï¼‰ï¼Œæœ€åè¿™ä¸ªposition embeddingå’Œword embeddingçš„ç»“åˆæ–¹å¼ä¸Šï¼ŒBERTé€‰æ‹©ç›´æ¥æ‹¼æ¥ã€‚ Google Bert NLPä»»åŠ¡åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œå…¶ä¸€æ˜¯é¢„è®­ç»ƒäº§ç”Ÿè¯å‘é‡ï¼Œå…¶äºŒæ˜¯å¯¹è¯å‘é‡è¿›è¡Œæ“ä½œ(ä¸‹æ¸¸ NLP ä»»åŠ¡) é¢„è®­ç»ƒäº§ç”Ÿè¯å‘é‡ ç›¸æ¯”äºä¹‹å‰æ‰€ç”¨åˆ°çš„ word2vecï¼Œè´Ÿé‡‡æ ·ä» word-level å‡çº§åˆ°äº† sentence-level ï¼Œä»è€Œå¯ä»¥è·å–å¥é—´å…³ç³»ã€‚ Bert ä½¿ç”¨åŒå‘encoding(æ¨¡å‹åœ¨å¤„ç†æŸä¸€ä¸ªè¯æ—¶ï¼Œå®ƒèƒ½åŒæ—¶åˆ©ç”¨å‰é¢çš„è¯å’Œåé¢çš„è¯ä¸¤éƒ¨åˆ†ä¿¡æ¯)ï¼Œé‡‡ç”¨çœ‹ä¸æ‡‚çš„ Transformer ç»“æ„ï¼Œç›´æ¥è·å¾—ä¸€æ•´ä¸ªå¥å­çš„å”¯ä¸€å‘é‡è¡¨ç¤ºã€‚åœ¨ Transformer ç»“æ„ä¸­ï¼Œæœ€ç»ˆçš„è¾“å…¥ç”±ä¸‹é¢ 3 ä¸ªembedding ç»„æˆã€‚ EA è¡¨ç¤ºå·¦å¥å­ï¼ŒEB è¡¨ç¤ºå³å¥å­ï¼ŒCLSä¸ºç‰¹æ®Šæ ‡è®°ç¬¦ï¼Œä¾› Transformer å¯¹ CLSè¿›è¡Œæ·±åº¦ embedding ###é¢„è®­ç»ƒæ¨¡å‹å’ŒåŠ è½½çš„è®­ç»ƒé›†ä¹‹é—´çš„å…³ç³» ä½¿ç”¨é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å·²ç»åœ¨å¤§å‹æ•°æ®é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œç„¶åé’ˆå¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œå¾®è°ƒã€‚ ä¸‹æ¸¸ NLP ä»»åŠ¡ åœ¨è·å¾— Bert è¯å‘é‡åï¼Œåªéœ€è¦åœ¨è¯å‘é‡ä¸ŠåŠ å…¥ç®€å•çš„åˆ†ç±»å™¨å³å¯å®Œæˆå·¥ä½œ","link":"/Fake%20News%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89Bert%20%E8%B4%9F%E9%87%87%E6%A0%B7%20Transformer.html"},{"title":"1987","text":"åŒã€Šå‡ºç§Ÿè½¦å¸æœºã€‹ä¸€æ ·ï¼Œè¯¥å½±ç‰‡åæ˜ çš„æ˜¯éŸ©å›½äººæ°‘ä¸ºäº‰å–æ°‘ä¸»è€Œåšå‡ºçš„ç‰ºç‰²ã€‚çœŸçš„æ„Ÿè°¢TSKSéŸ©å‰§ç¤¾â€¦èƒ½ç¿»è¯‘å‡ºè¿™ä¹ˆä¼˜ç§€çš„ç”µå½±ä½œå“â€¦è¿™ç§å¿ƒæ½®æ¾æ¹ƒçš„æ„Ÿè§‰â€¦å¾ˆä¹…æ²¡æœ‰å‡ºç°äº† imdb8.2åˆ† å€¼å¾—è§‚çœ‹","link":"/1987.html"},{"title":"Dec 6, 2017","text":"æˆ‘å–œæ¬¢ä½ æ˜¯å¯‚é™çš„ï¼Œä»¿ä½›ä½ æ¶ˆå¤±äº†ä¸€æ ·ï¼Œ ä½ ä»è¿œå¤„è†å¬æˆ‘ï¼Œæˆ‘çš„å£°éŸ³å´æ— æ³•è§¦åŠä½ ã€‚ å¥½åƒä½ çš„åŒçœ¼å·²ç»é£ç¦»è¿œå»ï¼Œå¦‚åŒä¸€ä¸ªå»ï¼Œå°ç¼„äº†ä½ çš„å˜´ã€‚ å¦‚åŒæ‰€æœ‰çš„äº‹ç‰©å……æ»¡äº†æˆ‘çš„çµé­‚ï¼Œ ä½  ä»æ‰€æœ‰çš„äº‹ç‰©ä¸­æµ®ç°ï¼Œå……æ»¡äº†æˆ‘çš„çµé­‚ã€‚ ä½ åƒæˆ‘çš„çµé­‚ï¼Œä¸€åªæ¢¦çš„è´è¶ã€‚ä½ å¦‚åŒå¿§éƒè¿™ä¸ªè¯ã€‚ æˆ‘å–œæ¬¢ä½ æ˜¯å¯‚é™çš„ï¼Œå¥½åƒä½ å·²è¿œå»ã€‚ ä½ å¬èµ·æ¥åƒåœ¨æ‚²å¹ï¼Œä¸€åªå¦‚é¸½æ‚²é¸£çš„è´è¶ã€‚ ä½ ä»è¿œå¤„è†å¬æˆ‘ï¼Œæˆ‘çš„å£°éŸ³æ— æ³•è§¦åŠä½ ï¼š ä½ è®©æˆ‘åœ¨ä½ çš„æ²‰é»˜ä¸­å®‰é™æ— å£°ã€‚ å¹¶ä¸”è®©æˆ‘å€Ÿä½ çš„æ²‰é»˜ä¸ä½ è¯´è¯ï¼Œ ä½ çš„æ²‰é»˜æ˜äº®å¦‚ç¯ï¼Œç®€å•å¦‚æŒ‡ç¯ï¼Œ ä½ å°±åƒé»‘å¤œï¼Œæ‹¥æœ‰å¯‚å¯ä¸ç¾¤æ˜Ÿã€‚ ä½ çš„æ²‰é»˜å°±æ˜¯æ˜Ÿæ˜Ÿçš„æ²‰é»˜ï¼Œé¥è¿œè€Œæ˜äº®ã€‚ æˆ‘å–œæ¬¢ä½ æ˜¯å¯‚é™çš„ï¼Œä»¿ä½›ä½ æ¶ˆå¤±äº†ä¸€æ ·ï¼Œ é¥è¿œè€Œä¸”å“€ä¼¤ï¼Œä»¿ä½›ä½  å·²ç»æ­»äº†ã€‚ å½¼æ—¶ï¼Œä¸€ä¸ªå­—ï¼Œä¸€ä¸ªå¾®ç¬‘ï¼Œå·²ç»è¶³å¤Ÿã€‚ è€Œæˆ‘ä¼šè§‰å¾—å¹¸ç¦ï¼Œå› é‚£ä¸æ˜¯çœŸçš„è€Œè§‰å¾—å¹¸ç¦ã€‚","link":"/Dec-6-2017.html"},{"title":"Fake News å­¦ä¹ ç¬”è®°ï¼ˆå››ï¼‰Project-Summary NLP-Summary","text":"è½¬è½½å¤§ä½¬çš„åšå®¢ï¼Œå†™çš„å¤ªç‰›é€¼äº†: [ä»Word Embeddingåˆ°Bertæ¨¡å‹â€”è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„é¢„è®­ç»ƒæŠ€æœ¯å‘å±•å²] ## ç‰¢éªš ä¸ºæœŸ6å‘¨çš„é¡¹ç›®ç»ˆäºç»“æŸäº†ï¼Œä»æ˜¨å¤©æ™šä¸Šè¿å¤œè®­ç»ƒè·‘ä»£ç åˆ°ä»Šå¤©çš„ Presentationï¼Œè™½ç„¶è¿˜æœ‰ç‚¹ç´§å¼ ï¼Œä½†æ›´å¤šçš„æ˜¯å¯¹é¡¹ç›®çš„æ— å¥ˆï¼Œä¸€ç»„4 ä¸ªäººï¼Œè¿å¸¦ Q&amp;A å…± 15minï¼Œå¹³å‡ä¸‹æ¥æ¯ä¸ªäººåªæœ‰ 2 åˆ†åŠçš„æ—¶é—´å»å±•ç¤ºè‡ªå·±åšçš„ä¸œè¥¿ã€‚æˆ‘å®è¯è¯´å§ï¼Œå°±å…‰ Bertï¼Œæˆ‘éƒ½å¯ä»¥è®²5minï¼Œä¸€å…± 9 ä¸ªç»„ï¼Œéš¾é“å°±ä¸èƒ½åˆ†æ¥ï¼Ÿï¼Ÿå“ªæ€• 3 ä¸ª 3 ä¸ªæ¥ä¹Ÿè¡Œï¼Œè¯´èµ·æ¥æˆ‘æ˜¯çœŸçš„çƒ¦ï¼Œæ—¢ç„¶å°±æ˜¯æ”¶é’±é‚£æ¨èä¿¡çš„é¡¹ç›®äº†ï¼Œæäº†å‡ ä¸‡å—é’±å°±ä¸èƒ½è®©è¿™ä¸ªé’±èŠ±çš„å€¼ä¸€ç‚¹ï¼Ÿå…¶å®æˆ‘åœ¨å°ç»„åˆ†å·¥æ–¹é¢æ˜¯æœ‰ç‚¹åå¿ƒçš„ï¼Œæˆ‘æ˜¯æƒ³åšæ–‡å­—å¤„ç†çš„éƒ¨åˆ†ï¼Œè€Œä¸”æœ€åé€‰æ‹©äº† Bert ï¼Œå› ä¸ºæˆ‘æƒ³å°è¯•ä¸€äº›ä¸ä¸€æ ·çš„ä¸œè¥¿ï¼Œåˆ†ç±»å™¨ä¹‹å‰å¤§ä¸‰ä¸‹æœ‰ä¸Šè¿‡è¯¾ï¼Œè™½ç„¶å­¦çš„ä¸æ˜¯ç‰¹åˆ«æ‡‚ï¼Œä½†æ€»ç®—æ˜¯æœ‰æ¥è§¦è¿‡ï¼Œå¤§å­¦ä¹Ÿä¸å°±æ˜¯é€šè¯†æ•™è‚²å—ï¼Œæˆ‘ä¹Ÿæ²¡æœ‰å¸Œæœ›æˆ‘èƒ½æœ‰å¤šä¹ˆæ·±å…¥çš„å­¦ä¹ ï¼Œåªå¸Œæœ›æˆ‘å¯ä»¥å¤šå­¦ä¸€ç‚¹ä¸ä¼šçš„ä¸œè¥¿ï¼Œå¯¹äº NLPï¼Œæˆ‘ä¹‹å‰æ˜¯ä¸€ç‚¹éƒ½æ²¡æœ‰æ¥è§¦ï¼Œå½“ç„¶åŸç†æ€§çš„ä¸œè¥¿å°±æ ¹æœ¬ä¸å¯èƒ½çŸ¥é“ï¼Œå¾—çŸ¥äº†é¡¹ç›®æ˜¯åšå…³äºè‡ªç„¶è¯­è¨€å¤„ç†çš„ï¼Œæˆ‘æœ‰è›®æ„Ÿå…´è¶£ï¼Œé€šè¿‡è¯¾ä¸Šçš„å­¦ä¹ ï¼Œæ•™æˆè¯´äº†å¾ˆå¤šæ–°å…´çš„è‡ªç„¶è¯­è¨€å¤„ç†å·¥å…·ï¼Œå…¶ä¸­å°±åŒ…æ‹¬äº† Bertï¼ŒBert æ˜¯ 18 å¹´åº•æå‡ºçš„çŸ¥è¯†ï¼Œæ€»æ„Ÿè§‰æ˜¯æˆ‘åœ¨å¤§å­¦å­¦ä¹ çš„æœ€æ–°çš„çŸ¥è¯†äº†å§ï¼Œç›¸æ¯”äº 11 å¹´çš„ C++è¯¾æœ¬ã€‚ã€‚ã€‚ä¸ç®¡äº†ï¼ŒçŸ¥è¯†æ˜¯å­¦ç»™è‡ªå·±çš„ï¼Œè°ä¹Ÿå·ä¸èµ°ï¼Œæœ€åæˆ‘è¿˜æ˜¯æ€»ç»“ä¸€ä¸‹æˆ‘æ€»çš„å­¦åˆ°çš„çŸ¥è¯†å§ã€‚ä¸‹é¢è‹±æ–‡çš„éƒ¨åˆ†æ˜¯ â€œå®˜æ–¹è¦æ±‚çš„é¡¹ç›®æ€»ç»“â€ï¼Œå°±ä¸å†å¤šè¯´äº†ï¼Œå…³äº Bert çš„å®ç°åœ¨å¦å¤–ä¸€ç¯‡åšå®¢ä¸­æœ‰æ‰€å±•ç¤ºï¼Œè¿™é‡Œå°±ä¸å†ä¸€ä¸€èµ˜è¿°äº†ã€‚ ä¸ªäººç†è§£ ä» Word2Vec åˆ° Bert ä»æœ€å¼€å§‹çš„ Word2Vecï¼Œåˆ° GloVeï¼Œä¸€ç›´åˆ°æœ€æ–°çš„ Bertï¼Œæ— éæ˜¯å°†æ–‡å­—è½¬åŒ–ä¸ºä¸€ä¸ªå¯ä»¥è®©æœºå™¨è¯†åˆ«çš„æ•°æ®æ ¼å¼-çŸ©é˜µã€‚åœ¨æœ€å¼€å§‹çš„æ¨¡å‹ä¸­ï¼Œä¹Ÿå°±æ˜¯ Word å’Œ Gloveï¼Œå­˜åœ¨ä¸€ä¸ªåˆå§‹çš„çŸ©é˜µï¼Œé‡Œé¢åŒ…å«äº†è¯¥æ–¹æ³•æ‰€ç”¨çš„æ–‡å­— token ä»¥åŠå¯¹åº”çš„ valueï¼Œåªéœ€è¦å°†æ–‡å­—è¾“å…¥åˆ°æ¨¡å‹ä¸­ï¼Œå³å¯å¾—åˆ°æ¯ä¸ªæ–‡å­—æ‰€å¯¹åº”çš„å‘é‡å€¼ï¼Œä¹Ÿå°±æ˜¯çŸ©é˜µå€¼(ç›¸ä¹˜)ï¼Œè¿™æ ·å°±æ¶‰åŠåˆ°äº†å¦‚ä½•å¾—åˆ°åˆå§‹çŸ©é˜µçš„é—®é¢˜ï¼ŒWord å’Œ Glove ä½¿ç”¨çš„æ–¹æ³•å½“ç„¶æ˜¯ä¸åŒçš„ï¼Œåœ¨æˆ‘ä»¬é¡¹ç›®å°ç»„ä¸­ï¼Œæˆ‘ä»¬å°è¯•äº†ç”¨ Glove ä»£æ›¿ Wordï¼Œå¹¶å–å¾—äº†è¾ƒå¥½çš„æ•ˆæœï¼Œä½†å®è´¨è¿˜æ˜¯æ²¡æœ‰å˜åŒ–ï¼Œå­˜åœ¨çš„é—®é¢˜ä¹Ÿæ˜¯æ˜¾ç„¶çš„ã€‚æˆ‘ä»¬éƒ½çŸ¥é“æ¯ä¸ªå•è¯åœ¨å¥å­ä¸­çš„æ„æ€æ˜¯ä¾é™„äºä¸Šä¸‹æ–‡çš„ï¼Œå°±æ¯”å¦‚æ‰€æœ‰åšå®¢ä¸­æåˆ°çš„ Bank è¿™ä¸ªå•è¯ï¼Œæœ‰é“¶è¡Œå’Œæ²³å²¸çš„æ„æ€ï¼Œæ‰€ä»¥å°†æ‰€æœ‰çš„æ„æ€ç”¨ä¸€ä¸ªçŸ©é˜µå»è¡¨ç¤ºæ˜¾å¾—æœ‰å¤±åé¢‡ï¼Œæ‰€ä»¥åŸºäºä¸¤è€…æå‡ºäº†æ›´å¤šçš„æ¨¡å‹ã€‚ è¿™å°±è¦æåˆ° Elmoäº†ï¼ˆæˆ‘å­¦çš„ä¸æ˜¯å¾ˆæ·±ï¼Œåªæ˜¯æŠŠå¤§æ¦‚çš„æ€æƒ³äº†è§£äº†ä¸€ä¸‹ï¼‰ï¼šæ ¹æ®ä¸Šä¸‹æ–‡å…³ç³»è¿›è¡Œå‘é‡çš„ç”Ÿæˆï¼Œä½†æ˜¯æœ‰åˆ«äºå‰é¢ä¸¤è€…ï¼Œä»€ä¹ˆæ„æ€ã€‚Word å’Œ Glove åªæ˜¯æŠŠåˆå§‹çŸ©é˜µç»™ä½ ï¼Œä½ å¹¶ä¸å¯ä»¥æ”¹å˜å…¶ä¸­çš„å€¼ï¼Œä½†æ˜¯åœ¨ Elmo ä¸­ï¼Œåº”è¯¥æ˜¯ä½¿ç”¨äº†è¿ç§»å­¦ä¹ çš„æ€æƒ³ï¼Œåœ¨åˆå§‹çŸ©é˜µçš„åŸºç¡€ä¸Šæ ¹æ®è®­ç»ƒé›†è¿›è¡Œç›¸å…³çš„æ›´æ–°ï¼Œä¹Ÿå°±æ˜¯çŸ©é˜µå€¼çš„æ›´æ–°ï¼Œä½†æ˜¯æ€ä¹ˆç”Ÿæˆåˆå§‹çŸ©é˜µæˆ‘å¹¶æ²¡æœ‰æ€ä¹ˆå­¦ä¹ ï¼ŒBert å€’æ˜¯äº†è§£äº†ä¸€ç‚¹ï¼Œåæ­£å¯¹äºæˆ‘æ¥è¯´ï¼ŒElmo çš„æ„ä¹‰å°±æ˜¯çŸ©é˜µçš„åŠ¨æ€æ›´æ–°ï¼Œä½¿å¾—çŸ©é˜µé‡Œé¢çš„å€¼å¯ä»¥æ›´è´´åˆ‡è®­ç»ƒé›†ä¸­ç‰¹å®šçš„æ–‡æœ¬ã€‚è€Œä¸”ä»è®­ç»ƒæ•ˆæœçœ‹ï¼Œå…·æœ‰å¾ˆå¤§çš„æé«˜ï¼Œè¯´åˆ°è¿™é‡Œï¼Œå…¶å®æœ‰ç‚¹é„™è§†æœ€å¼€å§‹çš„ Word å’Œ Glove äº†ï¼Œå› ä¸ºè€ƒè™‘çš„ä¸œè¥¿å¤ªå°‘ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆæˆ‘çœ‹åˆ°åˆ«äººç”¨ Word2Vec å¯ä»¥è¾¾åˆ°0.9å¤šæ­£ç¡®ç‡è€Œç›´å‘¼ç‰›é€¼çš„åŸå› ã€‚ ä» Elmo åˆ° Bertï¼Œåˆæ˜¯ä¸€ä¸ªé£è·ƒï¼Œå½“ç„¶ä¸èƒ½å¦è®¤ï¼ŒBert æ˜¯åŸºäºå‰äººçš„å·¥ä½œè€Œæå‡ºçš„æ–°å‹çš„æ¨¡å‹ï¼Œå› ä¸ºå¾ˆå¤šæ€æƒ³å’Œå‰è€…éƒ½æœ‰å¾ˆå¤šç›¸ä¼¼ä¹‹å¤„ï¼Œå¯ä»¥è¯´æ˜¯ç«™åœ¨å·¨äººçš„è‚©è†€ä¸Šçœ‹ä¸–ç•Œã€‚Bert é‡‡ç”¨äº†æ›´ä¸ºé«˜æ•ˆçš„ç½‘ç»œç»“æ„-Transformeræ¥æ›´æ–°åˆå§‹çŸ©é˜µ, ä»¥åŠå·¨å¤§çš„é¢„è®­ç»ƒæ¨¡å‹ç”¨æ¥ç”Ÿæˆåˆå§‹çŸ©é˜µã€‚åŒæ ·æ˜¯è€ƒè™‘åˆ°äº†æ–‡ç« çš„ä¸Šä¸‹æ–‡å…³ç³»ï¼Œåœ¨ Bert ä¸­å…±æœ‰ 3 ä¸ªä¸åŒçš„å˜é‡ä½œä¸ºæ¨¡å‹çš„è¾“å…¥ï¼Œæ¯ä¸ªå•è¯çš„ Embeddingï¼Œä½ç½®çš„ Embedding å’Œå¥å­çš„ Embeddingï¼ˆå¯ä»¥ç†è§£ä¸ºå’Œåˆå§‹çŸ©é˜µçš„ä¹˜ç§¯ï¼Ÿï¼‰ï¼Œè¿™äº›éƒ½æ˜¯ä¾é™„äºåˆå§‹çŸ©é˜µå¾—åˆ°çš„ç»“æœï¼Œä½†æ˜¯æœ‰æ–‡ç« è¯´ Word çš„ Embedding ä¸ä¾é™„äºåˆå§‹çŸ©é˜µï¼Œé‚£æˆ‘å°±ä¸æ˜¯å¾ˆæ‡‚äº†ï¼Œanywayï¼Œæœ‰ä¸‰ç§ä¸åŒçš„è¾“å…¥è¿›è¡Œç½‘ç»œæ¨¡å‹ã€‚ åœ¨æ¨¡å‹ä¸­åªä½¿ç”¨åˆ°äº† Transformer çš„ Encode éƒ¨åˆ†ï¼Œå…·ä½“çš„å·¥ä½œæµç¨‹æˆ‘å°±ä¸æ‡‚äº†ï¼Œåæ­£ç»è¿‡äº†å¤šå±‚çš„ Encodeï¼Œä¼´éšç€çŸ©é˜µçš„æ›´æ–°ï¼ˆfune-tuningï¼‰ï¼Œæœ€ç»ˆå¯ä»¥å¾—åˆ°å¾ˆå¤šä¸ªå‘é‡çš„ç»“æœï¼Œå†åŠ ä¸Š linear å’Œ softmax å±‚å³å¯è§£å†³åˆ†ç±»é—®é¢˜ã€‚æœ‰äººä¼šé—®äº†ï¼Œé‚£ Bert æ˜¯å¦‚ä½•å¾—åˆ°åˆå§‹çŸ©é˜µçš„ã€‚è¿™å°±æ˜¯ Bert ç‰›é€¼ä¹‹å¤„äº†ï¼Œé€šè¿‡ mask é®ç›–å¥å­ä¸­çš„å•è¯æ¥è®­ç»ƒå•ä¸ªå•è¯ï¼Œé€šè¿‡é®ç›–æ•´ä¸ªå¥å­æ¥è®­ç»ƒæ•´ä¸ªå¥å­ï¼Œå¬è¿‡ Google è®­ç»ƒäº†æ•´ä¸ª Wikipediaï¼ŒçœŸçš„ç‰›é€¼ã€‚æœ€ç»ˆé€šè¿‡çŸ©é˜µçš„æ›´æ–°å¾—åˆ°äº†ç›¸åº”çš„ç»“æœã€‚åˆ©ç”¨ Transformer åŠ ä¸Šå¼ºå¤§çš„ä¸è®­ç»ƒæ¨¡å‹ä½¿å¾— Bert è„±é¢–è€Œå‡ºï¼Œæ‘˜å¾—äº† NLP çš„å¤´ç‰Œï¼Œæœ‰äººè¯´ Bert æ˜¯ NLP çš„é¡¶å³°ï¼Œæˆ‘çœ‹äº†å‡ ç¯‡æ–‡ç« ï¼Œä¸€ä¸ªæ˜¯æ¸…åå¤§å­¦çš„ï¼Œä¸€ä¸ªæ˜¯æ–¯å¦ç¦å¤§å­¦çš„ï¼Œéƒ½æ˜¯åŸºäº Bert çš„ç°æœ‰æ¨¡å‹ï¼Œè¦ä¹ˆæ˜¯ä¿®æ”¹ç½‘ç»œç»“æ„ï¼Œè¦ä¹ˆæ˜¯å¢åŠ æ¨¡å‹çš„è¾“å…¥ä»¥æé«˜æ–‡ç« çš„ Contextual å±æ€§ï¼Œä¹Ÿå¾—åˆ°äº†æ¯”åˆå§‹æ¨¡å‹æ›´å¥½çš„ç»“æœï¼Œå¯ä»¥è¯´æ˜¯ç‚¼ä¸¹æˆåŠŸçš„å…¸èŒƒäº†ã€‚ æ€»ç»“ è¯´åˆ°è¿™é‡Œï¼Œé¡¹ç›®ä¹Ÿå°±ç»“æŸäº†ï¼Œä»æœ€å¼€å§‹çš„æ‰“å¼€ FakeNewsTutorial åˆ°å†™ä¸‹è¿™æœ€åä¸€ç¯‡åšå®¢ï¼Œå®Œæˆäº†é¡¹ç›®æ‰€æœ‰çš„å·¥ä½œï¼Œè¿˜8.23 ä¸‹åˆèµ¶äº† Github çš„ repo ä½œä¸ºå±•ç¤ºï¼Œä¿®æ”¹ä¸­ä»‹å…³äºé¡¹ç›®çš„ç»†èŠ‚ï¼Œä»¥åŠé¡¹ç›®çš„æ€»ç»“ä¹¦ï¼Œæ„Ÿè°¢ç»„å‘˜çš„é…åˆå’Œåˆä½œï¼Œæˆ‘æ„Ÿè§‰æˆ‘ä»¬åœ¨æœ€åçš„ Pre å‘æŒ¥çš„å¾ˆå¥½ï¼Œå¸Œæœ›ç»™æ•™æˆç•™ä¸‹ä¸é”™çš„å°è±¡å§ï¼Œå¸Œæœ›å¤§å®¶éƒ½å¥½å¥½åŠªåŠ›ï¼Œå‰ç¨‹ä¼¼é”¦ã€‚ â€”â€”ç‹ä¾å‡¡ 08/24/2019 åç§‘ä¸œ 11 æ ‹ Project Summary 1. Contribution My job in our group is to use Google Bert to classify the text and complete a pipeline. Use various word processing methods for specific text to improve the final f1 score (0.986) I arrange memberâ€™s work within the group and meeting time. Three rehearsals were completed through communication with members before the final pre. Use my own server to build a python environment for team members Check out the relevant information and code about Glove on the Internet and use it as a demo for other members. 2. Idea Specific text optimization for specific texts, such as fake_or_real_news.csv. Because Bert learns each sentence and the relationship between the sentences, using regular expressions to process non-sentences in the article (such as #hashtag) is necessary. By checking out the relevant information, I learned that EDA (Easiest Data Augmentation) can improve the classification in the case of small text, so I tried two methods of EDA, one is Random Insertion, the other is Synonym Replacement) Use Google Bert as a method of text classification. Google Bert is a cutting-edge approach to do NLP tasks with excellent and efficient classification and I use the Bert model with the softmax layer to complete text classification. 3. Something I want to share The initial idea of our group was to use Google Bert to generate vectors for downstream text classification tasks. However, through code testing, the output includes word vectors and sentence vectors with high dimensions and huge time consumption. Therefore, extracting vectors separately from the Bert model is a bit hard. If the vector can be extracted, the output also includes the word vector and the sentence vector, which is difficult to handle. Thus, we used the method mentioned in the article- adding softmax layer to finish the text. Then, I begin my work to use a completed Bert pipeline to finish the job. At the beginning, I spent a lot of time collecting various information about Bert. Because Bert is based on the existing NLP model, I started with the history of NLP and learned the principles of multiple models, from GloVe to LSTM and ELMo, and finally to Bert. I finally got a glimpse of how Bert works and wrote a blog to my URL: https://nave.work . In fact, I used the original data to feed the model and got a 0.98 f1 score, so how to optimize on this basis becomes a problem. I observed a lot of content that was not a sentence by observing the text, including the URL and #hashtag, so I used regular expressions to remove specific content to improve the f1 score, and finally reached the score of 0.986. In the final training process, due to the tight time and heavy tasks, I rented 1080ti to complete all the tasks. Of course, I am satisfied with the final result. This is based on the powerful per-training model of Google Bert. Anyway, I gained a lot of knowledge through this project and learned a lot of debugging skills, I love NLP!! (Finally attach my Contribution chart: and Github repo: https://github.com/NavePnow/Google-BERT-on-fake_or_real-news-dataset#5-part4-reference","link":"/Fake-News-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89.html"},{"title":"Google-BERT-on-fake_or_real-news-dataset","text":"Description: Use Google BERT on fake_or_real news dataset with best f1 score: 0.986 ## Showcase ### 1. Pipeline First, we got the raw text with title, text and label. Then we use some methods of data processing to operate the text. After the data processing, we put them into the Bert model to train the data, which includes the Bert itself and the Classifier, here I used the feed-forward neural network and add a softmax layer to normalize the output. In the end, we got the predication and other details. 2. Part1: Data processing Drop non-sentence â€¢ Type1: http[s]://www.claritypress.com/LendmanIII.html â€¢ Type2: [email protected] â€¢ Type3: @EP_President #EP_President â€¢ Type4: Want FOX News First * in your inbox every day? Sign up here. â€¢ Type5: â˜®ï¸ ğŸ’š ğŸŒ etc EDA methods â€¢ Insert word by BERT similarity (Random Insertion) â€¢ Substitute word by BERT similarity (Synonym Replacement) AS for the first part, I use two methods: drop non-sentence and some EDA methods. I read some text within the fake_or_real news and I find that it contains various type of non-sentence, so I use the regular expression to drop them. And then, I use random insertion and synonym replacement to augment the text. 3. Part2: Bert Model Bert model As for the second part, we put the text which we got from the first part into the bert model. The Bert model uses 12 encode layers and finally classifier to get the output. 4. Part3: Result Result In the end, we combine different methods of data processing and u can see the f1 score from the chart. We get the best f1 score(0.986) from Cased text + drop sentence. 5. Part4: Reference EDA: â€¢Knowledge: https://towardsdatascience.com/these-are-the-easiest-data-augmentation-techniques-in-natural-language-processing-you-can-think-of-88e393fd610 â€¢Implemenation: https://github.com/makcedward/nlpaug Canâ€™t remove stopwords: â€¢Deeper Text Understanding for IR with Contextual NeuralLanguage Modeling: https://arxiv.org/pdf/1905.09217 â€¢Understanding the Behaviors of BERT in Ranking : https://arxiv.org/pdf/1904.07531 Bert by Pytorch: â€¢https://pytorch.org/hub/huggingface_pytorch-pretrained-bert_bert/ Bert Demo: https://github.com/sugi-chan/custom_bert_pipeline Dataset: https://cbmm.mit.edu/sites/default/files/publications/fake-news-paper-NIPS.pdf I learn the EDA from the two web site and through two articles, I learn that we shouldnâ€™t remove Stopwords which otherwise will destroy the context of sentence. The end is implementation of BERT with Pytorch and the Bert model I learned. Implementation 1. Preparation 1.1 Set parameters and install and load required package 1### parameters Setting2par_cased = 0 # default cased, 0 means uncased3par_cleanup = 1 # default cleanup, 0 means non-cleanup4par_eda = 0 # default eda, 0 means non-eda56pip install pytorch_pretrained_bert nlpaug bert matplotlib sklearn librosa SoundFile nltk pandas78from __future__ import print_function, division9import torch10import torch.nn as nn11import torch.optim as optim12from torch.optim import lr_scheduler13import numpy as np14import torchvision15from torchvision import datasets, models, transforms16import matplotlib.pyplot as plt17import time18import os19import copy20from torch.utils.data import Dataset, DataLoader21from PIL import Image22from random import randrange23import torch.nn.functional as F24from sklearn.metrics import roc_curve, auc25import nlpaug.augmenter.char as nac26#import nlpaug.augmenter.word as naw27import nlpaug.flow as naf28from nlpaug.util import Action 1.2 Set tokenizer 1import torch2from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM34# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows5import logging6logging.basicConfig(level=logging.INFO)78# Load pre-trained model tokenizer (vocabulary)9if par_cased ==1:10 tokenizer = BertTokenizer.from_pretrained('bert-base-cased')11else:12 tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') 1.3 Define Bert Config 1class BertLayerNorm(nn.Module):2 def __init__(self, hidden_size, eps=1e-12):3 \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).4 \"\"\"5 super(BertLayerNorm, self).__init__()6 self.weight = nn.Parameter(torch.ones(hidden_size))7 self.bias = nn.Parameter(torch.zeros(hidden_size))8 self.variance_epsilon = eps910 def forward(self, x):11 u = x.mean(-1, keepdim=True)12 s = (x - u).pow(2).mean(-1, keepdim=True)13 x = (x - u) / torch.sqrt(s + self.variance_epsilon)14 return self.weight * x + self.bias15 1617class BertForSequenceClassification(nn.Module):18 \"\"\"BERT model for classification.19 This module is composed of the BERT model with a linear layer on top of20 the pooled output.21 Params:22 `config`: a BertConfig class instance with the configuration to build a new model.23 `num_labels`: the number of classes for the classifier. Default = 2.24 Inputs:25 `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]26 with the word token indices in the vocabulary. Items in the batch should begin with the special \"CLS\" token. (see the tokens preprocessing logic in the scripts27 `extract_features.py`, `run_classifier.py` and `run_squad.py`)28 `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token29 types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to30 a `sentence B` token (see BERT paper for more details).31 `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices32 selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max33 input sequence length in the current batch. It's the mask that we typically use for attention when34 a batch has varying length sentences.35 `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]36 with indices selected in [0, ..., num_labels].37 Outputs:38 if `labels` is not `None`:39 Outputs the CrossEntropy classification loss of the output with the labels.40 if `labels` is `None`:41 Outputs the classification logits of shape [batch_size, num_labels].42 Example usage:43 ```python44 # Already been converted into WordPiece token ids45 input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])46 input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])47 token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])48 config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,49 num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)50 num_labels = 251 model = BertForSequenceClassification(config, num_labels)52 logits = model(input_ids, token_type_ids, input_mask)5354 def __init__(self, num_labels=2):55 super(BertForSequenceClassification, self).__init__()56 self.num_labels = num_labels57 if par_cased ==1:58 self.bert = BertModel.from_pretrained('bert-base-cased')59 else:60 self.bert = BertModel.from_pretrained('bert-base-uncased')61 self.dropout = nn.Dropout(config.hidden_dropout_prob)62 self.classifier = nn.Linear(config.hidden_size, num_labels)63 nn.init.xavier_normal_(self.classifier.weight)64 def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):65 _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)66 pooled_output = self.dropout(pooled_output)67 logits = self.classifier(pooled_output)6869 return logits70 def freeze_bert_encoder(self):71 for param in self.bert.parameters():72 param.requires_grad = False73 74 def unfreeze_bert_encoder(self):75 for param in self.bert.parameters():76 param.requires_grad = True7778from pytorch_pretrained_bert import BertConfig7980config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,81 num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)8283num_labels = 284model = BertForSequenceClassification(num_labels)8586# Convert inputs to PyTorch tensors87#tokens_tensor = torch.tensor([tokenizer.convert_tokens_to_ids(zz)])8889#logits = model(tokens_tensor) 2. Dataset Processing 2.1 Read the data and convert label into binary text 1import pandas as pd23dat = pd.read_csv('/data/fake_or_real_news.csv')4dat.head()5dat = dat.drop(columns=['Unnamed: 0', 'title_vectors'])6for i in range(len(dat)):7 if dat.loc[i, 'label'] == \"REAL\": #REAL equal 08 dat.loc[i, 'label'] = 09 elif dat.loc[i, 'label'] == \"FAKE\": #FAKE equal 110 dat.loc[i, 'label'] = 111 if dat.loc[i, 'text'] == \"\":12 dat = dat.drop([i])13dat.head() 2.2 Combine the title and text 1dat_plus = dat.copy()2dat_plus['title_text']=dat['title']+'. '+dat['text']3dat_plus = dat_plus.drop(columns=['title', 'text'])45dat_plus['title_text'] 2.3 Use regular expression to drop non-sentence 1import re2def cleanup(text):3 if par_cased == 0: # transfer into lower text if par_cased is false4 text = text.lower()5 text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','',text) # drop http[s]://*6 text = re.sub(u\"\\\\{.*?}|\\\\[.*?]\",'',text) # drop [*]7 text = re.sub(u\"\\(\\@.*?\\s\", '', text) # drop something like (@EP_President)8 text = re.sub(u\"\\@.*?\\s\", '', text) # drop soething liek @EP_President9 text = re.sub(u\"\\#.*?\\s\", '', text) # drop something like #EP_President (maybe hashtag)10 text = re.sub(u\"\\Â© .*?\\s\", '', text) # drop something like Â© EP_President11 text = re.sub(r'pic.tw(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+#]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','',text) # drop pic.twitter.com/*12 text = re.sub(u\"\\*\\*\", '', text) # drop something like **Want FOX News First * in your inbox every day? Sign up here.**13 text = re.sub(u\"ï‚·|â€¢|â˜®ï¸|ğŸ’š|ğŸŒ|ğŸ˜|â™¦|â˜¢\", '', text) # drop something like ï‚· and â€¢ etc14 return(text) 2.4 Use EDA method to augment the text 1import nlpaug.augmenter.char as nac2import nlpaug.augmenter.word as naw3import nlpaug.flow as nafc45from nlpaug.util import Action6import nltk7nltk.download('punkt')89if par_cased ==1:10 aug = naf.Sequential([11 naw.BertAug(action=\"substitute\", aug_p=0.8, aug_n=20,model_path='bert-base-cased',tokenizer_path='bert-base-cased'),12 naw.BertAug(action=\"insert\", aug_p=0.1)13 ])14else:15 aug = naf.Sequential([16 naw.BertAug(action=\"substitute\", aug_p=0.8, aug_n=20,model_path='bert-base-uncased',tokenizer_path='bert-base-uncased'),17 naw.BertAug(action=\"insert\", aug_p=0.1)18 ])19def aug_text(text):20 text = aug.augment(text)21 return(text)22from nltk.tokenize import sent_tokenize23def sentence_token_nltk(text):24 sent_tokenize_list = sent_tokenize(text)25 return sent_tokenize_list26def eda_text(text):27 if len(text) &lt; 2:28 return(text)29 # split text into sentences30 text = sentence_token_nltk(text)31 if len(text) &lt;= 1:32 return(text)33 if len(text) == 2:34 for i in range(len(text)):35 if i == 0:36 tmp_text = text[i]37 else:38 tmp_text += text[i]39 return(tmp_text)40 # operate prior 3 sentences41 for i in range(3):42 if i == 0:43 tmp_text = text[i]44 else:45 tmp_text += text[i]46 zz = tokenizer.tokenize(tmp_text)47 # operate proper sentences48 if len(zz) &lt;= 500:49 #print(len(zz))50 tmp_text = aug_text(tmp_text)51 # conbine prior 3 sentences and rest sentences52 for j in range(len(text)-3):53 tmp_text += text[j+3]54 return(tmp_text)5556if par_eda == 1: # use eda to operate sentences when par_eda is true57 for i in range(len(dat_plus['title_text'])):58 if i%6 == 1: 59 #print(i)60 dat_plus['title_text'][i] = copy.deepcopy(eda_text(dat_plus['title_text'][i]))61 dat_plus['title_text'][i] = \"\".join(dat_plus['title_text'][i]) 3. Google Bert 1import torch.nn.functional as F23#F.softmax(logits,dim=1)45from sklearn.model_selection import train_test_split6if par_cleanup == 1:7 X = dat_plus['title_text'].apply(cleanup)8else:9 X = dat_plus['title_text']10y = dat_plus['label']11X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)1213X_train = X_train.values.tolist()14X_test = X_test.values.tolist()1516y_train = pd.get_dummies(y_train).values.tolist() # convert to one-hot encoding17y_test = pd.get_dummies(y_test).values.tolist()1819max_seq_length = 25620class text_dataset(Dataset):21 def __init__(self,x_y_list, transform=None):22 23 self.x_y_list = x_y_list24 self.transform = transform25 26 def __getitem__(self,index):27 28 tokenized_title_text = tokenizer.tokenize(self.x_y_list[0][index])29 30 if len(tokenized_title_text) &gt; max_seq_length:31 tokenized_title_text = tokenized_title_text[:max_seq_length]32 33 ids_title_text = tokenizer.convert_tokens_to_ids(tokenized_title_text) #tokens-&gt;input_ids3435 padding = [0] * (max_seq_length - len(ids_title_text))36 37 ids_title_text += padding # use padding to make the same ids38 39 assert len(ids_title_text) == max_seq_length40 41 #print(ids_title_text)42 ids_title_text = torch.tensor(ids_title_text)43 44 label = self.x_y_list[1][index] # color 45 list_of_labels = [torch.from_numpy(np.array(label))]46 47 48 return ids_title_text, list_of_labels[0]49 50 def __len__(self):51 return len(self.x_y_list[0]) 3.1 Create data dictionary 1batch_size = 16 # divide into 16 batches23train_lists = [X_train, y_train]4test_lists = [X_test, y_test]56training_dataset = text_dataset(x_y_list = train_lists )78test_dataset = text_dataset(x_y_list = test_lists )910dataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True, num_workers=0),11 'val':torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)12 } 13dataset_sizes = {'train':len(train_lists[0]),14 'val':len(test_lists[0])}1516device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")17print(device) 3.2 Define the train model 1def train_model(model, criterion, optimizer, scheduler, num_epochs=25):2 since = time.time()3 print('starting')4 best_model_wts = copy.deepcopy(model.state_dict())5 best_loss = 1006 best_f1 = 0.9787 best_acc_test = 0.968 best_acc_train = 0.969 best_auc = 0.9610 for epoch in range(num_epochs):11 print('Epoch {}/{}'.format(epoch, num_epochs - 1))12 print('-' * 10)1314 # Each epoch has a training and validation phase15 for phase in ['train', 'val']:16 if phase == 'train':17 scheduler.step()18 model.train() # Set model to training mode19 else:20 model.eval() # Set model to evaluate mode2122 running_loss = 0.023 24 label_corrects = 025 TP = 026 TN = 027 FN = 028 FP = 029 total_scores = []30 total_tar = []31 # Iterate over data.32 for inputs, label in dataloaders_dict[phase]:33 #inputs = inputs34 #print(len(inputs),type(inputs),inputs)35 #inputs = torch.from_numpy(np.array(inputs)).to(device) 36 inputs = inputs.to(device) 37 label = label.to(device)3839 # zero the parameter gradients40 optimizer.zero_grad()4142 # forward43 # track history if only in train44 with torch.set_grad_enabled(phase == 'train'):45 # acquire output46 outputs = model(inputs)4748 outputs = F.softmax(outputs,dim=1)49 50 loss = criterion(outputs, torch.max(label.float(), 1)[1])51 # backward + optimize only if in training phase52 if phase == 'train':53 54 loss.backward()55 optimizer.step()5657 # statistics58 running_loss += loss.item() * inputs.size(0)59 label_corrects += torch.sum(torch.max(outputs, 1)[1] == torch.max(label, 1)[1]) #è¿”å›æ¯ä¸€è¡Œä¸­æœ€å¤§å€¼çš„é‚£ä¸ªå…ƒç´ ï¼Œä¸”è¿”å›å…¶ç´¢å¼•ï¼ˆè¿”å›æœ€å¤§å…ƒç´ åœ¨è¿™ä¸€è¡Œçš„åˆ—ç´¢å¼•ï¼‰60 pred_choice = torch.max(outputs, 1)[1]61 target = torch.max(label, 1)[1]62 scores = pred_choice.cpu().tolist()63 tar = target.cpu().tolist()64 total_scores = total_scores + scores65 total_tar = total_tar + tar6667 tmp_tp = 068 tmp_tn = 069 tmp_fn = 070 tmp_fp = 071 if pred_choice.numel()!= target.numel():72 print(\"error\")73 for i in range(pred_choice.numel()):74 if pred_choice[i] == 1 and target[i] == 1 :75 tmp_tp = tmp_tp + 176 elif pred_choice[i] == 0 and target[i] == 0 :77 tmp_tn = tmp_tn + 178 elif pred_choice[i] == 0 and target[i] == 1 :79 tmp_fn = tmp_fn + 180 elif pred_choice[i] == 1 and target[i] == 0 :81 tmp_fp = tmp_fp + 182 # TP both predict and label are 183 TP += tmp_tp84 # TN both predict and label are 085 TN += tmp_tn86 # FN predict 0 label 187 FN += tmp_fn88 # FP predict 1 label 089 FP += tmp_fp90 epoch_loss = running_loss / dataset_sizes[phase]91 p = TP / (TP + FP)92 r = TP / (TP + FN)93 F1 = 2 * r * p / (r + p)94 acc = (TP + TN) / (TP + TN + FP + FN)9596 ### draw ROC curce97 tpr = TP/(TP+FN)98 fpr = FP/(FP+TN)99 tnr = TN/(FP+TN)100101 total_scores = np.array(total_scores)102 total_tar = np.array(total_tar)103 fpr, tpr, thresholds = roc_curve(total_tar, total_scores)104 roc_auc = auc(fpr, tpr) 105 plt.title('ROC')106 if roc_auc &gt; best_auc:107 best_auc = roc_auc108 if epoch &lt; num_epochs -1:109 plt.plot(fpr, tpr,'b',label='AUC = %0.4f'% roc_auc)110 if epoch == num_epochs -1:111 plt.plot(fpr, tpr, color='darkorange', label='MAX AUC = %0.4f'% best_auc) 112 plt.legend(loc='lower right')113 plt.plot([0,1],[0,1],'r--')114 plt.ylabel('TPR')115 plt.xlabel('FPR')116 plt.show()117118 #print('{} p: {:.4f} '.format(phase,p ))119 #print('{} r: {:.4f} '.format(phase,r ))120 print('{} F1: {:.4f} '.format(phase,F1 ))121 print('{} accuracy: {:.4f} '.format(phase,acc ))122123 if phase == 'val' and epoch_loss &lt; best_loss:124 print('saving with loss of {}'.format(epoch_loss),125 'improved over previous {}'.format(best_loss))126 best_loss = epoch_loss127 best_model_wts = copy.deepcopy(model.state_dict())128 #torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/bert_model_test_loss.pth')129 if F1 &gt; best_f1:130 best_f1 = F1131 if phase == 'val' and acc &gt; best_acc_test:132 best_acc_test = acc133 if phase == 'train' and acc &gt; best_acc_train:134 best_acc_train = acc135 #best_model_wts = copy.deepcopy(model.state_dict())136 #torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/bert_model_test_f1.pth')137 print()138139 time_elapsed = time.time() - since140 print('Training complete in {:.0f}m {:.0f}s'.format(141 time_elapsed // 60, time_elapsed % 60))142 print(\"Parament setting: \")143 print(\"cased: \",par_cased)144 print(\"cleanup: \",par_cleanup)145 print(\"eda: \",par_eda)146 print('Best train Acc: {:4f}'.format(float(best_acc_train)))147 print('Best test Acc: {:4f}'.format(float(best_acc_test)))148 print('Best f1 score: {:4f}'.format(float(best_f1)))149 # load best model weights150 model.load_state_dict(best_model_wts)151 return model 4. Final output 4.1 Model details 1print(model)2model.to(device) 4.2 F1 and other details 1model_ft1 = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=10)","link":"/Google-BERT-on-fake-or-real-news-dataset.html"},{"title":"Fake News å­¦ä¹ ç¬”è®°ï¼ˆä¸€ï¼‰åˆ†ç±»å™¨ï¼Œf1 score","text":"NFL data ç¾å›½èŒä¸šæ©„æ¦„çƒå¤§è”ç›Ÿï¼ˆNational Football Leagueï¼Œç®€ç§°NFLï¼‰ ä½ å¦¹çš„ï¼Œè¿™æ•™æˆæˆ‘ä½›äº†ã€‚ é€»è¾‘å›å½’ åœ¨ç¬¬ä¸€èŠ‚è¯¾ä¸­ï¼Œx è½´ä»£è¡¨è¯¥é˜Ÿè§¦åœ°å¾—åˆ†çš„æ¬¡æ•°ï¼Œy è½´ä»£è¡¨è¯¥é˜Ÿæ˜¯å¦èƒœåˆ©ï¼Œè¾“ä¸º 0ï¼Œèµ¢ä¸º 1ï¼Œä¸ä½¿ç”¨çº¿æ€§å›å½’çš„åŸå› æ˜¯è¯¥ç»“æœçš„è¾“å‡ºä¸ºäºŒåˆ†ç±»é—®é¢˜ï¼Œä¸éœ€è¦æ•°æ®çš„è¿ç»­æ€§ï¼Œåªéœ€è¦è¾“å‡º 0 å’Œ 1 å³å¯ï¼ŒåŒæ—¶è¯¥é—®é¢˜ä¸æ˜¯ç®€å•åœ°çº¿æ€§é—®é¢˜ï¼Œå³å¾ˆéš¾ç”¨ä¸€æ¡ç›´çº¿ç›´æ¥æ¨¡æ‹Ÿè¯¥é˜Ÿè§¦åœ°å¾—åˆ†æ¬¡æ•°ä¸è¾“èµ¢çš„å…³ç³»ï¼ŒåŒæ—¶å—ç¦»ç¾¤å€¼çš„å½±å“ï¼ˆå½“ x å€¼ç‰¹åˆ«å¤§ï¼Œè¶…è¿‡äº†æ­£å¸¸çš„èŒƒå›´ï¼Œå°±ä¼šå½±å“æ­£å¸¸å€¼çš„åˆ†ç±»ï¼‰ï¼Œä½¿ç”¨çº¿æ€§å›å½’æœ‰å¾ˆå¤§çš„å‡ ç‡åˆ†ç±»é”™è¯¯ï¼Œæ‰€ä»¥æ‰€ä»¥ä½¿ç”¨é€»è¾‘å›å½’æ–¹æ³•è¿›è¡Œåˆ†ç±»ã€‚ é€»è¾‘å›å½’ä½¿ç”¨ Sigmoid å‡½æ•°ï¼Œå°†å‡½æ•°çš„è¾“å…¥èŒƒå›´æ˜¯è´Ÿæ— ç©·åˆ°æ­£æ— ç©·çš„å®šä¹‰åŸŸè§„å®šä¸º 0-1 ä¹‹å†…çš„èŒƒå›´ï¼Œè¿™æ ·å°±è§£å†³äº†ç”±äºç¦»ç¾¤å€¼å¯¹äºé˜ˆå€¼çš„å½±å“ä½œç”¨ã€‚ å‚æ•°å®šä¹‰ï¼ˆç”¨äº F1 score è®¡ç®—ï¼‰ True Positives (TP): Correct positive predictions é¢„æµ‹ yesï¼ŒçœŸå® yes False Positives (FP): Incorrect positive predictions (false alarm) é¢„æµ‹ yesï¼ŒçœŸå® no True Negatives (TN): Correct negative predictions é¢„æµ‹ noï¼ŒçœŸå® no False Negatives (FN): Incorrect negative predictions (a miss) é¢„æµ‹ noï¼ŒçœŸå® yes F1 score ç”¨æ¥è¡¡é‡äºŒåˆ†ç±»æ¨¡å‹ç²¾ç¡®çš„ä¸€ç§æŒ‡æ ‡ ç²¾ç¡®ç‡ï¼šTP/æ‰€æœ‰é¢„æµ‹çš„ yesï¼ˆæ‰€æœ‰é¢„æµ‹ yes ä¸­çœŸå®ä¸º yes çš„æ¯”ç‡ï¼‰ å¬å›ç‡ï¼šTP/æ‰€æœ‰çœŸå®çš„ yesï¼ˆæ‰€æœ‰çœŸå® yes ä¸­é¢„æµ‹ä¸º yes çš„æ¯”ç‡ï¼‰ F1 scoreï¼š2/(1/P+1/C)=2TP(2TP+FN+FP) å†³ç­–æ ‘ åˆ©ç”¨ if-then åŸåˆ™ï¼ŒæŒ‰ç…§æ ‘çŠ¶ç»“æ„çš„ç‰¹ç‚¹ï¼Œå¶èŠ‚ç‚¹è¡¨ç¤ºå…¶åˆ†ç±»æ ‡è®°ï¼Œéå¶èŠ‚ç‚¹è¡¨ç¤ºå…¶å„ä¸ª featureï¼Œåˆ©ç”¨ feature è¿›è¡ŒåŒ¹é…ï¼Œç›´è‡³æ‰¾åˆ°æœ€ç¬¦åˆæ•°æ®çš„åˆ†ç±»ã€‚ éšæœºæ£®æ—ï¼ˆRandom Forestsï¼‰ åŒ…å«å¤šä¸ªå†³ç­–æ ‘çš„åˆ†ç±»å™¨ï¼Œ å¹¶ä¸”å…¶è¾“å‡ºçš„ç±»åˆ«æ˜¯ç”±ä¸ªåˆ«æ ‘è¾“å‡ºçš„ç±»åˆ«çš„ä¼—æ•°è€Œå®šã€‚ï¼Œéšæœºæ£®æ—å¯¹å›å½’çš„ç»“æœåœ¨å†…éƒ¨æ˜¯å–å¾—å¹³å‡ åœ¨å¾—åˆ°æ£®æ—ä¹‹åï¼Œå½“æœ‰ä¸€ä¸ªæ–°çš„è¾“å…¥æ ·æœ¬è¿›å…¥çš„æ—¶å€™ï¼Œå°±è®©æ£®æ—ä¸­çš„æ¯ä¸€æ£µå†³ç­–æ ‘åˆ†åˆ«è¿›è¡Œä¸€ä¸‹åˆ¤æ–­ï¼Œçœ‹çœ‹è¿™ä¸ªæ ·æœ¬åº”è¯¥å±äºå“ªä¸€ç±»ï¼ˆå¯¹äºåˆ†ç±»ç®—æ³•ï¼‰ï¼Œç„¶åçœ‹çœ‹å“ªä¸€ç±»è¢«é€‰æ‹©æœ€å¤šï¼Œå°±é¢„æµ‹è¿™ä¸ªæ ·æœ¬ä¸ºé‚£ä¸€ç±»ã€‚ XGBoost XGBoostæ˜¯boostingç®—æ³•çš„å…¶ä¸­ä¸€ç§ã€‚Boostingç®—æ³•çš„æ€æƒ³æ˜¯å°†è®¸å¤šå¼±åˆ†ç±»å™¨é›†æˆåœ¨ä¸€èµ·å½¢æˆä¸€ä¸ªå¼ºåˆ†ç±»å™¨ã€‚å› ä¸ºXGBoostæ˜¯ä¸€ç§æå‡æ ‘æ¨¡å‹ï¼Œæ‰€ä»¥å®ƒæ˜¯å°†è®¸å¤šæ ‘æ¨¡å‹é›†æˆåœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ªå¾ˆå¼ºçš„åˆ†ç±»å™¨ã€‚è€Œæ‰€ç”¨åˆ°çš„æ ‘æ¨¡å‹åˆ™æ˜¯CARTå›å½’æ ‘æ¨¡å‹ã€‚","link":"/Fake%20News%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E5%88%86%E7%B1%BB%E5%99%A8%EF%BC%8Cf1%20score.html"},{"title":"Hexoä¸»é¢˜æŠ˜è…¾æ—¥è®°(äºŒ) æ·»åŠ è±†ç“£å’ŒèŠå¤©æ’ä»¶","text":"å‰è¨€ ä»Šä¸Šåˆç¿»çœ‹åˆ«äººçš„åšå®¢ï¼Œçœ‹åˆ°äº†Nextä¸»é¢˜ç›¸å…³ä¼˜åŒ–çš„å¸–å­ï¼Œæœ‰å…³äºè±†ç“£ä¸»é¡µå’Œåšå®¢èŠå¤©æ’ä»¶çš„å†…å®¹ï¼Œäºæ˜¯å°±æƒ³åœ¨ icarus ä¸»é¢˜å†…ä¹Ÿå®ç°è¿™ä¸ªåŠŸèƒ½ï¼ŒæŠ˜è…¾äº†ä¸€ä¸‹åˆï¼Œç»ˆäºæå¥½äº†ã€‚ è±†ç“£ä¸»é¡µæ’ä»¶ å®ç°æ•ˆæœ é…ç½® å®‰è£…æ¨¡å—ä¾èµ– $ npm install hexo-douban --save åœ¨ç«™ç‚¹é…ç½®æ–‡ä»¶ä¸­æ·»åŠ é…ç½® åœ¨ _config.xml æ–‡ä»¶ä¸­æ·»åŠ  1douban:2 user: mythsman3 builtin: false4 book:5 title: 'This is my book title'6 quote: 'This is my book quote'7 movie:8 title: 'This is my movie title'9 quote: 'This is my movie quote'10 game:11 title: 'This is my game title'12 quote: 'This is my game quote'13 timeout: 10000 è¯´æ˜: - user: ä½ çš„è±†ç“£ID.æ‰“å¼€è±†ç“£ï¼Œç™»å…¥è´¦æˆ·ï¼Œç„¶ååœ¨å³ä¸Šè§’ç‚¹å‡» &quot;ä¸ªäººä¸»é¡µ&quot; ï¼Œè¿™æ—¶å€™åœ°å€æ çš„URLå¤§æ¦‚æ˜¯è¿™æ ·ï¼š&quot;https://www.douban.com/people/xxxxxx/&quot; ï¼Œå…¶ä¸­çš„&quot;xxxxxx&quot;å°±æ˜¯ä½ çš„ä¸ªäººIDäº†ã€‚ - builtin: æ˜¯å¦å°†ç”Ÿæˆé¡µé¢çš„åŠŸèƒ½åµŒå…¥hexo så’Œhexo gä¸­ï¼Œé»˜è®¤æ˜¯false,å¦ä¸€å¯é€‰é¡¹ä¸ºtrue, å¦‚æœè±†ç“£æ›´æ–°é¢‘ç‡ä¸é«˜å»ºè®®é€‰æ‹©falseï¼Œæ²¡æœ‰å¿…è¦å†æ¯ä¸€æ¬¡éƒ¨ç½²çš„æ—¶å€™é‡æ–°ç”Ÿæˆè±†ç“£çš„é¡µé¢ - title: è¯¥é¡µé¢çš„æ ‡é¢˜. - quote: å†™åœ¨é¡µé¢å¼€å¤´çš„ä¸€æ®µè¯,æ”¯æŒhtmlè¯­æ³•. - timeout: çˆ¬å–æ•°æ®çš„è¶…æ—¶æ—¶é—´ï¼Œé»˜è®¤æ˜¯ 10000ms ,å¦‚æœåœ¨ä½¿ç”¨æ—¶å‘ç°æŠ¥äº†è¶…æ—¶çš„é”™(ETIMEOUT)å¯ä»¥æŠŠè¿™ä¸ªæ•°æ®è®¾ç½®çš„å¤§ä¸€ç‚¹ã€‚ å¦‚æœåªæƒ³æ˜¾ç¤ºæŸä¸€ä¸ªé¡µé¢(æ¯”å¦‚movie)ï¼Œé‚£å°±æŠŠå…¶ä»–çš„é…ç½®é¡¹æ³¨é‡Šæ‰å³å¯ã€‚ 3. ä¿®æ”¹/layout/common/article.ejs 1&lt;%- list_categories(post.categories, {2 class: 'has-link-grey ',3 show_count: false,4 style: 'none',5 separator: '&amp;nbsp;/&amp;nbsp;'6 }) %&gt;7 &lt;/div&gt;8 &lt;% } %&gt;9+ &lt;% if (post._content &amp;&amp; word_count(post._content)) { %&gt;10 &lt;% if (!has_config('article.readtime') || get_config('article.readtime') === true) { %&gt;11 &lt;span class=\"level-item has-text-grey\"&gt;12 &lt;% const words = word_count(post._content); %&gt;13 &lt;% const time = duration((words / 150.0) * 60, 'seconds') %&gt;14 &lt;%= `${ time.locale(get_config('language', 'en')).humanize() } ${ __('article.read')} (${ __('article.about') } ${ words } ${ __('article.words') })` %&gt;15 &lt;/span&gt;16 &lt;% } %&gt;17+ &lt;% } %&gt;18 &lt;% if (!index &amp;&amp; (has_config('plugins.busuanzi') ? get_config('plugins.busuanzi') : false)) { %&gt;19 &lt;span class=\"level-item has-text-grey\" id=\"busuanzi_container_page_pv\"&gt;20 &lt;i class=\"far fa-eye\"&gt;&lt;/i&gt;21 &lt;%- _p('plugin.visit', '&lt;span id=\"busuanzi_value_page_pv\"&gt;0&lt;/span&gt;') %&gt; 4. æµ‹è¯•å¹¶å‘å¸ƒ hexo douban -bgm &amp;&amp; hexo server å¦‚æœç»ˆç«¯æ²¡æœ‰æŠ¥é”™ä¸”ç½‘é¡µ http://localhost:4000/books http://localhost:4000/movies http://localhost:4000/movies æ²¡æœ‰é—®é¢˜ï¼Œå°±å¯ä»¥ç›´æ¥å‘å¸ƒäº†ï¼Œè¿™é‡Œæ³¨æ„ bgm = books+ games+ movies, å¦‚æœå‰é¢çš„é…ç½®ä¸­åªé€‰æ‹©äº† booksï¼Œé‚£è¿™é‡Œåªéœ€è¦ hexo douban -bå³å¯ï¼Œå…¶ä»–åŒç†ã€‚ ä¸»é¢˜æ–‡ä»¶ä¿®æ”¹ åœ¨å¯¹åº”ä¸»é¢˜çš„ _config.xml æ–‡ä»¶ menu æ¨¡å—æ·»åŠ å¯¹åº”çš„é…ç½®ï¼Œç¤ºä¾‹å¦‚ä¸‹ã€‚ 1menu:2 Home: /3 About: /about4 Articles: /archives5 Gallery: /gallery6 Books: /books æœ€åæµ‹è¯•å‘å¸ƒ åšå®¢èŠå¤©æ’ä»¶ å®ç°æ•ˆæœ é…ç½® é¦–å…ˆéœ€è¦æ³¨å†Œ Tidio è´¦å·ï¼Œæ ¹æ®å¼•å¯¼å¡«å†™åº”ç”¨ä¿¡æ¯ã€‚ åœ¨ä¸ªäººä¸»é¡µä¸­é€‰æ‹© Channels -&gt; Live Chat -&gt; Integration ,å¤åˆ¶ JS ä»£ç  ä¿®æ”¹ /layout/layout.ejs, åœ¨æ–‡ä»¶æœ€åæ’å…¥å¯¹åº”çš„ä»£ç . 1 &lt;% } %&gt;2+ &lt;script src=\"//code.tidio.co/token.js\" async&gt;&lt;/script&gt;3&lt;/body&gt;4&lt;/html&gt; å…¶ä¸­å°†tokenæ›¿æ¢æˆä½ å¯¹åº”çš„tokenå³å¯ï¼Œæ¥ä¸‹æ¥å¯ä»¥åœ¨ Tidio æ§åˆ¶å°çš„ Channel -&gt; Live chat -&gt; Appearance ä¸­æ ¹æ®æç¤ºå®šåˆ¶èŠå¤©å¯¹è¯æ¡†çš„ä¸»é¢˜å¤–è§‚å’Œè¯­è¨€åŒ…ï¼Œä»¥é€‚åº”è‡ªå·±çš„éœ€æ±‚ã€‚","link":"/Hexo%E4%B8%BB%E9%A2%98%E6%8A%98%E8%85%BE%E6%97%A5%E8%AE%B0-%E4%BA%8C-%E6%B7%BB%E5%8A%A0%E8%B1%86%E7%93%A3%E5%92%8C%E8%81%8A%E5%A4%A9%E6%8F%92%E4%BB%B6.html"},{"title":"Fake News å­¦ä¹ ç¬”è®°ï¼ˆäºŒï¼‰ one-hot-coding Stem-and-Lem Word2Vec","text":"One-hot coding(ç‹¬çƒ­ç¼–ç ) æœç„¶åˆæ˜¯ 1ä¸ªåŠå°æ—¶åªè®°ä½ä¸“æœ‰åå­—çš„è¯¾ç¨‹ã€‚ target:å°†éæ•°å€¼ç±»å‹é‡åŒ–æ•°å€¼ç±»å‹ï¼Œä»¥ä¾¿äºæ¨¡å‹çš„è¾“å…¥ process:Nä½çŠ¶æ€å¯„å­˜å™¨æ¥å¯¹Nä¸ªçŠ¶æ€è¿›è¡Œç¼–ç å°±æ˜¯å°†æ‰€æœ‰çŠ¶æ€æ’åˆ—ï¼Œå…·æœ‰å“ªäº›çŠ¶æ€å°±å°†çŠ¶æ€è¿›è¡Œæ ‡è®° instance: face = ['handsome','ugly'] stature = ['tall','middle','short'] country = ['Chinese','American,'Japan','korea'] å…±æœ‰ 9 ç§çŠ¶æ€ï¼Œç”¨ 9 ä½æ•°å­—è¡¨ç¤ºã€‚ ['handsome','tall','Japan'] è¡¨ç¤ºä¸º 101000010 ['ugly','short','Japan'] è¡¨ç¤ºä¸º 010010010 Bag of words ä¸è€ƒè™‘å•è¯åœ¨æ–‡ç« ä¸­çš„é¡ºåºï¼Œåªè€ƒè™‘å•è¯åœ¨æ–‡ç« ä¸­çš„è¯é¢‘ç‡(occurence) Stemming and Lemmatizing cliche:normalize different forms of the same word to a single root token before indexing stemming can often create non-existent words, whereas lemmas are actual words. Stemming æ‰¾è¯æ ¹(chops off the endings of different forms of words) &quot;derivational affixes&quot; questions:some decorations like ir or un, some of them will be deleted? eg:unchange to change (not implentation) ## Lemmatizing æ ¹æ®è¯å…¸æ‰¾å•è¯æœ¬èº«çš„å½¢å¼ eg: saw to see Word2Vec cliche:Word2Vecä½¿ç”¨ä¸€å±‚ç¥ç»ç½‘ç»œå°†one-hotï¼ˆç‹¬çƒ­ç¼–ç ï¼‰å½¢å¼çš„è¯å‘é‡æ˜ å°„åˆ°åˆ†å¸ƒå¼å½¢å¼çš„è¯å‘é‡ã€‚ä½¿ç”¨äº†Hierarchical softmaxï¼Œ negative samplingç­‰æŠ€å·§è¿›è¡Œè®­ç»ƒé€Ÿåº¦ä¸Šçš„ä¼˜åŒ–. åœ¨å‰æ–‡ä¸­ä»‹ç»äº† one-hot codingï¼Œä½†æ˜¯ç”±äºè‹±æ–‡å•è¯è¯æ±‡é‡å·¨å¤§çš„ç‰¹å¾ï¼Œæ¯ä¸€ä¸ªå•è¯éƒ½å¯¹åº”ä¸Šæ–‡ä¾‹å­ä¸­çš„ featureï¼Œå¯æƒ³è€ŒçŸ¥ï¼Œä¼šé€ æˆç»´åº¦ç¾éš¾å’Œæ•°æ®ç¨€ç–çš„é—®é¢˜ï¼ˆå¦ˆçš„ï¼Œä¸Šè¯¾è¿™ä¸ªä¸œè¥¿è®²äº†è¿‘ 40minï¼‰ï¼Œæ‰€ä»¥ä½¿ç”¨Word2Vecèƒ½å¤Ÿè§£å†³è¿™äº›é—®é¢˜ã€‚ TD-IDF è¯„ä¼°ä¸€å­—è¯å¯¹äºä¸€ä¸ªæ–‡ä»¶é›†æˆ–ä¸€ä¸ªè¯­æ–™åº“ä¸­çš„å…¶ä¸­ä¸€ä»½æ–‡ä»¶çš„é‡è¦ç¨‹åº¦ï¼ŒTFæ„æ€æ˜¯è¯é¢‘(Term Frequency)ï¼ŒIDFæ„æ€æ˜¯é€†æ–‡æœ¬é¢‘ç‡æŒ‡æ•°(Inverse Document Frequency)ã€‚ ## softmax æŠŠä¸€äº›è¾“å…¥æ˜ å°„ä¸º0-1ä¹‹é—´çš„å®æ•°ï¼Œå¹¶ä¸”å½’ä¸€åŒ–ä¿è¯å’Œä¸º1 ## CBOW(Continous Bag of Words) å·²çŸ¥è¯wä¸Šä¸‹æ–‡context(w)å‰æä¸‹ï¼Œé¢„æµ‹å½“å‰è¯w ## skip-gram å·²çŸ¥å½“å‰è¯wï¼Œé¢„æµ‹å…¶ä¸Šä¸‹æ–‡context(w) ## distributed representation é€šè¿‡è®­ç»ƒå¾—åˆ°æ¯ä¸ªè¯k ç»´å®æ•°å‘é‡ï¼Œé€šè¿‡è¯é—´è·ç¦»æ¥è®¡ç®—è¯é—´ç›¸ä¼¼åº¦ã€‚ é€šè¿‡è®­ç»ƒï¼Œå°†æ¯ä¸€ä¸ªè¯æ˜ å°„åˆ°ä¸€ä¸ªå›ºå®šé•¿åº¦çš„çŸ­å‘é‡ä¸­ï¼ŒæŠŠè¯çš„ä¿¡æ¯åˆ†å¸ƒåˆ°å„ä¸ªåˆ†é‡ä¸­ï¼Œå¹¶ä¸”è¯­ä¹‰ç›¸è¿‘çš„è¯å‘é‡è§è·ç¦»è¶Šè¿‘ ## å‚æ•°è®¾ç½® size: Number of dimensions for the word embedding model window: Number of context words to observe in each direction min_count: Minimum frequency for words included in model sg (Skip-Gram): '0' indicates CBOW model; '1' indicates Skip-Gram alpha: Learning rate (initial); prevents model from over-correcting, enables finer tuning iterations: Number of passes through dataset batch_words: Number of words to sample from data during each pass","link":"/Fake%20News%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%20one-hot-coding%20Stem-and-Lem%20Word2Vec.html"},{"title":"Hexoä¸»é¢˜æŠ˜è…¾æ—¥è®°(ä¸€) ä»cactusåˆ°icarus","text":"å‰è¨€ ä»Hexoå»ºç«™å¼€å§‹ï¼Œä¸€ç›´æ˜¯ä½¿ç”¨çš„cactusä¸»é¢˜ï¼Œå¾ˆå–œæ¬¢é‚£ç§ç®€çº¦çš„é£æ ¼ï¼Œä¸»é¡µæ–‡ç« é¢„è§ˆçš„éƒ½æ²¡æœ‰çš„é‚£ä¸€ç§ã€‚ ç›´åˆ°æ˜¨å¤©å¿ƒè¡€æ¥æ½®æƒ³æä¸€ä¸ªåŸºäºghostçš„åŠ¨æ€åšå®¢ï¼ŒåŒæ—¶çˆ±ä¸Šäº†ä»–çš„é»˜è®¤ä¸»é¢˜casperï¼Œå¿ƒæƒ³è¿™ä¸å°±æ˜¯æˆ‘æ¢¦å¯å·²ä¹…çš„ä¸»é¢˜ä¹ˆï¼Œç»“æœæœäº†å¾ˆå¤šçš„èµ„æ–™ï¼Œå‘ç°ä¸ªäººç»´æŠ¤çš„å»ºç«™å·¥å…·éƒ½æ˜¯è‡³å°‘1å¹´ä»¥ä¸Šçš„ï¼Œæœ‰ä¸€ä¸ªåŸºäº python å¯ä»¥é€šè¿‡ghostéƒ¨ç½²åˆ°github pagsä¸Šçš„å·¥å…·è¿˜æ˜¯åŸºäº2.7,æˆ‘ç›´æ¥è£‚å¼€ï¼Œæœ€ç»ˆç›´æ¥æ”¾å¼ƒäº†è¿™å¥—æ–¹æ¡ˆï¼Œå›è¿‡å¤´æ¥æƒ³èƒ½ä¸èƒ½æŠŠcasperç§»æ¤åˆ°hexoä¸Šå‘¢ï¼Œåœ¨githubä¸Šä¹Ÿæœåˆ°äº†ç›¸åº”çš„é¡¹ç›®ï¼Œä½†æ•ˆæœemmmï¼Œä¸æ˜¯ç‰¹åˆ«èƒ½è®©æˆ‘æ»¡æ„ï¼Œè´´ä¸€å¼ demoä¾›å¤§å®¶å‚è€ƒã€‚ ä¸»è¦è¿˜æ˜¯æ’ä»¶çš„æ”¯æŒåº¦æ²¡æœ‰æˆç†Ÿä¸»é¢˜çš„é«˜ï¼Œç„¶åå°±åˆå¼€å§‹google: hexoä¸»é¢˜æ¨è2019ç±»ä¼¼çš„å…³é”®è¯ï¼Œç»ˆäºå‘ç°äº†è¿™ä¸ªæ¨¡ç‰ˆï¼Œicarusï¼Œæ²¡æœ‰cactusé‚£ä¹ˆæœ´ç´ ï¼Œæ’ä»¶æ”¯æŒåº¦å’Œcommitæ´»è·ƒåº¦ä¹Ÿæ¯”hexo-casperé«˜ï¼Œæ‰€ä»¥æ˜¨å¤©èŠ±äº†å¾ˆé•¿å¾ˆé•¿çš„æ—¶é—´è°ƒæ•´ç½‘é¡µå¸ƒå±€å’Œæ–‡ç« æ¸²æŸ“é—®é¢˜ï¼Œæœ€ç»ˆæ•ˆæœæˆ‘æ‰“9åˆ†å§ï¼Œå› ä¸ºè¿˜æœ‰ä¸€ç‚¹é—®é¢˜æ²¡æœ‰è§£å†³ï¼Œç­‰å†™å®Œè¿™ä¸ªåšå®¢æˆ‘å†æï¼Œä¸‹é¢ä¸»è¦æŠŠæˆ‘åŸºäºåˆ«äººä¿®æ”¹çš„æ¨¡ç‰ˆå’Œè‡ªå·±ä¿®æ”¹çš„å†…å®¹åšä¸€ä¸‹æ€»ç»“ï¼Œä»¥å…ä»¥ågit pullä¹‹åä¸çŸ¥é“è‡ªå·±åšäº†å“ªäº›ä¿®æ”¹ã€‚ icarusä¸»é¢˜ä¹‹ä¸Šä¸»è¦æ”¹åŠ¨ ä¸»é¡µæ˜¾ç¤ºä¸¤æ widgetï¼Œæ–‡ç« åªæ˜¾ç¤ºå·¦è¾¹widget æ–‡ç« å›¾ç‰‡å±…ä¸­ å¢åŠ profileä¸‹é¢çš„ bio, å¯ä»¥æ”¾ä¸€ç‚¹è‡ªå·±æƒ³è¯´çš„è¯ ç½®é¡¶æ–‡ç«  æ–‡ç« åº•éƒ¨æ–‡ç« è¯¦ç»†ä¿¡æ¯æ˜¾ç¤ºä»¥åŠæ¨èæ–‡ç« æ¨¡å—é…ç½® é¡µè„šè®¿é—®äººæ•°æ˜¾ç¤ºä¿®æ”¹ ä¸»é¡µæ˜¾ç¤ºä¸¤æ widgetï¼Œæ–‡ç« åªæ˜¾ç¤ºå·¦è¾¹widget ä¸»è¦å‚è€ƒ æ°´å¯’blog ### é…ç½® 1. ä¿®æ”¹ /includes/helpers/layout.js 1hexo.extend.helper.register('column_count', function () {2 let columns = 1;3+ if (this.page.__post === true || this.page.__page === true) {4+ return 2;5+ }6const hasColumn = hexo.extend.helper.get('has_column').bind(this);7columns += hasColumn('left') ? 1 : 0;8columns += hasColumn('right') ? 1 : 0; ä¿®æ”¹ /layout/common/widget.ejs 1&lt;%- partial('widget/' + widget.type, { widget, post: page }) %&gt;2&lt;% }) %&gt;3&lt;% if (position === 'left') { %&gt;4- &lt;div class=\"column-right-shadow is-hidden-widescreen &lt;%= sticky_class('right') %&gt;\"&gt;5+ &lt;div class=\"column-right-shadow &lt;%= (page.__page !== true &amp;&amp; page.__post !== true) ? 'is-hidden-widescreen' : '' %&gt; &lt;%= sticky_class('right') %&gt;\"&gt;6 &lt;% get_widgets('right').forEach(widget =&gt; {%&gt;7 &lt;%- partial('widget/' + widget.type, { widget, post: page }) %&gt;8 &lt;% }) %&gt; ä¿®æ”¹ /layout/layout.ejs 1 &lt;div class=\"columns\"&gt;2 &lt;div class=\"column &lt;%= main_column_class() %&gt; has-order-2 column-main\"&gt;&lt;%- body %&gt;&lt;/div&gt;3 &lt;%- partial('common/widget', { position: 'left' }) %&gt;4+ &lt;% if (page.__page !== true &amp;&amp; page.__post !== true) { %&gt;5 &lt;%- partial('common/widget', { position: 'right' }) %&gt;6+ &lt;% } %&gt;7 &lt;/div&gt;8 &lt;/div&gt;9 &lt;/section&gt; ä¿®æ”¹ /source/css/style.styl 1@media screen and (min-width: screen-widescreen)2 .is-1-column .container3 .is-2-column .container4 max-width: screen-widescreen - 2 * gap5 width: screen-widescreen - 2 * gap6@media screen and (min-width: screen-fullhd)7 .is-2-column .container8 max-width: screen-fullhd - 2 * gap9 width: screen-fullhd - 2 * gap10 .is-1-column .container11 max-width: screen-desktop - 2 * gap12 width: screen-desktop - 2 * gapp ä¿®æ”¹ /layout/layout.ejs 1 &lt;% function main_column_class() {2switch (column_count()) {3 case 1:4 return 'is-12';5 case 2:6 return 'is-8-tablet is-9-desktop is-9-widescreen';7 case 3:8 return 'is-8-tablet is-8-desktop is-6-widescreen'9}10return '';11} %&gt; ä¿®æ”¹ /layout/common/widget.ejs 1&lt;% function side_column_class() {2switch (column_count()) {3case 2:4 return 'is-4-tablet is-3-desktop is-3-widescreen';5case 3:6 return 'is-4-tablet is-4-desktop is-3-widescreen';7}8return '';9} %&gt; æ–‡ç« å›¾ç‰‡å±…ä¸­ æœ€å¼€å§‹å°è¯•äº†ä¿®æ”¹ source/js/main.js å’Œ layout/css/style.styl , ä¿®æ”¹çš„å†…å®¹ä¹Ÿæ˜¯åŸºäºæ°´å¯’çš„åšå®¢ï¼Œæœ¬åœ° hexo serveræ²¡æœ‰é—®é¢˜ï¼Œä½†æ˜¯ hexo g -d ä¹‹åå°±æ€»æ˜¯å‡ºé—®é¢˜ï¼Œæœ€åè¿˜æ˜¯è€è€å®å® 1&lt;center&gt; 2&lt;/center&gt; å¢åŠ profileä¸‹é¢çš„ bio, å¯ä»¥æ”¾ä¸€ç‚¹è‡ªå·±æƒ³è¯´çš„è¯ å®ç°æ•ˆæœ é…ç½® ä¿®æ”¹ /layout/widget/profile.ejs, åœ¨æœ€ååŠ ä¸Šä½ æƒ³è¯´çš„è¯ 1 &lt;% } %&gt;2 &lt;/div&gt;3 &lt;% } %&gt;4+ &lt;hr&gt;5+ &lt;p id=\"evan\"&gt;ä¿®å­ä¹Ÿå¥½ï¼Œè¿œé‡ä¹Ÿå¥½ï¼Œå¯¹äºæƒ…æ„Ÿä¸–ç•Œå‘ç”Ÿçš„äº‹ï¼Œå¾ˆéš¾ç®€å•ä»¥å¯¹å’Œé”™æ¥è¡¡é‡ï¼Œåœ¨è¿™æ ·çš„ä¸–ç•Œé‡Œæ²‰æµ®ï¼Œé£˜è½çš„æ˜¯æƒ…æ„Ÿï¼Œä¸è´¥çš„æ€»æ˜¯æ¯å¹´ç››å¼€çš„æ¨±èŠ±ã€‚ --ã€Šæƒ…äººã€‹&lt;/p&gt;6&lt;/div&gt;7&lt;/div&gt; ## ç½®é¡¶æ–‡ç«  å‚è€ƒæ–‡ç« : https://removeif.github.io/2019/09/19/%E5%8D%9A%E5%AE%A2%E6%BA%90%E7%A0%81%E5%88%86%E4%BA%AB.html#more github commit history ### å®ç°æ•ˆæœ ä½¿ç”¨è¯´æ˜ åœ¨æ¯ç¯‡æ–‡ç« çš„top commentéƒ¨åˆ†é…ç½®topå­—æ®µï¼Œåˆå§‹å€¼æ˜¯100ï¼Œå¦‚æœè¦ç½®é¡¶ï¼Œéœ€è¦è®¾ç½®ä¸ºå¤§äº100çš„å€¼ï¼Œå€¼è¶Šå¤§è¶Šé å‰ã€‚ç›¸ç­‰æ—¶ï¼Œæ ¹æ®æ—¶é—´é™åºã€‚å…·ä½“è®¾ç½®å¦‚ä¸‹ 1title: ä¸€äº©ä¸‰åˆ†åœ°è‡ªåŠ¨ç­¾åˆ°è„šæœ¬2top: 1023toc: true4recommend: 1 5date: 2019-09-19 22:10:436thumbnail: https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2019/20190919221611.png7tags: 8categories: ### é…ç½® ä¿®æ”¹ /layout/common/article.ejs 1&lt;% if (post.layout != 'page') { %&gt;2&lt;div class=\"level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto\"&gt;3 &lt;div class=\"level-left\"&gt;4+ &lt;% if(post.top &gt; 100) { %&gt;5+ &lt;div class=\"level-item tag is-danger\" style=\"background-color: #3273dc;\"&gt;Pin&lt;/div&gt;6+ &lt;%} %&gt;7 &lt;time class=\"level-item has-text-grey\" datetime=\"&lt;%= date_xml(post.date) %&gt;\"&gt;&lt;%= date(post.date) %&gt;&lt;/time&gt;8 &lt;% if (post.categories &amp;&amp; post.categories.length) { %&gt;9 &lt;div class=\"level-item\"&gt; æ–‡ç« åº•éƒ¨æ–‡ç« è¯¦ç»†ä¿¡æ¯æ˜¾ç¤ºä»¥åŠæ¨èæ–‡ç« æ¨¡å—é…ç½® å‚è€ƒæ–‡ç« : https://removeif.github.io/2019/09/19/%E5%8D%9A%E5%AE%A2%E6%BA%90%E7%A0%81%E5%88%86%E4%BA%AB.html#more github commit history ### å®ç°æ•ˆæœ ä½¿ç”¨è¯´æ˜ åœ¨æ¯ç¯‡æ–‡ç« çš„top commentéƒ¨åˆ†é…ç½®recommendå€¼ï¼ˆå¿…é¡»å¤§äº0ï¼‰ï¼Œè¶Šå¤§è¶Šé å‰ï¼Œç›¸ç­‰å–æœ€æ–°çš„ï¼Œæœ€å¤šå–5æ¡ã€‚å…·ä½“è®¾ç½®å¦‚ä¸‹ 1title: ä¸€äº©ä¸‰åˆ†åœ°è‡ªåŠ¨ç­¾åˆ°è„šæœ¬2top: 1023toc: true4recommend: 1 5date: 2019-09-19 22:10:436thumbnail: https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2019/20190919221611.png7tags: 8categories: ### é…ç½® 1. åœ¨ languages/xx.yml ä¸­æ’å…¥ recommend_postsï¼Œå…·ä½“å¦‚ä¸‹ 1widget:2 follow: 'Follow'3 recents: 'Recent'4+ recommend_posts: 'Recommend Posts'5 links: 'Links'6 tag_cloud: 'Tag Cloud'7 catalogue: 'Catalogue' æ³¨æ„æ‰€ä½¿ç”¨çš„è¯­è¨€æ‰€å¯¹åº”çš„æ–‡ä»¶ ä¿®æ”¹ /layout/common/article.ejs 1&lt;div class=\"level-start\"&gt;2 &lt;div class=\"level-item\"&gt;3- &lt;span class=\"is-size-6 has-text-grey has-mr-7\"&gt;#&lt;/span&gt;4+ &lt;i class=\"fas fa-tags has-text-grey\"&gt;&lt;/i&gt;&amp;nbsp;5 &lt;%- list_tags(post.tags, {6 class: 'has-link-grey ',7 show_count: false,8 9..........1011 &lt;/div&gt;12&lt;/div&gt;13&lt;% } %&gt;14+ &lt;!-- éƒ¨åˆ†å‚è€ƒè‡ªhttps://www.alphalxy.com/2019/03/customize-icarus/ --&gt;15+ &lt;% if (!index &amp;&amp; post.layout === 'post' &amp;&amp; post.copyright !== false) { %&gt;16 + &lt;ul class=\"post-copyright\"&gt;17 + &lt;li&gt;&lt;strong&gt;æœ¬æ–‡æ ‡é¢˜ï¼š&lt;/strong&gt;&lt;a href=\"&lt;%= post.permalink %&gt;\"&gt;&lt;%= page.title %&gt;&lt;/a&gt;&lt;/li&gt;18 + &lt;li&gt;&lt;strong&gt;æœ¬æ–‡ä½œè€…ï¼š&lt;/strong&gt;&lt;a href=\"&lt;%= theme.url %&gt;\"&gt;&lt;%= theme.author %&gt;&lt;/a&gt;&lt;/li&gt;19 + &lt;li&gt;&lt;strong&gt;æœ¬æ–‡é“¾æ¥ï¼š&lt;/strong&gt;&lt;a href=\"&lt;%= post.permalink %&gt;\"&gt;&lt;%= post.permalink %&gt;&lt;/a&gt;&lt;/li&gt;20 + &lt;li&gt;&lt;strong&gt;ç‰ˆæƒå£°æ˜ï¼š&lt;/strong&gt;æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ &lt;a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh\" rel=\"external nofollow\" target=\"_blank\"&gt;CC BY-NC-SA 4.0&lt;/a&gt; è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ï¼21 + &lt;/li&gt;22 + &lt;/ul&gt;23 + &lt;br&gt;24 + &lt;%- _partial('widget/recommend_posts') %&gt;25 + &lt;br&gt;26+ br&gt;27 + %&gt;28&lt;% if (!index &amp;&amp; has_config('share.type')) { %&gt;29&lt;%- _partial('share/' + get_config('share.type')) %&gt;30&lt;% } %&gt; /layout/widget ç›®å½•ä¸‹æ·»åŠ  recommend_posts.ejs 1&lt;span class=&quot;is-size-6 has-text-grey has-mr-7&quot;&gt;#&amp;nbsp;&lt;%= __('widget.recommend_posts') %&gt;&lt;/span&gt;2&lt;br&gt;3&lt;% var i = 1;posts.forEach(post =&gt; { %&gt;4&amp;nbsp;&lt;%=i %&gt;.&lt;a href=&quot;&lt;%- url_for((post.link?post.link:post.path)) %&gt;&quot; class=&quot;is-size-6&quot; target=&quot;_blank&quot;&gt;&lt;%= post.title %&gt;&lt;/a&gt;&lt;br&gt;5&lt;% i++;}) %&gt; /layout/widget ç›®å½•ä¸‹æ·»åŠ  recommend_posts.locals.js 1module.exports = (ctx, locals) =&gt; {2const { has_config, get_config, get_thumbnail } = ctx;3const { posts } = ctx.site;4if (!posts.length) {5return null;6}7const thumbnail = !has_config('article.thumbnail') || get_config('article.thumbnail') !== false;8const _posts = posts.filter((item, index, arr) =&gt; item.recommend != undefined &amp;&amp; item.recommend &gt; 0).sort('recommend',-1).sort('recommend',-1).limit(5).map(post =&gt; ({9link: post.link,10path: post.path,11title: post.title,12date: post.date,13thumbnail: thumbnail ? get_thumbnail(post) : null,14// fix circular JSON serialization issue15categories: () =&gt; post.categories16}));17return Object.assign(locals, { thumbnail, posts: _posts });18} ## é¡µè„šè®¿é—®äººæ•°æ˜¾ç¤ºä¿®æ”¹ ### å®ç°æ•ˆæœ é…ç½® ä¿®æ”¹ /layout/common/footer.ejs åœç®—å­éƒ¨åˆ†. 1&lt;% if (busuanzi) { %&gt;2 &lt;br&gt;3 &lt;span id=&quot;busuanzi_container_site_uv&quot;&gt;4 &lt;!-- &lt;%- _p('plugin.visitor', '&lt;span id=&quot;busuanzi_value_site_uv&quot;&gt;0&lt;/span&gt;') %&gt;5 &lt;/span&gt;6 &lt;br&gt; --&gt;7 &lt;span id=&quot;busuanzi_container_site_pv&quot;&gt;8 Visited by &lt;span id=&quot;busuanzi_value_site_uv&quot;&gt;&lt;/span&gt; users with &lt;span id=&quot;busuanzi_value_site_pv&quot;&gt;&lt;/span&gt; times9 &lt;/span&gt;10 &lt;/span&gt;11 &lt;% } %&gt;","link":"/Hexo%E4%B8%BB%E9%A2%98%E6%8A%98%E8%85%BE%E6%97%A5%E8%AE%B0-%E4%BB%8Ecactus%E5%88%B0icarus.html"},{"title":"Sep 17ï¼Œ2019 ä¿ç ”","text":"ä»Šå¤©ä¿ç ”åå•å‡ºæ¥äº†ï¼Œè›®å¤šäººéƒ½å¦‚é‡Šé‡è´Ÿä¸€èˆ¬ï¼Œçº·çº·åœ¨æœ‹å‹åœˆæ¬¢é€è‡ªå·±ç»ˆäºæœ‰å­¦ä¸Šäº†ï¼Œå½“ç„¶åœ¨æœ‹å‹åœˆï¼Œè¿˜æ˜¯æœ‰é‚£ä¹ˆå¤šäººåœ¨é¢è¯•çš„æˆ˜åœºä¸Šå¤„å¤„ç¢°å£ã€‚æ…¢æ…¢çš„ï¼Œå¤§å­¦å››å¹´çœŸçš„å°±è¦ç”»ä¸Šå¥å·äº†ï¼Œèº«è¾¹çš„åŒå­¦è€ƒç ”çš„è€ƒç ”ï¼Œä¿ç ”çš„ä¿ç ”ï¼Œå‡ºå›½çš„å‡ºå›½ï¼Œè¿˜æœ‰æœ€åçœŸçš„å°±æ˜¯æ··åƒæ··å–çš„â€œå¤§å­¦ç”Ÿäº†â€ã€‚æ¯ä¸ªäººéƒ½å¿™ç¢Œç€ï¼Œæ†§æ†¬ç€èƒ½æœ‰ä¸€ä¸ªä¸é”™çš„æœªæ¥ã€‚å‰å‡ å¤©ç­é•¿è®©ç­¾æ”¾å¼ƒä¿ç ”åè®®çš„æ—¶å€™ï¼Œæˆ‘è¿˜æ˜¯å¾ˆéšæ„çš„è¡¨æƒ…ï¼Œå¦ˆçš„ï¼Œä¸å°±æ˜¯ä¸€å¼ çº¸ï¼Œå‡ å¥è¯çš„äº‹æƒ…ã€‚å¯æ˜¯ä»Šå¤©çš„æˆ‘ï¼Œå¿ƒæƒ…çœŸçš„æ²¡æœ‰é‚£å¤©é‚£ä¹ˆæ½‡æ´’ï¼Œ ä»¿ä½›æ˜¯è‡ªå·±å…»å¤§çš„å­©å­è¢«è½»æ˜“çš„é€èµ°ï¼Œè€Œè‡ªå·±æ²¡æœ‰ä¸æ¯«çš„ä¼¤å¿ƒï¼Œè¿™ç§æ„Ÿè§‰å¾ˆå¥‡å¦™ï¼ŒæŠŠå¤§å­¦å››å¹´çš„æˆç»©èµŒåœ¨äº†å‡ºå›½çš„è·¯ä¸Šï¼Œæ”¾å¼ƒäº†å›½å†…æ‰€æœ‰çš„ç ”ç©¶ç”Ÿèµ„æºã€‚æˆ–è®¸ä»ä»Šå¤©å¼€å§‹ï¼Œä¿ç ”çš„é‚£äº›åŒå­¦å°±å¼€å§‹äº†æš‘å‡ç”Ÿæ´»ï¼Œè¿æ¥å±äºè‡ªå·±æœ€åçš„ä¸€ä¸ªæš‘å‡ï¼Ÿè€Œæˆ‘ä»¬è¿˜æ˜¯è¢« GT å›°æ‰°ç€ï¼Œè¢«ç”³è¯·æŸç¼šç€ã€‚ç”³è¯·äº†å¤§å››ä¸‹çš„æ–°å›½å¤§çš„é¡¹ç›®å…¶å®å°±æ˜¯æƒ³è®©è‡ªå·±é€ƒç¦»è¿™ä¸ªç†Ÿæ‚‰çš„ç¯å¢ƒï¼Œå»ä¸€ä¸ªç›¸å¯¹é™Œç”Ÿçš„åœ°æ–¹å­¦ä¹ ï¼Œä¼‘æ¯ï¼Œç”Ÿæ´»ã€‚ ä¿ç ”çš„æ¯•ç«Ÿæ˜¯å°‘æ•°ï¼Œæ›´å¤šçš„æ˜¯åœ¨å›¾ä¹¦é¦†å¥‹ç¬”è¯»ä¹¦å¤‡æˆ˜çš„è€ƒç ”å…šï¼Œä¸çŸ¥é“ä»–ä»¬çš„å¿ƒé‡Œæ˜¯ä»€ä¹ˆæ„Ÿå—ï¼Œçœ‹ç€åŒå­¦çº·çº·å±•ç¤ºè‡ªå·±å¤§å­¦å››å¹´è¾›è‹¦è¯»ä¹¦æˆåŠŸä¿ç ”äººç”Ÿå·…å³°ï¼Œè€Œè‡ªå·±è¿˜åœ¨å¼ å®‡è‚–ç§€è£çš„ä¹¦æœ¬é‡Œè‹¦è‹¦æŒ£æ‰ã€‚æˆ‘ä»¬ä¸€èµ·è¯´è¦å‡ºå›½çš„ä¸€ä¸ªåŒå­¦æ²¡æœ‰ç­¾ä¿ç ”åè®®ï¼Œåœ¨ä¿ç ”çš„åé¢é‡Œæ˜¯æœ€åä¸€åï¼Œè²Œä¼¼åªæœ‰å›½å…‰å®éªŒå®¤ç›´åšçš„åé¢ä¾›ä»–é€‰æ‹©ï¼Œä¹Ÿä¸çŸ¥é“ä»–ä¼šä¸ä¼šçœŸé¦™ã€‚4 å¹´çš„ç”Ÿæ´»çœŸçš„å°±ç»“æŸäº†ï¼Œæ˜¨æ™šè›®å¤šäººè¿˜æ˜¯è¾—è½¬ååˆ™ä¸çŸ¥é“èƒ½ä¸èƒ½ä¿ç ”ï¼Œä»Šå¤©å°±æ˜¯å®‰å®‰ç¨³ç¨³èººåœ¨åºŠä¸Šæƒ³ç€æ¥ä¸‹æ¥çš„ç¾å¥½ç”Ÿæ´»ã€‚æ—¥å­æ€»è¦è¿‡å»å•Šï¼Œè°ä¸æ˜¯è¸©ç€æ³¥æ³çš„é“è·¯çœ‹ç€åˆ«äººå¼€ç€è½¦é©°éª‹åœ¨åº·åº„å¤§é“ä¸Šå‘¢ã€‚","link":"/Sep-17%EF%BC%8C2019-%E4%BF%9D%E7%A0%94.html"},{"title":"Sep 2, 2019","text":"æ˜¨å¤©çœŸçš„æŒºå·§çš„ï¼Œ9 æœˆ1 å·æ˜¯æˆ‘æ‰˜ç¦è€ƒè¯•ï¼Œä¹Ÿæ­£å¥½åˆæ¢¦è§äºŒå§¨äº†ã€‚è™½ç„¶æ¢¦æ—©å·²ç»è®°ä¸æ¸…äº†ï¼Œä½†æˆ‘æ—©ä¸Šèµ·æ¥ï¼Œè¿˜æ˜¯æ‰“å¼€äº†ç¬”è®°æœ¬å†™äº† è€äºŒå§¨ ä¸‰ä¸ªå­—ï¼Œå› ä¸ºæˆ‘æ€•æˆ‘å¿˜è®°ï¼Œæˆ‘æ¢¦è§äº†äºŒå§¨ã€‚ä¸çŸ¥é“æˆ‘å“­äº†æ²¡æœ‰ï¼Œä¸çŸ¥é“ä½ åœ¨é‚£é‡Œè¿‡å¾—æ€ä¹ˆæ ·ï¼Œä½†çœŸçš„ï¼Œæˆ‘å¥½ä¹…æ²¡æœ‰æ¢¦è§è¿‡ä½ äº†ï¼ŒçœŸçš„æƒ³å†æ‘¸æ‘¸ä½ çš„æ‰‹ï¼Œå‘Šè¯‰ä½ ç«¥ç«¥ç°åœ¨æŒºå¥½çš„ï¼Œä¹Ÿå¾ˆåŠªåŠ›ï¼Œç°åœ¨å·²ç»é«˜ä¸‰äº†ï¼Œå†è¿‡ä¸€å¹´ä¹Ÿè·Ÿæˆ‘ä¸€æ ·ä¸Šäº†å¤§å­¦ï¼Œåˆ°é‚£ä¸ªæ—¶å€™æˆ‘ä¹Ÿå°±æ¯•ä¸šå˜ï¼Œç«¥ç«¥ä¸€å®šå¯ä»¥çš„ã€‚å§¥çˆ·æœ€è¿‘å»æ‹”ç‰™äº†ï¼Œå¥½åƒæ˜¯å…¨æ‹”äº†å§ï¼Œè¿™æ ·å°±å¯ä»¥ç›´æ¥å¸¦å‡ç‰™åƒç¡¬ä¸€ç‚¹ï¼Œå¥½ä¸€ç‚¹çš„ä¸œè¥¿äº†ã€‚è¯´çœŸçš„ï¼Œæˆ‘ä»¥åå›å®¶çš„æ—¶é—´çœŸçš„å¾ˆå°‘äº†ï¼Œé‚£å¤©ä¸‰å§¨å‘Šè¯‰ä½ ï¼Œä½ ä»¥åè¿˜æœ‰å¤šé•¿æ—¶é—´åœ¨éƒ‘å·å¾…ç€ï¼Œæ˜¯å•Šï¼ŒçœŸçš„å°±æ²¡æœ‰å¤šå°‘å¤©äº†ã€‚æ„Ÿè§‰æ¯ä¸ªäººéƒ½å¿™ç¢Œç€ï¼Œä¸‹åŠå¹´æŒºå¿™çš„ï¼ŒGREï¼Œæ‰˜ç¦ï¼Œæ–‡ä¹¦ï¼Œç”³è¯·ï¼Œäº‹æƒ…æ¥è¸µè€Œæ¥ï¼Œè€Œæˆ‘è¿˜æ²¡æœ‰å®Œæˆä¸€ä»¶äº‹ï¼Œæ‰˜ç¦å­¦äº†ä¸çŸ¥é“å¤šä¹…äº†ï¼Œè¿˜æ˜¯å› ä¸ºå¬åŠ›è€Œæ²¡æœ‰å®è´¨çš„è¿›æ­¥ï¼ŒGRE å› ä¸ºåšé¢˜æ²¡æœ‰å¤šå°‘ï¼Œæ‰€ä»¥å‡ æ–¤å‡ ä¸¤ä¹Ÿä¸æ˜¯å¾ˆæ¸…æ¥šã€‚èº«è¾¹æŒºå¤šäººéƒ½å»è€ƒç ”äº†ï¼Œå¤©å¤© 7 ç‚¹å¤šèµ·åºŠã€‚å¿™ç‚¹å¥½å•Šï¼Œå¿™ç‚¹å°±ä¸ä¼šå»æƒ³é‚£äº›ä¼¤å¿ƒçš„äº‹äº†ã€‚ä½ åœ¨é‚£è¾¹è®°å¾—å¤šåƒä¸€ç‚¹ï¼Œhhï¼Œæˆ‘æœ€è¿‘è¿˜åœ¨å‡è‚¥å‘¢ï¼Œä¸è¿‡ç­‰æˆ‘ç˜¦ä¸‹å»ä¹‹åå°±å»åƒå¥½åƒçš„ï¼é‚£å¤©æˆ‘é—»çƒ­æ°´æ¯çš„çƒ­æ°”ï¼Œçªç„¶æƒ³èµ·ä½ å‘¢ï¼Œçœ¼ç›éƒ½çªç„¶æ¹¿æ‰äº†ï¼Œhhã€‚ä¸ç®¡æ€ä¹ˆæ ·ï¼Œéƒ½è¦èº«ä½“å¥åº·å˜ï¼Œä¹Ÿä¸€å®šè¦å¼€å¿ƒå‘€ã€‚","link":"/Sep-2-2019.html"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new \"My New Post\" More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment","link":"/hello-world.html"},{"title":"March 18, 2019","text":"å¯»æ‰¾ï¼Œæ‰¾å¯»ï¼Œç”Ÿå‘½ï¼Œç›¸å…³ï¼Œèµ·ç‚¹ äºŒå§¨ï¼Œå’±ä»¬åˆè§é¢äº†ï¼Œå¯æ˜¯ä½ è¿™æ¬¡çœŸçš„ï¼Œè¯å¥½å°‘ã€‚ æˆ‘å’Œè€å˜Ÿåœ¨ä½ è®¾è®¡çš„å¯†å®¤é‡Œé¢ï¼Œéœ€è¦å¯»æ‰¾4ä¸ª16è¿›åˆ¶æ•°ï¼Œä½†æˆ‘ä»¬å¤ªç¬¨äº†ï¼Œæ€ä¹ˆéƒ½æ‰¾ä¸åˆ°ï¼Œæœ€åä½ åˆ°äº†æˆ‘ä»¬è¿™é‡Œï¼Œä½†åœºæ™¯çªç„¶å˜äº†ï¼Œæˆ‘çœ‹åˆ°äº†å§¥çˆ·çš„åºŠå¤´æŸœï¼Œä½ å°±ååœ¨åºŠå¤´æŸœæ—çš„å‡³å­ä¸Šï¼Œå½“æˆ‘ç¿»æ‰¾æŸœå­é‡Œé¢çš„ä¸œè¥¿çš„æ—¶å€™ï¼Œä½ ç»™æˆ‘è¯´ï¼Œæç¤ºä¸åœ¨é‡Œé¢ã€‚å¾ˆé—æ†¾ï¼Œæˆ‘æ²¡æœ‰çœ‹ä½ çš„è„¸ï¼Œä¸çŸ¥é“ä½ è€äº†æ²¡æœ‰ï¼Œä½†ä½ çš„å£°éŸ³è¿˜æ˜¯é‚£ä¹ˆå¥½å¬ã€‚æ¢¦é†’äº†ï¼Œæˆ‘èƒ½è®°ä½çš„å‡ ä¸ªè¯æ±‡ï¼Œå°±æ˜¯ å¯»æ‰¾ï¼Œæ‰¾å¯»ï¼Œç”Ÿå‘½ï¼Œç›¸å…³ï¼Œèµ·ç‚¹ã€‚ä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼Œæ¢¦é‡Œæ²¡æœ‰çœ‹åˆ°ç«¥ç«¥ï¼Œæ˜¯ä¸æ˜¯çœ‹åˆ°å¥¹ï¼Œä½ åˆå¼€å“­äº†ã€‚åœ¨é‚£è¾¹ä¸€ä¸ªäººç”Ÿæ´»æŒºè‹¦çš„å§ï¼Œä½†ä½ è¿˜æ˜¯è¦å¼€å¿ƒï¼Œå› ä¸ºç«¥ç«¥ç”Ÿçš„é•¿å¤§äº†ï¼Œç»™è€å˜Ÿè¯´äº†é‚£ä¹ˆå¤šé“ç†ï¼Œå­¦ä¹ çš„ï¼Œç”Ÿæ´»çš„ã€‚å…¶ä¸­æœ€ä»¤æˆ‘æ„ŸåŠ¨çš„ä¸€å¥ï¼Œæ˜¯å¥¹è¯´ï¼Œä½ ä¸è¦åƒå§å§ä¸€æ ·ï¼Œåˆä¸­ä¸å¥½å¥½å­¦ä¹ ï¼Œä¸Šäº†ä¸€ä¸ªä¸å¥½çš„é«˜ä¸­ï¼Œä½ è¦å¥½å¥½å­¦ï¼Œåƒå“¥å“¥ä¸€æ ·ï¼Œè€ƒä¸€ä¸ªå¥½é«˜ä¸­ã€‚ä½ åœ¨é‚£è¾¹å¬åˆ°è¿™å¥è¯ä¸€å®šå¾ˆæ¬£æ…°å§ï¼Œç«¥ç«¥é•¿å¤§äº†ï¼Œä¼šç…§é¡¾å¥½è‡ªå·±çš„ï¼Œä½ æ”¾å¿ƒå¥½äº†ï¼Œè¿™æ¬¡å°±èŠåˆ°è¿™é‡Œå§ï¼Œæˆ‘è¦ç»§ç»­ç¡äº†ã€‚","link":"/March-18-2019.html"},{"title":"March 26, 2019","text":"äºŒå§¨ï¼Œæˆ‘åˆæ¢¦è§ä½ äº†ï¼Œå¥½åƒæ˜¯çœ‹äº†ä¼Šè—¤æ¶¦äºŒçš„è§†é¢‘ï¼Œäººæ­»åå¾ˆå¯ä»¥é€šè¿‡æŸç§ä»ªå¼è®©ä½ çš„çµé­‚æ´»åœ¨ä¸–ç•Œä¸­ï¼Œä½ å°±æ˜¯è¿™æ ·å›åˆ°æˆ‘ä»¬èº«è¾¹çš„ï¼Œè™½ç„¶çœ‹èµ·æ¥å¾ˆä¸çœŸå®ï¼Œä½†æˆ‘åˆå¯ä»¥åœ¨ä½ çš„èº«è¾¹äº†ã€‚","link":"/March-26-2019.html"},{"title":"The Post","text":"å†å²é¢˜æç”µå½±ï¼Œæ¶‰åŠç¾å›½æ–°é—»è‡ªç”±ã€åæˆ˜ç­‰è¯é¢˜ã€‚ã€‚ã€‚ã€‚ç”µå½±è®²è¿°çš„æ˜¯åœ¨â€œæ°´é—¨äº‹ä»¶â€çš„å‰å¤•ï¼Œä¸€ç¾¤æ–°é—»åª’ä½“äººä¸ºäº†æå«æ–°é—»çš„åŸåˆ™ï¼Œä¸æƒœèˆå¼ƒå‰é€”è€Œä¸å°¼å…‹æ¾æ”¿åºœå¯¹æŠ—çš„æ•…äº‹ã€‚ã€ŠThe Postã€‹å’Œç”µå½±ã€Š1987ã€‹ä¸€æ ·ï¼Œè™½è¯´æ—¶ä»£èƒŒæ™¯ä¸åŒï¼Œä½†æ˜¯éƒ½åæ˜ äº†æ–°é—»å·¥ä½œè€…å¯¹äºä¸ªäººå®‰å±å’Œå›½å®¶å­˜äº¡çš„æ–¹é¢çš„å–èˆé—®é¢˜ã€‚ æ‘˜å½•ç”µå½±é‡Œé¢æœ€åä¸€å¥ï¼š The founding fathers gave the free press, the protection it must have to fulfill its essential role in our democracy. The press was to serve the governed, not the governors. imdb7.4åˆ† æ–¯çš®å°”ä¼¯æ ¼å¯¼æ¼”çš„ç”µå½±è¿˜æ˜¯å€¼å¾—è§‚çœ‹çš„","link":"/The-Post.html"},{"title":"ä¸€äº©ä¸‰åˆ†åœ°è‡ªåŠ¨ç­¾åˆ°è„šæœ¬","text":"è„šæœ¬ä»‹ç» å‰ä¸€æ®µæ—¶é—´æ¥è§¦åˆ°äº†Surgeï¼Œä¹Ÿé—´æ¥æ¥è§¦åˆ°äº†jsè„šæœ¬çš„ä½¿ç”¨ã€‚ç¾¤é‡Œå¾ˆå¤šäººé€šè¿‡è„šæœ¬å®ç°äº†è­¬å¦‚å¤©æ°”æé†’ï¼Œç™¾åº¦è´´å§ç­¾åˆ°ï¼Œç”šè‡³æ˜¯å»é™¤å¹¿å‘Šçš„åŠŸèƒ½ï¼Œè™½è¯´ä¹‹å‰æ²¡æœ‰æ¥è§¦è¿‡jsï¼Œåªå†™è¿‡ä¸€ç‚¹pythonçš„è„šæœ¬ï¼Œä½†é‰´äºjsè„šæœ¬çš„ä½¿ç”¨èŒƒå›´å®åœ¨å¤ªå¤§ï¼Œè¿™å‡ å¤©å°±åŠ¨æ‰‹å­¦ä¹ äº†ä¸€ç‚¹jsçš„è¯­æ³•ï¼Œä¿®æ”¹äº†ç‚¹è„šæœ¬ï¼Œå‰å¤©èŠ±äº†ç‚¹æ—¶é—´ä¿®æ”¹äº†ä½œè€… Neurogram å®šç‚¹ç­¾åˆ°çš„è„šæœ¬ï¼Œé€‚é…äº†ç‰¹å®šçš„htmlæ ¼å¼ï¼Œä»¥åŠå¢åŠ äº†åˆ°æœŸæ—¶é—´çš„æ˜¾ç¤ºï¼Œæˆå°±æ„Ÿè¿˜æ˜¯è›®å¼ºçš„ã€‚ç”±äºåˆ°äº†ç”³è¯·å­£ï¼Œå¾ˆå¤šåŒå­¦éƒ½éœ€è¦åœ¨æ¯”å¦‚ä¸€äº©ä¸‰åˆ†åœ°çš„ç•™å­¦è®ºå›ä¸Šé€›å¸–ï¼Œæ‰€ä»¥å‡ºäºå…´è¶£ï¼Œå†™äº†ä¸€äº©ä¸‰åˆ†åœ°çš„è‡ªåŠ¨ç­¾åˆ°è„šæœ¬ã€‚ Check in for Shortcuts è¿è¡Œ Shortcuts ç‰ˆæ—¶ï¼Œéœ€è¦å…ˆè¿›å…¥ç¼–è¾‘é¡µé¢ï¼Œåœ¨URL_æäº¤ç™»é™†æ¨¡å—å¡«å†™è´¦å·ä¿¡æ¯ï¼Œè´¦å·ä¿¡æ¯åˆ†ä¸º ç”¨æˆ·åã€å¯†ç ã€é—®é¢˜ç¼–å·ï¼Œé—®é¢˜ç­”æ¡ˆ 4ä¸ª DICTIONARYï¼ˆå­—å…¸ï¼‰ï¼Œå…¶ä¸­å¦‚æœæ²¡æœ‰é—®é¢˜ï¼Œé—®é¢˜ç¼–å·å†™0ï¼Œé—®é¢˜ç­”æ¡ˆç•™ç©ºã€‚ Check in for Surge å¡«å†™è´¦å·ä¿¡æ¯ const accounts = [ [&quot;username@xxx.com&quot;, &quot;xxx&quot;,&quot;x&quot;,&quot;xxxx&quot;] ] è´¦å·ä¿¡æ¯çš„å¡«å†™è¦ä¸¥è°¨æŒ‰ç…§ä»£ç ç¤ºä¾‹çš„æ ¼å¼å¡«å†™ï¼Œå†…å®¹é¡ºåºä¾æ¬¡ä¸º ç”¨æˆ·åã€å¯†ç ã€é—®é¢˜ç¼–å·ï¼Œé—®é¢˜ç­”æ¡ˆï¼Œ4ä¸ªå†…å®¹ç”¨åŒå¼•å·&quot;&quot;æ‹¬èµ·æ¥ï¼Œä¸”ä¸éœ€è¦urlencodeï¼Œç›´æ¥åŸæ–‡æ˜¾ç¤ºã€‚å…¶ä¸­å¦‚æœæ²¡æœ‰é—®é¢˜ï¼Œé—®é¢˜ç¼–å·å†™0ï¼Œé—®é¢˜ç­”æ¡ˆç•™ç©ºã€‚ å®‰è£…è„šæœ¬ äº‘ç«¯ï¼šè‡ªå·±çš„æœåŠ¡å™¨æˆ–å…¶ä»–å¯ç”Ÿæˆæ–‡ä»¶ç›´é“¾çš„åœ°æ–¹(githubè®°å¾—ä½¿ç”¨ç‚¹rawè¿›å…¥ç›´é“¾) æœ¬åœ°ï¼š iCloud / Dropbox çš„ Surge æ–‡ä»¶å¤¹ä¸‹ é…ç½®è„šæœ¬ è¿›å…¥ é…ç½®æ–‡ä»¶ çš„æ–‡æœ¬ç¼–è¾‘æ¨¡å¼ï¼Œåœ¨ [Script] ï¼ˆå¦‚æ—  [Script]ï¼Œç¼–è¾‘ä¸€ä¸ªå³å¯ï¼‰ä¸‹æ–°å»ºä¸€è¡Œ [Script] cron &quot;30 8 * * *&quot; script-path=checkin_1point.js ä»¥ä¸Šå®ä¾‹ä¸º æ¯å¤©æ—©ä¸Š 8:30 è¿è¡Œå­˜æ”¾äº æœ¬åœ°çš„ checkin_1point.js è„šæœ¬ï¼ˆå¦‚è„šæœ¬å­˜æ”¾äºäº‘ç«¯ï¼Œåˆ™ script-path=è„šæœ¬ç›´é“¾ï¼‰è‡ªå®šä¹‰è§¦å‘æ—¶é—´é…ç½®ä½¿ç”¨çš„æ˜¯ crontab æ ·å¼ï¼Œapiå¯å‚è€ƒ Scripting çš„ä»‹ç» ä»£ç é€»è¾‘ é—®é¢˜ ç”±äºhashå’Œcookieæœ‰å…³è”ï¼Œç™»é™†çš„cookieæœ‰è¾ƒé•¿çš„ä½¿ç”¨æœŸï¼Œè€Œç­¾åˆ°çš„cookieåœ¨æ¯ä¸€æ¬¡ç™»é™†ä¹‹åéƒ½ä¼šæ›´æ–°ï¼Œæ‰€ä»¥ä¸èƒ½ç›´æ¥é€šè¿‡æŠ“ç­¾åˆ°çš„åŒ…ç›´æ¥è¿›è¡ŒPOSTæ“ä½œã€‚åŒæ—¶åœ¨åæœŸçš„æµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œå¦‚æœæƒ³åŒæ—¶è¿›è¡Œå¤šè´¦å·çš„ç­¾åˆ°ï¼Œç”±äºç™»é™†cookieåœ¨æœ¬æœºæœ‰ä¿å­˜ï¼Œå¾ˆå¯èƒ½å‡ºç°æç¤ºäº†ç­¾åˆ°æˆåŠŸä½†è´¦å·å®é™…æ²¡æœ‰ç­¾åˆ°æˆåŠŸçš„æƒ…å†µï¼Œæ‰€ä»¥å»ºè®®å¤§å®¶åªä½¿ç”¨ä¸€ä¸ªè´¦å·ï¼Œæˆ–è€…ç­¾åˆ°å®Œæˆåæ¸…é™¤Safariçš„ç¼“å­˜ï¼Œå†è¿›è¡Œå¦å¤–ä¸€ä¸ªè´¦å·çš„ç­¾åˆ°æ“ä½œã€‚ ç»†å¿ƒçš„åŒå­¦çœ‹å®Œä»£ç ä¼šå‘ç°æœ€åç­¾åˆ°çš„å‡½æ•°æ­£åˆ™é‡Œé¢åŒ…å«äº†ä¹±ç å­—ç¬¦ï¼Œå› ä¸ºæœ€åæŠ“åŒ…ä¹‹åè¿”å›çš„htmlæ˜¯gbkç¼–ç çš„ï¼Œå¤„ç†èµ·æ¥ä¸æ˜¯ç‰¹åˆ«æ–¹ä¾¿ï¼Œäºæ˜¯æš‚æ—¶å°±ç”¨äº†æ¯”è¾ƒç¬¨çš„æ–¹æ³•è¿›è¡Œäº†å­—ç¬¦åŒ¹é…ã€‚ è¿™ä¹Ÿæ˜¯æˆ‘ç¬¬ä¸€ä¸ªå®Œæ•´çš„å†™ä¸€ä¸ªjsè„šæœ¬ï¼Œä¸šåŠ¡é€»è¾‘æ–¹é¢åŒ…æ‹¬å‡½æ•°ï¼Œå­—å…¸æ ¼å¼çš„ä½¿ç”¨æˆ–å¤šæˆ–å°‘å­˜åœ¨ä¸åˆç†çš„åœ°æ–¹ï¼Œå¦‚æœå¤§å®¶æœ‰æ›´å¥½çš„æ„è§ï¼Œæ¬¢è¿ç»™æˆ‘è”ç³»ã€‚ - åé¦ˆ ğŸ’¡ å¦‚æœå¤§å®¶è¿è¡Œä¸äº†è„šæœ¬æˆ–è€…è¿è¡Œå‡ºé”™ï¼Œ[åé¦ˆ](https://t.me/Leped_Bot)çš„æ—¶å€™ä¸€å®šè¦å¸¦ä¸ŠæŠ¥é”™çš„æˆªå›¾ï¼Œæœ‰èƒ½åŠ›çš„åŒå­¦åœ¨ä»£ç é‡Œé¢å–æ¶ˆå¯¹åº”çš„`console.log(data)`çš„æ³¨é‡Šï¼Œå¹¶é™„ä¸Šsurge logçš„å¯¹åº”æˆªå›¾ï¼Œæ„Ÿè°¢å¤§å®¶ã€‚ è„šæœ¬ä¸‹è½½ ğŸ‘‰ Check in for Shortcuts (feat @wangfei021325) ğŸ‘‰ Check in for Surge å…³äºä½œè€… Telegram: Leped_Bot GitHub: NavePnow Reference ğŸ”— Check-in Demo ğŸ”— Tutorial Demo ğŸ‘¨â€ğŸ« Advisor","link":"/%E4%B8%80%E4%BA%A9%E4%B8%89%E5%88%86%E5%9C%B0%E8%87%AA%E5%8A%A8%E7%AD%BE%E5%88%B0%E8%84%9A%E6%9C%AC.html"},{"title":"åˆ†å¸ƒå¼è®¡ç®—å­¦ä¹ ç¬”è®°(ä¸€) ä»åˆ†å¸ƒå¼ç³»ç»Ÿåˆ°åˆ†å¸ƒå¼è®¡ç®—","text":"ä¸“æœ‰åå­— ACID Atomicityï¼ˆåŸå­æ€§ï¼‰ï¼šä¸€å€‹äº‹åŠ¡ï¼ˆtransactionï¼‰ä¸­çš„æ‰€æœ‰æ“ä½œï¼Œæˆ–è€…å…¨éƒ¨å®Œæˆï¼Œæˆ–è€…å…¨éƒ¨ä¸å®Œæˆï¼Œä¸ä¼šç»“æŸåœ¨ä¸­é—´æŸä¸ªç¯èŠ‚ã€‚äº‹åŠ¡åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œä¼šè¢«å›æ»šï¼ˆRollbackï¼‰åˆ°äº‹åŠ¡å¼€å§‹å‰çš„çŠ¶æ€ï¼Œå°±åƒè¿™ä¸ªäº‹åŠ¡ä»æ¥æ²¡æœ‰æ‰§è¡Œè¿‡ä¸€æ ·ã€‚å³ï¼Œäº‹åŠ¡ä¸å¯åˆ†å‰²ã€ä¸å¯çº¦ç®€ã€‚ Consistencyï¼ˆä¸€è‡´æ€§ï¼‰ï¼šåœ¨äº‹åŠ¡å¼€å§‹ä¹‹å‰å’Œäº‹åŠ¡ç»“æŸä»¥åï¼Œæ•°æ®åº“çš„å®Œæ•´æ€§æ²¡æœ‰è¢«ç ´åã€‚ Isolationï¼ˆéš”ç¦»æ€§ï¼‰ï¼šæ•°æ®åº“å…è®¸å¤šä¸ªå¹¶å‘äº‹åŠ¡åŒæ—¶å¯¹å…¶æ•°æ®è¿›è¡Œè¯»å†™å’Œä¿®æ”¹çš„èƒ½åŠ›ï¼Œéš”ç¦»æ€§å¯ä»¥é˜²æ­¢å¤šä¸ªäº‹åŠ¡å¹¶å‘æ‰§è¡Œæ—¶ç”±äºäº¤å‰æ‰§è¡Œè€Œå¯¼è‡´æ•°æ®çš„ä¸ä¸€è‡´ã€‚ Durabilityï¼ˆæŒä¹…æ€§ï¼‰ï¼šäº‹åŠ¡å¤„ç†ç»“æŸåï¼Œå¯¹æ•°æ®çš„ä¿®æ”¹å°±æ˜¯æ°¸ä¹…çš„ï¼Œå³ä¾¿ç³»ç»Ÿæ•…éšœä¹Ÿä¸ä¼šä¸¢å¤±ã€‚ ## CAP Consistency ä¸­æ–‡å«åš&quot;ä¸€è‡´æ€§&quot;ã€‚æ„æ€æ˜¯ï¼Œå†™æ“ä½œä¹‹åçš„è¯»æ“ä½œï¼Œå¿…é¡»è¿”å›è¯¥å€¼ã€‚ Availability ä¸­æ–‡å«åš&quot;å¯ç”¨æ€§&quot;ï¼Œæ„æ€æ˜¯åªè¦æ”¶åˆ°ç”¨æˆ·çš„è¯·æ±‚ï¼ŒæœåŠ¡å™¨å°±å¿…é¡»ç»™å‡ºå›åº”ã€‚ Partition toleranceï¼Œä¸­æ–‡å«åš&quot;åˆ†åŒºå®¹é”™â€, åŒºé—´é€šä¿¡å¯èƒ½å¤±è´¥ï¼ŒæœåŠ¡å™¨ä¹‹é—´é€šä¿¡å¤±è´¥ ## è´Ÿè½½å‡è¡¡ æœ‰ç‚¹ SDN çš„æ„Ÿè§‰ï¼Œä½œä¸ºå—åŒ—å‘çš„æ•°æ®æ¥å£ï¼Œè¿æ¥ç”¨æˆ·å’Œåç«¯æœåŠ¡å™¨ï¼Œç”¨æˆ·è¯·æ±‚é¦–å…ˆåˆ°è¾¾è´Ÿè½½å‡è¡¡å™¨ï¼Œç”±è´Ÿè½½å‡è¡¡å™¨åˆ†é…å¯ç”¨èµ„æºï¼ˆæœåŠ¡å™¨ï¼‰ï¼Œé€šå¸¸æƒ…å†µä¸‹ï¼Œæ‰€æœ‰çš„åç«¯æœåŠ¡å™¨ä¼šä¿è¯æä¾›ç›¸åŒçš„å†…å®¹ï¼Œä»¥ä¾¿ç”¨æˆ·æ— è®ºå“ªä¸ªæœåŠ¡å™¨å“åº”ï¼Œéƒ½èƒ½æ”¶åˆ°ä¸€è‡´çš„å†…å®¹ï¼ˆé€šè¿‡å†—ä½™æé«˜å¯é æ€§ï¼‰ï¼Œä»¥è¾¾åˆ°æœ€ä½³åŒ–èµ„æºä½¿ç”¨ã€æœ€å¤§åŒ–ååç‡ã€æœ€å°åŒ–å“åº”æ—¶é—´ã€åŒæ—¶é¿å…è¿‡è½½çš„ç›®çš„ã€‚ ## åè°ƒä¸­å¿ƒ ä¸€ä¸ªç”¨æˆ·è¯·æ±‚åŒ…å«å¤šä¸ªæœåŠ¡ï¼Œæ¯ä¸ªæœåŠ¡åˆåŒ…å«å¤šä¸ªèŠ‚ç‚¹ï¼Œä¸åŒæœåŠ¡ä¹‹é—´çš„è½¬æ¥éœ€è¦èŠ‚ç‚¹é—´ååŒé…åˆï¼Œæä¾›æœåŠ¡çš„èŠ‚ç‚¹å‘ä¸€ä¸ªåè°ƒä¸­å¿ƒæ³¨å†Œè‡ªå·±çš„åœ°å€ï¼Œä½¿ç”¨æœåŠ¡çš„èŠ‚ç‚¹å»åè°ƒä¸­å¿ƒæ‹‰å–åœ°å€ï¼Œä¸åŒèŠ‚ç‚¹é€šè¿‡åè°ƒä¸­å¿ƒå®ŒæˆæœåŠ¡çš„äº¤æ¥ã€‚ ## RPC Remote Produce Call, ç”¨äºæœåŠ¡å†…ä¸åŒèŠ‚ç‚¹é—´çš„è¿œç¨‹é€šä¿¡å’Œç›¸äº’è°ƒç”¨ ## åˆ†å¸ƒå¼ç³»ç»Ÿ åˆ†å¸ƒå¼ç³»ç»Ÿæ˜¯ä¸€ç»„ç”µå­è®¡ç®—æœºï¼ˆcomputerï¼‰ï¼Œé€šè¿‡è®¡ç®—æœºç½‘ç»œç›¸äº’é“¾æ¥ä¸é€šä¿¡åå½¢æˆçš„ç³»ç»Ÿã€‚æŠŠéœ€è¦è¿›è¡Œå¤§é‡è®¡ç®—çš„å·¥ç¨‹æ•°æ®åˆ†åŒºæˆå°å—ï¼Œç”±å¤šå°è®¡ç®—æœºåˆ†åˆ«è®¡ç®—ï¼Œåœ¨ä¸Šä¼ è¿ç®—ç»“æœåï¼Œå°†ç»“æœç»Ÿä¸€åˆå¹¶å¾—å‡ºæ•°æ®ç»“è®ºçš„ç§‘å­¦ã€‚åˆ†å¸ƒå¼ç³»ç»Ÿç”±åˆ†å¸ƒå¼è®¡ç®—å’Œåˆ†å¸ƒå¼å­˜å‚¨ç»„æˆï¼Œå—é™äº CAP ç‰¹æ€§ã€‚ ## åˆ†å¸ƒå¼è®¡ç®— æ ¸å¿ƒé—®é¢˜ï¼š å¦‚ä½•å°†ä»»åŠ¡è¿›è¡Œåˆ†è§£ï¼Œå¦‚ä½•æ•´åˆï¼Œä¹Ÿå°±æ˜¯å…ˆMapåReduceï¼Œå‚è€ƒä¸­é—´ä»¶è¯¾ä¸Šæ‰€å­¦ä¹ çš„ Word-Count è¿‡ç¨‹ã€‚ Reference https://zhuanlan.zhihu.com/p/32841479 https://zh.wikipedia.org/wiki/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1 https://zh.wikipedia.org/wiki/ACID https://www.ruanyifeng.com/blog/2018/07/cap.html https://blog.csdn.net/trochiluses/article/details/19327639","link":"/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80-%E4%BB%8E%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%88%B0%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97.html"},{"title":"åˆ†å¸ƒå¼è®¡ç®—å­¦ä¹ ç¬”è®°(äºŒ) Ray","text":"Ray å‰è¨€ ä¸‹å­¦æœŸå»æ–°åŠ å¡åšæ¯•è®¾ï¼Œè€å¸ˆç»™æˆ‘è®¢çš„ä¸»é¢˜æ˜¯å…³äºRay-åˆ†å¸ƒå¼æ‰§è¡Œæ¡†æ¶çš„å†…å®¹ï¼Œå…¶å®å°±æ˜¯æƒ³è®©æˆ‘åœ¨è¿™ä¸ªæ¡†æ¶ä¸­åšä¸€äº›åº”ç”¨ï¼Œä¹Ÿå¯ä»¥è¯´æ˜¯å¤§ä¼—åŒ–ï¼Ÿå‰å‡ å¤©å’ŒHUSTçš„æŒ‚åè€å¸ˆèŠäº†èŠï¼Œå¥¹ä¹Ÿæ²¡æœ‰å¬è¯´è¿‡è¿™ä¸ªæ¡†æ¶ï¼Œåœ¨ç½‘ä¸Šæœäº†ä¸€ä¸‹ï¼Œè¯´è®©æˆ‘å°è¯•ä¸€ä¸‹åœ¨è¿™ä¸ªåˆ†å¸ƒå¼æ‰§è¡Œæ¡†æ¶ä¸­å®ç°ä¸€ä¸ªèšç±»ç®—æ³•ï¼Œå…³é”®è¯æœ‰ Ray Tensor Clustering, è¯´å®è¯ï¼Œä¸æ‡‚ï¼ŒçœŸçš„ï¼Œçœ‹ä¸€ä¸ªåæ¬¡å°±ä¼šè¹¦å‡º5ä¸ªä¹‹å‰æ²¡è§è¿‡çš„ï¼Œå¤šä¸ªåå­—å åŠ ç›´æ¥æŠŠæˆ‘ææ‡µé€¼äº†ã€‚æ‰€ä»¥è¿™ä¸ªç³»åˆ—ä¹Ÿç®—æ˜¯æˆ‘çš„å­¦ä¹ ç¬”è®°å§ã€‚ ## æ¦‚è¿° Rayæ˜¯UC Berkeley RISELabæ–°æ¨å‡ºçš„é«˜æ€§èƒ½åˆ†å¸ƒå¼æ‰§è¡Œæ¡†æ¶ï¼Œå®ƒä½¿ç”¨äº†å’Œä¼ ç»Ÿåˆ†å¸ƒå¼è®¡ç®—ç³»ç»Ÿä¸ä¸€æ ·çš„æ¶æ„å’Œå¯¹åˆ†å¸ƒå¼è®¡ç®—çš„æŠ½è±¡æ–¹å¼ï¼Œå…·æœ‰æ¯”Sparkæ›´ä¼˜å¼‚çš„è®¡ç®—æ€§èƒ½ã€‚ - ä¼˜ç‚¹: - æµ·é‡ä»»åŠ¡è°ƒåº¦èƒ½åŠ›ã€‚ - æ¯«ç§’çº§åˆ«çš„å»¶è¿Ÿã€‚ - å¼‚æ„ä»»åŠ¡çš„æ”¯æŒã€‚ - ä»»åŠ¡æ‹“æ‰‘å›¾åŠ¨æ€ä¿®æ”¹çš„èƒ½åŠ›ã€‚ - ç¼ºç‚¹ï¼š - APIå±‚ä»¥ä¸Šçš„éƒ¨åˆ†è¿˜æ¯”è¾ƒè–„å¼±ï¼ŒCoreæ¨¡å—æ ¸å¿ƒé€»è¾‘ä¼°éœ€è¦æ—¶é—´æ‰“ç£¨ã€‚ - å›½å†…ç›®å‰é™¤äº†èš‚èšé‡‘æœå’ŒRISELabæœ‰é’ˆå¯¹æ€§çš„åˆä½œä»¥å¤–ï¼Œå…³æ³¨ç¨‹åº¦è¿˜å¾ˆä½ï¼Œæ²¡æœ‰å®é™…çš„åº”ç”¨å®ä¾‹çœ‹åˆ°ï¼Œæ•´ä½“æ¥è¯´è¿˜å¤„äºæ¯”è¾ƒæ—©æœŸçš„æ¡†æ¶æ„å»ºé˜¶æ®µã€‚ - ç”¨é€”ï¼š å¢å¼ºå­¦ä¹  - åˆ†ç±» - èšç±» - å›¾åƒè¯†åˆ« - æ¨èç³»ç»Ÿ - æ–‡æœ¬ç¿»è¯‘ - Application: deep reinforcement learning using RLlib, scalable hyperparameter search using Ray Tune, automatic program synthesis using AutoPandas, etc. (advanced library from tutorial) Reference https://blog.csdn.net/lzc4869/article/details/94663616","link":"/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%BA%8C-Ray.html"},{"title":"å¥‡è¿¹å”±ç‰‡è¡Œ","text":"è¢«è®¸è®¸å¤šå¤šå¾®å°åˆå¹³å‡¡çš„äº‹ç‰©è£…ç‚¹è¿‡çš„ç”Ÿæ´»æœ¬èº«ï¼Œä¸€ç›´é²œæ´»è€Œç¿çƒ‚ï¼Œé—ªè€€åˆ°è®©æˆ‘ä»¬æ— è®ºå¦‚ä½•ï¼Œéƒ½çœ‹å¾—åˆ°ã€‚ â€”smarttreeï¼ˆæ¥è‡ªè±†ç“£ï¼‰ ã€Šå¥‡è¿¹å”±ç‰‡è¡Œã€‹ ä¼°è®¡è¿™æ˜¯2018å¹´èƒ½å®Œæˆçš„æœ€åä¸€æœ¬ä¹¦äº†ï¼Œå½“ç„¶æˆ‘å¹¶æ²¡æœ‰æŒ‡æœ›åœ¨æ¥ä¸‹æ¥çš„4å¤©èƒ½çœ‹å®Œä¸€æœ¬ä¹¦ã€‚ æˆ‘è›®äº«å—åœ¨åŸå¸‚ç©¿æ¢­çš„è¿‡ç¨‹ä¸­ä»æœ‰ä¸€æ®µé™é»˜çš„æ—¶å…‰ï¼Œä¹Ÿå¾ˆåº†å¹¸æœ€ååœ¨åœ°é“ä¸Šå®Œæˆäº†æœ¬ä¹¦çš„é˜…è¯»ï¼Œä¸Šä¸€æ¬¡æœ‰åŒæ ·çš„ç»å†è¿˜æ˜¯åœ¨é£æœºä¸Šã€‚å·§äº†ï¼Œè¿™æ¬¡æ˜¯é€æœ‹å‹å»åé£æœºã€‚ è¿™æœ¬ä¹¦æˆ‘è›®å–œæ¬¢ä¸¤ä¸ªå…ƒç´  1.éŸ³ä¹ 2.è‡ªç”±ï¼ˆçˆ±æƒ…è¿™ç©æ„æš‚ä¸”ä¸è°ˆï¼‰ æˆ–è®¸ä½©æ ¼ï¼ˆç”·ä¸»æ¯äº²ï¼‰å¹¶ä¸èƒ½ç§°ä¹‹ä¸ºä¸€ä¸ªâ€œåˆæ ¼â€çš„æ¯äº²ï¼Œå¥¹æ²¡æœ‰ç»™ç”·ä¸»å¼—å…°å…‹è¶³å¤Ÿçš„æ¯çˆ±ï¼Ÿæˆ–è€…è¶³å¤Ÿçš„ç…§é¡¾ï¼Ÿä½†é‡è¦çš„æ˜¯ï¼Œä»–ç»™äº†å¥¹æ¬£èµéŸ³ä¹çš„æŠ€å·§å’Œå’Œå¯»æ‰¾éŸ³ä¹çš„èƒ½åŠ›ã€‚æˆ–è®¸æ˜¯å› ä¸ºä»å°çš„å®¶æ•™ä¸åŒäºä¼ ç»Ÿçš„å®¶åº­ï¼Œä»–çš„ä¸€ç”Ÿæ³¨å®šä¸ä¼šå’Œæ™®é€šäººä¸€æ ·ï¼Œä»¿ä½›ä»–çš„ä¸€ç”Ÿï¼Œå°±ä¸ºäº†è¿½æ±‚äººä»¬æ‰€æŠ›å¼ƒçš„ä¸œè¥¿ï¼šå”±ç‰‡ã€‚æˆ–è¯´æ˜¯ï¼Œä»–æ‰€ç†è§£çš„éŸ³ä¹ã€‚ä»–æ˜¯ä¸€ä¸ªä¼˜ç§€çš„è†å¬è€…ï¼Œå€¾å¬ä»–äººçš„æ¬¢å–œå’Œè‹¦æ¥šï¼Œåˆ©ç”¨å¼—å…°å…‹è‡ªå·±æ‰€ç†è§£çš„éŸ³ä¹ï¼Œæ¨èç»™åˆ«äººï¼Œé€šè¿‡éŸ³ä¹æ²»æ„ˆå¿ƒçµã€‚æˆ‘çœ‹è¿™æœ¬ä¹¦ï¼Œå›ºå®šçš„bgmæ˜¯Loving Vincentçš„OSTï¼Œè¿™ä¸ªä¸“è¾‘å¾ˆç¬¦åˆé‚£ç§å®‰é™çš„æ°›å›´ï¼Œä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼Œæˆ‘æ€»æ„Ÿè§‰æ­Œå’Œä¹¦æ˜¯ä¸€æ ·çš„ï¼Œæœ‰å¾ˆå¤šçš„æƒ³è±¡ç©ºé—´ï¼Œèƒ½è®©æˆ‘åœ¨å›¾ä¹¦é¦†å“­æˆæ³ªäººï¼Œä¹Ÿèƒ½è®©æˆ‘åœ¨å›°éš¾çš„æ—¶å€™å¼ºæŒ¤å‡ºä¸€ä¸ªæ¸©æš–çš„ç¬‘å®¹ã€‚åœ¨çœ‹è¿™æœ¬ä¹¦çš„æ—¶å€™ï¼Œæˆ‘æ›¾æƒ³åˆ°ä¹‹å‰åœ¨å›½å®¶å¤§å‰§é™¢å¬åˆ°çš„éŸ³ä¹ä¼šï¼Œé‚£ç§éœ‡æ’¼åŠ›ï¼Œå“ªæ€•éŸ³è´¨æœ€é«˜çš„éŸ³ä¹ä¹Ÿéš¾ä»¥æœ›å…¶é¡¹èƒŒã€‚ è‡ªç”±ï¼Œä¹¦ä¸­æ¯ä¸ªä¸ªä½“ï¼Œå¿ƒçµä¸Šéƒ½æ˜¯è‡ªç”±çš„ã€‚å“ªæ€•æ˜¯å†å¹³å‡¡çš„ç”Ÿæ´»ï¼Œä¹Ÿèƒ½ä¹åœ¨å…¶ä¸­ï¼Œä½†ç¤¾ä¼šå˜åŒ–å¤ªå¿«äº†ï¼Œä¸€æŠŠç«çš„åŠŸå¤«ï¼Œçƒ§æ¯äº†å”±ç‰‡è¡Œï¼Œæ–­äº†å¼—å…°å…‹çš„æ¢¦ï¼Œä»–ä¹Ÿä¸å¾—ä¸ä¸ºäº†ç”Ÿæ´»ï¼Œæ”¾å¼ƒäº†è‡ªå·±å¸Œæœ›ä¸€è¾ˆå­éƒ½èƒ½ä»äº‹çš„å·¥ä½œ-å”±ç‰‡è¡Œè€æ¿ã€‚è‹¥ä¸æ˜¯é‚£çŸ­çŸ­çš„ä¸€æ¬¡é‚‚é€…ï¼Œå¦‚ä»Šçš„ä»–æ—©å·²è¿‡ä¸Šâ€œæ™®é€šäººâ€çš„ç”Ÿæ´»ã€‚å…¨ä¹¦ä»¿ä½›å°±æ˜¯å›´ç»•ä¸¤ä¸ªè¯ CDå’Œé»‘èƒ¶å”±ç‰‡ æ¥åˆ»ç”»å¼—å…°å…‹çš„äººç”Ÿï¼Œä»–å´‡å°šå”±ç‰‡ï¼Œè®¤ä¸ºCDæ²¡æœ‰çµé­‚ï¼Œå“ªæ€•æ˜¯æ‰€æœ‰çš„é›¶å”®å•†æ–­äº†ä»–çš„è´¢è·¯ï¼Œä»–ä¹Ÿä¸ºäº†å¿ƒä¸­çš„æ¢¦æƒ³ï¼Œä¸€ç‚¹ä¸€ç‚¹åŠªåŠ›ç€ã€‚å¾ˆå¿«çš„ï¼ŒCDè¢«æ•°å­—åŒ–çš„ç”Ÿæ´»æ‰€å–ä»£ï¼Œäººä»¬çº·çº·æˆ´ä¸Šè€³æœºï¼Œåªè¦æ‰‹æŒ‡è½»è½»ä¸€åŠ¨ï¼Œæƒ³è¦æ’­æ”¾çš„éŸ³ä¹å°±è‡ªåŠ¨æµè¿›è€³æœµã€‚æœ¬ä¹¦çš„æœ€åï¼Œå¾—åˆ°ä»–äººå¸®åŠ©åçš„å¼—å…°å…‹ï¼Œé‡æ–°ç»è¥èµ·äº†å”±ç‰‡è¡Œï¼Œå¯è¿™æ¬¡ï¼Œä»–çš„èº«è¾¹å¤šäº†ä¸€ä¸ªå¯ä»¥ä¸€ç›´é™ªä¼´ä»–çš„äººã€‚ ä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼Œæ„Ÿè§‰è¿™æœ¬ä¹¦æœ‰äº›åœ°æ–¹å’Œã€Šå²›ä¸Šä¹¦åº—ã€‹è›®åƒï¼Œæˆ–è®¸å› ä¸ºä¹¦å’ŒéŸ³ä¹ï¼Ÿ ä¸ç®¡äº†ï¼Œåˆä¸€æ®µç²¾å½©çš„æ—…ç¨‹ç”»ä¸Šå¥å·ï¼Œåœ°é“å¿«åˆ°ç«™äº†ï¼Œæˆ‘è¦æ”¶æ‹¾æ”¶æ‹¾ä¸‹è½¦äº†ã€‚ ä»¥ä¸‹å†…å®¹æ‘˜è‡ªã€Šå¥‡è¿¹å”±ç‰‡è¡Œã€‹ é»‘èƒ¶å”±ç‰‡æ˜¯æœ‰ç”Ÿå‘½çš„ï¼Œä½ åªèƒ½ç­‰å¾…ã€‚ å„ç§ä¸åŒçš„éŸ³ä¹ä¹‹ä¸­éƒ½å¯ä»¥çœ‹è§ä¸åŒçš„ç”»é¢ï¼Œåªè¦ä½ è‚¯é©»è¶³è†å¬ã€‚ æœºä¼šå·²å¤±ï¼Œå°±åƒé”™è¿‡ç«è½¦æˆ–æŸç§æ›´é‡è¦çš„ä¸œè¥¿ä¸€æ ·â€”â€”æŸç§å†ä¹Ÿä¸ä¼šå‡ºç°çš„ä¸œè¥¿ã€‚ äºŒåä¸€å¹´çš„å²æœˆå¯ä»¥æµ“ç¼©æˆå¤šä¹ˆç®€çŸ­çš„å­—å¥å•Šã€‚è¿™ç©¶ç«Ÿæ˜¯å¥½äº‹è¿˜æ˜¯åäº‹å‘¢ï¼Ÿä¹Ÿæˆ–è®¸äººç”Ÿæœ¬å°±æ˜¯è¿™æ ·ã€‚","link":"/%E5%A5%87%E8%BF%B9%E5%94%B1%E7%89%87%E8%A1%8C.html"},{"title":"å¦‚çˆ¶å¦‚å­","text":"å½“é‡‘é’±ä½œä¸ºäº¤æ¢äº²æƒ…çš„ç­¹ç  åœ¨ç©¿æ¢­åŸå¸‚çš„å·´å£«ä¸Šå®Œæˆäº†æœ¬ä¹¦çš„é˜…è¯»ï¼Œå¤§æ¦‚3ä¸ªå¤šå°æ—¶çš„æ—¶é—´ï¼Œä¼°è®¡çœ‹å®Œè¿™éƒ¨ç”µå½±ï¼Œä¹Ÿå·®ä¸å¤šéœ€è¦è¿™ä¹ˆé•¿æ—¶é—´å§ã€‚ ä¸¤ä¸ªå…¨ç„¶ä¸åŒçš„å®¶åº­ç¯å¢ƒå¡‘é€ äº†åº†å¤šã€ç‰æ™´ä¸¤ä¸ªå°å­©è¿¥å¼‚çš„æ€§æ ¼ï¼Œåº†å¤šæ‡‚å¾—å¾…äººæ¥ç‰©çš„é“ç†ï¼Œæ˜¯å®¶é•¿çœ¼é‡Œçš„â€œå¥½å­©å­â€ï¼Œå½“ç„¶è¿™å’Œä»–çš„ç”Ÿé•¿ç¯å¢ƒæœ‰å…³ï¼Œçˆ¶äº²å¿™äºå·¥ä½œï¼Œæ¯äº²ä¹Ÿä¹ æƒ¯äº†ä¸€ä¸ªäººå®‰å®‰é™é™åœ°å¸¦å­©å­é•¿å¤§ï¼Œä¸¥æ ¼çš„å®¶è§„ï¼Œä¸‰ç‚¹ä¸€çº¿çš„æ—¥å¸¸ç”Ÿæ´»ï¼Œæ‰€æœ‰çš„ä¸€åˆ‡åœ¨åº†å¤šçˆ¶æ¯çœ¼é‡Œæ—©å·²æˆä¸ºç†æ‰€åº”å½“çš„ä¸œè¥¿ï¼Œä½†å› ä¸ºå­©å­æŠ±é”™çš„äº‹æƒ…ï¼Œæ—¥å¸¸çš„ç”Ÿæ´»èŠ‚å¥è¢«æ‰“ä¹±ï¼Œåº†å¤šä»¿ä½›æ˜¯å¯¼ç«ç´¢ï¼Œç‚¹ç‡ƒäº†è¿™ä¸ªç ´ç¢çš„å®¶åº­æœ€åçš„æ•‘å‘½ç¨»è‰ã€‚ç‰æ™´å‡ºç”Ÿåœ¨ä¹¡ä¸‹ï¼Œæˆ–è®¸æ˜¯èº«è¾¹éƒ½æ˜¯å°å­©çš„ç¼˜æ•…ï¼Œä»–å¾ˆä¼šç©ï¼Œå½“ç„¶ï¼Œæ˜¯çˆ¶æ¯çœ¼é‡Œæ‰€è°“çš„â€œè°ƒçš®æ£è›‹â€çš„å­©å­ï¼Œæ²¡æœ‰é‚£ä¹ˆå¤šçš„è§„çŸ©ï¼Œå°æ—¶å€™çš„ç‰æ™´å……æ»¡äº†å’Œçˆ¶æ¯å¿«ä¹çš„å›å¿†ã€‚ä»–ä»¬ä¸¤ä¸ªå› ä¸ºè¡€ç¼˜è€Œéœ€è¦è¢«äº¤æ¢ï¼Œä¸åœçš„äº¤æ¢ç”Ÿæ´»æ²¡æœ‰ç»™ç‰æ™´å¸¦æ¥å¤šå¤§çš„â€œè¿›æ­¥â€ï¼Œåå€’è®©åº†å¤šä»åŸæ¥çš„èƒ†å°ï¼Œå˜å¾—æ›´åŠ å¼€æœ—æ´»æ³¼ï¼ŒåŒæ ·çš„ï¼Œåº†å¤šçš„å®¶åº­ä¹Ÿå› ä¸ºè¿™ä»¶äº‹ï¼Œä»æ”¯ç¦»ç ´ç¢çš„æ„Ÿæƒ…ä¸­é€æ¸æ‰¾åˆ°å±äºè‡ªå·±çš„äº²æƒ…ã€‚ åº†å¤šçš„çˆ¶äº²è‰¯å¤šå·¥ä½œé¡ºåˆ©ï¼Œå®¶åº­â€œç¾æ»¡â€ï¼Œæ˜¯å¤–äººåªè¦æèµ·å°±ä¼šç¾¡æ…•çš„â€œå¥½ç”·äººâ€å½¢è±¡ï¼Œä½†ä»–å°†å¯¹å·¥ä½œä¸­çš„æ€åº¦æ”¾åˆ°äº†æ—¥å¸¸çš„ç”Ÿæ´»ä¸­ï¼Œä¸å…è®¸è‡ªå·±å’Œå…¶ä»–äººæœ‰ä»»ä½•çš„è¿‡é”™ã€‚å› ä¸ºä»–å¯¹äºå·¥ä½œæœ‰è¿‘ä¹ç—´è¿·çš„çŠ¶æ€ï¼Œè¿™å¯¼è‡´äº†ä»–æ²¡æœ‰è¿‡å¤šå‚ä¸åˆ°åº†å¤šæˆé•¿çš„ç‰‡æ®µä¸­ï¼Œè¿›è€Œï¼Œä»–æ²¡æœ‰ç†è§£åº†å¤šæ¯äº²ç»¿çš„è¾›è‹¦å°±æ˜¾å¾—æœ‰é‚£ä¹ˆå‡ åˆ†åˆç†ï¼Œå½“ä»–çŸ¥é“äº†åº†å¤šä¸æ˜¯è‡ªå·±çš„è¡€è‚‰çš„æ—¶å€™ï¼Œä»–çš„æ€åº¦å¼€å§‹å˜å¾—å†·æ·¡ï¼Œæƒ³è±¡æ‰€æœ‰åº†å¤šåšçš„ä¸å¥½çš„åœ°æ–¹ï¼Œå˜´é‡Œå†’å‡ºäº†é‚£å¥å¦ç»¿æœ€ä¸ºç—›å¿ƒçš„ä¸€å¥è¯â€œæœç„¶å°±æ˜¯è¿™æ ·å•Šâ€ï¼Œä»–æŠŠæ‰€æœ‰ä¸å¥½çš„ä¸œè¥¿éƒ½å½’ç»“ä¸ºç»¿çš„ä¸å¯¹å’Œè¡€ç¼˜ï¼ŒæŠŠæ‰€æœ‰å¯¹çš„äº‹æƒ…éƒ½å½“æ˜¯ç†æ‰€åº”å½“ï¼Œå½“ä»–æƒ³ç”¨é‡‘é’±æ”¶ä¹°ç‰æ™´ï¼Œå°†ä¸¤ä¸ªå­©å­éƒ½å ä¸ºå·±æœ‰çš„æ—¶å€™ï¼Œç»¿å¼€å§‹æ„è¯†åˆ°ï¼Œåœ¨ä»–çœ¼é‡Œï¼Œä¸€ä¸ªæ¯äº²å¯¹ä¸€ä¸ªå­©å­æƒ…æ„Ÿçš„ä»˜å‡ºæ˜¯å¯ä»¥ç”¨é‡‘é’±å»äº¤æ¢çš„ã€‚ æ•…äº‹å’Œæˆ‘é¢„æƒ³çš„ç»“æœä¸å¤ªä¸€æ ·ï¼Œåœ¨æˆ‘çœ¼é‡Œï¼Œè‰¯å¤šæ˜¯ä¸åº”è¯¥æœ‰å­©å­çš„ï¼Œåº†å¤šå’Œç‰æ™´åº”è¯¥éƒ½å±äºä»–ä»¬ï¼Œä½†è¿™å¯¹äºç»¿çš„æ‰“å‡»å¤ªå¤§äº†ï¼Œå¤ªå¤§äº†ï¼Œå¥¹å¯¹äºåº†å¤šå€¾æ³¨äº†å¤ªå¤šå¤ªå¤šæ„Ÿæƒ…ï¼Œæ•…äº‹çš„æœ€ååº†å¤šè¿˜æ˜¯å±äºè‰¯å¤šå’Œç»¿ï¼Œä½†è¿™æ¬¡ï¼Œè‰¯å¤šä»ç‰æ™´èº«ä¸Šï¼Œå­¦åˆ°äº†å¾ˆå¤šä¸ºäººçˆ¶åº”è¯¥æœ‰çš„æ ·å­ï¼ŒåŒæ ·éƒ½æ˜¯çˆ¶äº²ï¼ŒåŒæ ·éƒ½æ˜¯ä¸€ä»½å·¥ä½œï¼Œæœ‰äº›äººï¼Œå¯ä»¥å’Œå­©å­ç»“ä¸‹æ·±åšçš„å‹æƒ…ï¼Œè€Œæœ‰äº›äººï¼Œåªæ˜¯æŠ«ç€â€œçˆ¶äº²â€çš„å¤–è¡£ç½¢äº†ã€‚ è¿™æ˜¯æˆ‘å®Œæˆçš„ç¬¬ä¸‰æœ¬æ˜¯æè£•å’Œçš„ä½œå“ï¼Œæˆ‘è›®å–œæ¬¢ä»–è¿™ç§ï¼Œè¿‘ä¹å¹³æ·¡çš„æ‰‹æ³•æŠŠç”Ÿæ´»æå†™çš„é‚£ä¹ˆæ·±å…¥äººå¿ƒï¼Œå¦‚æ­¤çœŸå®çš„ç”Ÿæ´»åœ¨ç°å®ç”Ÿæ´»ä¸­ï¼Œå“ªæ€•åœ¨ä¸­å›½ï¼Œææ€•ä¹Ÿæ˜¯æ¯å¤©éƒ½åœ¨éƒ½åœ¨ä¸Šæ¼”å§ã€‚","link":"/%E5%A6%82%E7%88%B6%E5%A6%82%E5%AD%90.html"},{"title":"å²›ä¸Šä¹¦åº—","text":"å¯’å‡ä¹¦å•2 ç‹¬è‡ªç”Ÿæ´»çš„çœŸæ­£éš¾å¤„åœ¨äºæ²¡äººåœ¨ä¹ä½ æ˜¯å¦å¿ƒçƒ¦æ„ä¹± æ˜¨å¤©çš„æ‰˜ç¦è¯¾å®åœ¨ä¸Šå¾—å¿ƒçƒ¦æ„ä¹±ï¼Œç”šè‡³åœ¨é˜…è¯»ã€Šå²›ä¸Šä¹¦åº—ã€‹æ—¶éƒ½äº§ç”Ÿäº†ä¸€ç§è´Ÿé¢çš„æƒ…æ„Ÿã€‚ä¸ç®¡æ€ä¹ˆæ ·ï¼Œæˆ‘è¿˜æ˜¯å®Œæˆäº†å¯¹è¿™æœ¬ä¹¦çš„é˜…è¯»ã€‚ã€Šå²›ä¸Šä¹¦åº—ã€‹æ˜¯å…³äºâ€œçˆ±ä¸è¢«çˆ±â€çš„æ•…äº‹ï¼Œä¹¦ä¸­å…³äºçˆ±æƒ…çš„è§‚ç‚¹æˆ‘åœ¨äº’è”ç½‘ä¸­è§è¿‡ç›¸ä¼¼çš„æå†™ï¼Œä½†è¿˜æ²¡æœ‰åšåˆ°äº²èº«ç»å†ï¼Œæ‰€ä»¥æš‚ä¸è¯„è®ºã€‚æ‰€ä»¥å¯¹äºè¿™æœ¬ä¹¦ï¼Œæˆ‘èƒ½æ„Ÿå—åˆ°çš„æœ€å¤§çš„é—æ†¾å°±æ˜¯ã€‚ä¹¦ä¸­æåˆ°çš„æ‰€æœ‰ä¹¦ç›®ï¼Œæˆ‘åŸºæœ¬ä¸Šæ²¡æœ‰çœ‹è¿‡ä¸€æœ¬ï¼Œä½œè€…å¯¹äºæƒ…æ„Ÿçš„æŠŠæ¡ï¼Œå¾ˆå¤šæ˜¯ä¾é™„äºå…¶ä»–å°è¯´çš„è§’è‰²ä¸Šé¢ï¼Œæ‰€ä»¥è¯´ï¼Œæˆ‘è¿˜æœ‰å¾ˆé•¿ä¸€æ®µè·¯è¦èµ°ã€‚æœ€åå¼•ç”¨ä¹¦ä¸­å°å¥³å­©å¯¹çº¸è´¨ä¹¦çš„å½¢å®¹ç»“æŸè¿™æ®µè¯„è®º ï¼ˆä¸œè¥¿ï¼‰ â€œçˆ¸çˆ¸çš„é¦™çš‚ï¼Œé’è‰ï¼Œå¤§æµ·ï¼Œå¨æˆ¿é‡Œçš„é¤æ¡Œï¼ŒåŠå¥¶é…ªã€‚â€","link":"/%E5%B2%9B%E4%B8%8A%E4%B9%A6%E5%BA%97.html"},{"title":"ç—›è‹¦çš„MARL(ä¸€)","text":"å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ (ä¸€) åŸºç¡€çŸ¥è¯†ä¸åšå¼ˆ 1. å¼•è¨€ å¤šæ™ºèƒ½ä½“é€šè¿‡å’Œç¯å¢ƒè¿›è¡Œäº¤äº’è·å–å¥–åŠ±å€¼æ¥å­¦ä¹ æ”¹å–„è‡ªå·±çš„ç­–ç•¥ï¼Œå…¶é‡ç‚¹åŒºåˆ«äºå• agent å¼ºåŒ–å­¦ä¹ ã€‚ ç®—æ³•æ”¶æ•›æ€§ä¸æ¯ä¸ª agent çš„æœ€ä¼˜ç­–ç•¥ç›¸å…³ï¼Œå…¶æœ€ä¼˜ç­–ç•¥åˆä¸ç©ºé—´ä¸­å…¶ä»–çš„ agent ç›¸å…³è”ã€‚ è”ç»“åŠ¨ä½œ:æ¯ä¸ªæ™ºèƒ½ä½“å½“å‰åŠ¨ä½œç»„åˆè€Œæˆçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå½“å‰æ—¶åˆ»çš„åŠ¨ä½œ \\[ A_t = [a_{1 ,t},a_{2 ,t},...,a_{n ,t}]^T \\] å…¶ä¸­\\(a_{i,t}\\)è¡¨ç¤ºç¬¬ i ä¸ªæ™ºèƒ½ä½“åœ¨æ—¶åˆ» té€‰å–çš„åŠ¨ä½œ ## 2. åšå¼ˆè®º ç”±äºå¤š agent ä¹‹é—´æ¶‰åŠåˆ°åˆä½œå’Œç«äº‰å…³ç³»ï¼Œå¼•å…¥åšå¼ˆçš„æ¦‚å¿µã€‚ ### 1. çŸ©é˜µåšå¼ˆ \\[ (n,A_1,A_2,...,A_n,R_1,R_2,...,R_n) \\] å…¶ä¸­ n ä¸º agent æ•°é‡ï¼Œ\\(A_i\\)ä¸ºç¬¬ i ä¸ª agent çš„ action é›†åˆï¼Œ\\(R_i\\)ä¸ºå¥–åŠ±å‡½æ•°ï¼Œå…¶å€¼ä¸ç©ºé—´ä¸­æ‰€æœ‰çš„ agent çš„ action é›†éƒ½æœ‰å…³ç³» Target: å¯»æ‰¾çº¯ç­–ç•¥æˆ–è€…æ··åˆç­–ç•¥ st å…¶æ”¶ç›Šè™½å¤§ #### 1. çº³ä»€å‡è¡¡ ç»™å®šå…¶ä»–ç©å®¶ç»§ç»­é‡‡ç”¨çº³ä»€å‡è¡¡ç­–ç•¥è€Œè¯¥ç©å®¶æ— æ³•é€šè¿‡æ”¹å˜å…¶è‡ªèº«ç­–ç•¥è·å¾—æ›´å¤§å›æŠ¥çš„æ‰€æœ‰ç©å®¶ç­–ç•¥çš„é›†åˆï¼Œå³ \\[ V_i(\\pi_1^*,...,\\pi_i^*,...,\\pi_n^*) \\geq V_i(\\pi_1^*,...,\\pi_i,...,\\pi_n^*) \\] å…¶ä¸­ \\(V_i(.)\\) è¡¨ç¤ºç©å®¶ i åœ¨ç»™å®šç©å®¶ç­–ç•¥ä¸‹çš„æœŸæœ›å›æŠ¥ï¼Œå…¶å«ä¹‰ä¸º\\(\\sum\\)ç”¨æˆ· i åœ¨è”åˆåŠ¨ä½œä¸‹æ‰€è·å¾—å›æŠ¥ä¹˜ä»¥æ¯ä¸ªç”¨æˆ·é‡‡ç”¨çº³ä»€å‡è¡¡ç­–ç•¥ä¸‹é€‰æ‹©è¯¥åŠ¨ä½œçš„æ¦‚ç‡ï¼Œ \\(\\pi_i\\)è¡¨ç¤ºç©å®¶ i åœ¨ç­–ç•¥ç©ºé—´\\(\\prod_i\\)ä¸­é€‰æ‹©çš„ä»»ä¸€ç­–ç•¥(å¯ä»¥ç†è§£ä¸ºæ¦‚ç‡) #### 2. ä¸¥æ ¼çº³ä»€å‡è¡¡ å¤§äºç­‰äºå…¬å¼ä¸¥æ ¼æˆç«‹ #### 3. å®Œå…¨æ··åˆç­–ç•¥ Definition: The strategy that agent choose specific action based on possibity of all actions. Possibities of all actions ara more than 0 percentage. åœ¨çŒœç¡¬å¸åšå¼ˆä¸­ï¼Œåªè¦ç”¨æˆ· 50%çš„æ¦‚ç‡é€‰æ‹©æ­£é¢ï¼Œ50%çš„æ¦‚ç‡é€‰æ‹©åé¢ï¼Œæ‰èƒ½è·å¾—æœ€å¤§æ”¶ç›Šã€‚å¦‚æœæŒ‰ç…§çº¯ç­–ç•¥ä¸€ç›´é€‰æ‹©æ­£é¢ï¼Œåˆ™å¯¹æ–¹ä¼šçŸ¥é“å¹¶é€‰æ‹©è®©è‡ªå·±ä¸€ç›´æ”¶ç›Šçš„æƒ…å†µï¼ˆä¸€ç›´æ­£é¢æˆ–åé¢ï¼‰ï¼Œæ— æ³•è¾¾åˆ°æœ€å¤§æ”¶ç›Š #### 4. çº¯ç­–ç•¥ åœ¨å›šå¾’å›°å¢ƒåšå¼ˆä¸­ï¼Œagent åœ¨ä»»ä½•æƒ…å†µä¸‹éƒ½é€‰æ‹©åŒæ ·çš„è¡Œä¸ºï¼Œä¹Ÿå°±æ˜¯å‘è­¦å®˜å¦ç™½ï¼Œè¿™æ—¶å€™æ— è®ºå¯¹æ–¹æ€ä¹ˆé€‰æ‹©ï¼Œè‡ªå·±éƒ½æ˜¯ reward å’Œéƒ½æ˜¯æœ€å¤§çš„ã€‚ ### 2. agentåœ¨çŸ©é˜µåšå¼ˆä¸­çš„çº³ä»€å‡è¡¡ å…¶å¥–åŠ±çŸ©é˜µä¸º \\[ \\begin{bmatrix} r_{11}&amp;r_{12} \\\\ r_{21}&amp;r_{22} \\end{bmatrix} \\] å…¶ä¸­è¡Œè¡¨ç¤ºè¡Œ agentï¼Œåˆ—è¡¨å¼åˆ— agentï¼Œå…¶ä¸‹è§’æ ‡è¡¨ç¤ºè¡Œåˆ— agent æ‰€é‡‡å–çš„åŠ¨ä½œè”ç»“ã€‚ #### 5. é›¶å’Œåšå¼ˆ æ¯ç©ä¸€å±€æ¸¸æˆï¼Œéƒ½æœ‰ä¸€ä¸ªç©å®¶ä¼šèµ¢è€Œå¦ä¸€ä¸ªç©å®¶ä¼šè¾“ã€‚ä¸¤ä¸ªç©å®¶ä¸ºå®Œå…¨ç«äº‰å…³ç³»ï¼Œ #### 6. ä¸€èˆ¬å’Œåšå¼ˆ ä»»ä½•ç±»å‹çš„çŸ©é˜µåšå¼ˆ ### 3. å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ç­–ç•¥ å¼•å…¥ä»–å¦ˆçš„éšæœºåšå¼ˆï¼šå¤šæ™ºèƒ½ä½“å¤šä¸ªçŠ¶æ€ï¼Œæ˜¯é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹å’ŒçŸ©é˜µåšå¼ˆçš„è¿‡ç¨‹ã€‚","link":"/%E7%97%9B%E8%8B%A6%E7%9A%84MARL-%E4%B8%80.html"},{"title":"æˆ¿æ€çªçš„åˆæ‹ä¹å›­","text":"å¯’å‡ä¹¦å•1 ç—›è‹¦çš„é™…é‡æ˜¯å¦‚æ­¤éš¾ä»¥åˆ†äº«ï¼Œå¥½é™©è¿™ä¸ªä¸–ç•Œè¿˜æœ‰æ–‡å­¦ã€‚ æˆ‘æ˜¯çŸ¥é“äº†æœ¬ä¹¦ä½œè€…è‡ªæ€çš„æ¶ˆæ¯åæ‰å¼€å§‹äº†è§£è¿™æœ¬ä¹¦ï¼Œä»¿ä½›æ˜¯ä¸ºäº†è¿›è¡ŒæŸç§å®—æ•™ä»ªå¼ä¸€æ ·ï¼Œè¿«ä½¿æˆ‘å®Œæˆå¯¹æœ¬ä¹¦çš„é˜…è¯»ã€‚æœ¬ä¹¦è®²è¿°çš„å†…å®¹å¤§å®¶å¯ä»¥ç™¾åº¦ï¼Œæˆ‘å°±ä¸æ„¿å†æ¬¡æ­å¼€æ—çš„ç—›è‹¦ï¼Œå¦‚æœè¯´ä½ å¯¹æœ¬ä¹¦æœ‰å…´è¶£ï¼Œé‚£ä½ å¯ä»¥ç»§ç»­å¾€ä¸‹çœ‹äº†ï¼š æˆ‘ä¸çŸ¥é“åˆæ‹å¯¹äºä¸€ä¸ªå¥³ç”Ÿçš„é‡è¦æ€§ï¼Œä¹Ÿå½“ç„¶ä¸çŸ¥é“ï¼Œä¸€ä¸ªä¸­å¹´æœ‰å®¶å®¤çš„è€å¸ˆçš„èŠ±è¨€å·§è¯­å’Œè¡Œä¸ºä¸Šçš„æ”¾çºµç«Ÿèƒ½å¯¹ä¸€ä¸ªå¥³ç”Ÿçš„å½±å“ä¼šé‚£ä¹ˆå¤§ã€‚è¿™æœ¬ä¹¦å°±åƒæ˜¯æ¢¦é­‡ä¸€æ ·ï¼ŒæŠ˜ç£¨ç€æˆ‘ã€‚ è€å¸ˆä»¬è¯´é“â€œæˆ‘ä»¬ä¼šè€å»ï¼Œå¯å¥¹ä»¬ä¸ä¼šè€å»â€ï¼Œæ— é™çš„ç¾å¥½çš„å¿ƒçµåœ¨è€å¸ˆçœ¼ä¸‹å°±åªæ˜¯è¿˜æ²¡æœ‰å¤±å»å¹¶ç­‰å¾…å‰¥å¤ºçš„ç«¥çœŸçš„ç¾ä¸½è€Œåˆå……æ»¡è¯±æƒ‘çš„å°‘å¥³ã€‚æˆ¿æ€çªçš„çˆ±æƒ…å’Œäººç”Ÿåœ¨é«˜ä¸­å°±é™æ­¢äº†ï¼›å¦å¤–ä¸€ä¸ªå¥³ç”Ÿåœ¨ç½‘ç«™ä¸Šå“­è¯‰ï¼Œæ”¶è·çš„å´æ˜¯ç½‘å‹ä»¬çš„åƒåˆ€ä¸‡å‰ï¼Œâ€œè¦çˆ½å°±ç›´è¯´â€çš„å¥å­æˆ‘ä¸æ˜¯æ²¡æœ‰åœ¨ä¸­å›½çš„ç½‘ç«™ä¸Šçœ‹åˆ°è¿‡ã€‚æˆ¿æ€çªçš„â€œæ­»â€ä¸åªæ˜¯ç”±ç®€ç®€å•å•ä¸€ä¸ªè€å¸ˆçš„åŠŸåŠ³ï¼Œè€Œæ˜¯æ•´ä¸ªç¤¾ä¼šå¯¹äºæ€§çš„å›é¿å’Œå¯¹æ€§æš´åŠ›çš„æ¼ è§†æ‰€é€ æˆçš„ã€‚ çœ‹å®Œæ•´æœ¬ä¹¦ï¼Œæˆ‘ç¿»çœ‹äº†æ—çš„fbï¼Œæœ‰å¥è¯æˆ‘è›®è§¦åŠ¨ â€œæˆ‘çªç„¶å‘ç°æˆ‘å¯¹Båšçš„æœ€æ®‹å¿çš„äº‹æƒ…å°±æ˜¯è®©ä»–æ˜ç™½ï¼Œèº«ä¸ºé‡åº¦ç²¾ç¥ç—…æ‚£è€…çš„ä¼´ä¾£ï¼Œä»–æ— è®ºå¦‚ä½•éƒ½æ— æ³•è®©æˆ‘çœŸæ­£å¹¸ç¦â€ å¦‚æœè¯´ä½ æ˜¯ä¸€åç”·ç”Ÿï¼Œæˆ‘ä¼šå‘Šè¯‰ä½ ï¼Œè¿™æœ¬ä¹¦çš„å†…å®¹ä¼šæœ‰ç”»é¢æ„Ÿï¼Œäº§ç”Ÿç”Ÿç†ä½œç”¨ä¸è¦è§‰å¾—å®³ç¾ï¼Œå› ä¸ºæˆ‘å°±æ˜¯ï¼›å¦‚æœæ˜¯ä¸€åå¥³ç”Ÿï¼Œæˆ‘è¦è¯´ä¸€å£°æŠ±æ­‰ï¼Œå› ä¸ºæˆ‘æ˜¯ä¸æ„¿è®©ä½ å»çœ‹æ¸…è¿™ä¸ªä¸–ç•Œçš„é»‘æš—é¢çš„ã€‚ ä¸œè¥¿å†™åˆ°è¿™é‡Œä¹Ÿè¦ç»“æŸäº†ã€‚æœ‰ç§‘å­¦æ–‡ç« è¡¨æ˜ï¼Œäººä»¬åœ¨ç½‘ä¸Šçœ‹é•¿ç¯‡ä¸œè¥¿æ˜¯å‘ˆFå½¢çŠ¶çš„ï¼Œä¸ä¸ºå†…å®¹ï¼Œä¹Ÿè¦çœ‹äº†ç»“å°¾ã€‚æ—¢ç„¶è¿™æ˜¯æœ€åï¼Œé‚£æˆ‘å¸Œæœ›ä½ ï¼Œèƒ½å¥½å¥½å¯¹å¾…æ¯ä¸€åœºæ‹çˆ±ï¼Œå¯¹ä»¥å‰çœŸå¿ƒçˆ±è¿‡çš„äººè¯´å£°â€œæˆ‘çœŸçš„æœ‰çˆ±è¿‡ä½ â€â€¦ä»¥åŠï¼Œå¯¹é‚£äº›ç¤¾ä¼šä¸Šçš„â€œå¹¸å­˜è€…â€æŠ±ä»¥å®½å®¹çš„æ€åº¦ï¼Œæœ‰äº›ç—›ä½ æ˜¯ä¸ä¼šç»å†çš„â€¦â€¦..anywayæˆ‘åˆå¤šäº†ä¸€ä¸ªå†å»ä¸€æ¬¡å°æ¹¾çš„ç†ç”±","link":"/%E6%88%BF%E6%80%9D%E7%90%AA%E7%9A%84%E5%88%9D%E6%81%8B%E4%B9%90%E5%9B%AD.html"},{"title":"æ— å£°å‘Šç™½","text":"åˆ«è®©äººç”Ÿä»ä½ èº«æ—æºœèµ° æ–­æ–­ç»­ç»­çœ‹äº†å°†è¿‘ä¸€ä¸ªæœˆï¼Œæœ€åè¿˜æ˜¯åœ¨å›¾ä¹¦é¦†å®Œæˆäº†æœ¬ä¹¦çš„é˜…è¯»ã€‚æœ¬æ€€ç€æœŸå¾…çš„å¿ƒæƒ…ï¼Œå‘Šè¯‰å¥¹æ‰€æœ‰çš„æ•…äº‹çš„æƒ…èŠ‚ï¼Œä½†å½“æˆ‘æ¥èµ·ç”µè¯ï¼Œæ‰å‘ç°ï¼Œæˆ‘å¾ˆéš¾å»æ¢³ç†å‡ºä¸€æ¡ç®€å•çš„é€»è¾‘çº¿ç»™å¥¹è®²æ¸…æ¥šæ‰€æœ‰çš„æ•…äº‹æ¢—æ¦‚ï¼Œæˆ–è®¸ï¼Œå¥¹æ°¸è¿œéƒ½ä¸ä¼šç†è§£å§ã€‚ æˆ‘è®¤ä¸ºä¹¦é‡Œæç»˜äº†ä¸¤ä¸ªé‡ç‚¹ï¼Œä¸€ä¸ªæ˜¯ç›¸åŒï¼Œè€Œå¦ä¸€ä¸ªï¼Œæ˜¯ä¸åŒã€‚ è©¹å§†æ–¯ï¼Œä½œä¸ºç¬¬ä¸€æ‰¹åˆ°è¾¾ç¾å›½çš„ä¸­å›½äººï¼Œçš®è‚¤ï¼Œçœ¼ç›çš„é¢œè‰²ï¼Œæœé¥°éƒ½ä¸å½“åœ°äººæ ¼æ ¼ä¸å…¥ï¼Œè€Œä¸”è©¹å§†æ–¯çš„çˆ¶æ¯éƒ½æ˜¯è“é¢†ï¼Œå¹²ç€è©¹å§†æ–¯ä¸æ„¿æåŠçš„å·¥ä½œã€‚ä¸€å¿ƒæƒ³è¦å¯»æ±‚â€œç›¸åŒâ€çš„è©¹å§†æ–¯åŠªåŠ›å­¦ä¹ ï¼Œæ•™è‚²å­©å­ä¸€å®šè¦èå…¥é›†ä½“ï¼Œæ‰¾åˆ°å°ä¼™ä¼´ï¼Œå¯ç»ˆå…¶ä¸€ç”Ÿï¼Œè¿˜é€ƒä¸è¿‡ä¸€å¥ï¼šä¸­å›½ä½¬æ‰¾ä¸åˆ°ä¸­å›½äº†ã€‚ ç›ä¸½ç³æ˜¯ç¾å›½å‡ºç”Ÿçš„æ­£ç‰Œç¾å›½äººï¼Œæ¥å—ç€ç›¸åŒçš„å­¦æ ¡æ•™è‚²ï¼Œå®¶åº­æ•™è‚²ã€‚ä»å°å°±è¢«æ¯äº²æ•™è‚²è¦åšå¥½é¥­ï¼Œç…§é¡¾å¥½æœªæ¥ä¸ˆå¤«ï¼Œå­©å­çš„å¥¹å†…å¿ƒæ·±å¤„å…¶å®æ˜¯æ’æ–¥è¿™äº›ä¸œè¥¿çš„ã€‚å¥¹æƒ³è¦è·å¾—è‡ªå·±çš„ç”Ÿæ´»ï¼Œä¸æ„¿æˆä¸ºäººä»¬çœ¼ä¸­ç›¸åŒçš„å¥³äººã€‚å³ä½¿æ˜¯æœ‰äº†å­©å­ï¼Œå¥¹ä¹Ÿæ„¿æ„è¿œç¦»å­©å­å’Œä¸ˆå¤«ï¼Œä¸ºäº†å®Œæˆè‡ªå·±çš„æ¢¦æƒ³ã€‚ å°±æ˜¯è¿™ä¹ˆä¸¤ä¸ªäººç”Ÿé“è·¯å®Œå…¨ä¸åŒçš„äººï¼Œèµ°åˆ°äº†ä¸€èµ·ã€‚æˆ–è®¸æ˜¯è©¹å§†æ–¯æƒ³è¦å¯»æ±‚èå…¥ï¼Œè€Œç›ä¸½ç³æƒ³è¦å¯»æ±‚ä¸åŒç½¢äº†ã€‚å†¥å†¥ä¸­ï¼Œæœ‰äº›äº‹æƒ…å°±å·²å¼€å§‹æ”¹å˜ã€‚ä»–ä»¬æœ‰ä¸‰ä¸ªå­©å­ï¼Œå†…æ–¯ï¼Œè‰è¿ªäºšå’Œæ±‰å¨œã€‚ä½œä¸ºå®¶é‡Œçš„å¤§å¥³å„¿ï¼Œè‰è¿ªäºšå¯„æ‰˜äº†æ¯äº²å¤ªå¤šçš„æœŸå¾…ï¼Œå³ä½¿æ˜¯è¿èƒŒäº†è‡ªå·±çš„æ„æ„¿ï¼Œå½“æ¯äº²ä»ç¦»å®¶å‡ºèµ°åˆ°å›åˆ°å®¶çš„é‚£ä¸€åˆ»ï¼Œè‰è¿ªäºšçŸ¥é“äº†ï¼Œè‡ªå·±ä¸€å®šè¦å¬æ¯äº²çš„ï¼Œä¸ºäº†å¥¹ä¸å†ç¦»å¼€è¿™ä¸ªå®¶ã€‚æ…¢æ…¢çš„ï¼Œè‰è¿ªäºšèº«ä¸Šçš„æ‹…å­è¶Šæ¥è¶Šå¤šï¼Œç”Ÿç‰©ï¼Œç‰©ç†ï¼Œæ¯äº²æ ¹æœ¬æ²¡æœ‰äº†è§£çœŸæ­£çš„è‰è¿ªäºšï¼Œåªæ˜¯åœ¨å¿ƒä¸­æ„æƒ³äº†ä¸€ä¸ªè‡ªå·±å¸Œæœ›çš„è‰è¿ªäºšç½¢äº†ã€‚å½“è©¹å§†æ–¯çŸ¥é“äº†è¿™ä¸€åˆ‡æœ‰äº›å¥‡æ€ªå¹¶å‘Šè¯‰è‰è¿ªäºšè¦èå…¥é›†ä½“çš„æ—¶å€™ï¼Œä¸€åˆ‡éƒ½æ™šäº†ã€‚ç”±äºæ³¨æ„åŠ›çš„è½¬ç§»ï¼Œèº«ä¸ºè€å¤§çš„å†…æ–¯å¯ä»¥æ²‰æµ¸åœ¨è‡ªå·±çš„ä¸–ç•Œä¸­ï¼Œå³ä½¿è¿™ä¸ªä¸–ç•Œå¹¶æ²¡æœ‰è¢«çˆ¶æ¯æ‰€å…³å¿ƒã€‚ä»–æ˜ç™½è¿™ä¸ªå®¶åº­çš„é—®é¢˜å¹¶ä¸€å¿ƒæƒ³è¦é€ƒç¦»ï¼Œä½†ä»–è¿˜æ˜¯çˆ±è‰è¿ªäºšçš„ï¼Œäº†è§£å¥¹ï¼Œç…§é¡¾å¥¹ã€‚ä½†ï¼Œå½“å†…æ–¯å»äº†å“ˆä½›ï¼Œæ²¡æœ‰äº†å®¶åº­çš„ç¾ç»Šï¼Œä»–å°±åƒç ´èŒ§è€Œå‡ºçš„è´è¶ï¼Œä¸å†å›å¤´çœ‹æœ›è‡ªå·±é—ç•™ä¸‹çš„ä¸œè¥¿ï¼Œè€Œæ˜¯å±•å¼€ç¿…è†€è¿æ¥æ–°çš„ç”Ÿæ´»ã€‚ä½œä¸ºå®¶ä¸­å”¯ä¸€äº†è§£è‰è¿ªäºšçš„äººï¼Œä»–èµ°äº†ã€‚è‰è¿ªäºšæ²¡æœ‰äº†ä¾é ï¼Œå¥¹æƒ³è¦è§£è„±ï¼Œæƒ³è¦é€ƒç¦»ï¼Œå½“å¥¹è·ƒå…¥æ°´ä¸­ï¼Œç°å®çš„ä¸–ç•Œæ­£è¿œç¦»å¥¹çš„æ—¶å€™ï¼Œå¥¹æ‰¾åˆ°äº†çœŸæ­£çš„å½’å®¿ã€‚ æœ¬ä¹¦æ— å£°å‘Šç™½ï¼Œä¹ä¸€çœ‹è¿˜ä»¥ä¸ºçœŸçš„æ˜¯å‘Šç™½ã€‚Everything I never told youæ˜¯æœ¬ä¹¦çš„åŸåã€‚è‰è¿ªäºšè‡ªå§‹è‡³ç»ˆéƒ½æ²¡æœ‰å‘Šè¯‰çˆ¶æ¯å¥¹çœŸæ­£æƒ³è¦çš„ï¼Œä¸€å‘³åœ°ç­”åº”æ¯äº†å¥¹çš„ä¸€ç”Ÿã€‚è°ä¸æ˜¯è¿™æ ·å‘¢ï¼Œäººæ€»æ˜¯å……æ»¡å¹»æƒ³ï¼Œå¯ä»¥ä»¥åæ´»æˆè‡ªå·±æƒ³è¦çš„æ¨¡æ ·ï¼Œä½†ç°å®æ˜¯ï¼Œç»å¤§éƒ¨åˆ†éƒ½æˆä¸ºäº†åˆ«äººçœ¼ä¸­çš„â€œç›¸åŒâ€ã€‚éµå¾ªè‡ªå·±å†…å¿ƒçš„æƒ³æ³•çœŸçš„å¾ˆéš¾ï¼Œä½†æˆ–è®¸å½“ä½ æƒ³ç€ï¼Œäººæ­»äº†ï¼Œæ€»è¦ç•™ä¸‹ç‚¹ä»€ä¹ˆçš„æ—¶å€™ï¼Œä½ æˆ–è®¸å°±ä¼šå¤šä¸€ç‚¹åœ¨æ„è‡ªå·±çš„æƒ³æ³•äº†å§ã€‚ ä»¥ä¸Šè¿™äº›ï¼Œæˆ–è®¸å°±æ˜¯æˆ‘æƒ³å¯¹ä½ è¯´çš„ï¼Œä½†æœºä¼šå·²ç»è¿‡å»äº†ï¼Œé‡æ–°æèµ·æœªå…æœ‰äº›çªå…€ï¼Œå½“ç„¶ï¼Œæˆ‘ä¹Ÿä¸æ˜¯å¾ˆæƒ³åˆ†äº«ç»™ä½ ï¼Œå› ä¸ºä½ ä¸ä¼šå»ç†ä¼šï¼Œæˆ–è®¸æˆ‘è¿™è¾ˆå­ï¼Œåªèƒ½å’Œè‡ªå·±å»åˆ†äº«è¯»è¿‡çš„ä¹¦äº†å§ã€‚å¯¹ä½ ï¼Œæˆ‘çœŸçš„ä¸çŸ¥é“è¯¥æ€ä¹ˆåŠï¼ŒçœŸçš„ã€‚ å’Œè‰è¿ªäºšä¸€æ ·ï¼Œä»–ä»¬æ²¡æœ‰çœŸæ­£çš„æœ‹å‹ã€‚","link":"/%E6%97%A0%E5%A3%B0%E5%91%8A%E7%99%BD.html"},{"title":"ç—›è‹¦çš„MARL(ä¸‰)","text":"å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ å…¥é—¨ï¼ˆä¸‰ï¼‰â€”â€”MFMARLç®—æ³•ï¼ˆMean Field Multi-Agent RLï¼‰ Idea:å°†ä¼ ç»Ÿçš„å¤šæ™ºèƒ½ä½“ç®—æ³•ï¼ˆæ¯ä¸ªæ™ºèƒ½ä½“éƒ½éœ€è€ƒè™‘å…¶ä»–æ‰€æœ‰æ™ºèƒ½ä½“çš„åŠ¨ä½œä»¥åŠçŠ¶æ€å¾—åˆ°è”åˆåŠ¨ä½œå€¼å‡½æ•°ï¼‰æ›¿æ¢æˆä¸€ç§è¿‘ä¼¼å‡è®¾ï¼ˆå…¶ä»–æ‰€æœ‰æ™ºèƒ½ä½“å¯¹å…¶äº§ç”Ÿçš„ä½œç”¨å¯ä»¥ç”¨ä¸€ä¸ªå‡å€¼æ›¿ä»£ï¼‰--MFT å¹³å‡åœºç†è®º Based on MFT, there are two basic algoritms: MFQ &amp; MFAC. ï¼ˆåˆ†åˆ«æ˜¯å¯¹ Q learning å’Œ AC ç®—æ³•çš„æ”¹è¿›ï¼‰ ## 1. Mean Field MARL Idea: å°† Q å‡½æ•°ä¸­çš„å‚æ•°è°ƒæ•´ä¸ºåªåŒ…å«é‚»å±…ä¹‹é—´ç›¸äº’ä½œç”¨çš„å½¢å¼ï¼š \\[ Q_j(s,a)=\\frac{1}{N_j}\\sum _{k\\epsilon N_{(j)}}Q_j(s,a_j,a_k) \\] å…¶ä¸­\\(N_j\\)è¡¨ç¤ºé‚»å±…èŠ‚ç‚¹ä¸ªæ•°ï¼ŒçŠ¶æ€ä¿¡æ¯ s ä¸ºå…¨å±€ä¿¡æ¯ã€‚ 1. Mean Field è¿‘ä¼¼ 2. ç®—æ³•è®¾è®¡ MF-Q + MF-AC Algorithm 1. MF-Q 2. MFAC","link":"/%E7%97%9B%E8%8B%A6%E7%9A%84MARL-%E4%B8%89.html"},{"title":"ç—›è‹¦çš„MARL(äºŒ)","text":"å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ (äºŒ) åŸºç¡€ç®—æ³•ï¼ˆMiniMax-Qï¼ŒNashQï¼ŒFFQï¼ŒWoLF-PHCï¼‰ 1. å¼•è¨€ å†å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œéœ€è¦å¤š agent åœ¨ä¸ç¯å¢ƒäº¤äº’è¿‡ç¨‹ä¸­ä¸æ–­å­¦ä¹ æ¯ä¸ªçŠ¶æ€çš„å¥–åŠ±å€¼ Qå‡½æ•°ï¼Œå†é€šè¿‡ Qå‡½æ•°æ¥å­¦ä¹ å¾—åˆ°æœ€ä¼˜çº³ä»€ç­–ç•¥ã€‚ åˆç†æ€§ï¼ˆrationalityï¼‰æ˜¯æŒ‡åœ¨å¯¹æ‰‹ä½¿ç”¨ä¸€ä¸ªæ’å®šç­–ç•¥çš„æƒ…å†µä¸‹ï¼Œå½“å‰æ™ºèƒ½ä½“èƒ½å¤Ÿå­¦ä¹ å¹¶æ”¶æ•›åˆ°ä¸€ä¸ªç›¸å¯¹äºå¯¹æ‰‹ç­–ç•¥çš„æœ€ä¼˜ç­–ç•¥ã€‚ æ”¶æ•›æ€§ï¼ˆconvergenceï¼‰æ˜¯æŒ‡åœ¨å…¶ä»–æ™ºèƒ½ä½“ä¹Ÿä½¿ç”¨å­¦ä¹ ç®—æ³•æ—¶ï¼Œå½“å‰æ™ºèƒ½ä½“èƒ½å¤Ÿå­¦ä¹ å¹¶æ”¶æ•›åˆ°ä¸€ä¸ªç¨³å®šçš„ç­–ç•¥ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œæ”¶æ•›æ€§é’ˆå¯¹ç³»ç»Ÿä¸­çš„æ‰€æœ‰çš„æ™ºèƒ½ä½“ä½¿ç”¨ç›¸åŒçš„å­¦ä¹ ç®—æ³•ã€‚ 2. Minimax-Qç®—æ³• Condition: ä¸¤ä¸ªç©å®¶çš„é›¶å’Œéšæœºåšå¼ˆ(eg.æŠ›ç¡¬å¸) Idea: åˆ©ç”¨ Qlearning çš„æ–¹æ³•æ›´æ–°Qå€¼ Algorithm: 3. Nash Q-Learningç®—æ³• Condition: å¤šä¸ªç©å®¶çš„ä¸€èˆ¬å’Œåšå¼ˆ(å®Œå…¨å¯¹æŠ—åšå¼ˆã€å®Œå…¨åˆä½œåšå¼ˆä»¥åŠäºŒè€…çš„æ··åˆåšå¼ˆ) Idea: ä½¿ç”¨äºŒæ¬¡è§„åˆ’æ±‚è§£çº³ä»€å‡è¡¡ç‚¹ Algorithm: é€šè¿‡ç®—æ³•å¯ä»¥å¾—çŸ¥ï¼Œåœ¨æ›´æ–° Q å€¼æ—¶ï¼Œå–ä»£äº†ä¼ ç»Ÿçš„æœŸæœ›å¥–åŠ± V å‡½æ•°ï¼Œè¿™é‡Œç”¨äº† Nash å‡½æ•°è¿›è¡Œäº†æ›´æ–°,éœ€è¦è§‚æµ‹å…¶ä»–æ‰€æœ‰æ™ºèƒ½ä½“çš„åŠ¨ä½œ \\(a_i\\) ä¸å¥–åŠ±å€¼ \\(r_i\\) 4. Friend-or-Foe Q-Learningç®—æ³• Condition: ä¸€ä¸ªæ™ºèƒ½ä½“iï¼Œå°†å…¶ä»–æ‰€æœ‰æ™ºèƒ½ä½“åˆ†ä¸ºä¸¤ç»„ï¼Œä¸€ç»„ä¸ºiçš„friendå¸®åŠ©iä¸€èµ·æœ€å¤§åŒ–å…¶å¥–åŠ±å›æŠ¥ï¼Œå¦ä¸€ç»„ä¸ºiçš„foeå¯¹æŠ—iå¹¶é™ä½içš„å¥–åŠ±å›æŠ¥ï¼Œå› æ­¤å¯¹æ¯ä¸ªæ™ºèƒ½ä½“è€Œè¨€éƒ½æœ‰ä¸¤ç»„ã€‚è¿™æ ·ä¸€ä¸ªnæ™ºèƒ½ä½“çš„ä¸€èˆ¬å’Œåšå¼ˆå°±è½¬åŒ–ä¸ºäº†ä¸€ä¸ªä¸¤æ™ºèƒ½ä½“çš„é›¶å’Œåšå¼ˆ Idea: å°†å‰©ä½™ agent è¿›è¡Œåˆ†ç»„ï¼Œåœ¨çº³ä»€å‡è¡¡ç­–ç•¥æ±‚è§£ä¸­ï¼Œä¼ ç»Ÿçš„æ‰€æœ‰ action æ›¿æ¢ä¸ºäº†å¸®åŠ©è‡ªå·±çš„ action å’Œæ•Œäººçš„ action Algorithm: ä¸ºäº†æ›´æ–° Q å€¼ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“éœ€è¦åœ¨æ¯ä¸€æ­¥è§‚æµ‹å…¶ä»–æ‰€æœ‰friendä¸foeçš„æ‰§è¡ŒåŠ¨ä½œã€‚ 5. WoLF Policy Hill-Climbingç®—æ³• Condition: æ¯ä¸ªæ™ºèƒ½ä½“åªç”¨ä¿å­˜è‡ªå·±çš„åŠ¨ä½œæ¥å®Œæˆå­¦ä¹ ä»»åŠ¡,ä¸ªäººè®¤ä¸ºä¸ºäº†é¿å…å‰é¢ä¸‰ä¸ªç®—æ³•å¸¦æ¥çš„ç»´åº¦ç¾éš¾é—®é¢˜ï¼Œå› ä¸ºæ¯ä¸ª agent éƒ½éœ€è¦å­˜å‚¨æ‰€æœ‰ agent çš„åŠ¨ä½œé›†ã€‚ Idea: WolF:å½“æ™ºèƒ½ä½“åšçš„æ¯”æœŸæœ›å€¼å¥½çš„æ—¶å€™å°å¿ƒç¼“æ…¢çš„è°ƒæ•´å‚æ•°ï¼Œå½“æ™ºèƒ½ä½“åšçš„æ¯”æœŸæœ›å€¼å·®çš„æ—¶å€™ï¼ŒåŠ å¿«æ­¥ä¼è°ƒæ•´å‚æ•°ã€‚ PHC:ä¸€ç§å•æ™ºèƒ½ä½“åœ¨ç¨³å®šç¯å¢ƒä¸‹çš„ä¸€ç§å­¦ä¹ ç®—æ³•ã€‚è¯¥ç®—æ³•çš„æ ¸å¿ƒå°±æ˜¯é€šå¸¸å¼ºåŒ–å­¦ä¹ çš„æ€æƒ³ï¼Œå¢å¤§èƒ½å¤Ÿå¾—åˆ°æœ€å¤§ç´¯ç§¯æœŸæœ›çš„åŠ¨ä½œçš„é€‰å–æ¦‚ç‡ã€‚è¯¥ç®—æ³•å…·æœ‰åˆç†æ€§ï¼Œèƒ½å¤Ÿæ”¶æ•›åˆ°æœ€ä¼˜ç­–ç•¥ã€‚å…¶ç®—æ³•æµç¨‹å¦‚ä¸‹ PHC Algorithm: WOLF+PHC Algorithm: é€šè¿‡PHCç®—æ³•è¿›è¡Œå­¦ä¹ æ”¹è¿›ç­–ç•¥,æ”¶æ•›æ€§æ²¡æœ‰å¾—åˆ°è¯æ˜ã€‚","link":"/%E7%97%9B%E8%8B%A6%E7%9A%84MARL-%E4%BA%8C.html"},{"title":"è¿½é£ç­çš„äºº","text":"å¯’å‡ä¹¦å•3 ç”Ÿæ´»åœ¨ä¸€ä¸ªç­‰çº§åˆ†æ˜çš„åœ°æ–¹ï¼Œç©¶ç«Ÿæ˜¯ä»€ä¹ˆæ»‹å‘³ æ•…äº‹çš„å‘å±•å¾ˆåƒæ˜¯ä¸€ä¸ªäººçš„æ•‘èµï¼Œç”šè‡³ä¹¦ä¸­çš„æŸäº›ç‰‡æ®µéƒ½ä¸ç”µå½±ã€Šç©¿æ¡çº¹ç¡è¡£çš„ç”·å­©ã€‹æä¸ºç›¸ä¼¼-å®—æ•™å’Œç§æ—å¯¹äºä¸€ç¾¤äººä¸€ç”Ÿçš„å½±å“ã€‚å¦è¯šæ¥è®²ï¼Œæˆ‘å¯¹äºä¼Šæ–¯å…°æ–‡åŒ–äº†è§£çš„å°‘ä¹‹åˆå°‘ï¼Œè¿™æœ¬ä¹¦å¯¹äºæˆ‘æ¥è¯´ä¹Ÿç®—æ˜¯ç§‘æ™®æ€§è´¨çš„ä¹¦ç±äº†ã€‚å¦‚æœä½ å¯¹äºä¼Šæ–¯å…°æ•™æ„Ÿå…´è¶£çš„è¯ï¼Œä¸å¦¨å»é˜…è¯»ä¸€ç•ªï¼Œå…¨ä¹¦æ—¶é•¿è¿‘7ä¸ªå°æ—¶ï¼Œè€ç€æ€§å­è¯»ä¸‹å»å§ã€‚ â€œä¹Ÿè®¸æ¯ä¸ªäººå¿ƒä¸­éƒ½æœ‰ä¸€ä¸ªé£ç­ï¼Œæ— è®ºå®ƒæ„å‘³ç€ä»€ä¹ˆï¼Œè®©æˆ‘ä»¬å‹‡æ•¢çš„è¿½â€â€”â€”ç¿»è¯‘ æç»§å®","link":"/%E8%BF%BD%E9%A3%8E%E7%AD%9D%E7%9A%84%E4%BA%BA.html"}],"tags":[{"name":"NLP","slug":"NLP","link":"/tags/NLP/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"JavaScript","slug":"JavaScript","link":"/tags/JavaScript/"},{"name":"RL","slug":"RL","link":"/tags/RL/"}],"categories":[{"name":"æ—§çš„æ¢¦","slug":"æ—§çš„æ¢¦","link":"/categories/%E6%97%A7%E7%9A%84%E6%A2%A6/"},{"name":"æ—§çš„æ–‡","slug":"æ—§çš„æ–‡","link":"/categories/%E6%97%A7%E7%9A%84%E6%96%87/"},{"name":"FakeNews","slug":"FakeNews","link":"/categories/FakeNews/"},{"name":"MARL","slug":"MARL","link":"/categories/MARL/"}]}
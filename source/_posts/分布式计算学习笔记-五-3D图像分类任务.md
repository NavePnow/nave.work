---
title: 分布式计算学习笔记(五) 3D图像分类任务
date: 2020-02-18 19:22:27
thumbnail: https://images.unsplash.com/photo-1434030216411-0b793f4b4173?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60
recommend: 0
top: 100
toc: true
categories: [Distributed System]
---

# 概述
本篇博客首先会对3D图像分类任务进行分析（因为我也不会），之后利用 Ray 的 API进行改写，完成分布式框架上的深度学习工作。
<!--more-->

## 3D图像数据表示

1. **点云（Point clouds）**: 3D空间点的集合，同时三维坐标(xyz)可以和其他属性(rgb)进行绑定进行点的属性的表示
2. ** 体素网格（Voxel grids）**: 在点云的基础上，将点变成具有固定大小和离散坐标的3D网络，有点类似于乐高。
3. ** 多边形网格（Polygon meshes）**: 3D物体表面存在有限个点的坐标并且相邻点之间都有线进行连接，从而形成了有一组与多边形表面近似，共享顶点的几何面组成。
4. ** 多视图表示（Multi-view representations）**: 顾名思义，具有多双目视觉的2D图像进行构建，从而形成真正的3D图像

## 3D图像分类任务

### 多视图输入学习（Learning with multi-view inputs）
Multi-view CNN([https://arxiv.org/pdf/1505.00880.pdf][1])

首先从3D图中利用双目视觉获得多个2D渲染图像，每一个2D图像通过各自的CNN网络进行训练，之后进行汇总进行池化，之后再套CNN进行特征提取，最终输出物品的分类。

缺点可想而知，该方法无法真正以 3D 形式进行学习——固定数量的 2D 视图依旧只是一个对底层 3D 结构的不完美近似。

### 体积表示法学习（Learning with volumetric representations）
VoxNet([https://www.ri.cmu.edu/pub\_files/2015/9/voxnet\_maturana\_scherer\_iros15.pdf][2])

和2D CNN网络结构差不多: 由2个卷积层，1个最大池化层和2个全连接层组成。首先给定一个输入-体素网格，利用占据栅格地图 (Occupancy Grid Map) 去表示每个体素在空间中的占有概率(Occupied状态的概率)，之后将修改后的数据喂入模型进行训练，输出类的分向量。

### 点云学习（Learning with point clouds）
PointNet([https://arxiv.org/pdf/1612.00593.pdf][3])



# Reference
- [https://blog.csdn.net/lzc4869/article/details/94663616]()
- [https://blog.csdn.net/weixin\_43255962/article/details/88689665][5]
- [http://www.oreilly.com.cn/ideas/?p=2156][6]
- [https://www.cnblogs.com/fanzhidongyzby/p/7901139.html][7]

[1]:	https://arxiv.org/pdf/1505.00880.pdf
[2]:	https://www.ri.cmu.edu/pub_files/2015/9/voxnet_maturana_scherer_iros15.pdf
[3]:	https://www.ri.cmu.edu/pub_files/2015/9/voxnet_maturana_scherer_iros15.pdf
[5]:	https://blog.csdn.net/weixin_43255962/article/details/88689665
[6]:	http://www.oreilly.com.cn/ideas/?p=2156
[7]:	https://www.cnblogs.com/fanzhidongyzby/p/7901139.html
{"meta":{"version":1,"warehouse":"3.0.1"},"models":{"Asset":[{"_id":"source/README.md","path":"README.md","modified":1,"renderable":0},{"_id":"source/robot.txt","path":"robot.txt","modified":1,"renderable":0},{"_id":"themes/icarus/source/css/back-to-top.css","path":"css/back-to-top.css","modified":1,"renderable":1},{"_id":"themes/icarus/source/css/insight.css","path":"css/insight.css","modified":1,"renderable":1},{"_id":"themes/icarus/source/css/progressbar.css","path":"css/progressbar.css","modified":1,"renderable":1},{"_id":"themes/icarus/source/css/search.css","path":"css/search.css","modified":1,"renderable":1},{"_id":"themes/icarus/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/icarus/source/images/F56DE54B62B5BCF1.png","path":"images/F56DE54B62B5BCF1.png","modified":1,"renderable":1},{"_id":"themes/icarus/source/images/favicon.svg","path":"images/favicon.svg","modified":1,"renderable":1},{"_id":"themes/icarus/source/images/logo2.svg","path":"images/logo2.svg","modified":1,"renderable":1},{"_id":"themes/icarus/source/images/logo_org.svg","path":"images/logo_org.svg","modified":1,"renderable":1},{"_id":"themes/icarus/source/images/thumbnail.svg","path":"images/thumbnail.svg","modified":1,"renderable":1},{"_id":"themes/icarus/source/images/og_image.png","path":"images/og_image.png","modified":1,"renderable":1},{"_id":"themes/icarus/source/js/animation.js","path":"js/animation.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/js/back-to-top.js","path":"js/back-to-top.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/js/gallery.js","path":"js/gallery.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/js/globalUtils.js","path":"js/globalUtils.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/js/insight.js","path":"js/insight.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/js/main.js","path":"js/main.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/js/theme-setting.js","path":"js/theme-setting.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/images/favicon1.svg","path":"images/favicon1.svg","modified":1,"renderable":1},{"_id":"themes/icarus/source/images/logo.png","path":"images/logo.png","modified":1,"renderable":1},{"_id":"themes/icarus/source/images/logo3","path":"images/logo3","modified":1,"renderable":1},{"_id":"source/images/2019/08/23/2f8318c0-c55a-11e9-b9cb-2ff8473d5c85.png","path":"images/2019/08/23/2f8318c0-c55a-11e9-b9cb-2ff8473d5c85.png","modified":1,"renderable":0},{"_id":"source/images/2019/08/23/336757d0-c55a-11e9-b9cb-2ff8473d5c85.png","path":"images/2019/08/23/336757d0-c55a-11e9-b9cb-2ff8473d5c85.png","modified":1,"renderable":0},{"_id":"source/images/2019/08/23/38cf50b0-c55a-11e9-b9cb-2ff8473d5c85.png","path":"images/2019/08/23/38cf50b0-c55a-11e9-b9cb-2ff8473d5c85.png","modified":1,"renderable":0},{"_id":"source/images/2019/08/23/42dd5200-c55a-11e9-b9cb-2ff8473d5c85.png","path":"images/2019/08/23/42dd5200-c55a-11e9-b9cb-2ff8473d5c85.png","modified":1,"renderable":0},{"_id":"source/images/2019/08/23/46288560-c55a-11e9-b9cb-2ff8473d5c85.png","path":"images/2019/08/23/46288560-c55a-11e9-b9cb-2ff8473d5c85.png","modified":1,"renderable":0},{"_id":"source/images/2019/08/23/4b872f70-c55a-11e9-b9cb-2ff8473d5c85.png","path":"images/2019/08/23/4b872f70-c55a-11e9-b9cb-2ff8473d5c85.png","modified":1,"renderable":0},{"_id":"source/images/2019/08/23/5394f3f0-c55a-11e9-b9cb-2ff8473d5c85.png","path":"images/2019/08/23/5394f3f0-c55a-11e9-b9cb-2ff8473d5c85.png","modified":1,"renderable":0},{"_id":"source/images/2019/08/23/c640c4a0-c55b-11e9-b9cb-2ff8473d5c85.png","path":"images/2019/08/23/c640c4a0-c55b-11e9-b9cb-2ff8473d5c85.png","modified":1,"renderable":0},{"_id":"source/images/2019/08/23/ced0a6e0-c55a-11e9-b9cb-2ff8473d5c85.png","path":"images/2019/08/23/ced0a6e0-c55a-11e9-b9cb-2ff8473d5c85.png","modified":1,"renderable":0},{"_id":"source/images/2019/08/23/5e563fb0-c55a-11e9-b9cb-2ff8473d5c85.png","path":"images/2019/08/23/5e563fb0-c55a-11e9-b9cb-2ff8473d5c85.png","modified":1,"renderable":0},{"_id":"source/images/2019/08/23/e92e9230-c55b-11e9-b9cb-2ff8473d5c85.png","path":"images/2019/08/23/e92e9230-c55b-11e9-b9cb-2ff8473d5c85.png","modified":1,"renderable":0},{"_id":"source/images/2019/08/23/73674620-c559-11e9-b9cb-2ff8473d5c85.png","path":"images/2019/08/23/73674620-c559-11e9-b9cb-2ff8473d5c85.png","modified":1,"renderable":0},{"_id":"source/images/2019/11/05/b6400f10-ffd1-11e9-b31e-e7c5b37d7122.png","path":"images/2019/11/05/b6400f10-ffd1-11e9-b31e-e7c5b37d7122.png","modified":1,"renderable":0},{"_id":"source/images/2019/11/05/b6405d30-ffd1-11e9-b31e-e7c5b37d7122.png","path":"images/2019/11/05/b6405d30-ffd1-11e9-b31e-e7c5b37d7122.png","modified":1,"renderable":0},{"_id":"source/images/2019/08/23/0a2dbf70-c5ba-11e9-a08f-f3347b368783.png","path":"images/2019/08/23/0a2dbf70-c5ba-11e9-a08f-f3347b368783.png","modified":1,"renderable":0},{"_id":"source/images/15739641433464.png","path":"images/15739641433464.png","modified":1,"renderable":0},{"_id":"themes/icarus/source/images/avatar.png","path":"images/avatar.png","modified":1,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"d005875770fb19e36ceeaad5755135610a1146ba","modified":1574067098618},{"_id":"source/.UlyssesRoot","hash":"6889ae2a1ab8ef99afbf8fa54c4cfb7104161b39","modified":1570100488362},{"_id":"source/README.md","hash":"d35806b1775737aeee447737cec5a6fe14320c27","modified":1574854119110},{"_id":"source/robot.txt","hash":"68ca84057b13d453ab5e5621419b5be34d55cf17","modified":1573298949753},{"_id":"themes/icarus/.DS_Store","hash":"ad6e7fbe5bafdeb6f28fbf526c3db912628d8069","modified":1574857029425},{"_id":"themes/icarus/LICENSE","hash":"41f72cd544612bc4589c924c776422b800a4eff7","modified":1573812312359},{"_id":"themes/icarus/_config.yml","hash":"b84fd1005f653462502bbfa75fc58ec0191dbb6b","modified":1574856004566},{"_id":"themes/icarus/README.md","hash":"c351bc76d3b4a138989c50f57bd3c52fa95eaa56","modified":1573812312359},{"_id":"themes/icarus/package.json","hash":"e9bcb9fcf69462d5b03c7870eb13ab28aa7933c7","modified":1573812312393},{"_id":"source/.MWebMetaData/setting.json","hash":"1658bd0b6c5005cc3cec11152b5220b25c932205","modified":1573126276368},{"_id":"source/.MWebMetaData/setting 2.json","hash":"48bf5bbbe944ddde981268eda5b1e71a1bf8d046","modified":1570158133000},{"_id":"source/FakeNews/index.md","hash":"adf701c7c0673d42741689259d461122cfacc978","modified":1566619122889},{"_id":"source/JS/index.md","hash":"aab76ed23888f0aca65e9a8e38e023ffaec9bba7","modified":1573906211907},{"_id":"source/MARL/index.md","hash":"ce464b0c11402107f5d2fe1fac2d709de45a09a0","modified":1573905993782},{"_id":"source/NLP/index.md","hash":"c39e672833b976ca2fbe7eedd93d3e8d3d941618","modified":1566618970093},{"_id":"source/Python/index.md","hash":"4810c9c64247f10c2012f70a93eb5ed8c199a30b","modified":1573906214348},{"_id":"source/RL/index.md","hash":"8fa7a6d1243335174942d18ac798ee6634f86474","modified":1573905575226},{"_id":"source/_posts/.DS_Store","hash":"d4166dd6e8e064c0ec7e89f1b887a9b1461a5e0a","modified":1574594955424},{"_id":"source/_posts/.Ulysses-Group.plist","hash":"9a696de076e56e3802722b448766aad8457c7329","modified":1574076168053},{"_id":"source/_posts/.UlyssesRoot","hash":"6889ae2a1ab8ef99afbf8fa54c4cfb7104161b39","modified":1574074832640},{"_id":"source/_posts/10-04-2019-柳烈的音乐专辑.md","hash":"09d87a73cfbdc1b6bce3bc45f89cd22c200bc53f","modified":1573829270712},{"_id":"source/_posts/1987.md","hash":"0bdadd084a1473f4a80f605e5bd03a4cd7221439","modified":1573821941336},{"_id":"source/_posts/Dec-15-2018.md","hash":"1e2695725a22a9ad0c072674d287d8c460e6ab84","modified":1573822488733},{"_id":"source/_posts/Cest-la-vie-Sep-24-2019.md","hash":"d81b240686db0f79d12c2fb3fdf6d5f31b6a877c","modified":1573821817081},{"_id":"source/_posts/Dec-6-2017.md","hash":"39ee3f31b0d18d710d98dc8e2774f018cc336fe2","modified":1573822635169},{"_id":"source/_posts/Dec-27-2017.md","hash":"84ab09666bfa4cc01535f8aceebfd6f76098185f","modified":1573822459773},{"_id":"source/_posts/Fake News 学习笔记（三）Bert 负采样 Transformer.md","hash":"1301f0343a9510ba7ef5c6892c0734a60c50a233","modified":1573906312902},{"_id":"source/_posts/Fake News 学习笔记（一）分类器，f1 score.md","hash":"a7dd2bff942a44fa6cc630d02ddec42ea0142c88","modified":1573906269429},{"_id":"source/_posts/Fake-News-学习笔记（四）.md","hash":"0b40b917ff3ad2aad6dbd2ce5077dad2a6d538cf","modified":1573906287358},{"_id":"source/_posts/Fake News 学习笔记（二） one-hot-coding Stem-and-Lem Word2Vec.md","hash":"9cdfb1114dcf842d9bb855ca5db7097a420e0e6e","modified":1573906272339},{"_id":"source/_posts/Google-BERT-on-fake-or-real-news-dataset.md","hash":"2fa17bb0f501ccd7a97c768e8a3098097031e8d3","modified":1573906301199},{"_id":"source/_posts/Hexo主题折腾日记-二-添加豆瓣和聊天插件.md","hash":"948173544b9d26ee7dcad5f1b718e48f7c547c5d","modified":1574083280302},{"_id":"source/_posts/March-18-2019.md","hash":"a1a576541f95ac6d660f1a5afaf4e152e9a03560","modified":1573822370518},{"_id":"source/_posts/Hexo主题折腾日记-从cactus到icarus.md","hash":"8a612af639adba917ce0d8306be9112a124eb7c4","modified":1573995605345},{"_id":"source/_posts/March-26-2019.md","hash":"c95094cc0aa79cc9a894adc77b60f24f7f10036b","modified":1573822349677},{"_id":"source/_posts/Sep-17，2019-保研.md","hash":"859e78c0f2707cd25dc6fd34dfcba7a2f04c9774","modified":1573822295383},{"_id":"source/_posts/Sep-2-2019.md","hash":"93a262b24ccfbdafa7b2c8ce614f24233c987949","modified":1573822325527},{"_id":"source/_posts/The-Post.md","hash":"8dc5b67282664dbcac43f7ec0a75b3de5b957886","modified":1573822256418},{"_id":"source/_posts/hello-world.md","hash":"97c63209c84dfa2a8ab89f491bc4e456b653d943","modified":1573822966895},{"_id":"source/_posts/一亩三分地自动签到脚本.md","hash":"426c14a1f40c0267e9eb240649b4fb293d4864b0","modified":1573906399835},{"_id":"source/_posts/分布式计算学习笔记-一-从分布式系统到分布式计算.md","hash":"91336e3242cd2032170e1b17158267c4e1d19456","modified":1574305219897},{"_id":"source/_posts/分布式计算学习笔记-二-Ray.md","hash":"0f7c8988f6a482a7d5e845a791ae0f5c167c882d","modified":1574595171709},{"_id":"source/_posts/奇迹唱片行.md","hash":"4177dad815139af9f86f157c71b2ad5239bd85d4","modified":1573822189962},{"_id":"source/_posts/如父如子.md","hash":"85c9aa956f7bea360346298e84875b651526b7b9","modified":1573822572800},{"_id":"source/_posts/岛上书店.md","hash":"fb2f29786cdeeec516a265c7ca0558098c68a185","modified":1573822546632},{"_id":"source/_posts/房思琪的初恋乐园.md","hash":"d86ea24305ca3924054a8c11630b90fa7fb3fc09","modified":1573822702121},{"_id":"source/_posts/无声告白.md","hash":"d1f5e36e970e1a15da660a19c0d1ad6074706a32","modified":1573822795099},{"_id":"source/_posts/痛苦的MARL-一.md","hash":"21424671be05e3ab8dec2f5d72bc73415a54b734","modified":1573906314838},{"_id":"source/_posts/痛苦的MARL-三.md","hash":"3aef1e3e6e2b2e66515f548b3322666947e8d40a","modified":1573906305819},{"_id":"source/_posts/痛苦的MARL-二.md","hash":"bacfb6963ee75e86bacc4c961e30a36abb651414","modified":1573906308867},{"_id":"source/_posts/追风筝的人.md","hash":"5a80856c71c8b84bad2444605d7db1e876225995","modified":1573822224232},{"_id":"source/categories/index.md","hash":"ddfef914f95fdf428099487a6f004b216393204d","modified":1565489390387},{"_id":"source/about/index.md","hash":"f94b0a164e3d190217df403145c272045845aab1","modified":1574854110861},{"_id":"source/gallery/index.md","hash":"127eef4bd359fd4739e480ba4b38251663338c00","modified":1574596636788},{"_id":"source/tags/index.md","hash":"a9dfa1bd33bfcb4362417698978cc3cafe825c41","modified":1565489584276},{"_id":"source/search/index.md","hash":"8b365ee5cf2e0616507c5e99556089ded71eabec","modified":1557483472710},{"_id":"source/旧的梦/index.md","hash":"5a50c0b920362437ef67f8b3e09bfa828b570218","modified":1565490906820},{"_id":"source/旧的文/index.md","hash":"9f99211c45a607bc5e7430a2f7cc6cfb944021f6","modified":1565487398925},{"_id":"themes/icarus/languages/en.yml","hash":"6a9fd88654e4ee010be2b70b75a4129b47f2aa3c","modified":1573961818547},{"_id":"themes/icarus/languages/es.yml","hash":"8827823e5b2ce967566854c9bfebc7c69098b4ac","modified":1573812312370},{"_id":"themes/icarus/languages/id.yml","hash":"92d2d19a62a17b6e99f82a014309bbf6c13c9ae8","modified":1573812312370},{"_id":"themes/icarus/languages/fr.yml","hash":"0017f93a5d491a9c0e55911cdc35316762c5a94e","modified":1573812312370},{"_id":"themes/icarus/languages/ja.yml","hash":"6eed7771de2353d71b720c6e605cceb3f230b12e","modified":1573812312370},{"_id":"themes/icarus/languages/ko.yml","hash":"eef426a7d580058024260ccc111476d5b1b688d1","modified":1573812312371},{"_id":"themes/icarus/languages/pl.yml","hash":"43f5447c38c9be2e1f5ce6181a0f97eeb437b059","modified":1573812312371},{"_id":"themes/icarus/languages/pt-BR.yml","hash":"bcf5bc81ca855d26bbc3b3bfabc7d84429e74b85","modified":1573812312371},{"_id":"themes/icarus/languages/ru.yml","hash":"ba8b4f7d77eb1d1e28aa1f9107bd0bbbdc4cba99","modified":1573812312371},{"_id":"themes/icarus/languages/tr.yml","hash":"eff1c0b3d5c4b328f6dd74a195ff378c898f4d29","modified":1573812312371},{"_id":"themes/icarus/languages/vn.yml","hash":"6d9f4fabca711a6cb0a0efd72aa75c3641beb4a6","modified":1573812312371},{"_id":"themes/icarus/languages/zh-CN.yml","hash":"804f6a1edee49bb6a5ecb8e9d14d3e93eaca37c0","modified":1573812312371},{"_id":"themes/icarus/languages/zh-TW.yml","hash":"6ff978a0c4c11e996925e1a912a1d805f4680a6c","modified":1573812312372},{"_id":"themes/icarus/layout/archive.ejs","hash":"2527527eaf3e757ab476325f691d2e2e0ff9c2d5","modified":1573812312372},{"_id":"themes/icarus/layout/categories.ejs","hash":"29d304f2b95a04fbc5e7529f9bdce9648e3545ef","modified":1573812312372},{"_id":"themes/icarus/layout/category.ejs","hash":"58aa84f75193b978b2072f29dbb84ed8279574b9","modified":1573812312372},{"_id":"themes/icarus/layout/index.ejs","hash":"8ab440868f721bb7256ab9f2be96996850b0cf44","modified":1573812312381},{"_id":"themes/icarus/layout/layout.ejs","hash":"e3adb831060d253b86302ed841d77972a1af335a","modified":1574594924223},{"_id":"themes/icarus/layout/page.ejs","hash":"ebf120d46074f67ea25a231d2f7a64fd1e751904","modified":1573812312381},{"_id":"themes/icarus/layout/post.ejs","hash":"ebf120d46074f67ea25a231d2f7a64fd1e751904","modified":1573812312384},{"_id":"themes/icarus/layout/tag.ejs","hash":"45eb077f2ac86f5c8090cb1a2361eed56a368e95","modified":1573812312388},{"_id":"themes/icarus/layout/tags.ejs","hash":"0c527c6b72386f11c18e8aa5249be8c601e69906","modified":1573812312388},{"_id":"themes/icarus/scripts/image-stream.js","hash":"1f281a6aed42f1b7edf58b2e0d27467e4dad35c2","modified":1568731445429},{"_id":"themes/icarus/scripts/index.js","hash":"f97eb95812480cc3b07cc0ad44dc39f9a0032f24","modified":1573812312393},{"_id":"themes/icarus/includes/common/ConfigGenerator.js","hash":"451397efc7808787419fa3eb6b043c0bd8bbdf30","modified":1573812312359},{"_id":"themes/icarus/includes/common/ConfigValidator.js","hash":"48cff5402e93b11d5266370e9c4b78ee21369cb9","modified":1573812312360},{"_id":"themes/icarus/includes/common/utils.js","hash":"c0aeaeb57a42bcc71a92da2249762f91abd83ffe","modified":1573812312360},{"_id":"themes/icarus/includes/filters/highlight.js","hash":"19a4dcd2dee7388544b57e473cfb0fc9eea9623e","modified":1573812312361},{"_id":"themes/icarus/includes/generators/categories.js","hash":"7cb370ac53a05d6b1b9203579716c0ca83d35c36","modified":1573812312362},{"_id":"themes/icarus/includes/generators/category.js","hash":"313e170e55d74526c4e1be7181ef7a21439147c9","modified":1573812312362},{"_id":"themes/icarus/includes/generators/insight.js","hash":"c4b981443927b87cc14a3a583029e13f819d6d71","modified":1573812312362},{"_id":"themes/icarus/includes/generators/tags.js","hash":"8195322c208706427a1cf56361669dca4d86f6f1","modified":1573812312362},{"_id":"themes/icarus/includes/helpers/cdn.js","hash":"7d34ea6400cb3611c374c135304abcb65ef291b7","modified":1573812312362},{"_id":"themes/icarus/includes/helpers/config.js","hash":"173e02987e7a7d5df1e686f6ee4edd8cf494bdd3","modified":1573812312363},{"_id":"themes/icarus/includes/helpers/layout.js","hash":"68bbfc74a02f5e4b4312d7474bb6d02248abebe0","modified":1573835057014},{"_id":"themes/icarus/includes/helpers/override.js","hash":"98f2c72c79de74bd01e3be10ef2f174c885d395a","modified":1573812312363},{"_id":"themes/icarus/includes/helpers/page.js","hash":"4ce98c781bcbc132672e6d16bf02df5bebcea7b3","modified":1573812312363},{"_id":"themes/icarus/includes/helpers/site.js","hash":"2f55818448fe83c73418dcf9751745c7918c10e3","modified":1573812312363},{"_id":"themes/icarus/includes/specs/article.spec.js","hash":"ce24279cd0cd39855216dab0cd5223c755757cdf","modified":1573812312364},{"_id":"themes/icarus/includes/specs/comment.spec.js","hash":"b0ef033e363b918134fb5a003143e9bd8fafa300","modified":1573812312364},{"_id":"themes/icarus/includes/specs/config.spec.js","hash":"7a9bac384a73cf9f39173fdb2dfc2813784d8891","modified":1573812312364},{"_id":"themes/icarus/includes/specs/donate.spec.js","hash":"722cb2662569957e8b1d1a467d9632b8cc6e69d6","modified":1573812312364},{"_id":"themes/icarus/includes/specs/footer.spec.js","hash":"8e6d7c5f9a13ce03241b6562259d210b389cb88e","modified":1573812312365},{"_id":"themes/icarus/includes/specs/icon_link.spec.js","hash":"f2a83ac5ccb74fc6f3dfbd25430e142297d8491c","modified":1573812312365},{"_id":"themes/icarus/includes/specs/meta.spec.js","hash":"28863042ad8fcf9ecb86d5288ecd3ce5250a984d","modified":1573812312365},{"_id":"themes/icarus/includes/specs/navbar.spec.js","hash":"7de29c0031738a4de4d31ed4f7b0c43447c7961c","modified":1573812312365},{"_id":"themes/icarus/includes/specs/plugins.spec.js","hash":"2fb7a28fdde9a46f576e69b9967f24d66adffb57","modified":1573812312366},{"_id":"themes/icarus/includes/specs/providers.spec.js","hash":"820cc6936ba75e3104cc2e8641716ed65ada8b6f","modified":1573812312366},{"_id":"themes/icarus/includes/specs/search.spec.js","hash":"1e3995cdc471e6a2817cd45e2b6f0fd39b4540ec","modified":1573812312366},{"_id":"themes/icarus/includes/specs/share.spec.js","hash":"5ec65409a17ead13974140fc5ddc19e526586d9f","modified":1573812312367},{"_id":"themes/icarus/includes/specs/sidebar.spec.js","hash":"630c9701affe2549abc61cd4d1e5153af2224fb6","modified":1573812312367},{"_id":"themes/icarus/includes/specs/widgets.spec.js","hash":"c5cedfe1074c0566baf8aca248f0392a501d9a74","modified":1573812312368},{"_id":"themes/icarus/includes/tasks/check_config.js","hash":"ce7626d643737c90dee6b75435ccdec26b89dacf","modified":1573812312368},{"_id":"themes/icarus/includes/tasks/check_deps.js","hash":"cfc357f27116d1b9285a3b0bec35c3e89ae73711","modified":1573812312369},{"_id":"themes/icarus/includes/tasks/welcome.js","hash":"00d1ef8c9609552b82e9a5140b838a9057c59508","modified":1573812312369},{"_id":"themes/icarus/layout/comment/changyan.ejs","hash":"73038ac4fdfdfa71d92edaa98cc194b3446586a3","modified":1573812312373},{"_id":"themes/icarus/layout/comment/changyan.locals.js","hash":"49bce2ee742c7224bda97092d6e0a1a09184ef34","modified":1573812312373},{"_id":"themes/icarus/layout/comment/disqus.ejs","hash":"7a8c656c8651d48e21ed24c469ea75898b2b12df","modified":1573812312373},{"_id":"themes/icarus/layout/comment/disqus.locals.js","hash":"a8d2cecaa82ec9e2e2e61cb73417d63d115335d6","modified":1573812312373},{"_id":"themes/icarus/layout/comment/facebook.ejs","hash":"1c3751f36f737527e352c65bb1ca7172ff792979","modified":1573812312373},{"_id":"themes/icarus/layout/comment/facebook.locals.js","hash":"77e3ef1d933660d980b26d15968aa1a5c8a93a56","modified":1573812312373},{"_id":"themes/icarus/layout/comment/gitalk.ejs","hash":"eb1314badf793924b5786e92f8b3ebb0f21f3b58","modified":1573812312374},{"_id":"themes/icarus/layout/comment/gitalk.locals.js","hash":"f920f130598148b4d9f213c82f2d7f88a796012f","modified":1573812312374},{"_id":"themes/icarus/layout/comment/gitment.ejs","hash":"d5e1a396e23df4e75e139d12846290bdb08ba01e","modified":1573812312374},{"_id":"themes/icarus/layout/comment/gitment.locals.js","hash":"f920f130598148b4d9f213c82f2d7f88a796012f","modified":1573812312375},{"_id":"themes/icarus/layout/comment/isso.ejs","hash":"cc6a43bd24be764086f88ad7c5c97ff04df87e0b","modified":1573812312375},{"_id":"themes/icarus/layout/comment/isso.locals.js","hash":"9a43112ac0a58df98bb418563ec04558023e1fae","modified":1573812312375},{"_id":"themes/icarus/layout/comment/livere.ejs","hash":"12ff9a345f6bba2f732f592e39508c2afde89b00","modified":1573812312375},{"_id":"themes/icarus/layout/comment/livere.locals.js","hash":"9a43112ac0a58df98bb418563ec04558023e1fae","modified":1573812312376},{"_id":"themes/icarus/layout/comment/valine.ejs","hash":"a29cf2e69f66a37ddcec8343c60af1e676dcb77d","modified":1573812312376},{"_id":"themes/icarus/layout/comment/valine.locals.js","hash":"9a43112ac0a58df98bb418563ec04558023e1fae","modified":1573812312376},{"_id":"themes/icarus/layout/common/article.locals.js","hash":"1f108fa96e61a681d7b1ee390b4f0ff60d042720","modified":1573812312377},{"_id":"themes/icarus/layout/common/article.ejs","hash":"15ab494fc08084f54e50c281aa46b8eb9c9b7f3d","modified":1574513351402},{"_id":"themes/icarus/layout/common/footer.ejs","hash":"8d9f303381cbe7a6be42e6b41818633e95f679c9","modified":1573985024443},{"_id":"themes/icarus/layout/common/footer.locals.js","hash":"504ed92dc76723f19777463d690acfbe1d89e2ba","modified":1573812312378},{"_id":"themes/icarus/layout/common/navbar.locals.js","hash":"7e523ba80667038f2e58cf4f9cb073e9afbc70e6","modified":1573812312378},{"_id":"themes/icarus/layout/common/head.ejs","hash":"ccb1425c7e51724e24b7df42bd0d0a9eeedc5113","modified":1574433479836},{"_id":"themes/icarus/layout/common/navbar.ejs","hash":"270df82a0cedd60f7125a21892b7e4c0263a7c23","modified":1574513355387},{"_id":"themes/icarus/layout/common/paginator.ejs","hash":"7837d80b27f166161b3deeffb571680025c7d723","modified":1573812312379},{"_id":"themes/icarus/layout/common/recommend_posts.ejs","hash":"d1f9ca3b22bf04c03bcacf3e27af9f157099fc0b","modified":1573828855460},{"_id":"themes/icarus/layout/common/scripts.ejs","hash":"52f54b4ba88253ad0ec13d3b40fa4232e691af57","modified":1573812312379},{"_id":"themes/icarus/layout/common/recommend_posts.locals.js","hash":"a76490cc0d82a2d82b7b9abec7979459aaa5d1b1","modified":1573828855461},{"_id":"themes/icarus/layout/common/widget.ejs","hash":"da6d368400fad02ddbe4c113895a873aba2fae0c","modified":1573834887061},{"_id":"themes/icarus/layout/donate/alipay.ejs","hash":"3290058879973e403a05472a0fe2ac0219d5b961","modified":1573812312379},{"_id":"themes/icarus/layout/donate/alipay.locals.js","hash":"9a43112ac0a58df98bb418563ec04558023e1fae","modified":1573812312379},{"_id":"themes/icarus/layout/donate/patreon.ejs","hash":"8e52a9c28ffaf4b0b786a20977b848c5f60f2274","modified":1573812312380},{"_id":"themes/icarus/layout/donate/patreon.locals.js","hash":"9a43112ac0a58df98bb418563ec04558023e1fae","modified":1573812312380},{"_id":"themes/icarus/layout/donate/paypal.ejs","hash":"3975dee39f9378975b9c10f37d118ad7cb6f5bf6","modified":1573812312380},{"_id":"themes/icarus/layout/donate/paypal.locals.js","hash":"9a43112ac0a58df98bb418563ec04558023e1fae","modified":1573812312380},{"_id":"themes/icarus/layout/donate/wechat.ejs","hash":"051b873e1fc28c1d7c2d6443991b6a2f43813e6b","modified":1573812312380},{"_id":"themes/icarus/layout/donate/wechat.locals.js","hash":"9a43112ac0a58df98bb418563ec04558023e1fae","modified":1573812312380},{"_id":"themes/icarus/layout/plugin/animejs.ejs","hash":"c17ea2cfe5cb239342166e2ba72cbfc663c8160f","modified":1573812312381},{"_id":"themes/icarus/layout/plugin/animejs.locals.js","hash":"3bf911060a222f00b03be708c37f20e36cb66ba9","modified":1573812312381},{"_id":"themes/icarus/layout/plugin/back-to-top.ejs","hash":"5936b5fd2f2444605a21c6c422623f07f02d5c9a","modified":1573812312382},{"_id":"themes/icarus/layout/plugin/back-to-top.locals.js","hash":"3bf911060a222f00b03be708c37f20e36cb66ba9","modified":1573812312382},{"_id":"themes/icarus/layout/plugin/baidu-analytics.ejs","hash":"7dbbea5722277e00a624c1796ec83d5f9c12d059","modified":1573812312382},{"_id":"themes/icarus/layout/plugin/baidu-analytics.locals.js","hash":"c02eb152e6aff05833006e6edd32b74c1c4258c3","modified":1573812312382},{"_id":"themes/icarus/layout/plugin/busuanzi.ejs","hash":"4285b0ae608c7c54e4ecbebb6d22d4cd1be28f70","modified":1573812312382},{"_id":"themes/icarus/layout/plugin/busuanzi.locals.js","hash":"ec80bcfa4c1302c04130a746df4b1298d117de0b","modified":1573812312382},{"_id":"themes/icarus/layout/plugin/gallery.ejs","hash":"7d19b7a5713d08a614578f079f1327a651c472ae","modified":1573812312382},{"_id":"themes/icarus/layout/plugin/gallery.locals.js","hash":"037fb56dffc128d3a91c1cb8852998d9539d3fac","modified":1573812312383},{"_id":"themes/icarus/layout/plugin/google-analytics.ejs","hash":"13b298b0026bfc7bcb6a47b6c795fe15cc4584fc","modified":1573812312383},{"_id":"themes/icarus/layout/plugin/google-analytics.locals.js","hash":"c02eb152e6aff05833006e6edd32b74c1c4258c3","modified":1573812312383},{"_id":"themes/icarus/layout/plugin/hotjar.ejs","hash":"6df0d8f77ed39e4d32c78177844115e31bf3a776","modified":1573812312383},{"_id":"themes/icarus/layout/plugin/hotjar.locals.js","hash":"9258fc2af057d2545a43fae54790743b63450378","modified":1573812312383},{"_id":"themes/icarus/layout/plugin/mathjax.ejs","hash":"dddb6f37487286fe2080118bcbb4a8d82dc84d5e","modified":1573812312383},{"_id":"themes/icarus/layout/plugin/mathjax.locals.js","hash":"7faa26fa6da6a93dc3f7fdcf5a784d1f8825b031","modified":1573812312384},{"_id":"themes/icarus/layout/plugin/outdated-browser.ejs","hash":"1437d1ac085a8110e61317254f6c0a034121bc39","modified":1573812312384},{"_id":"themes/icarus/layout/plugin/outdated-browser.locals.js","hash":"037fb56dffc128d3a91c1cb8852998d9539d3fac","modified":1573812312384},{"_id":"themes/icarus/layout/plugin/progressbar.ejs","hash":"34423f74787cc9d67b2598dd69b07c84d5bf2280","modified":1573812312384},{"_id":"themes/icarus/layout/plugin/progressbar.locals.js","hash":"ec80bcfa4c1302c04130a746df4b1298d117de0b","modified":1573812312384},{"_id":"themes/icarus/layout/search/baidu.ejs","hash":"850aa91778100d693a52b10eaa8586c8e3215ee6","modified":1573812312385},{"_id":"themes/icarus/layout/search/baidu.locals.js","hash":"9a43112ac0a58df98bb418563ec04558023e1fae","modified":1573812312385},{"_id":"themes/icarus/layout/search/google-cse.ejs","hash":"4b881a99325a6a0cebf97ac53e09d8fc67f87d29","modified":1573812312385},{"_id":"themes/icarus/layout/search/insight.ejs","hash":"9a27db2a007582ceee7ca4b1eebddbd456893568","modified":1573812312385},{"_id":"themes/icarus/layout/search/google-cse.locals.js","hash":"9a43112ac0a58df98bb418563ec04558023e1fae","modified":1573812312385},{"_id":"themes/icarus/layout/search/insight.locals.js","hash":"9a43112ac0a58df98bb418563ec04558023e1fae","modified":1573812312385},{"_id":"themes/icarus/layout/share/addthis.locals.js","hash":"9a43112ac0a58df98bb418563ec04558023e1fae","modified":1573812312386},{"_id":"themes/icarus/layout/share/addtoany.ejs","hash":"95d3bc1a841bd934b1ae9209ad1af74e743ecb10","modified":1573812312386},{"_id":"themes/icarus/layout/share/addthis.ejs","hash":"f1c5f337333009d5f00dfbac4864a16ef8f9cb8d","modified":1573812312386},{"_id":"themes/icarus/layout/share/addtoany.locals.js","hash":"9a43112ac0a58df98bb418563ec04558023e1fae","modified":1573812312386},{"_id":"themes/icarus/layout/share/bdshare.ejs","hash":"f14c8084b7ee16a091f0bd2ae9039e3bfff7e7b7","modified":1573812312386},{"_id":"themes/icarus/layout/share/bdshare.locals.js","hash":"9a43112ac0a58df98bb418563ec04558023e1fae","modified":1573812312387},{"_id":"themes/icarus/layout/share/sharejs.ejs","hash":"65d08316cc479910ea4f526cd1c299d0104daf7f","modified":1573812312387},{"_id":"themes/icarus/layout/share/sharejs.locals.js","hash":"11976fd4cfed1044be29b476b34c33175c9b4308","modified":1573812312387},{"_id":"themes/icarus/layout/share/sharethis.ejs","hash":"4f2c40f790f3be0a4e79db04f02ea41ba2f4d4c0","modified":1573812312388},{"_id":"themes/icarus/layout/share/sharethis.locals.js","hash":"9a43112ac0a58df98bb418563ec04558023e1fae","modified":1573812312388},{"_id":"themes/icarus/layout/widget/archive.ejs","hash":"eb738a2ac2935ce7a542964d90088613b281dd15","modified":1573812312389},{"_id":"themes/icarus/layout/widget/archive.locals.js","hash":"9a43112ac0a58df98bb418563ec04558023e1fae","modified":1573812312389},{"_id":"themes/icarus/layout/widget/category.ejs","hash":"17e58e537645c4434a1140377ae3e7f43cca4927","modified":1573812312389},{"_id":"themes/icarus/layout/widget/category.locals.js","hash":"9a43112ac0a58df98bb418563ec04558023e1fae","modified":1573812312389},{"_id":"themes/icarus/layout/widget/links.ejs","hash":"c18dab874af84147349a596d9e713f8e0ee5e17e","modified":1573812312390},{"_id":"themes/icarus/layout/widget/links.locals.js","hash":"872cf1a18e152361f5739c6d5fecc0bf46d59513","modified":1573812312390},{"_id":"themes/icarus/layout/widget/profile.ejs","hash":"9bd7bed642c39e93a957728661fcea97e7acbc2d","modified":1573838138667},{"_id":"themes/icarus/layout/widget/profile.locals.js","hash":"9a43112ac0a58df98bb418563ec04558023e1fae","modified":1573812312390},{"_id":"themes/icarus/layout/widget/recent_posts.ejs","hash":"14a2f4587831e017b93818c06dbe18a7e8a27c1e","modified":1573812312391},{"_id":"themes/icarus/layout/widget/recent_posts.locals.js","hash":"5065aca74ec2c98ec88994636fee8408f769c5f2","modified":1573812312391},{"_id":"themes/icarus/layout/widget/recommend_posts.ejs","hash":"d1f9ca3b22bf04c03bcacf3e27af9f157099fc0b","modified":1573828855460},{"_id":"themes/icarus/layout/widget/recommend_posts.locals.js","hash":"a76490cc0d82a2d82b7b9abec7979459aaa5d1b1","modified":1573828855461},{"_id":"themes/icarus/layout/widget/subscribe_email.ejs","hash":"391622e9c1d17bf79180faa617ed8c1ee1871a87","modified":1573812312391},{"_id":"themes/icarus/layout/widget/subscribe_email.locals.js","hash":"aae87fbdb7a1245a0fc0637225a935fc39836916","modified":1573812312391},{"_id":"themes/icarus/layout/widget/tag.ejs","hash":"e41aff420cc4ea1c454de49bd8af0e7a93f3db3f","modified":1573812312392},{"_id":"themes/icarus/layout/widget/tagcloud.ejs","hash":"26fa17afaf0cb345a213816c44c39575a66759ba","modified":1573812312392},{"_id":"themes/icarus/layout/widget/tagcloud.locals.js","hash":"093f59d2f43e7ffa47bee79da15f98705300dfba","modified":1573812312392},{"_id":"themes/icarus/layout/widget/toc.ejs","hash":"e800b4b38eab716882389a09527e9f59a189dea6","modified":1573812312392},{"_id":"themes/icarus/layout/widget/toc.locals.js","hash":"e730a7fff2717f17741540e5ed77b89e289fdeab","modified":1573812312393},{"_id":"themes/icarus/source/css/back-to-top.css","hash":"5805bee2445e997d64dfe526b08b5fe0bce357eb","modified":1573812312394},{"_id":"themes/icarus/source/css/insight.css","hash":"22943a610d5cfffedfb823c692f4db2b1f37a4c9","modified":1573812312394},{"_id":"themes/icarus/source/css/progressbar.css","hash":"bbc737b7a8feb19901e792c447a846273779d5c3","modified":1573812312395},{"_id":"themes/icarus/source/css/search.css","hash":"d6a59894819e7431d42b249b6c2fc9ff3b99a488","modified":1573812312395},{"_id":"themes/icarus/source/css/style.styl","hash":"c7e09da5bb90519a238678be99658ec81be2c281","modified":1574433140624},{"_id":"themes/icarus/source/images/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1573904760758},{"_id":"themes/icarus/source/images/F56DE54B62B5BCF1.png","hash":"2c135acbbfd20ea3e259134595420abecf8a3e2e","modified":1573904062468},{"_id":"themes/icarus/source/images/favicon.svg","hash":"16fd847265845063a16596761cddb32926073dd2","modified":1573812312396},{"_id":"themes/icarus/source/images/logo2.svg","hash":"94fabc0c15aad0954afed44baeedac0a27c94607","modified":1573904062471},{"_id":"themes/icarus/source/images/logo_org.svg","hash":"e9b5c1438ddb576693a15d0713b2a1d9ceda4be9","modified":1573812312397},{"_id":"themes/icarus/source/images/thumbnail.svg","hash":"b9c58ff09ed415e6cf08b42b35faa2bc000d5059","modified":1573812312398},{"_id":"themes/icarus/source/images/og_image.png","hash":"b03f163096ca9c350ec962feee9836277b5c2509","modified":1573812312397},{"_id":"themes/icarus/source/js/animation.js","hash":"d744581909d2d092a584be07c39f9d3f0d009ec7","modified":1573812312398},{"_id":"themes/icarus/source/js/back-to-top.js","hash":"b1dcf30577cefe833dc6151757c0a05ea5b5a643","modified":1573812312398},{"_id":"themes/icarus/source/js/gallery.js","hash":"bb74e694457dc23b83ac80cf5aadcd26b60469fd","modified":1573812312399},{"_id":"themes/icarus/source/js/globalUtils.js","hash":"e791ef24da1f4654d698d7b073975f2fb6986946","modified":1574433526797},{"_id":"themes/icarus/source/js/insight.js","hash":"8ba56fd5e4232a05ccef5f8b733c7ecca0814633","modified":1573812312399},{"_id":"themes/icarus/source/js/main.js","hash":"cf917a627d400993d285ed83712aec170ebc92ad","modified":1573841133556},{"_id":"themes/icarus/source/js/theme-setting.js","hash":"ad9760e68369049af8c699e3034a89a94db4d2ed","modified":1574433239963},{"_id":"themes/icarus/source/images/favicon1.svg","hash":"5c5b3fc2105eeda0cbc58061f248f941a9e7dce2","modified":1573824387830},{"_id":"themes/icarus/source/images/logo.png","hash":"855f3f6f839f9f1da7ed13faa6fc8c3ab74e026b","modified":1573904510471},{"_id":"themes/icarus/source/images/logo3","hash":"5cded40b24ede6308b8d2280ded08378f43eb157","modified":1573904193466},{"_id":"source/images/2019/08/23/2f8318c0-c55a-11e9-b9cb-2ff8473d5c85.png","hash":"f7accd70722e6b3c3313e0eaf274a9e81d568378","modified":1566532674677},{"_id":"source/images/2019/08/23/336757d0-c55a-11e9-b9cb-2ff8473d5c85.png","hash":"f7accd70722e6b3c3313e0eaf274a9e81d568378","modified":1566532681166},{"_id":"source/images/2019/08/23/38cf50b0-c55a-11e9-b9cb-2ff8473d5c85.png","hash":"f7accd70722e6b3c3313e0eaf274a9e81d568378","modified":1566532690236},{"_id":"source/images/2019/08/23/42dd5200-c55a-11e9-b9cb-2ff8473d5c85.png","hash":"f7accd70722e6b3c3313e0eaf274a9e81d568378","modified":1566532707105},{"_id":"source/images/2019/08/23/46288560-c55a-11e9-b9cb-2ff8473d5c85.png","hash":"f7accd70722e6b3c3313e0eaf274a9e81d568378","modified":1566532712631},{"_id":"source/images/2019/08/23/4b872f70-c55a-11e9-b9cb-2ff8473d5c85.png","hash":"f7accd70722e6b3c3313e0eaf274a9e81d568378","modified":1566532721640},{"_id":"source/images/2019/08/23/5394f3f0-c55a-11e9-b9cb-2ff8473d5c85.png","hash":"f7accd70722e6b3c3313e0eaf274a9e81d568378","modified":1566532735151},{"_id":"source/images/2019/08/23/c640c4a0-c55b-11e9-b9cb-2ff8473d5c85.png","hash":"265eb049f4965eff5775c29dc0def8925118e0b7","modified":1566533357036},{"_id":"source/images/2019/08/23/ced0a6e0-c55a-11e9-b9cb-2ff8473d5c85.png","hash":"13280726c3419de7f35c4b709015d7ea8bc940d6","modified":1566532941904},{"_id":"source/images/2019/08/23/5e563fb0-c55a-11e9-b9cb-2ff8473d5c85.png","hash":"f7accd70722e6b3c3313e0eaf274a9e81d568378","modified":1566532753197},{"_id":"source/images/2019/08/23/e92e9230-c55b-11e9-b9cb-2ff8473d5c85.png","hash":"84ab8f3d45b77741c4108de77e2fa6d6ef7a454d","modified":1566533415638},{"_id":"source/images/2019/08/23/73674620-c559-11e9-b9cb-2ff8473d5c85.png","hash":"6e1ad379639044c3407d55c1089d5db10ce56b41","modified":1566532359047},{"_id":"source/images/2019/11/05/b6400f10-ffd1-11e9-b31e-e7c5b37d7122.png","hash":"e2a317df3b5f52567b18b12bf48b70a9d1b841a8","modified":1572961178245},{"_id":"source/images/2019/11/05/b6405d30-ffd1-11e9-b31e-e7c5b37d7122.png","hash":"81b522e47d182d11a44a7336a07a79144c3b3bce","modified":1572961178245},{"_id":"source/images/2019/08/23/0a2dbf70-c5ba-11e9-a08f-f3347b368783.png","hash":"e578a85b5c11dd74de9a87674f078399672cefab","modified":1566573843694},{"_id":"source/images/15739641433464.png","hash":"018d2b1278c171c7502b819732b8f45609e49987","modified":1573964143489},{"_id":"themes/icarus/source/images/avatar.png","hash":"a4fa62fd5a67f2f8182d5da5736fc8a17b8f5ff6","modified":1573811143362},{"_id":"public/CNAME","hash":"bc6ba17a1c836a4ed19a341b05927a874c94b978","modified":1574857395277},{"_id":"public/baidusitemap.xml","hash":"d362ba07455aaed08d578bb07113f35c0ef0632c","modified":1574857395277},{"_id":"public/atom.xml","hash":"5e446b989523c529962806f97a160d404da272a9","modified":1574857395277},{"_id":"public/search.xml","hash":"bcd7468e812a92d3a209fc9dbc0463b5474c577d","modified":1574857395277},{"_id":"public/sitemap.xml","hash":"317d21ae89ccaa5764f99368abe53ed3f0779448","modified":1574857395277},{"_id":"public/content.json","hash":"d62c3fb74715c7c51550bffc534dd41068961e19","modified":1574857395277},{"_id":"public/FakeNews/index.html","hash":"1d286705001a60548cd39d0a1c0789db50efc9e2","modified":1574857395277},{"_id":"public/JS/index.html","hash":"b9f85024a0946e3eeacfc3c31c272c253eb9ea3b","modified":1574857395277},{"_id":"public/MARL/index.html","hash":"8a8c06280a348aa44719c1d403d39bc7a08b3f65","modified":1574857395277},{"_id":"public/NLP/index.html","hash":"e2b0e7f3a396fea0d2d0147e926aa254f01d8ddc","modified":1574857395277},{"_id":"public/Python/index.html","hash":"be7e020106f36d0cee18458fa6eeb5a01229362e","modified":1574857395277},{"_id":"public/RL/index.html","hash":"74b4ec7d78d0f6fb5dba8c7355680e809c0694be","modified":1574857395277},{"_id":"public/categories/index.html","hash":"11774f1a3043a209b8d39d68db5985d43c597bef","modified":1574857395277},{"_id":"public/tags/index.html","hash":"9da69f88751969bda77fe0a4e8e6802c95ef5132","modified":1574857395277},{"_id":"public/gallery/index.html","hash":"baba98783144a2b1fb4a9e3d477019dbf513791b","modified":1574857395277},{"_id":"public/search/index.html","hash":"62bf267dc0a05c8becf04a5b24753a54737d628b","modified":1574857395277},{"_id":"public/about/index.html","hash":"8b8244350f2aa62756a679e38e87569091766ff8","modified":1574857395277},{"_id":"public/旧的梦/index.html","hash":"ca39bdc61658e2b06596db13e8f098f34f9cba95","modified":1574857395277},{"_id":"public/分布式计算学习笔记-二-Ray.html","hash":"a5b7f0044b192fd0e92eaf2146e753b1c2c16c58","modified":1574857395277},{"_id":"public/分布式计算学习笔记-一-从分布式系统到分布式计算.html","hash":"5bb61092466352c0ea49692f9fb1295d7d43a55a","modified":1574857395277},{"_id":"public/Hexo主题折腾日记-二-添加豆瓣和聊天插件.html","hash":"1c3d8ad484db8daaf74d3a7412b1593a3528b0e7","modified":1574857395277},{"_id":"public/Hexo主题折腾日记-从cactus到icarus.html","hash":"a8c1387f9e539f311182a73cbb864b726f173554","modified":1574857395277},{"_id":"public/一亩三分地自动签到脚本.html","hash":"5b581b6cf7fc22ab936f1d3ef2e49439e0b5df20","modified":1574857395277},{"_id":"public/10-04-2019-柳烈的音乐专辑.html","hash":"3d70c3972419cbf418eccb60ee62fe7565013c76","modified":1574857395277},{"_id":"public/Cest-la-vie-Sep-24-2019.html","hash":"c8f94cedce5332591ac9f99c88be9c880d0b5fee","modified":1574857395277},{"_id":"public/Sep-17，2019-保研.html","hash":"327f25f349189d56e3a6128e70bda05c57ae288f","modified":1574857395277},{"_id":"public/Sep-2-2019.html","hash":"6025ab0f987e9c1022c0e4704e8d70f5020b8f49","modified":1574857395277},{"_id":"public/Google-BERT-on-fake-or-real-news-dataset.html","hash":"aaeccabf97047968a7c03acedfed2054e73d4ff9","modified":1574857395277},{"_id":"public/旧的文/index.html","hash":"e7611926fdf5bb1a734a042d7abcf78e68719698","modified":1574857395277},{"_id":"public/Fake-News-学习笔记（四）.html","hash":"d3be7eed4c2872ebb50d26bcdd4f629c58a61aa2","modified":1574857395277},{"_id":"public/如父如子.html","hash":"14830806a9ccf61dd2e682564e3b46e9ddadcaf3","modified":1574857395277},{"_id":"public/Fake News 学习笔记（三）Bert 负采样 Transformer.html","hash":"726fc3e6132b08824411663928acd0c34759a0c3","modified":1574857395277},{"_id":"public/奇迹唱片行.html","hash":"89c4ac9becfc217dac118fbedacfbe871431beec","modified":1574857395277},{"_id":"public/1987.html","hash":"d7213683770a6eda15d2fa41ff099a4e18c21b6a","modified":1574857395277},{"_id":"public/hello-world.html","hash":"978bc48e84e3118af12abd0d93ff3ea5d9aa5a16","modified":1574857395277},{"_id":"public/The-Post.html","hash":"f91f1dfe92576afea328abf37b656ef7a6f5fafe","modified":1574857395277},{"_id":"public/追风筝的人.html","hash":"6399f00eb13eabe35bf96166273dbecde58bac48","modified":1574857395277},{"_id":"public/岛上书店.html","hash":"f468711eb5a351c3917e0d18045874169d31cc10","modified":1574857395277},{"_id":"public/房思琪的初恋乐园.html","hash":"2d4b7e0538cd97510838b59182ec63ed6b94e556","modified":1574857395277},{"_id":"public/Fake News 学习笔记（一）分类器，f1 score.html","hash":"cb1d553460f70274800fd1f391b84e54b5ee5c3d","modified":1574857395277},{"_id":"public/Fake News 学习笔记（二） one-hot-coding Stem-and-Lem Word2Vec.html","hash":"2ea8a77fccb05b42d691b7be9b7bc27be0584a44","modified":1574857395277},{"_id":"public/痛苦的MARL-三.html","hash":"e7e2a8ea9b97e3912904b5d9ec687794a058b41e","modified":1574857395277},{"_id":"public/痛苦的MARL-二.html","hash":"46fc7c89255dd6f6a86896fcbf412e7a4bca4074","modified":1574857395277},{"_id":"public/痛苦的MARL-一.html","hash":"8079d21697f1e26ab0180fb15290f5cee62dede5","modified":1574857395277},{"_id":"public/无声告白.html","hash":"d878ace8e7f1b45ce98c5e21dcbc7d87a866e92f","modified":1574857395277},{"_id":"public/March-26-2019.html","hash":"9146418d28718f6f16d95f6eaa736c91d2fd0ff2","modified":1574857395277},{"_id":"public/March-18-2019.html","hash":"4c0430ef4f6f6b65da7f08a2afd973a2e541e27e","modified":1574857395277},{"_id":"public/Dec-15-2018.html","hash":"08026c0737bbb591b83e43ade971014152e73885","modified":1574857395277},{"_id":"public/Dec-27-2017.html","hash":"3f02cf766f1ac18498a2b9749db6ed55577ed39a","modified":1574857395277},{"_id":"public/Dec-6-2017.html","hash":"2ed481324317ec58d29df97b36c71ff437b0fdc0","modified":1574857395277},{"_id":"public/archives/index.html","hash":"410329f33772eb8233e86b3ff14e05f095c666b8","modified":1574857395277},{"_id":"public/archives/page/2/index.html","hash":"4e886c5cf07df078afc463b35d3d22cbab77bafa","modified":1574857395277},{"_id":"public/archives/page/3/index.html","hash":"906dea14425ef80a31b27c23f351bd916f0db45b","modified":1574857395277},{"_id":"public/archives/page/4/index.html","hash":"20f1e32236607ccd64edf8f2dbd614d475de1685","modified":1574857395277},{"_id":"public/archives/2017/12/index.html","hash":"27dad2939802015a7783e227cb31e80f6a0eafec","modified":1574857395277},{"_id":"public/archives/2018/index.html","hash":"ef5d05993142b45e0cc41f37b40c46198d31e205","modified":1574857395277},{"_id":"public/archives/2017/index.html","hash":"199d42064f512c74d1609635c3bba3cb31b585f4","modified":1574857395277},{"_id":"public/archives/2018/12/index.html","hash":"002b5dd941265f7cc2466d9d2a3aed7fd35d62ce","modified":1574857395277},{"_id":"public/archives/2019/index.html","hash":"e48755319aa97b03432ad0da637cbf4e9045b90a","modified":1574857395277},{"_id":"public/archives/2019/page/2/index.html","hash":"59256ec324c19fa8b37267764e90ab3edba4ea26","modified":1574857395277},{"_id":"public/archives/2019/page/3/index.html","hash":"7217c1aa420fb2348cd11cb992225d9bc5b22d19","modified":1574857395277},{"_id":"public/archives/2019/03/index.html","hash":"a959a85855c6c7436ae7f34909a8a266cba0ab95","modified":1574857395277},{"_id":"public/archives/2019/05/index.html","hash":"2dc4d9cba2142190fa235f74ff98b157c5394dcc","modified":1574857395277},{"_id":"public/archives/2019/07/index.html","hash":"5290616d21dfc1d4f3d29250612af6cd252a9fc1","modified":1574857395277},{"_id":"public/archives/2019/08/index.html","hash":"d333df973edd5caaed27ea17c3265212156f4cf9","modified":1574857395277},{"_id":"public/archives/2019/08/page/2/index.html","hash":"be689b543f4ec3c1167550bf5de08fd414e4d2c0","modified":1574857395277},{"_id":"public/archives/2019/09/index.html","hash":"ce2538358aed432badba196236e7a0dfe299f35e","modified":1574857395277},{"_id":"public/archives/2019/10/index.html","hash":"ef537ddcc96e2a2c89cc9fb4b2d109ff902bdb1d","modified":1574857395277},{"_id":"public/archives/2019/11/index.html","hash":"724219bb400af74996c36bfa1a98422b092fe1e3","modified":1574857395277},{"_id":"public/index.html","hash":"d44774608d0e21c9b10cb30a08ab228222b976ef","modified":1574857395277},{"_id":"public/page/2/index.html","hash":"9c5e309235a9631a69f681b64b9150a8e65dcce0","modified":1574857395277},{"_id":"public/page/3/index.html","hash":"8ac098ab4784abeadb0f4b4cf615a45337ad1410","modified":1574857395277},{"_id":"public/page/4/index.html","hash":"e8a4b534cb8332d6b2e9d821f0a4d392dabe3668","modified":1574857395277},{"_id":"public/categories/旧的文/index.html","hash":"769ebb2a1fc1e14e665cecc9027ed9b8adc91d98","modified":1574857395277},{"_id":"public/categories/旧的文/page/2/index.html","hash":"2d113ab20790dc6be12514240808c84ba7870e5b","modified":1574857395277},{"_id":"public/categories/旧的梦/index.html","hash":"2ad59257a78b4e759c1a6a4a6b0a0492528d3c87","modified":1574857395277},{"_id":"public/categories/FakeNews/index.html","hash":"7c3d3d34bb0c507943cba92b8b308ae9282e02c4","modified":1574857395277},{"_id":"public/categories/MARL/index.html","hash":"63e9ab965bf04d93af7f94aa0f04a20e3cc60dfd","modified":1574857395277},{"_id":"public/tags/NLP/index.html","hash":"46b6e657ac496d3c4460a353d7d92e2fbc5c0e2d","modified":1574857395277},{"_id":"public/tags/Python/index.html","hash":"ad1d543fbc10929d3a9851a0d6b69a3160cf2ca8","modified":1574857395277},{"_id":"public/tags/JS/index.html","hash":"91f531b2d336853381bbd470bf1b9d79f1371558","modified":1574857395277},{"_id":"public/tags/RL/index.html","hash":"39bf044dc8ddbd8cb5ca5ba5c1f3dc92a62ff66a","modified":1574857395277},{"_id":"public/README.md","hash":"d35806b1775737aeee447737cec5a6fe14320c27","modified":1574857395277},{"_id":"public/robot.txt","hash":"68ca84057b13d453ab5e5621419b5be34d55cf17","modified":1574857395277},{"_id":"public/images/favicon.svg","hash":"16fd847265845063a16596761cddb32926073dd2","modified":1574857395277},{"_id":"public/images/F56DE54B62B5BCF1.png","hash":"2c135acbbfd20ea3e259134595420abecf8a3e2e","modified":1574857395277},{"_id":"public/images/logo2.svg","hash":"94fabc0c15aad0954afed44baeedac0a27c94607","modified":1574857395277},{"_id":"public/images/logo_org.svg","hash":"e9b5c1438ddb576693a15d0713b2a1d9ceda4be9","modified":1574857395277},{"_id":"public/images/thumbnail.svg","hash":"b9c58ff09ed415e6cf08b42b35faa2bc000d5059","modified":1574857395277},{"_id":"public/images/og_image.png","hash":"b03f163096ca9c350ec962feee9836277b5c2509","modified":1574857395277},{"_id":"public/images/2019/08/23/2f8318c0-c55a-11e9-b9cb-2ff8473d5c85.png","hash":"f7accd70722e6b3c3313e0eaf274a9e81d568378","modified":1574857395277},{"_id":"public/images/2019/08/23/336757d0-c55a-11e9-b9cb-2ff8473d5c85.png","hash":"f7accd70722e6b3c3313e0eaf274a9e81d568378","modified":1574857395277},{"_id":"public/images/2019/08/23/38cf50b0-c55a-11e9-b9cb-2ff8473d5c85.png","hash":"f7accd70722e6b3c3313e0eaf274a9e81d568378","modified":1574857395277},{"_id":"public/images/2019/08/23/42dd5200-c55a-11e9-b9cb-2ff8473d5c85.png","hash":"f7accd70722e6b3c3313e0eaf274a9e81d568378","modified":1574857395277},{"_id":"public/images/2019/08/23/4b872f70-c55a-11e9-b9cb-2ff8473d5c85.png","hash":"f7accd70722e6b3c3313e0eaf274a9e81d568378","modified":1574857395277},{"_id":"public/images/2019/08/23/46288560-c55a-11e9-b9cb-2ff8473d5c85.png","hash":"f7accd70722e6b3c3313e0eaf274a9e81d568378","modified":1574857395277},{"_id":"public/images/2019/08/23/5394f3f0-c55a-11e9-b9cb-2ff8473d5c85.png","hash":"f7accd70722e6b3c3313e0eaf274a9e81d568378","modified":1574857395277},{"_id":"public/images/2019/08/23/ced0a6e0-c55a-11e9-b9cb-2ff8473d5c85.png","hash":"13280726c3419de7f35c4b709015d7ea8bc940d6","modified":1574857395277},{"_id":"public/images/2019/08/23/5e563fb0-c55a-11e9-b9cb-2ff8473d5c85.png","hash":"f7accd70722e6b3c3313e0eaf274a9e81d568378","modified":1574857395277},{"_id":"public/images/2019/08/23/c640c4a0-c55b-11e9-b9cb-2ff8473d5c85.png","hash":"265eb049f4965eff5775c29dc0def8925118e0b7","modified":1574857395277},{"_id":"public/images/favicon1.svg","hash":"5c5b3fc2105eeda0cbc58061f248f941a9e7dce2","modified":1574857395277},{"_id":"public/images/2019/08/23/e92e9230-c55b-11e9-b9cb-2ff8473d5c85.png","hash":"84ab8f3d45b77741c4108de77e2fa6d6ef7a454d","modified":1574857395277},{"_id":"public/images/2019/08/23/73674620-c559-11e9-b9cb-2ff8473d5c85.png","hash":"6e1ad379639044c3407d55c1089d5db10ce56b41","modified":1574857395277},{"_id":"public/images/2019/11/05/b6400f10-ffd1-11e9-b31e-e7c5b37d7122.png","hash":"e2a317df3b5f52567b18b12bf48b70a9d1b841a8","modified":1574857395277},{"_id":"public/images/2019/11/05/b6405d30-ffd1-11e9-b31e-e7c5b37d7122.png","hash":"81b522e47d182d11a44a7336a07a79144c3b3bce","modified":1574857395277},{"_id":"public/images/2019/08/23/0a2dbf70-c5ba-11e9-a08f-f3347b368783.png","hash":"e578a85b5c11dd74de9a87674f078399672cefab","modified":1574857395277},{"_id":"public/css/back-to-top.css","hash":"5805bee2445e997d64dfe526b08b5fe0bce357eb","modified":1574857395277},{"_id":"public/css/insight.css","hash":"22943a610d5cfffedfb823c692f4db2b1f37a4c9","modified":1574857395277},{"_id":"public/css/progressbar.css","hash":"bbc737b7a8feb19901e792c447a846273779d5c3","modified":1574857395277},{"_id":"public/css/search.css","hash":"d6a59894819e7431d42b249b6c2fc9ff3b99a488","modified":1574857395277},{"_id":"public/js/animation.js","hash":"d744581909d2d092a584be07c39f9d3f0d009ec7","modified":1574857395277},{"_id":"public/js/back-to-top.js","hash":"b1dcf30577cefe833dc6151757c0a05ea5b5a643","modified":1574857395277},{"_id":"public/js/gallery.js","hash":"bb74e694457dc23b83ac80cf5aadcd26b60469fd","modified":1574857395277},{"_id":"public/js/globalUtils.js","hash":"e791ef24da1f4654d698d7b073975f2fb6986946","modified":1574857395277},{"_id":"public/js/insight.js","hash":"8ba56fd5e4232a05ccef5f8b733c7ecca0814633","modified":1574857395277},{"_id":"public/js/main.js","hash":"cf917a627d400993d285ed83712aec170ebc92ad","modified":1574857395277},{"_id":"public/js/theme-setting.js","hash":"ad9760e68369049af8c699e3034a89a94db4d2ed","modified":1574857395277},{"_id":"public/css/style.css","hash":"683a1561be58d62d5ec029d05e749426cfbae13c","modified":1574857395277},{"_id":"public/images/logo3","hash":"5cded40b24ede6308b8d2280ded08378f43eb157","modified":1574857395277},{"_id":"public/images/logo.png","hash":"855f3f6f839f9f1da7ed13faa6fc8c3ab74e026b","modified":1574857395277},{"_id":"public/images/15739641433464.png","hash":"018d2b1278c171c7502b819732b8f45609e49987","modified":1574857395277},{"_id":"public/images/avatar.png","hash":"a4fa62fd5a67f2f8182d5da5736fc8a17b8f5ff6","modified":1574857395277}],"Category":[{"name":"旧的文","_id":"ck3h9fkoi0004k3x6ev2y7w9i"},{"name":"旧的梦","_id":"ck3h9fkp2000hk3x6am4r4lst"},{"name":"FakeNews","_id":"ck3h9fkpq0012k3x68b19bdbi"},{"name":"MARL","_id":"ck3h9fkqu002lk3x6c90w8hdt"}],"Data":[],"Page":[{"title":"FakeNews","date":"2019-08-24T03:58:17.000Z","type":"categories","_content":"","source":"FakeNews/index.md","raw":"---\ntitle: FakeNews\ndate: 2019-08-24 11:58:17\ntype: \"categories\"\n---\n","updated":"2019-08-24T03:58:42.889Z","path":"FakeNews/index.html","comments":1,"layout":"page","_id":"ck3h9fko30000k3x660812aa0","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"JS","type":"tags","date":"2019-11-16T12:09:56.000Z","_content":"","source":"JS/index.md","raw":"---\ntitle: JS\ntype: \"tags\"\ndate: 2019-11-16 20:09:56\n---\n","updated":"2019-11-16T12:10:11.907Z","path":"JS/index.html","comments":1,"layout":"page","_id":"ck3h9fkoe0002k3x63fch2o9m","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"MARL","date":"2019-11-16T12:06:25.000Z","type":"categories","_content":"","source":"MARL/index.md","raw":"---\ntitle: MARL\ndate: 2019-11-16 20:06:25\ntype: \"categories\"\n---\n","updated":"2019-11-16T12:06:33.782Z","path":"MARL/index.html","comments":1,"layout":"page","_id":"ck3h9fkol0005k3x6dedegnyu","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"NLP","date":"2019-08-24T03:54:39.000Z","type":"tags","_content":"","source":"NLP/index.md","raw":"---\ntitle: NLP\ndate: 2019-08-24 11:54:39\ntype: \"tags\"\n---","updated":"2019-08-24T03:56:10.093Z","path":"NLP/index.html","comments":1,"layout":"page","_id":"ck3h9fkop0007k3x6hha71pv4","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Python","type":"tags","date":"2019-11-16T12:09:43.000Z","_content":"","source":"Python/index.md","raw":"---\ntitle: Python\ntype: \"tags\"\ndate: 2019-11-16 20:09:43\n---\n","updated":"2019-11-16T12:10:14.348Z","path":"Python/index.html","comments":1,"layout":"page","_id":"ck3h9fkor0009k3x687924z0j","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"RL","date":"2019-11-16T11:59:08.000Z","type":"tags","_content":"","source":"RL/index.md","raw":"---\ntitle: RL\ndate: 2019-11-16 19:59:08\ntype: \"tags\"\n---\n","updated":"2019-11-16T11:59:35.226Z","path":"RL/index.html","comments":1,"layout":"page","_id":"ck3h9fkox000ck3x67aib9sbz","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"categories","date":"2019-08-11T02:08:57.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2019-08-11 10:08:57\ntype: categories\n---\n","updated":"2019-08-11T02:09:50.387Z","path":"categories/index.html","comments":1,"layout":"page","_id":"ck3h9fkp0000ek3x61tb5fjnp","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"about","date":"2019-11-16T07:45:01.000Z","thumbnail":"https://raw.githubusercontent.com/NavePnow/blog_photo/master/Xnip2019-11-15_17-48-40.jpg","_content":"\n# nave.work\n\n> My lovely blog\n\n[![Build Status](https://travis-ci.org/NavePnow/nave.work.svg?branch=master)](https://travis-ci.org/NavePnow/nave.work) [![dependencies Status](https://david-dm.org/NavePnow/nave.work/status.svg)](https://david-dm.org/NavePnow/nave.work)\n\n## **About me**\n\n还活着。\n\n本科 CS 专业，不知道是不是知名的985院校，目前大四，GT狗，预计美妍继续 CS，12.1最后一次托，再拼一把争取前三十。想去LA, 去感受一下 LALALAND 的氛围，当然毕业之前有很多打算，换一个电脑，买一个微单，去很多很多地方。。地址之所以写台湾是因为我对她，爱的深沉。\n\n不要对我有期待。\n\n## **About website**\n\n总要试着留下些东西，就像 Remember me 里面提到的，人真的会随着时间和记忆慢慢消逝，所以我要记下来，即使是霎那间溜走的梦，我也要记下来，还记得有一次托福考前我梦见你了，流着泪拿起手机赶快记下梦里的事情，哪怕一句话，一个微笑。我会忘记，但东西一旦放到网上，他就永远不会丢失，就像漂流瓶一样，即使看不见他在哪里，但你知道，它确确实实存在在这个物理世界里。\n\n不要手懒，看完一本书，看完一个电影，和他人的美好邂逅，值得回忆的东西都值得让你动动手记录下来，即使以后忘记了，也可以翻出来，说，你看，我还有这样的故事呢。\n\n> Build: [Hexo](https://hexo.io/) + [Icarus](http://github.com/ppoffice/hexo-theme-icarus)  + [Travis CI](https://travis-ci.org/) +  [Github pages](https://github.com/NavePnow/navepnow.github.io)\n\n> Image Hosting: [Github](https://github.com/NavePnow/blog_photo) + [Tencent Cloud COS](https://cloud.tencent.com/product/cos)\n\n> Thumbnail library: [UNPLASH PHOTO](https://unsplash.com/)\n\n> DNS + SSL : [Cloudflare](https://www.cloudflare.com/)\n\n## Some tips about hexo\n1. Save original README.md (navepnow.github.io) after each update\n    1. touch source/README.md\n    2. echo \"skip_render: - README.md\" >> _config.yml\n2. Use LaTex in my blog\n    `https://www.jianshu.com/p/68e6f82d88b7`\n3. DO NOT PRESS SPACE CASUALLY WHILE WRITING","source":"about/index.md","raw":"---\ntitle: about\ndate: 2019-11-16 15:45:01\nthumbnail: https://raw.githubusercontent.com/NavePnow/blog_photo/master/Xnip2019-11-15_17-48-40.jpg\n---\n\n# nave.work\n\n> My lovely blog\n\n[![Build Status](https://travis-ci.org/NavePnow/nave.work.svg?branch=master)](https://travis-ci.org/NavePnow/nave.work) [![dependencies Status](https://david-dm.org/NavePnow/nave.work/status.svg)](https://david-dm.org/NavePnow/nave.work)\n\n## **About me**\n\n还活着。\n\n本科 CS 专业，不知道是不是知名的985院校，目前大四，GT狗，预计美妍继续 CS，12.1最后一次托，再拼一把争取前三十。想去LA, 去感受一下 LALALAND 的氛围，当然毕业之前有很多打算，换一个电脑，买一个微单，去很多很多地方。。地址之所以写台湾是因为我对她，爱的深沉。\n\n不要对我有期待。\n\n## **About website**\n\n总要试着留下些东西，就像 Remember me 里面提到的，人真的会随着时间和记忆慢慢消逝，所以我要记下来，即使是霎那间溜走的梦，我也要记下来，还记得有一次托福考前我梦见你了，流着泪拿起手机赶快记下梦里的事情，哪怕一句话，一个微笑。我会忘记，但东西一旦放到网上，他就永远不会丢失，就像漂流瓶一样，即使看不见他在哪里，但你知道，它确确实实存在在这个物理世界里。\n\n不要手懒，看完一本书，看完一个电影，和他人的美好邂逅，值得回忆的东西都值得让你动动手记录下来，即使以后忘记了，也可以翻出来，说，你看，我还有这样的故事呢。\n\n> Build: [Hexo](https://hexo.io/) + [Icarus](http://github.com/ppoffice/hexo-theme-icarus)  + [Travis CI](https://travis-ci.org/) +  [Github pages](https://github.com/NavePnow/navepnow.github.io)\n\n> Image Hosting: [Github](https://github.com/NavePnow/blog_photo) + [Tencent Cloud COS](https://cloud.tencent.com/product/cos)\n\n> Thumbnail library: [UNPLASH PHOTO](https://unsplash.com/)\n\n> DNS + SSL : [Cloudflare](https://www.cloudflare.com/)\n\n## Some tips about hexo\n1. Save original README.md (navepnow.github.io) after each update\n    1. touch source/README.md\n    2. echo \"skip_render: - README.md\" >> _config.yml\n2. Use LaTex in my blog\n    `https://www.jianshu.com/p/68e6f82d88b7`\n3. DO NOT PRESS SPACE CASUALLY WHILE WRITING","updated":"2019-11-27T11:28:30.861Z","path":"about/index.html","comments":1,"layout":"page","_id":"ck3h9fkp5000ik3x65mlubdo3","content":"<h1 id=\"nave-work\"><a href=\"#nave-work\" class=\"headerlink\" title=\"nave.work\"></a>nave.work</h1><blockquote>\n<p>My lovely blog</p>\n</blockquote>\n<p><a href=\"https://travis-ci.org/NavePnow/nave.work\" target=\"_blank\" rel=\"noopener\"><img src=\"https://travis-ci.org/NavePnow/nave.work.svg?branch=master\" alt=\"Build Status\"></a> <a href=\"https://david-dm.org/NavePnow/nave.work\" target=\"_blank\" rel=\"noopener\"><img src=\"https://david-dm.org/NavePnow/nave.work/status.svg\" alt=\"dependencies Status\"></a></p>\n<h2 id=\"About-me\"><a href=\"#About-me\" class=\"headerlink\" title=\"About me\"></a><strong>About me</strong></h2><p>还活着。</p>\n<p>本科 CS 专业，不知道是不是知名的985院校，目前大四，GT狗，预计美妍继续 CS，12.1最后一次托，再拼一把争取前三十。想去LA, 去感受一下 LALALAND 的氛围，当然毕业之前有很多打算，换一个电脑，买一个微单，去很多很多地方。。地址之所以写台湾是因为我对她，爱的深沉。</p>\n<p>不要对我有期待。</p>\n<h2 id=\"About-website\"><a href=\"#About-website\" class=\"headerlink\" title=\"About website\"></a><strong>About website</strong></h2><p>总要试着留下些东西，就像 Remember me 里面提到的，人真的会随着时间和记忆慢慢消逝，所以我要记下来，即使是霎那间溜走的梦，我也要记下来，还记得有一次托福考前我梦见你了，流着泪拿起手机赶快记下梦里的事情，哪怕一句话，一个微笑。我会忘记，但东西一旦放到网上，他就永远不会丢失，就像漂流瓶一样，即使看不见他在哪里，但你知道，它确确实实存在在这个物理世界里。</p>\n<p>不要手懒，看完一本书，看完一个电影，和他人的美好邂逅，值得回忆的东西都值得让你动动手记录下来，即使以后忘记了，也可以翻出来，说，你看，我还有这样的故事呢。</p>\n<blockquote>\n<p>Build: <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a> + <a href=\"http://github.com/ppoffice/hexo-theme-icarus\" target=\"_blank\" rel=\"noopener\">Icarus</a>  + <a href=\"https://travis-ci.org/\" target=\"_blank\" rel=\"noopener\">Travis CI</a> +  <a href=\"https://github.com/NavePnow/navepnow.github.io\" target=\"_blank\" rel=\"noopener\">Github pages</a></p>\n</blockquote>\n<blockquote>\n<p>Image Hosting: <a href=\"https://github.com/NavePnow/blog_photo\" target=\"_blank\" rel=\"noopener\">Github</a> + <a href=\"https://cloud.tencent.com/product/cos\" target=\"_blank\" rel=\"noopener\">Tencent Cloud COS</a></p>\n</blockquote>\n<blockquote>\n<p>Thumbnail library: <a href=\"https://unsplash.com/\" target=\"_blank\" rel=\"noopener\">UNPLASH PHOTO</a></p>\n</blockquote>\n<blockquote>\n<p>DNS + SSL : <a href=\"https://www.cloudflare.com/\" target=\"_blank\" rel=\"noopener\">Cloudflare</a></p>\n</blockquote>\n<h2 id=\"Some-tips-about-hexo\"><a href=\"#Some-tips-about-hexo\" class=\"headerlink\" title=\"Some tips about hexo\"></a>Some tips about hexo</h2><ol>\n<li>Save original README.md (navepnow.github.io) after each update<ol>\n<li>touch source/README.md</li>\n<li>echo “skip_render: - README.md” &gt;&gt; _config.yml</li>\n</ol>\n</li>\n<li>Use LaTex in my blog<br> <code>https://www.jianshu.com/p/68e6f82d88b7</code></li>\n<li>DO NOT PRESS SPACE CASUALLY WHILE WRITING</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"nave-work\"><a href=\"#nave-work\" class=\"headerlink\" title=\"nave.work\"></a>nave.work</h1><blockquote>\n<p>My lovely blog</p>\n</blockquote>\n<p><a href=\"https://travis-ci.org/NavePnow/nave.work\" target=\"_blank\" rel=\"noopener\"><img src=\"https://travis-ci.org/NavePnow/nave.work.svg?branch=master\" alt=\"Build Status\"></a> <a href=\"https://david-dm.org/NavePnow/nave.work\" target=\"_blank\" rel=\"noopener\"><img src=\"https://david-dm.org/NavePnow/nave.work/status.svg\" alt=\"dependencies Status\"></a></p>\n<h2 id=\"About-me\"><a href=\"#About-me\" class=\"headerlink\" title=\"About me\"></a><strong>About me</strong></h2><p>还活着。</p>\n<p>本科 CS 专业，不知道是不是知名的985院校，目前大四，GT狗，预计美妍继续 CS，12.1最后一次托，再拼一把争取前三十。想去LA, 去感受一下 LALALAND 的氛围，当然毕业之前有很多打算，换一个电脑，买一个微单，去很多很多地方。。地址之所以写台湾是因为我对她，爱的深沉。</p>\n<p>不要对我有期待。</p>\n<h2 id=\"About-website\"><a href=\"#About-website\" class=\"headerlink\" title=\"About website\"></a><strong>About website</strong></h2><p>总要试着留下些东西，就像 Remember me 里面提到的，人真的会随着时间和记忆慢慢消逝，所以我要记下来，即使是霎那间溜走的梦，我也要记下来，还记得有一次托福考前我梦见你了，流着泪拿起手机赶快记下梦里的事情，哪怕一句话，一个微笑。我会忘记，但东西一旦放到网上，他就永远不会丢失，就像漂流瓶一样，即使看不见他在哪里，但你知道，它确确实实存在在这个物理世界里。</p>\n<p>不要手懒，看完一本书，看完一个电影，和他人的美好邂逅，值得回忆的东西都值得让你动动手记录下来，即使以后忘记了，也可以翻出来，说，你看，我还有这样的故事呢。</p>\n<blockquote>\n<p>Build: <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a> + <a href=\"http://github.com/ppoffice/hexo-theme-icarus\" target=\"_blank\" rel=\"noopener\">Icarus</a>  + <a href=\"https://travis-ci.org/\" target=\"_blank\" rel=\"noopener\">Travis CI</a> +  <a href=\"https://github.com/NavePnow/navepnow.github.io\" target=\"_blank\" rel=\"noopener\">Github pages</a></p>\n</blockquote>\n<blockquote>\n<p>Image Hosting: <a href=\"https://github.com/NavePnow/blog_photo\" target=\"_blank\" rel=\"noopener\">Github</a> + <a href=\"https://cloud.tencent.com/product/cos\" target=\"_blank\" rel=\"noopener\">Tencent Cloud COS</a></p>\n</blockquote>\n<blockquote>\n<p>Thumbnail library: <a href=\"https://unsplash.com/\" target=\"_blank\" rel=\"noopener\">UNPLASH PHOTO</a></p>\n</blockquote>\n<blockquote>\n<p>DNS + SSL : <a href=\"https://www.cloudflare.com/\" target=\"_blank\" rel=\"noopener\">Cloudflare</a></p>\n</blockquote>\n<h2 id=\"Some-tips-about-hexo\"><a href=\"#Some-tips-about-hexo\" class=\"headerlink\" title=\"Some tips about hexo\"></a>Some tips about hexo</h2><ol>\n<li>Save original README.md (navepnow.github.io) after each update<ol>\n<li>touch source/README.md</li>\n<li>echo “skip_render: - README.md” &gt;&gt; _config.yml</li>\n</ol>\n</li>\n<li>Use LaTex in my blog<br> <code>https://www.jianshu.com/p/68e6f82d88b7</code></li>\n<li>DO NOT PRESS SPACE CASUALLY WHILE WRITING</li>\n</ol>\n"},{"title":"tags","date":"2019-08-11T02:12:46.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2019-08-11 10:12:46\ntype: tags\n---\n","updated":"2019-08-11T02:13:04.276Z","path":"tags/index.html","comments":1,"layout":"page","_id":"ck3h9fkp8000mk3x626hog7zr","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"gallery","date":"2019-09-04T01:30:51.000Z","comment":true,"_content":"<center>\n<div style='width:48%;float:left;'>{% spotify https://open.spotify.com/playlist/1nsgzt7HlwOnf154ruMGbX?si=h9Mh9uRTSweSkWAqiAC8_Q %}</div>\n<div style='width:48%;float:left;'>{% spotify https://open.spotify.com/playlist/1ckpZgfArzXJi5y8kAXkfD?si=Vv6BgnUQTR-S4TFBLMDVDA %}</div>\n</center>\n\n{% stream %}\n<!--\n{% figure https://ww1.sinaimg.cn/large/006tNc79gy1g57wss1nnxj30b40gognn.jpg [轮到你了](https://movie.douban.com/subject/30446788/) %}\n{% figure https://raw.githubusercontent.com/NavePnow/blog_photo/master/d4b98fdcf540caed49ced3745e9026fd80299cf4.jpg %}\n{% figure https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight22.jpg [Cover 1] %}\n-->\n{% figure https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight22.jpg [Cover 1] %}\n{% figure https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight25.jpg [Cover 2] %}\n{% figure https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight23.jpg [Cover 3] %}\n{% figure https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight24.jpg [Cover 4] %}\n{% figure https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight21.jpeg [Cover 5] %}\n{% figure https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight10.jpg [Cover 6] %}\n{% figure https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/IMG_1737.jpeg [Dorm 1] %}\n{% figure https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/IMG_1785.jpeg [Dorm 2] %}\n{% figure https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/123.jpg [Goodbye] %}\n\n{% endstream %}\n","source":"gallery/index.md","raw":"---\ntitle: gallery\ndate: 2019-09-04 09:30:51\ncomment: true\n---\n<center>\n<div style='width:48%;float:left;'>{% spotify https://open.spotify.com/playlist/1nsgzt7HlwOnf154ruMGbX?si=h9Mh9uRTSweSkWAqiAC8_Q %}</div>\n<div style='width:48%;float:left;'>{% spotify https://open.spotify.com/playlist/1ckpZgfArzXJi5y8kAXkfD?si=Vv6BgnUQTR-S4TFBLMDVDA %}</div>\n</center>\n\n{% stream %}\n<!--\n{% figure https://ww1.sinaimg.cn/large/006tNc79gy1g57wss1nnxj30b40gognn.jpg [轮到你了](https://movie.douban.com/subject/30446788/) %}\n{% figure https://raw.githubusercontent.com/NavePnow/blog_photo/master/d4b98fdcf540caed49ced3745e9026fd80299cf4.jpg %}\n{% figure https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight22.jpg [Cover 1] %}\n-->\n{% figure https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight22.jpg [Cover 1] %}\n{% figure https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight25.jpg [Cover 2] %}\n{% figure https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight23.jpg [Cover 3] %}\n{% figure https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight24.jpg [Cover 4] %}\n{% figure https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight21.jpeg [Cover 5] %}\n{% figure https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight10.jpg [Cover 6] %}\n{% figure https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/IMG_1737.jpeg [Dorm 1] %}\n{% figure https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/IMG_1785.jpeg [Dorm 2] %}\n{% figure https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/123.jpg [Goodbye] %}\n\n{% endstream %}\n","updated":"2019-11-24T11:57:16.788Z","path":"gallery/index.html","comments":1,"layout":"page","_id":"ck3h9fkpd000qk3x64vzqhf9r","content":"<center>\n<div style=\"width:48%;float:left;\"><iframe src=\"https://open.spotify.com/embed/playlist/1nsgzt7HlwOnf154ruMGbX?si=h9Mh9uRTSweSkWAqiAC8_Q/undefined\" width=\"300\" height=\"380\" frameborder=\"0\" allowtransparency=\"allowtransparency\" allow=\"encrypted-media\"></iframe></div>\n<div style=\"width:48%;float:left;\"><iframe src=\"https://open.spotify.com/embed/playlist/1ckpZgfArzXJi5y8kAXkfD?si=Vv6BgnUQTR-S4TFBLMDVDA/undefined\" width=\"300\" height=\"380\" frameborder=\"0\" allowtransparency=\"allowtransparency\" allow=\"encrypted-media\"></iframe></div>\n</center>\n\n<script src=\"//cdn.bootcss.com/jquery/3.4.1/jquery.min.js\"></script><script src=\"//cdn.bootcss.com/jquery.lazyload/1.9.1/jquery.lazyload.min.js\"></script><div class=\"hexo-img-stream\"><style type=\"text/css\">.hexo-image-steam-lazy {display:none;}.hexo-img-stream{width:90%;max-width:1210px;margin:3% auto}div.hexo-img-stream figure{background:#fefefe;box-shadow:0 1px 2px rgba(34,25,25,0.4);margin:0 0.05% 3%;padding:3%;padding-bottom:10px;display:inline-block;max-width:32%}div.hexo-img-stream figure img{border-bottom:1px solid #ccc;padding-bottom:15px;margin-bottom:5px}div.hexo-img-stream figure figcaption{font-size:.9rem;color:#444;line-height:1.5;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;}div.hexo-img-stream small{font-size:1rem;float:right;text-transform:uppercase;color:#aaa}div.hexo-img-stream small a{color:#666;text-decoration:none;transition:.4s color}@media screen and (max-width:950px){.hexo-img-stream{column-gap:0}}</style><!--\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://ww1.sinaimg.cn/large/006tNc79gy1g57wss1nnxj30b40gognn.jpg\"/><noscript><img src=\"https://ww1.sinaimg.cn/large/006tNc79gy1g57wss1nnxj30b40gognn.jpg\"/></noscript><figcaption><a href=\"https://movie.douban.com/subject/30446788/\" target=\"_blank\" rel=\"noopener\">轮到你了</a>\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/d4b98fdcf540caed49ced3745e9026fd80299cf4.jpg\"/><noscript><img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/d4b98fdcf540caed49ced3745e9026fd80299cf4.jpg\"/></noscript><figcaption></figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight22.jpg\"/><noscript><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight22.jpg\"/></noscript><figcaption>[Cover 1]\n</figcaption></figure>\n-->\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight22.jpg\"><noscript><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight22.jpg\"></noscript><figcaption>[Cover 1]\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight25.jpg\"><noscript><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight25.jpg\"></noscript><figcaption>[Cover 2]\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight23.jpg\"><noscript><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight23.jpg\"></noscript><figcaption>[Cover 3]\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight24.jpg\"><noscript><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight24.jpg\"></noscript><figcaption>[Cover 4]\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight21.jpeg\"><noscript><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight21.jpeg\"></noscript><figcaption>[Cover 5]\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight10.jpg\"><noscript><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight10.jpg\"></noscript><figcaption>[Cover 6]\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/IMG_1737.jpeg\"><noscript><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/IMG_1737.jpeg\"></noscript><figcaption>[Dorm 1]\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/IMG_1785.jpeg\"><noscript><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/IMG_1785.jpeg\"></noscript><figcaption>[Dorm 2]\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/123.jpg\"><noscript><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/123.jpg\"></noscript><figcaption>[Goodbye]\n</figcaption></figure>\n</div><script type=\"text/javascript\">$('img.hexo-image-steam-lazy').lazyload({ effect:'fadeIn' });</script>\n","site":{"data":{}},"excerpt":"","more":"<center>\n<div style='width:48%;float:left;'><iframe src=\"https://open.spotify.com/embed/playlist/1nsgzt7HlwOnf154ruMGbX?si=h9Mh9uRTSweSkWAqiAC8_Q/undefined\" width=\"300\" height=\"380\" frameborder=\"0\" allowtransparency=\"allowtransparency\" allow=\"encrypted-media\"></div>\n<div style='width:48%;float:left;'><iframe src=\"https://open.spotify.com/embed/playlist/1ckpZgfArzXJi5y8kAXkfD?si=Vv6BgnUQTR-S4TFBLMDVDA/undefined\" width=\"300\" height=\"380\" frameborder=\"0\" allowtransparency=\"allowtransparency\" allow=\"encrypted-media\"></div>\n</center>\n\n<script src=\"//cdn.bootcss.com/jquery/3.4.1/jquery.min.js\"></script><script src=\"//cdn.bootcss.com/jquery.lazyload/1.9.1/jquery.lazyload.min.js\"></script><div class=\"hexo-img-stream\"><style type=\"text/css\">.hexo-image-steam-lazy {display:none;}.hexo-img-stream{width:90%;max-width:1210px;margin:3% auto}div.hexo-img-stream figure{background:#fefefe;box-shadow:0 1px 2px rgba(34,25,25,0.4);margin:0 0.05% 3%;padding:3%;padding-bottom:10px;display:inline-block;max-width:32%}div.hexo-img-stream figure img{border-bottom:1px solid #ccc;padding-bottom:15px;margin-bottom:5px}div.hexo-img-stream figure figcaption{font-size:.9rem;color:#444;line-height:1.5;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;}div.hexo-img-stream small{font-size:1rem;float:right;text-transform:uppercase;color:#aaa}div.hexo-img-stream small a{color:#666;text-decoration:none;transition:.4s color}@media screen and (max-width:950px){.hexo-img-stream{column-gap:0}}</style><!--\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://ww1.sinaimg.cn/large/006tNc79gy1g57wss1nnxj30b40gognn.jpg\"/><noscript><img src=\"https://ww1.sinaimg.cn/large/006tNc79gy1g57wss1nnxj30b40gognn.jpg\"/></noscript><figcaption><a href=\"https://movie.douban.com/subject/30446788/\" target=\"_blank\" rel=\"noopener\">轮到你了</a>\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/d4b98fdcf540caed49ced3745e9026fd80299cf4.jpg\"/><noscript><img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/d4b98fdcf540caed49ced3745e9026fd80299cf4.jpg\"/></noscript><figcaption></figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight22.jpg\"/><noscript><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight22.jpg\"/></noscript><figcaption>[Cover 1]\n</figcaption></figure>\n-->\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight22.jpg\"/><noscript><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight22.jpg\"/></noscript><figcaption>[Cover 1]\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight25.jpg\"/><noscript><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight25.jpg\"/></noscript><figcaption>[Cover 2]\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight23.jpg\"/><noscript><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight23.jpg\"/></noscript><figcaption>[Cover 3]\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight24.jpg\"/><noscript><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight24.jpg\"/></noscript><figcaption>[Cover 4]\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight21.jpeg\"/><noscript><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight21.jpeg\"/></noscript><figcaption>[Cover 5]\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight10.jpg\"/><noscript><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/Enlight10.jpg\"/></noscript><figcaption>[Cover 6]\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/IMG_1737.jpeg\"/><noscript><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/IMG_1737.jpeg\"/></noscript><figcaption>[Dorm 1]\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/IMG_1785.jpeg\"/><noscript><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/IMG_1785.jpeg\"/></noscript><figcaption>[Dorm 2]\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/123.jpg\"/><noscript><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/123.jpg\"/></noscript><figcaption>[Goodbye]\n</figcaption></figure>\n</div><script type=\"text/javascript\">$('img.hexo-image-steam-lazy').lazyload({ effect:'fadeIn' });</script>\n"},{"title":"search","type":"search","date":"2019-05-10T09:44:58.000Z","_content":"\n","source":"search/index.md","raw":"---\ntitle: search\ntype: search\ndate: 2019-05-10 17:44:58\n---\n\n","updated":"2019-05-10T10:17:52.710Z","path":"search/index.html","comments":1,"layout":"page","_id":"ck3h9fkpf000sk3x6h9qr87b9","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"旧的梦","date":"2019-08-11T02:34:47.000Z","type":"categories","_content":"","source":"旧的梦/index.md","raw":"---\ntitle: 旧的梦\ndate: 2019-08-11 10:34:47\ntype: \"categories\"\n---\n","updated":"2019-08-11T02:35:06.820Z","path":"旧的梦/index.html","comments":1,"layout":"page","_id":"ck3h9fkpm000xk3x662r30kjw","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"旧的文","date":"2019-08-11T01:30:51.000Z","type":"categories","_content":"","source":"旧的文/index.md","raw":"---\ntitle: 旧的文\ndate: 2019-08-11 09:30:51\ntype: \"categories\"\n---\n","updated":"2019-08-11T01:36:38.925Z","path":"旧的文/index.html","comments":1,"layout":"page","_id":"ck3h9fkpo000zk3x6csm53z9s","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"柳烈的音乐专辑","date":"2019-10-04T05:09:23.000Z","thumbnail":"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/2019/10/04/img0152.jpg","toc":false,"_content":"\n昨天在网上偶然间看到了一个帖子，名字是《柳烈的音乐专辑》，丁海寅和高金银主演，乍一看名字，感觉是跟奇迹唱片行一样的男女主因为音乐在一起的故事，而且丁海寅和高金银两位演员我蛮喜欢，正好也好久没看爱情片了，就直接在网上找了资源。不过说真的，凌晨 1 点开始，看完电影又在 b站上看了高金银的视频，粉了高金银的 ins，一直搞到了 5 点钟，算是 22 岁生日自己给自己的一份“大礼”吧(爆肝的开始)\n<!--more-->\n讲真，我看别人评价这部电影，哭的都已经不行了，我全程看下来，还真的没有哭，感觉没有《现在去见你》那么催泪，不知道是不是我的情感殆尽，已经体会不到这种爱情带来的痛苦与温暖了。一个是被人误会犯下估计谋杀罪进入少管所看似辈子就已经没有任何希望的丁海寅饰演的角色（对不住了，我对名字实在不敏感），一个是刻苦学习想找一份工作但遇到经济危机难以生存的高金银饰演的角色，两个人的相遇是在丁海寅出狱的当天，因为韩国好像有出狱就一定要吃豆腐的原因，他进到了高金银打工的面包店里，询问是否有豆制品，这一天也恰好是柳烈的音乐专辑开播的第一天：1994年 10 月 1 日，一切都是新的开始，丁海寅抱着对生活新的期许，在这家店做起了兼职，仿佛忙碌着忙碌着就可以忘记之前的痛苦，但电影是不允许这样的，好的生活节奏被他一起出狱的朋友打破，一起出去喝酒结果和别人发生了口角，生活再次将他们打回原形，这一走就是 3 年，再次的重逢还是发生在面包店前，突然的偶遇让金高银重拾心中的花火，可第二天，丁海寅就要服役了。深夜的她打开电脑，给丁海寅注册了电邮，想他在军队的时候，也可以正常来往，结果，最终的电邮的密码却忘记告诉了他。服役的那么长时间里，邮箱里只有高金银的来信，没有一封是有回复的。丁海寅在休假的时候，有去过高金银之前租房子的地方，很聪明的猜到了邮箱的密码，两人的第三次相遇，这时时间到了 2000 年。仿佛是时间在捉弄两个人，丁海寅做兼职的地方出现了问题，约定的电话时间她被放了鸽子，而高金银自己也因为很多的不如意的地方而接近崩溃，不如意的工作，无聊而嘈杂的环境都让她无时无刻不在怀疑自己存在的价值，那天晚上，她哭着发了最后的一封邮件，说着“我也会在有好事发生的时候，再联系你”，电邮那头的他，也是对生活抱着怀疑的态度，犹豫的打下的字最后也只存在于垃圾箱中，就这样，两人再次失去了联系。时间到了 2005 年，高金银找到了自己如意的编辑工作，而且获得了满意的成就，丁海寅也和别人一起，做起了摄影相关的创业工作，巧的是，两人的工作室就是 1 层和 2 层的关系，于是，再次的相逢重新勾起了他们对于往事的回忆。同居生活，一起做饭，看书，睡觉，分享生活，但中间有一个细节，我当时看真的没有在意，看了别人的评论，我才发现的。当时高金银对丁海寅说：“我们结婚吧”，面对突然的问题，他一定是没有做好准备的，自己无法了却的过去和不确定的未来，哪一样都无法给她一个确定的答案，唯有夜里深深地拥抱才能给予他和她短暂的安全感。生活的冷水再次倒给了丁海寅，死去的朋友的 10 年祭到来了，作为“主犯”的他站在朋友家的门口，口口声声说自己并没有那么做，迎来的却是一句“就算知道也不知道”，这个世界仿佛总要去给每一件不好的事情找到一个看似合理的理由，即使大家都没有足够的理由去相信这是真的，仿佛是为了填补人们心中的创伤，也算是一种慰藉了。这个事情也恰好被金高银知道了，在丁海寅眼里，他只希望她能记住 1994 年之后的自己，因为过去的事情唯有少数人理解他，更多的人是不希望他能顺利的活在这个世界上的，即使他有多努力去改变自己。因为创业资金不足，他要搬离和金高银一起工作的地方，而且她的上司的油性骚扰有一种不可抗力，让丁海寅觉得她会跟上司一起生活。我第一遍看的时候，高金银上了上司的车真的以为他俩在一起了，后面看了影评才知道他们是一块去看了新的店面设计，是为了工作，我也算是长疏了一口气。而那一段丁海寅追汽车的桥段，仿佛是点燃了她心中仍有余温但快燃烧殆尽的火苗，和阿姨在一起的谈话也让她相信了他的难处以及想要努力生活的愿望。再一次也是电影最后的一个桥段，发生在了柳烈演播室的外面，高金银在电台节目里面听到了自己的名字，总有一种声音告诉她丁海寅就在电台的录制现场，于是，电影的最后，隔着一面玻璃，一个是 10 年都他妈没有任何变化甚至更加年轻的丁海寅，一个是拥有稳定工作又漂亮的高金银。\n\n电影的题目是一档电台节目，两人因为电台节目的开始而相遇，因为电台的互诉新生，又因为电台而重新相逢。电影中的 bgm 用的也都是同时代韩国的爱情音乐，那首 Fin.K.L的永恒的爱一想起来，眼泪真的差点就忍不住了。电影看完又看了一遍他们两个在 Begin Again3 上的表演，嗓音真的绝了。10 年断断续续的相遇，都是努力生活的样子，都是对爱情充满了希望，真的很不错的爱情电影。最后推一首今天淘的歌作为结尾，金光石的《三十岁之际》![IMG_0152](https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/2019/10/04/img0152.jpg)\n![IMG_0154](https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/2019/10/04/img0154.PNG)\n\n","source":"_posts/10-04-2019-柳烈的音乐专辑.md","raw":"---\ntitle: 柳烈的音乐专辑\ndate: 2019-10-04 13:09:23\nthumbnail: https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/2019/10/04/img0152.jpg\ntags:\ncategories:\n  - 旧的文\ntoc: false\n---\n\n昨天在网上偶然间看到了一个帖子，名字是《柳烈的音乐专辑》，丁海寅和高金银主演，乍一看名字，感觉是跟奇迹唱片行一样的男女主因为音乐在一起的故事，而且丁海寅和高金银两位演员我蛮喜欢，正好也好久没看爱情片了，就直接在网上找了资源。不过说真的，凌晨 1 点开始，看完电影又在 b站上看了高金银的视频，粉了高金银的 ins，一直搞到了 5 点钟，算是 22 岁生日自己给自己的一份“大礼”吧(爆肝的开始)\n<!--more-->\n讲真，我看别人评价这部电影，哭的都已经不行了，我全程看下来，还真的没有哭，感觉没有《现在去见你》那么催泪，不知道是不是我的情感殆尽，已经体会不到这种爱情带来的痛苦与温暖了。一个是被人误会犯下估计谋杀罪进入少管所看似辈子就已经没有任何希望的丁海寅饰演的角色（对不住了，我对名字实在不敏感），一个是刻苦学习想找一份工作但遇到经济危机难以生存的高金银饰演的角色，两个人的相遇是在丁海寅出狱的当天，因为韩国好像有出狱就一定要吃豆腐的原因，他进到了高金银打工的面包店里，询问是否有豆制品，这一天也恰好是柳烈的音乐专辑开播的第一天：1994年 10 月 1 日，一切都是新的开始，丁海寅抱着对生活新的期许，在这家店做起了兼职，仿佛忙碌着忙碌着就可以忘记之前的痛苦，但电影是不允许这样的，好的生活节奏被他一起出狱的朋友打破，一起出去喝酒结果和别人发生了口角，生活再次将他们打回原形，这一走就是 3 年，再次的重逢还是发生在面包店前，突然的偶遇让金高银重拾心中的花火，可第二天，丁海寅就要服役了。深夜的她打开电脑，给丁海寅注册了电邮，想他在军队的时候，也可以正常来往，结果，最终的电邮的密码却忘记告诉了他。服役的那么长时间里，邮箱里只有高金银的来信，没有一封是有回复的。丁海寅在休假的时候，有去过高金银之前租房子的地方，很聪明的猜到了邮箱的密码，两人的第三次相遇，这时时间到了 2000 年。仿佛是时间在捉弄两个人，丁海寅做兼职的地方出现了问题，约定的电话时间她被放了鸽子，而高金银自己也因为很多的不如意的地方而接近崩溃，不如意的工作，无聊而嘈杂的环境都让她无时无刻不在怀疑自己存在的价值，那天晚上，她哭着发了最后的一封邮件，说着“我也会在有好事发生的时候，再联系你”，电邮那头的他，也是对生活抱着怀疑的态度，犹豫的打下的字最后也只存在于垃圾箱中，就这样，两人再次失去了联系。时间到了 2005 年，高金银找到了自己如意的编辑工作，而且获得了满意的成就，丁海寅也和别人一起，做起了摄影相关的创业工作，巧的是，两人的工作室就是 1 层和 2 层的关系，于是，再次的相逢重新勾起了他们对于往事的回忆。同居生活，一起做饭，看书，睡觉，分享生活，但中间有一个细节，我当时看真的没有在意，看了别人的评论，我才发现的。当时高金银对丁海寅说：“我们结婚吧”，面对突然的问题，他一定是没有做好准备的，自己无法了却的过去和不确定的未来，哪一样都无法给她一个确定的答案，唯有夜里深深地拥抱才能给予他和她短暂的安全感。生活的冷水再次倒给了丁海寅，死去的朋友的 10 年祭到来了，作为“主犯”的他站在朋友家的门口，口口声声说自己并没有那么做，迎来的却是一句“就算知道也不知道”，这个世界仿佛总要去给每一件不好的事情找到一个看似合理的理由，即使大家都没有足够的理由去相信这是真的，仿佛是为了填补人们心中的创伤，也算是一种慰藉了。这个事情也恰好被金高银知道了，在丁海寅眼里，他只希望她能记住 1994 年之后的自己，因为过去的事情唯有少数人理解他，更多的人是不希望他能顺利的活在这个世界上的，即使他有多努力去改变自己。因为创业资金不足，他要搬离和金高银一起工作的地方，而且她的上司的油性骚扰有一种不可抗力，让丁海寅觉得她会跟上司一起生活。我第一遍看的时候，高金银上了上司的车真的以为他俩在一起了，后面看了影评才知道他们是一块去看了新的店面设计，是为了工作，我也算是长疏了一口气。而那一段丁海寅追汽车的桥段，仿佛是点燃了她心中仍有余温但快燃烧殆尽的火苗，和阿姨在一起的谈话也让她相信了他的难处以及想要努力生活的愿望。再一次也是电影最后的一个桥段，发生在了柳烈演播室的外面，高金银在电台节目里面听到了自己的名字，总有一种声音告诉她丁海寅就在电台的录制现场，于是，电影的最后，隔着一面玻璃，一个是 10 年都他妈没有任何变化甚至更加年轻的丁海寅，一个是拥有稳定工作又漂亮的高金银。\n\n电影的题目是一档电台节目，两人因为电台节目的开始而相遇，因为电台的互诉新生，又因为电台而重新相逢。电影中的 bgm 用的也都是同时代韩国的爱情音乐，那首 Fin.K.L的永恒的爱一想起来，眼泪真的差点就忍不住了。电影看完又看了一遍他们两个在 Begin Again3 上的表演，嗓音真的绝了。10 年断断续续的相遇，都是努力生活的样子，都是对爱情充满了希望，真的很不错的爱情电影。最后推一首今天淘的歌作为结尾，金光石的《三十岁之际》![IMG_0152](https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/2019/10/04/img0152.jpg)\n![IMG_0154](https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/2019/10/04/img0154.PNG)\n\n","slug":"10-04-2019-柳烈的音乐专辑","published":1,"updated":"2019-11-15T14:47:50.712Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkoa0001k3x6afec9xy3","content":"<p>昨天在网上偶然间看到了一个帖子，名字是《柳烈的音乐专辑》，丁海寅和高金银主演，乍一看名字，感觉是跟奇迹唱片行一样的男女主因为音乐在一起的故事，而且丁海寅和高金银两位演员我蛮喜欢，正好也好久没看爱情片了，就直接在网上找了资源。不过说真的，凌晨 1 点开始，看完电影又在 b站上看了高金银的视频，粉了高金银的 ins，一直搞到了 5 点钟，算是 22 岁生日自己给自己的一份“大礼”吧(爆肝的开始)</p>\n<a id=\"more\"></a>\n<p>讲真，我看别人评价这部电影，哭的都已经不行了，我全程看下来，还真的没有哭，感觉没有《现在去见你》那么催泪，不知道是不是我的情感殆尽，已经体会不到这种爱情带来的痛苦与温暖了。一个是被人误会犯下估计谋杀罪进入少管所看似辈子就已经没有任何希望的丁海寅饰演的角色（对不住了，我对名字实在不敏感），一个是刻苦学习想找一份工作但遇到经济危机难以生存的高金银饰演的角色，两个人的相遇是在丁海寅出狱的当天，因为韩国好像有出狱就一定要吃豆腐的原因，他进到了高金银打工的面包店里，询问是否有豆制品，这一天也恰好是柳烈的音乐专辑开播的第一天：1994年 10 月 1 日，一切都是新的开始，丁海寅抱着对生活新的期许，在这家店做起了兼职，仿佛忙碌着忙碌着就可以忘记之前的痛苦，但电影是不允许这样的，好的生活节奏被他一起出狱的朋友打破，一起出去喝酒结果和别人发生了口角，生活再次将他们打回原形，这一走就是 3 年，再次的重逢还是发生在面包店前，突然的偶遇让金高银重拾心中的花火，可第二天，丁海寅就要服役了。深夜的她打开电脑，给丁海寅注册了电邮，想他在军队的时候，也可以正常来往，结果，最终的电邮的密码却忘记告诉了他。服役的那么长时间里，邮箱里只有高金银的来信，没有一封是有回复的。丁海寅在休假的时候，有去过高金银之前租房子的地方，很聪明的猜到了邮箱的密码，两人的第三次相遇，这时时间到了 2000 年。仿佛是时间在捉弄两个人，丁海寅做兼职的地方出现了问题，约定的电话时间她被放了鸽子，而高金银自己也因为很多的不如意的地方而接近崩溃，不如意的工作，无聊而嘈杂的环境都让她无时无刻不在怀疑自己存在的价值，那天晚上，她哭着发了最后的一封邮件，说着“我也会在有好事发生的时候，再联系你”，电邮那头的他，也是对生活抱着怀疑的态度，犹豫的打下的字最后也只存在于垃圾箱中，就这样，两人再次失去了联系。时间到了 2005 年，高金银找到了自己如意的编辑工作，而且获得了满意的成就，丁海寅也和别人一起，做起了摄影相关的创业工作，巧的是，两人的工作室就是 1 层和 2 层的关系，于是，再次的相逢重新勾起了他们对于往事的回忆。同居生活，一起做饭，看书，睡觉，分享生活，但中间有一个细节，我当时看真的没有在意，看了别人的评论，我才发现的。当时高金银对丁海寅说：“我们结婚吧”，面对突然的问题，他一定是没有做好准备的，自己无法了却的过去和不确定的未来，哪一样都无法给她一个确定的答案，唯有夜里深深地拥抱才能给予他和她短暂的安全感。生活的冷水再次倒给了丁海寅，死去的朋友的 10 年祭到来了，作为“主犯”的他站在朋友家的门口，口口声声说自己并没有那么做，迎来的却是一句“就算知道也不知道”，这个世界仿佛总要去给每一件不好的事情找到一个看似合理的理由，即使大家都没有足够的理由去相信这是真的，仿佛是为了填补人们心中的创伤，也算是一种慰藉了。这个事情也恰好被金高银知道了，在丁海寅眼里，他只希望她能记住 1994 年之后的自己，因为过去的事情唯有少数人理解他，更多的人是不希望他能顺利的活在这个世界上的，即使他有多努力去改变自己。因为创业资金不足，他要搬离和金高银一起工作的地方，而且她的上司的油性骚扰有一种不可抗力，让丁海寅觉得她会跟上司一起生活。我第一遍看的时候，高金银上了上司的车真的以为他俩在一起了，后面看了影评才知道他们是一块去看了新的店面设计，是为了工作，我也算是长疏了一口气。而那一段丁海寅追汽车的桥段，仿佛是点燃了她心中仍有余温但快燃烧殆尽的火苗，和阿姨在一起的谈话也让她相信了他的难处以及想要努力生活的愿望。再一次也是电影最后的一个桥段，发生在了柳烈演播室的外面，高金银在电台节目里面听到了自己的名字，总有一种声音告诉她丁海寅就在电台的录制现场，于是，电影的最后，隔着一面玻璃，一个是 10 年都他妈没有任何变化甚至更加年轻的丁海寅，一个是拥有稳定工作又漂亮的高金银。</p>\n<p>电影的题目是一档电台节目，两人因为电台节目的开始而相遇，因为电台的互诉新生，又因为电台而重新相逢。电影中的 bgm 用的也都是同时代韩国的爱情音乐，那首 Fin.K.L的永恒的爱一想起来，眼泪真的差点就忍不住了。电影看完又看了一遍他们两个在 Begin Again3 上的表演，嗓音真的绝了。10 年断断续续的相遇，都是努力生活的样子，都是对爱情充满了希望，真的很不错的爱情电影。最后推一首今天淘的歌作为结尾，金光石的《三十岁之际》<img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/2019/10/04/img0152.jpg\" alt=\"IMG_0152\"><br><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/2019/10/04/img0154.PNG\" alt=\"IMG_0154\"></p>\n","site":{"data":{}},"excerpt":"<p>昨天在网上偶然间看到了一个帖子，名字是《柳烈的音乐专辑》，丁海寅和高金银主演，乍一看名字，感觉是跟奇迹唱片行一样的男女主因为音乐在一起的故事，而且丁海寅和高金银两位演员我蛮喜欢，正好也好久没看爱情片了，就直接在网上找了资源。不过说真的，凌晨 1 点开始，看完电影又在 b站上看了高金银的视频，粉了高金银的 ins，一直搞到了 5 点钟，算是 22 岁生日自己给自己的一份“大礼”吧(爆肝的开始)</p>","more":"<p>讲真，我看别人评价这部电影，哭的都已经不行了，我全程看下来，还真的没有哭，感觉没有《现在去见你》那么催泪，不知道是不是我的情感殆尽，已经体会不到这种爱情带来的痛苦与温暖了。一个是被人误会犯下估计谋杀罪进入少管所看似辈子就已经没有任何希望的丁海寅饰演的角色（对不住了，我对名字实在不敏感），一个是刻苦学习想找一份工作但遇到经济危机难以生存的高金银饰演的角色，两个人的相遇是在丁海寅出狱的当天，因为韩国好像有出狱就一定要吃豆腐的原因，他进到了高金银打工的面包店里，询问是否有豆制品，这一天也恰好是柳烈的音乐专辑开播的第一天：1994年 10 月 1 日，一切都是新的开始，丁海寅抱着对生活新的期许，在这家店做起了兼职，仿佛忙碌着忙碌着就可以忘记之前的痛苦，但电影是不允许这样的，好的生活节奏被他一起出狱的朋友打破，一起出去喝酒结果和别人发生了口角，生活再次将他们打回原形，这一走就是 3 年，再次的重逢还是发生在面包店前，突然的偶遇让金高银重拾心中的花火，可第二天，丁海寅就要服役了。深夜的她打开电脑，给丁海寅注册了电邮，想他在军队的时候，也可以正常来往，结果，最终的电邮的密码却忘记告诉了他。服役的那么长时间里，邮箱里只有高金银的来信，没有一封是有回复的。丁海寅在休假的时候，有去过高金银之前租房子的地方，很聪明的猜到了邮箱的密码，两人的第三次相遇，这时时间到了 2000 年。仿佛是时间在捉弄两个人，丁海寅做兼职的地方出现了问题，约定的电话时间她被放了鸽子，而高金银自己也因为很多的不如意的地方而接近崩溃，不如意的工作，无聊而嘈杂的环境都让她无时无刻不在怀疑自己存在的价值，那天晚上，她哭着发了最后的一封邮件，说着“我也会在有好事发生的时候，再联系你”，电邮那头的他，也是对生活抱着怀疑的态度，犹豫的打下的字最后也只存在于垃圾箱中，就这样，两人再次失去了联系。时间到了 2005 年，高金银找到了自己如意的编辑工作，而且获得了满意的成就，丁海寅也和别人一起，做起了摄影相关的创业工作，巧的是，两人的工作室就是 1 层和 2 层的关系，于是，再次的相逢重新勾起了他们对于往事的回忆。同居生活，一起做饭，看书，睡觉，分享生活，但中间有一个细节，我当时看真的没有在意，看了别人的评论，我才发现的。当时高金银对丁海寅说：“我们结婚吧”，面对突然的问题，他一定是没有做好准备的，自己无法了却的过去和不确定的未来，哪一样都无法给她一个确定的答案，唯有夜里深深地拥抱才能给予他和她短暂的安全感。生活的冷水再次倒给了丁海寅，死去的朋友的 10 年祭到来了，作为“主犯”的他站在朋友家的门口，口口声声说自己并没有那么做，迎来的却是一句“就算知道也不知道”，这个世界仿佛总要去给每一件不好的事情找到一个看似合理的理由，即使大家都没有足够的理由去相信这是真的，仿佛是为了填补人们心中的创伤，也算是一种慰藉了。这个事情也恰好被金高银知道了，在丁海寅眼里，他只希望她能记住 1994 年之后的自己，因为过去的事情唯有少数人理解他，更多的人是不希望他能顺利的活在这个世界上的，即使他有多努力去改变自己。因为创业资金不足，他要搬离和金高银一起工作的地方，而且她的上司的油性骚扰有一种不可抗力，让丁海寅觉得她会跟上司一起生活。我第一遍看的时候，高金银上了上司的车真的以为他俩在一起了，后面看了影评才知道他们是一块去看了新的店面设计，是为了工作，我也算是长疏了一口气。而那一段丁海寅追汽车的桥段，仿佛是点燃了她心中仍有余温但快燃烧殆尽的火苗，和阿姨在一起的谈话也让她相信了他的难处以及想要努力生活的愿望。再一次也是电影最后的一个桥段，发生在了柳烈演播室的外面，高金银在电台节目里面听到了自己的名字，总有一种声音告诉她丁海寅就在电台的录制现场，于是，电影的最后，隔着一面玻璃，一个是 10 年都他妈没有任何变化甚至更加年轻的丁海寅，一个是拥有稳定工作又漂亮的高金银。</p>\n<p>电影的题目是一档电台节目，两人因为电台节目的开始而相遇，因为电台的互诉新生，又因为电台而重新相逢。电影中的 bgm 用的也都是同时代韩国的爱情音乐，那首 Fin.K.L的永恒的爱一想起来，眼泪真的差点就忍不住了。电影看完又看了一遍他们两个在 Begin Again3 上的表演，嗓音真的绝了。10 年断断续续的相遇，都是努力生活的样子，都是对爱情充满了希望，真的很不错的爱情电影。最后推一首今天淘的歌作为结尾，金光石的《三十岁之际》<img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/2019/10/04/img0152.jpg\" alt=\"IMG_0152\"><br><img src=\"https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/2019/10/04/img0154.PNG\" alt=\"IMG_0154\"></p>"},{"title":"1987","originContent":"","toc":false,"date":"2019-08-11T02:33:38.000Z","thumbnail":"https://images.unsplash.com/photo-1573747238416-730b008b68b1?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n同《出租车司机》一样，该影片反映的是韩国人民为争取民主而做出的牺牲。真的感谢TSKS韩剧社…能翻译出这么优秀的电影作品…这种心潮澎湃的感觉…很久没有出现了\nimdb8.2分 值得观看","source":"_posts/1987.md","raw":"---\ntitle: '1987'\ntags: []\noriginContent: ''\ncategories:\n  - 旧的文\ntoc: false\ndate: 2019-08-11 10:33:38\nthumbnail: https://images.unsplash.com/photo-1573747238416-730b008b68b1?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n同《出租车司机》一样，该影片反映的是韩国人民为争取民主而做出的牺牲。真的感谢TSKS韩剧社…能翻译出这么优秀的电影作品…这种心潮澎湃的感觉…很久没有出现了\nimdb8.2分 值得观看","slug":"1987","published":1,"updated":"2019-11-15T12:45:41.336Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkof0003k3x6cdge1dot","content":"<p>同《出租车司机》一样，该影片反映的是韩国人民为争取民主而做出的牺牲。真的感谢TSKS韩剧社…能翻译出这么优秀的电影作品…这种心潮澎湃的感觉…很久没有出现了<br>imdb8.2分 值得观看</p>\n","site":{"data":{}},"excerpt":"","more":"<p>同《出租车司机》一样，该影片反映的是韩国人民为争取民主而做出的牺牲。真的感谢TSKS韩剧社…能翻译出这么优秀的电影作品…这种心潮澎湃的感觉…很久没有出现了<br>imdb8.2分 值得观看</p>\n"},{"title":"Dec 15, 2018","originContent":"","toc":false,"date":"2018-12-15T02:41:24.000Z","thumbnail":"https://images.unsplash.com/photo-1491598601902-712af90cc6ee?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n太美好了…美好的我想哭。\n\n仿佛这个梦…从我入睡…就开始了…<!--more-->一直到…她说：咱们要做一辈子的好兄弟啊。现在8:27，我醒了，一切又回到了现实。\n\n梦的原型，很像我和我前女友的故事。梦里的那个女孩，好想现实中的确存在，而且面部轮廓那么清晰，我是那么熟悉。她有男朋友的，但从梦的开始，我就没有见到他的男朋友。之前听人说，所有人都不记得梦是怎么开始的，我只记得，梦是在一间教室开始的，她坐在我后面，那堂客课，因为老师的封建迷信，我和老师吵了起来（由于梦里的元素实在太多了，我只能挑重要的元素去讲）后来不知怎么的，下课了，我就和那个女生，一块走了出来，我还记得那一天，我们去了星巴克，去了很多吃的地方，但每一次，都是我去找的她，仿佛她才是目的地，而我，只是一个奔跑者，而且每次都是我看着她吃，我一口也没有吃下去。我记得最清楚的一个桥段，是我们去吃串，店不大，在二楼，一楼是健身器材，同样是出现在我生命里的元素。我记得很清楚，她带了她两个朋友，而她两个朋友都误以为，我是她的男朋友，而她也不慌不忙地解释，连笑容都好好看。那一天过得好快，从一家店面出来，天已经黑了，我说，我送你回去吧，之后在路边扫了一辆电动车（校园里共享电动车的元素），她坐在后面，我带着她，当时的我，虽说不想和她处成兄弟，但她有男朋友。我的初恋，我也是作为第三者，但在现实生活中，我最终，追到了那个女生，但在梦里，是那个女生先开的口：咱们要做一辈子的好兄弟啊。我很清楚的记得，当时的我，骑着电动车，一句话也说不出来，哽咽着，我多希望我身边的那个人，是你。对不起，是我多想了。我醒了。","source":"_posts/Dec-15-2018.md","raw":"---\ntitle: 'Dec 15, 2018'\ntags: []\noriginContent: ''\ncategories:\n  - 旧的梦\ntoc: false\ndate: 2018-12-15 10:41:24\nthumbnail: https://images.unsplash.com/photo-1491598601902-712af90cc6ee?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n太美好了…美好的我想哭。\n\n仿佛这个梦…从我入睡…就开始了…<!--more-->一直到…她说：咱们要做一辈子的好兄弟啊。现在8:27，我醒了，一切又回到了现实。\n\n梦的原型，很像我和我前女友的故事。梦里的那个女孩，好想现实中的确存在，而且面部轮廓那么清晰，我是那么熟悉。她有男朋友的，但从梦的开始，我就没有见到他的男朋友。之前听人说，所有人都不记得梦是怎么开始的，我只记得，梦是在一间教室开始的，她坐在我后面，那堂客课，因为老师的封建迷信，我和老师吵了起来（由于梦里的元素实在太多了，我只能挑重要的元素去讲）后来不知怎么的，下课了，我就和那个女生，一块走了出来，我还记得那一天，我们去了星巴克，去了很多吃的地方，但每一次，都是我去找的她，仿佛她才是目的地，而我，只是一个奔跑者，而且每次都是我看着她吃，我一口也没有吃下去。我记得最清楚的一个桥段，是我们去吃串，店不大，在二楼，一楼是健身器材，同样是出现在我生命里的元素。我记得很清楚，她带了她两个朋友，而她两个朋友都误以为，我是她的男朋友，而她也不慌不忙地解释，连笑容都好好看。那一天过得好快，从一家店面出来，天已经黑了，我说，我送你回去吧，之后在路边扫了一辆电动车（校园里共享电动车的元素），她坐在后面，我带着她，当时的我，虽说不想和她处成兄弟，但她有男朋友。我的初恋，我也是作为第三者，但在现实生活中，我最终，追到了那个女生，但在梦里，是那个女生先开的口：咱们要做一辈子的好兄弟啊。我很清楚的记得，当时的我，骑着电动车，一句话也说不出来，哽咽着，我多希望我身边的那个人，是你。对不起，是我多想了。我醒了。","slug":"Dec-15-2018","published":1,"updated":"2019-11-15T12:54:48.733Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkom0006k3x6dxk7gvwr","content":"<p>太美好了…美好的我想哭。</p>\n<p>仿佛这个梦…从我入睡…就开始了…<a id=\"more\"></a>一直到…她说：咱们要做一辈子的好兄弟啊。现在8:27，我醒了，一切又回到了现实。</p>\n<p>梦的原型，很像我和我前女友的故事。梦里的那个女孩，好想现实中的确存在，而且面部轮廓那么清晰，我是那么熟悉。她有男朋友的，但从梦的开始，我就没有见到他的男朋友。之前听人说，所有人都不记得梦是怎么开始的，我只记得，梦是在一间教室开始的，她坐在我后面，那堂客课，因为老师的封建迷信，我和老师吵了起来（由于梦里的元素实在太多了，我只能挑重要的元素去讲）后来不知怎么的，下课了，我就和那个女生，一块走了出来，我还记得那一天，我们去了星巴克，去了很多吃的地方，但每一次，都是我去找的她，仿佛她才是目的地，而我，只是一个奔跑者，而且每次都是我看着她吃，我一口也没有吃下去。我记得最清楚的一个桥段，是我们去吃串，店不大，在二楼，一楼是健身器材，同样是出现在我生命里的元素。我记得很清楚，她带了她两个朋友，而她两个朋友都误以为，我是她的男朋友，而她也不慌不忙地解释，连笑容都好好看。那一天过得好快，从一家店面出来，天已经黑了，我说，我送你回去吧，之后在路边扫了一辆电动车（校园里共享电动车的元素），她坐在后面，我带着她，当时的我，虽说不想和她处成兄弟，但她有男朋友。我的初恋，我也是作为第三者，但在现实生活中，我最终，追到了那个女生，但在梦里，是那个女生先开的口：咱们要做一辈子的好兄弟啊。我很清楚的记得，当时的我，骑着电动车，一句话也说不出来，哽咽着，我多希望我身边的那个人，是你。对不起，是我多想了。我醒了。</p>\n","site":{"data":{}},"excerpt":"<p>太美好了…美好的我想哭。</p>\n<p>仿佛这个梦…从我入睡…就开始了…</p>","more":"一直到…她说：咱们要做一辈子的好兄弟啊。现在8:27，我醒了，一切又回到了现实。</p>\n<p>梦的原型，很像我和我前女友的故事。梦里的那个女孩，好想现实中的确存在，而且面部轮廓那么清晰，我是那么熟悉。她有男朋友的，但从梦的开始，我就没有见到他的男朋友。之前听人说，所有人都不记得梦是怎么开始的，我只记得，梦是在一间教室开始的，她坐在我后面，那堂客课，因为老师的封建迷信，我和老师吵了起来（由于梦里的元素实在太多了，我只能挑重要的元素去讲）后来不知怎么的，下课了，我就和那个女生，一块走了出来，我还记得那一天，我们去了星巴克，去了很多吃的地方，但每一次，都是我去找的她，仿佛她才是目的地，而我，只是一个奔跑者，而且每次都是我看着她吃，我一口也没有吃下去。我记得最清楚的一个桥段，是我们去吃串，店不大，在二楼，一楼是健身器材，同样是出现在我生命里的元素。我记得很清楚，她带了她两个朋友，而她两个朋友都误以为，我是她的男朋友，而她也不慌不忙地解释，连笑容都好好看。那一天过得好快，从一家店面出来，天已经黑了，我说，我送你回去吧，之后在路边扫了一辆电动车（校园里共享电动车的元素），她坐在后面，我带着她，当时的我，虽说不想和她处成兄弟，但她有男朋友。我的初恋，我也是作为第三者，但在现实生活中，我最终，追到了那个女生，但在梦里，是那个女生先开的口：咱们要做一辈子的好兄弟啊。我很清楚的记得，当时的我，骑着电动车，一句话也说不出来，哽咽着，我多希望我身边的那个人，是你。对不起，是我多想了。我醒了。</p>"},{"title":"Cest la vie - Sep 24, 2019","originContent":"","thumbnail":"https://images.unsplash.com/photo-1569313815155-9c7206ddb924?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjQzMzEwfQ&auto=format&fit=crop&w=800&q=60","toc":false,"date":"2019-09-25T02:23:12.000Z","_content":"\n今天还在跟我们班一起出国的人一起聊天，突然有一种作为倾听者的感觉。<!--more-->我们班其实还有另外一个帅气小伙子，本来要出国，花了2年时间考英语， GT考了出来，最后选择了保研，选择了硬件，选择了国光的直博。当时听到这个消息，其实我有想到他的女朋友诶，有可能是为了爱情？今天和这个哥们聊天，好像有点确认了这个消息，然后这哥们就问我关于女朋友，出国的各种不确定性。或许是因为硬件条件？他说他不会在那边找的，想要在国内带一个过去，但又怕之后自己放弃这段爱情，然后就把问题抛给我了，我啷个知道咯，随缘吧？其实我有一条路的选择是，读完master工作，然后去新加坡，把孩子落户在那里，但这个旅程缺失了另外一个人，说真的，我也不知道她能在哪里被我遇到，愿意不愿意去新加坡，她家里愿意不愿意让她跟我去新加坡；或者说我有想法要读博，那以后的日子可就要更加想清楚了，当然我憧憬着lalaland里面现实的爱情故事，能遇到不能遇到就两说了。那哥们也是挺不容易的，自己背了债，想到美帝读phd回本，但又怕自己读完回来30+，看到自己的名字出现在非诚勿扰的名单里，资料里写着美国计算机博士的那种。我还记得很清楚，我们俩之前聊过这东西，大三的时候，他当时还是一脸不在乎，仿佛是梦中人，误以为自己找到了所有可行的道路。读完大学，大家都各奔东西了啊，结婚生孩，就仿佛是紧箍咒一般，永远去不掉，搞得你死去活来。昨天刚看了七毛的文章，心想真有这样的婆婆啊，卧槽，要是我妈这样，直接让她滚好了。话说回来，钱，爱情，生活，还有朋友，哪个是可以割舍的呢，都憧憬着甜甜的恋爱，说不定亲亲抱抱之后催债的电话就来了。活到这么大，真就是花父母的钱，我想作为父母，这或许就是教育投资吧，高投入，高风险的那种。生活啊，谁不是淌着一摊浑水艰难前行呢，当然有那种出生就比别人有更多的资源，房产加身，我是没有机会，我孩儿？先有个孩子再说吧。当他说到他家里对他出国态度的时候（国内保研多好，工作读博娶妻生子，安安稳稳，谁让你选择这条路了），我想到了大冰的书中说到的，年轻人，趁有活力，多闯一闯，多体验自己想要的生活，是啊，可如果失败了，真的就头破血流，落日黄花般模样了。朋友，加油啊，我真的不知道该怎么办，我也没经历过，所以我没给你一个明确的答复，到底是选择在国内还是国外。但总归，这就是生活啊，以梦为马，随处可栖？现在1:42了，手机打字是真的搞人，我也睡了。晚安。","source":"_posts/Cest-la-vie-Sep-24-2019.md","raw":"---\ntitle: 'Cest la vie - Sep 24, 2019'\ntags: []\noriginContent: ''\ncategories:\n  - 旧的文\nthumbnail: https://images.unsplash.com/photo-1569313815155-9c7206ddb924?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjQzMzEwfQ&auto=format&fit=crop&w=800&q=60\ntoc: false\ndate: 2019-09-25 10:23:12\n---\n\n今天还在跟我们班一起出国的人一起聊天，突然有一种作为倾听者的感觉。<!--more-->我们班其实还有另外一个帅气小伙子，本来要出国，花了2年时间考英语， GT考了出来，最后选择了保研，选择了硬件，选择了国光的直博。当时听到这个消息，其实我有想到他的女朋友诶，有可能是为了爱情？今天和这个哥们聊天，好像有点确认了这个消息，然后这哥们就问我关于女朋友，出国的各种不确定性。或许是因为硬件条件？他说他不会在那边找的，想要在国内带一个过去，但又怕之后自己放弃这段爱情，然后就把问题抛给我了，我啷个知道咯，随缘吧？其实我有一条路的选择是，读完master工作，然后去新加坡，把孩子落户在那里，但这个旅程缺失了另外一个人，说真的，我也不知道她能在哪里被我遇到，愿意不愿意去新加坡，她家里愿意不愿意让她跟我去新加坡；或者说我有想法要读博，那以后的日子可就要更加想清楚了，当然我憧憬着lalaland里面现实的爱情故事，能遇到不能遇到就两说了。那哥们也是挺不容易的，自己背了债，想到美帝读phd回本，但又怕自己读完回来30+，看到自己的名字出现在非诚勿扰的名单里，资料里写着美国计算机博士的那种。我还记得很清楚，我们俩之前聊过这东西，大三的时候，他当时还是一脸不在乎，仿佛是梦中人，误以为自己找到了所有可行的道路。读完大学，大家都各奔东西了啊，结婚生孩，就仿佛是紧箍咒一般，永远去不掉，搞得你死去活来。昨天刚看了七毛的文章，心想真有这样的婆婆啊，卧槽，要是我妈这样，直接让她滚好了。话说回来，钱，爱情，生活，还有朋友，哪个是可以割舍的呢，都憧憬着甜甜的恋爱，说不定亲亲抱抱之后催债的电话就来了。活到这么大，真就是花父母的钱，我想作为父母，这或许就是教育投资吧，高投入，高风险的那种。生活啊，谁不是淌着一摊浑水艰难前行呢，当然有那种出生就比别人有更多的资源，房产加身，我是没有机会，我孩儿？先有个孩子再说吧。当他说到他家里对他出国态度的时候（国内保研多好，工作读博娶妻生子，安安稳稳，谁让你选择这条路了），我想到了大冰的书中说到的，年轻人，趁有活力，多闯一闯，多体验自己想要的生活，是啊，可如果失败了，真的就头破血流，落日黄花般模样了。朋友，加油啊，我真的不知道该怎么办，我也没经历过，所以我没给你一个明确的答复，到底是选择在国内还是国外。但总归，这就是生活啊，以梦为马，随处可栖？现在1:42了，手机打字是真的搞人，我也睡了。晚安。","slug":"Cest-la-vie-Sep-24-2019","published":1,"updated":"2019-11-15T12:43:37.081Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkoq0008k3x6380e7cmw","content":"<p>今天还在跟我们班一起出国的人一起聊天，突然有一种作为倾听者的感觉。<a id=\"more\"></a>我们班其实还有另外一个帅气小伙子，本来要出国，花了2年时间考英语， GT考了出来，最后选择了保研，选择了硬件，选择了国光的直博。当时听到这个消息，其实我有想到他的女朋友诶，有可能是为了爱情？今天和这个哥们聊天，好像有点确认了这个消息，然后这哥们就问我关于女朋友，出国的各种不确定性。或许是因为硬件条件？他说他不会在那边找的，想要在国内带一个过去，但又怕之后自己放弃这段爱情，然后就把问题抛给我了，我啷个知道咯，随缘吧？其实我有一条路的选择是，读完master工作，然后去新加坡，把孩子落户在那里，但这个旅程缺失了另外一个人，说真的，我也不知道她能在哪里被我遇到，愿意不愿意去新加坡，她家里愿意不愿意让她跟我去新加坡；或者说我有想法要读博，那以后的日子可就要更加想清楚了，当然我憧憬着lalaland里面现实的爱情故事，能遇到不能遇到就两说了。那哥们也是挺不容易的，自己背了债，想到美帝读phd回本，但又怕自己读完回来30+，看到自己的名字出现在非诚勿扰的名单里，资料里写着美国计算机博士的那种。我还记得很清楚，我们俩之前聊过这东西，大三的时候，他当时还是一脸不在乎，仿佛是梦中人，误以为自己找到了所有可行的道路。读完大学，大家都各奔东西了啊，结婚生孩，就仿佛是紧箍咒一般，永远去不掉，搞得你死去活来。昨天刚看了七毛的文章，心想真有这样的婆婆啊，卧槽，要是我妈这样，直接让她滚好了。话说回来，钱，爱情，生活，还有朋友，哪个是可以割舍的呢，都憧憬着甜甜的恋爱，说不定亲亲抱抱之后催债的电话就来了。活到这么大，真就是花父母的钱，我想作为父母，这或许就是教育投资吧，高投入，高风险的那种。生活啊，谁不是淌着一摊浑水艰难前行呢，当然有那种出生就比别人有更多的资源，房产加身，我是没有机会，我孩儿？先有个孩子再说吧。当他说到他家里对他出国态度的时候（国内保研多好，工作读博娶妻生子，安安稳稳，谁让你选择这条路了），我想到了大冰的书中说到的，年轻人，趁有活力，多闯一闯，多体验自己想要的生活，是啊，可如果失败了，真的就头破血流，落日黄花般模样了。朋友，加油啊，我真的不知道该怎么办，我也没经历过，所以我没给你一个明确的答复，到底是选择在国内还是国外。但总归，这就是生活啊，以梦为马，随处可栖？现在1:42了，手机打字是真的搞人，我也睡了。晚安。</p>\n","site":{"data":{}},"excerpt":"<p>今天还在跟我们班一起出国的人一起聊天，突然有一种作为倾听者的感觉。</p>","more":"我们班其实还有另外一个帅气小伙子，本来要出国，花了2年时间考英语， GT考了出来，最后选择了保研，选择了硬件，选择了国光的直博。当时听到这个消息，其实我有想到他的女朋友诶，有可能是为了爱情？今天和这个哥们聊天，好像有点确认了这个消息，然后这哥们就问我关于女朋友，出国的各种不确定性。或许是因为硬件条件？他说他不会在那边找的，想要在国内带一个过去，但又怕之后自己放弃这段爱情，然后就把问题抛给我了，我啷个知道咯，随缘吧？其实我有一条路的选择是，读完master工作，然后去新加坡，把孩子落户在那里，但这个旅程缺失了另外一个人，说真的，我也不知道她能在哪里被我遇到，愿意不愿意去新加坡，她家里愿意不愿意让她跟我去新加坡；或者说我有想法要读博，那以后的日子可就要更加想清楚了，当然我憧憬着lalaland里面现实的爱情故事，能遇到不能遇到就两说了。那哥们也是挺不容易的，自己背了债，想到美帝读phd回本，但又怕自己读完回来30+，看到自己的名字出现在非诚勿扰的名单里，资料里写着美国计算机博士的那种。我还记得很清楚，我们俩之前聊过这东西，大三的时候，他当时还是一脸不在乎，仿佛是梦中人，误以为自己找到了所有可行的道路。读完大学，大家都各奔东西了啊，结婚生孩，就仿佛是紧箍咒一般，永远去不掉，搞得你死去活来。昨天刚看了七毛的文章，心想真有这样的婆婆啊，卧槽，要是我妈这样，直接让她滚好了。话说回来，钱，爱情，生活，还有朋友，哪个是可以割舍的呢，都憧憬着甜甜的恋爱，说不定亲亲抱抱之后催债的电话就来了。活到这么大，真就是花父母的钱，我想作为父母，这或许就是教育投资吧，高投入，高风险的那种。生活啊，谁不是淌着一摊浑水艰难前行呢，当然有那种出生就比别人有更多的资源，房产加身，我是没有机会，我孩儿？先有个孩子再说吧。当他说到他家里对他出国态度的时候（国内保研多好，工作读博娶妻生子，安安稳稳，谁让你选择这条路了），我想到了大冰的书中说到的，年轻人，趁有活力，多闯一闯，多体验自己想要的生活，是啊，可如果失败了，真的就头破血流，落日黄花般模样了。朋友，加油啊，我真的不知道该怎么办，我也没经历过，所以我没给你一个明确的答复，到底是选择在国内还是国外。但总归，这就是生活啊，以梦为马，随处可栖？现在1:42了，手机打字是真的搞人，我也睡了。晚安。</p>"},{"title":"Dec 6, 2017","originContent":"","toc":false,"date":"2017-12-06T02:53:12.000Z","thumbnail":"https://images.unsplash.com/photo-1525876183281-0d0d9308010d?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n我喜欢你是寂静的，仿佛你消失了一样，<!--more-->\n你从远处聆听我，我的声音却无法触及你。\n好像你的双眼已经飞离远去，如同一个吻，封缄了你的嘴。\n如同所有的事物充满了我的灵魂，\n你 从所有的事物中浮现，充满了我的灵魂。\n你像我的灵魂，一只梦的蝴蝶。你如同忧郁这个词。\n我喜欢你是寂静的，好像你已远去。\n你听起来像在悲叹，一只如鸽悲鸣的蝴蝶。\n你从远处聆听我，我的声音无法触及你：\n你让我在你的沉默中安静无声。\n并且让我借你的沉默与你说话，\n你的沉默明亮如灯，简单如指环，\n你就像黑夜，拥有寂寞与群星。\n你的沉默就是星星的沉默，遥远而明亮。\n我喜欢你是寂静的，仿佛你消失了一样，\n遥远而且哀伤，仿佛你   已经死了。\n彼时，一个字，一个微笑，已经足够。\n而我会觉得幸福，因那不是真的而觉得幸福。","source":"_posts/Dec-6-2017.md","raw":"---\ntitle: 'Dec 6, 2017'\ntags: []\noriginContent: ''\ncategories:\n  - 旧的梦\ntoc: false\ndate: 2017-12-06 10:53:12\nthumbnail: https://images.unsplash.com/photo-1525876183281-0d0d9308010d?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n我喜欢你是寂静的，仿佛你消失了一样，<!--more-->\n你从远处聆听我，我的声音却无法触及你。\n好像你的双眼已经飞离远去，如同一个吻，封缄了你的嘴。\n如同所有的事物充满了我的灵魂，\n你 从所有的事物中浮现，充满了我的灵魂。\n你像我的灵魂，一只梦的蝴蝶。你如同忧郁这个词。\n我喜欢你是寂静的，好像你已远去。\n你听起来像在悲叹，一只如鸽悲鸣的蝴蝶。\n你从远处聆听我，我的声音无法触及你：\n你让我在你的沉默中安静无声。\n并且让我借你的沉默与你说话，\n你的沉默明亮如灯，简单如指环，\n你就像黑夜，拥有寂寞与群星。\n你的沉默就是星星的沉默，遥远而明亮。\n我喜欢你是寂静的，仿佛你消失了一样，\n遥远而且哀伤，仿佛你   已经死了。\n彼时，一个字，一个微笑，已经足够。\n而我会觉得幸福，因那不是真的而觉得幸福。","slug":"Dec-6-2017","published":1,"updated":"2019-11-15T12:57:15.169Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkos000ak3x66ymxesnp","content":"<p>我喜欢你是寂静的，仿佛你消失了一样，<a id=\"more\"></a><br>你从远处聆听我，我的声音却无法触及你。<br>好像你的双眼已经飞离远去，如同一个吻，封缄了你的嘴。<br>如同所有的事物充满了我的灵魂，<br>你 从所有的事物中浮现，充满了我的灵魂。<br>你像我的灵魂，一只梦的蝴蝶。你如同忧郁这个词。<br>我喜欢你是寂静的，好像你已远去。<br>你听起来像在悲叹，一只如鸽悲鸣的蝴蝶。<br>你从远处聆听我，我的声音无法触及你：<br>你让我在你的沉默中安静无声。<br>并且让我借你的沉默与你说话，<br>你的沉默明亮如灯，简单如指环，<br>你就像黑夜，拥有寂寞与群星。<br>你的沉默就是星星的沉默，遥远而明亮。<br>我喜欢你是寂静的，仿佛你消失了一样，<br>遥远而且哀伤，仿佛你   已经死了。<br>彼时，一个字，一个微笑，已经足够。<br>而我会觉得幸福，因那不是真的而觉得幸福。</p>\n","site":{"data":{}},"excerpt":"<p>我喜欢你是寂静的，仿佛你消失了一样，</p>","more":"<br>你从远处聆听我，我的声音却无法触及你。<br>好像你的双眼已经飞离远去，如同一个吻，封缄了你的嘴。<br>如同所有的事物充满了我的灵魂，<br>你 从所有的事物中浮现，充满了我的灵魂。<br>你像我的灵魂，一只梦的蝴蝶。你如同忧郁这个词。<br>我喜欢你是寂静的，好像你已远去。<br>你听起来像在悲叹，一只如鸽悲鸣的蝴蝶。<br>你从远处聆听我，我的声音无法触及你：<br>你让我在你的沉默中安静无声。<br>并且让我借你的沉默与你说话，<br>你的沉默明亮如灯，简单如指环，<br>你就像黑夜，拥有寂寞与群星。<br>你的沉默就是星星的沉默，遥远而明亮。<br>我喜欢你是寂静的，仿佛你消失了一样，<br>遥远而且哀伤，仿佛你   已经死了。<br>彼时，一个字，一个微笑，已经足够。<br>而我会觉得幸福，因那不是真的而觉得幸福。</p>"},{"title":"Dec 27, 2017","originContent":"","toc":false,"date":"2017-12-27T02:53:47.000Z","thumbnail":"https://images.unsplash.com/photo-1545276000-974f15d80cf1?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n昨天在梦里，梦见姥娘因为太瘦，营养不良而双目失明，<!--more-->我坐在桌前，哭了，或许是梦境太过于真实，哭醒了泪还是止不住。我坐了起来，用毛巾擦擦泪，但再也睡不着了。\n\n这一年经历了太多…如意的…不顺的…生死离别也只不过是半个星期的事。希望姥娘能多吃点肉，别再那么瘦了，希望远方的你，也能照顾好自己，累了就蹲下来给自己一个大大的拥抱，告诉自己我还行。","source":"_posts/Dec-27-2017.md","raw":"---\ntitle: 'Dec 27, 2017'\ntags: []\noriginContent: ''\ncategories:\n  - 旧的梦\ntoc: false\ndate: 2017-12-27 10:53:47\nthumbnail: https://images.unsplash.com/photo-1545276000-974f15d80cf1?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n昨天在梦里，梦见姥娘因为太瘦，营养不良而双目失明，<!--more-->我坐在桌前，哭了，或许是梦境太过于真实，哭醒了泪还是止不住。我坐了起来，用毛巾擦擦泪，但再也睡不着了。\n\n这一年经历了太多…如意的…不顺的…生死离别也只不过是半个星期的事。希望姥娘能多吃点肉，别再那么瘦了，希望远方的你，也能照顾好自己，累了就蹲下来给自己一个大大的拥抱，告诉自己我还行。","slug":"Dec-27-2017","published":1,"updated":"2019-11-15T12:54:19.773Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkoy000dk3x627zrb3yj","content":"<p>昨天在梦里，梦见姥娘因为太瘦，营养不良而双目失明，<a id=\"more\"></a>我坐在桌前，哭了，或许是梦境太过于真实，哭醒了泪还是止不住。我坐了起来，用毛巾擦擦泪，但再也睡不着了。</p>\n<p>这一年经历了太多…如意的…不顺的…生死离别也只不过是半个星期的事。希望姥娘能多吃点肉，别再那么瘦了，希望远方的你，也能照顾好自己，累了就蹲下来给自己一个大大的拥抱，告诉自己我还行。</p>\n","site":{"data":{}},"excerpt":"<p>昨天在梦里，梦见姥娘因为太瘦，营养不良而双目失明，</p>","more":"我坐在桌前，哭了，或许是梦境太过于真实，哭醒了泪还是止不住。我坐了起来，用毛巾擦擦泪，但再也睡不着了。</p>\n<p>这一年经历了太多…如意的…不顺的…生死离别也只不过是半个星期的事。希望姥娘能多吃点肉，别再那么瘦了，希望远方的你，也能照顾好自己，累了就蹲下来给自己一个大大的拥抱，告诉自己我还行。</p>"},{"title":"Fake News 学习笔记（三）Bert 负采样 Transformer","toc":false,"date":"2019-08-11T14:36:47.000Z","thumbnail":"https://images.unsplash.com/photo-1434030216411-0b793f4b4173?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n# 使用 Google Bert 实现 Word-Embedding\n<!--more-->\n(由于组内分工，我和另外一位同学负责文字处理部分，所以这里主要介绍对于 Google Bert 的学习过程以及对于文字处理的一些细节)\n**idea**:\n1. 将 cleaned 后的文本进行提取，如果 len(text)为 0，删掉 label\n2. 使用学习笔记二中提到的stemming lemmatizing技术，对文本进行处理(不知道结果怎么样)\n3. to be continued\n\n## 负采样\n负采样通过使每一个训练样本仅仅改变一小部分的权重而不是所有权重。也就是对正确的一个输出单词up，选择5-20个不正确的单词low。在 Bert 中，首先给定的一个句子，下一句子正例（正确词），随机采样一句负例（随机采样词）,句子级上来做二分类（即判断句子是当前句子的下一句还是噪声），类似word2vec的单词级负采样。\n\n## Transformer 模型结构\n![The Transformer Architecture](https://i.loli.net/2019/08/11/DZd3vpK7OhyjgLX.png)\n\n如图所示，左边为encoder，右边为 decoder，具有高并行性的特点抱歉，现阶段本人能力有限，根本看不懂，反正牛逼就完事了，放上 link，万一以后回看呢。\n[Transformer arch.](https://www.cnblogs.com/sxron/p/10035802.html)\n### **multi-head attention:**\n将一个词的vector切分成h个维度，求attention相似度时每个h维度计算。由于单词映射在高维空间作为向量形式，每一维空间都可以学到不同的特征，相邻空间所学结果更相似，相较于全体空间放到一起对应更加合理。比如对于vector-size=512的词向量，取h=8，每64个空间做一个attention，学到结果更细化。\n### **self-attention：**\n每个词位的词都可以无视方向和距离，有机会直接和句子中的每个词encoding。比如下面这个句子，每个单词和同句其他单词之间都有一条边作为联系，边的颜色越深表明联系越强，而一般意义模糊的词语所连的边都比较深。比如：law，application，missing，opinion。。。\n### **position encoding:**\n因为transformer既没有RNN的recurrence也没有CNN的convolution，但序列顺序信息很重要，比如你欠我100万明天要还和我欠你100万明天要还的含义截然不同。。。\n　transformer计算token的位置信息这里使用正弦波，类似模拟信号传播周期性变化。这样的循环函数可以一定程度上增加模型的泛化能力。\n　　但BERT直接训练一个position embedding来保留位置信息，每个位置随机初始化一个向量，加入模型训练，最后就得到一个包含位置信息的embedding（简单粗暴。。），最后这个position embedding和word embedding的结合方式上，BERT选择直接拼接。\n![Output](https://i.loli.net/2019/08/11/mnRFiSh8MkjHA5I.png)\n\n## Google Bert\nNLP任务分为两部分，其一是预训练产生**词向量**，其二是对词向量进行操作(下游 NLP 任务)\n\n### 预训练产生词向量\n相比于之前所用到的 word2vec，负采样从 word-level 升级到了 sentence-level ，从而可以获取句间关系。\nBert 使用双向encoding(模型在处理某一个词时，它能同时利用前面的词和后面的词两部分信息)，采用看不懂的 Transformer 结构，直接获得一整个句子的唯一向量表示。在 Transformer 结构中，最终的输入由下面 3 个embedding 组成。\n![Input](https://i.loli.net/2019/08/11/jdZ792TAniEIPhY.jpg)\nEA 表示左句子，EB 表示右句子，CLS为特殊标记符，供 Transformer 对 CLS进行深度 embedding\n\n###预训练模型和加载的训练集之间的关系\n使用预先训练的模型，该模型已经在大型数据集上进行了训练，然后针对特定任务进行微调。\n\n### 下游 NLP 任务\n在获得 Bert 词向量后，只需要在词向量上加入简单的分类器即可完成工作","source":"_posts/Fake News 学习笔记（三）Bert 负采样 Transformer.md","raw":"---\ntitle: Fake News 学习笔记（三）Bert 负采样 Transformer\ntags: [NLP, Python]\ncategories: [FakeNews]\ntoc: false\ndate: 2019-08-11 22:36:47\nthumbnail: https://images.unsplash.com/photo-1434030216411-0b793f4b4173?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n# 使用 Google Bert 实现 Word-Embedding\n<!--more-->\n(由于组内分工，我和另外一位同学负责文字处理部分，所以这里主要介绍对于 Google Bert 的学习过程以及对于文字处理的一些细节)\n**idea**:\n1. 将 cleaned 后的文本进行提取，如果 len(text)为 0，删掉 label\n2. 使用学习笔记二中提到的stemming lemmatizing技术，对文本进行处理(不知道结果怎么样)\n3. to be continued\n\n## 负采样\n负采样通过使每一个训练样本仅仅改变一小部分的权重而不是所有权重。也就是对正确的一个输出单词up，选择5-20个不正确的单词low。在 Bert 中，首先给定的一个句子，下一句子正例（正确词），随机采样一句负例（随机采样词）,句子级上来做二分类（即判断句子是当前句子的下一句还是噪声），类似word2vec的单词级负采样。\n\n## Transformer 模型结构\n![The Transformer Architecture](https://i.loli.net/2019/08/11/DZd3vpK7OhyjgLX.png)\n\n如图所示，左边为encoder，右边为 decoder，具有高并行性的特点抱歉，现阶段本人能力有限，根本看不懂，反正牛逼就完事了，放上 link，万一以后回看呢。\n[Transformer arch.](https://www.cnblogs.com/sxron/p/10035802.html)\n### **multi-head attention:**\n将一个词的vector切分成h个维度，求attention相似度时每个h维度计算。由于单词映射在高维空间作为向量形式，每一维空间都可以学到不同的特征，相邻空间所学结果更相似，相较于全体空间放到一起对应更加合理。比如对于vector-size=512的词向量，取h=8，每64个空间做一个attention，学到结果更细化。\n### **self-attention：**\n每个词位的词都可以无视方向和距离，有机会直接和句子中的每个词encoding。比如下面这个句子，每个单词和同句其他单词之间都有一条边作为联系，边的颜色越深表明联系越强，而一般意义模糊的词语所连的边都比较深。比如：law，application，missing，opinion。。。\n### **position encoding:**\n因为transformer既没有RNN的recurrence也没有CNN的convolution，但序列顺序信息很重要，比如你欠我100万明天要还和我欠你100万明天要还的含义截然不同。。。\n　transformer计算token的位置信息这里使用正弦波，类似模拟信号传播周期性变化。这样的循环函数可以一定程度上增加模型的泛化能力。\n　　但BERT直接训练一个position embedding来保留位置信息，每个位置随机初始化一个向量，加入模型训练，最后就得到一个包含位置信息的embedding（简单粗暴。。），最后这个position embedding和word embedding的结合方式上，BERT选择直接拼接。\n![Output](https://i.loli.net/2019/08/11/mnRFiSh8MkjHA5I.png)\n\n## Google Bert\nNLP任务分为两部分，其一是预训练产生**词向量**，其二是对词向量进行操作(下游 NLP 任务)\n\n### 预训练产生词向量\n相比于之前所用到的 word2vec，负采样从 word-level 升级到了 sentence-level ，从而可以获取句间关系。\nBert 使用双向encoding(模型在处理某一个词时，它能同时利用前面的词和后面的词两部分信息)，采用看不懂的 Transformer 结构，直接获得一整个句子的唯一向量表示。在 Transformer 结构中，最终的输入由下面 3 个embedding 组成。\n![Input](https://i.loli.net/2019/08/11/jdZ792TAniEIPhY.jpg)\nEA 表示左句子，EB 表示右句子，CLS为特殊标记符，供 Transformer 对 CLS进行深度 embedding\n\n###预训练模型和加载的训练集之间的关系\n使用预先训练的模型，该模型已经在大型数据集上进行了训练，然后针对特定任务进行微调。\n\n### 下游 NLP 任务\n在获得 Bert 词向量后，只需要在词向量上加入简单的分类器即可完成工作","slug":"Fake News 学习笔记（三）Bert 负采样 Transformer","published":1,"updated":"2019-11-16T12:11:52.902Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkp1000fk3x615f93njx","content":"<h1 id=\"使用-Google-Bert-实现-Word-Embedding\"><a href=\"#使用-Google-Bert-实现-Word-Embedding\" class=\"headerlink\" title=\"使用 Google Bert 实现 Word-Embedding\"></a>使用 Google Bert 实现 Word-Embedding</h1><a id=\"more\"></a>\n<p>(由于组内分工，我和另外一位同学负责文字处理部分，所以这里主要介绍对于 Google Bert 的学习过程以及对于文字处理的一些细节)<br><strong>idea</strong>:</p>\n<ol>\n<li>将 cleaned 后的文本进行提取，如果 len(text)为 0，删掉 label</li>\n<li>使用学习笔记二中提到的stemming lemmatizing技术，对文本进行处理(不知道结果怎么样)</li>\n<li>to be continued</li>\n</ol>\n<h2 id=\"负采样\"><a href=\"#负采样\" class=\"headerlink\" title=\"负采样\"></a>负采样</h2><p>负采样通过使每一个训练样本仅仅改变一小部分的权重而不是所有权重。也就是对正确的一个输出单词up，选择5-20个不正确的单词low。在 Bert 中，首先给定的一个句子，下一句子正例（正确词），随机采样一句负例（随机采样词）,句子级上来做二分类（即判断句子是当前句子的下一句还是噪声），类似word2vec的单词级负采样。</p>\n<h2 id=\"Transformer-模型结构\"><a href=\"#Transformer-模型结构\" class=\"headerlink\" title=\"Transformer 模型结构\"></a>Transformer 模型结构</h2><p><img src=\"https://i.loli.net/2019/08/11/DZd3vpK7OhyjgLX.png\" alt=\"The Transformer Architecture\"></p>\n<p>如图所示，左边为encoder，右边为 decoder，具有高并行性的特点抱歉，现阶段本人能力有限，根本看不懂，反正牛逼就完事了，放上 link，万一以后回看呢。<br><a href=\"https://www.cnblogs.com/sxron/p/10035802.html\" target=\"_blank\" rel=\"noopener\">Transformer arch.</a></p>\n<h3 id=\"multi-head-attention\"><a href=\"#multi-head-attention\" class=\"headerlink\" title=\"multi-head attention:\"></a><strong>multi-head attention:</strong></h3><p>将一个词的vector切分成h个维度，求attention相似度时每个h维度计算。由于单词映射在高维空间作为向量形式，每一维空间都可以学到不同的特征，相邻空间所学结果更相似，相较于全体空间放到一起对应更加合理。比如对于vector-size=512的词向量，取h=8，每64个空间做一个attention，学到结果更细化。</p>\n<h3 id=\"self-attention：\"><a href=\"#self-attention：\" class=\"headerlink\" title=\"self-attention：\"></a><strong>self-attention：</strong></h3><p>每个词位的词都可以无视方向和距离，有机会直接和句子中的每个词encoding。比如下面这个句子，每个单词和同句其他单词之间都有一条边作为联系，边的颜色越深表明联系越强，而一般意义模糊的词语所连的边都比较深。比如：law，application，missing，opinion。。。</p>\n<h3 id=\"position-encoding\"><a href=\"#position-encoding\" class=\"headerlink\" title=\"position encoding:\"></a><strong>position encoding:</strong></h3><p>因为transformer既没有RNN的recurrence也没有CNN的convolution，但序列顺序信息很重要，比如你欠我100万明天要还和我欠你100万明天要还的含义截然不同。。。<br>　transformer计算token的位置信息这里使用正弦波，类似模拟信号传播周期性变化。这样的循环函数可以一定程度上增加模型的泛化能力。<br>　　但BERT直接训练一个position embedding来保留位置信息，每个位置随机初始化一个向量，加入模型训练，最后就得到一个包含位置信息的embedding（简单粗暴。。），最后这个position embedding和word embedding的结合方式上，BERT选择直接拼接。<br><img src=\"https://i.loli.net/2019/08/11/mnRFiSh8MkjHA5I.png\" alt=\"Output\"></p>\n<h2 id=\"Google-Bert\"><a href=\"#Google-Bert\" class=\"headerlink\" title=\"Google Bert\"></a>Google Bert</h2><p>NLP任务分为两部分，其一是预训练产生<strong>词向量</strong>，其二是对词向量进行操作(下游 NLP 任务)</p>\n<h3 id=\"预训练产生词向量\"><a href=\"#预训练产生词向量\" class=\"headerlink\" title=\"预训练产生词向量\"></a>预训练产生词向量</h3><p>相比于之前所用到的 word2vec，负采样从 word-level 升级到了 sentence-level ，从而可以获取句间关系。<br>Bert 使用双向encoding(模型在处理某一个词时，它能同时利用前面的词和后面的词两部分信息)，采用看不懂的 Transformer 结构，直接获得一整个句子的唯一向量表示。在 Transformer 结构中，最终的输入由下面 3 个embedding 组成。<br><img src=\"https://i.loli.net/2019/08/11/jdZ792TAniEIPhY.jpg\" alt=\"Input\"><br>EA 表示左句子，EB 表示右句子，CLS为特殊标记符，供 Transformer 对 CLS进行深度 embedding</p>\n<p>###预训练模型和加载的训练集之间的关系<br>使用预先训练的模型，该模型已经在大型数据集上进行了训练，然后针对特定任务进行微调。</p>\n<h3 id=\"下游-NLP-任务\"><a href=\"#下游-NLP-任务\" class=\"headerlink\" title=\"下游 NLP 任务\"></a>下游 NLP 任务</h3><p>在获得 Bert 词向量后，只需要在词向量上加入简单的分类器即可完成工作</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"使用-Google-Bert-实现-Word-Embedding\"><a href=\"#使用-Google-Bert-实现-Word-Embedding\" class=\"headerlink\" title=\"使用 Google Bert 实现 Word-Embedding\"></a>使用 Google Bert 实现 Word-Embedding</h1>","more":"<p>(由于组内分工，我和另外一位同学负责文字处理部分，所以这里主要介绍对于 Google Bert 的学习过程以及对于文字处理的一些细节)<br><strong>idea</strong>:</p>\n<ol>\n<li>将 cleaned 后的文本进行提取，如果 len(text)为 0，删掉 label</li>\n<li>使用学习笔记二中提到的stemming lemmatizing技术，对文本进行处理(不知道结果怎么样)</li>\n<li>to be continued</li>\n</ol>\n<h2 id=\"负采样\"><a href=\"#负采样\" class=\"headerlink\" title=\"负采样\"></a>负采样</h2><p>负采样通过使每一个训练样本仅仅改变一小部分的权重而不是所有权重。也就是对正确的一个输出单词up，选择5-20个不正确的单词low。在 Bert 中，首先给定的一个句子，下一句子正例（正确词），随机采样一句负例（随机采样词）,句子级上来做二分类（即判断句子是当前句子的下一句还是噪声），类似word2vec的单词级负采样。</p>\n<h2 id=\"Transformer-模型结构\"><a href=\"#Transformer-模型结构\" class=\"headerlink\" title=\"Transformer 模型结构\"></a>Transformer 模型结构</h2><p><img src=\"https://i.loli.net/2019/08/11/DZd3vpK7OhyjgLX.png\" alt=\"The Transformer Architecture\"></p>\n<p>如图所示，左边为encoder，右边为 decoder，具有高并行性的特点抱歉，现阶段本人能力有限，根本看不懂，反正牛逼就完事了，放上 link，万一以后回看呢。<br><a href=\"https://www.cnblogs.com/sxron/p/10035802.html\" target=\"_blank\" rel=\"noopener\">Transformer arch.</a></p>\n<h3 id=\"multi-head-attention\"><a href=\"#multi-head-attention\" class=\"headerlink\" title=\"multi-head attention:\"></a><strong>multi-head attention:</strong></h3><p>将一个词的vector切分成h个维度，求attention相似度时每个h维度计算。由于单词映射在高维空间作为向量形式，每一维空间都可以学到不同的特征，相邻空间所学结果更相似，相较于全体空间放到一起对应更加合理。比如对于vector-size=512的词向量，取h=8，每64个空间做一个attention，学到结果更细化。</p>\n<h3 id=\"self-attention：\"><a href=\"#self-attention：\" class=\"headerlink\" title=\"self-attention：\"></a><strong>self-attention：</strong></h3><p>每个词位的词都可以无视方向和距离，有机会直接和句子中的每个词encoding。比如下面这个句子，每个单词和同句其他单词之间都有一条边作为联系，边的颜色越深表明联系越强，而一般意义模糊的词语所连的边都比较深。比如：law，application，missing，opinion。。。</p>\n<h3 id=\"position-encoding\"><a href=\"#position-encoding\" class=\"headerlink\" title=\"position encoding:\"></a><strong>position encoding:</strong></h3><p>因为transformer既没有RNN的recurrence也没有CNN的convolution，但序列顺序信息很重要，比如你欠我100万明天要还和我欠你100万明天要还的含义截然不同。。。<br>　transformer计算token的位置信息这里使用正弦波，类似模拟信号传播周期性变化。这样的循环函数可以一定程度上增加模型的泛化能力。<br>　　但BERT直接训练一个position embedding来保留位置信息，每个位置随机初始化一个向量，加入模型训练，最后就得到一个包含位置信息的embedding（简单粗暴。。），最后这个position embedding和word embedding的结合方式上，BERT选择直接拼接。<br><img src=\"https://i.loli.net/2019/08/11/mnRFiSh8MkjHA5I.png\" alt=\"Output\"></p>\n<h2 id=\"Google-Bert\"><a href=\"#Google-Bert\" class=\"headerlink\" title=\"Google Bert\"></a>Google Bert</h2><p>NLP任务分为两部分，其一是预训练产生<strong>词向量</strong>，其二是对词向量进行操作(下游 NLP 任务)</p>\n<h3 id=\"预训练产生词向量\"><a href=\"#预训练产生词向量\" class=\"headerlink\" title=\"预训练产生词向量\"></a>预训练产生词向量</h3><p>相比于之前所用到的 word2vec，负采样从 word-level 升级到了 sentence-level ，从而可以获取句间关系。<br>Bert 使用双向encoding(模型在处理某一个词时，它能同时利用前面的词和后面的词两部分信息)，采用看不懂的 Transformer 结构，直接获得一整个句子的唯一向量表示。在 Transformer 结构中，最终的输入由下面 3 个embedding 组成。<br><img src=\"https://i.loli.net/2019/08/11/jdZ792TAniEIPhY.jpg\" alt=\"Input\"><br>EA 表示左句子，EB 表示右句子，CLS为特殊标记符，供 Transformer 对 CLS进行深度 embedding</p>\n<p>###预训练模型和加载的训练集之间的关系<br>使用预先训练的模型，该模型已经在大型数据集上进行了训练，然后针对特定任务进行微调。</p>\n<h3 id=\"下游-NLP-任务\"><a href=\"#下游-NLP-任务\" class=\"headerlink\" title=\"下游 NLP 任务\"></a>下游 NLP 任务</h3><p>在获得 Bert 词向量后，只需要在词向量上加入简单的分类器即可完成工作</p>"},{"title":"Fake News 学习笔记（一）分类器，f1 score","originContent":"","toc":false,"date":"2019-07-20T10:28:57.000Z","thumbnail":"https://images.unsplash.com/photo-1434030216411-0b793f4b4173?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n## NFL data\n美国职业橄榄球大联盟（National Football League，简称NFL）<!--more-->\n你妹的，这教授我佛了。\n\n## 逻辑回归\n在第一节课中，x 轴代表该队触地得分的次数，y 轴代表该队是否胜利，输为 0，赢为 1，不使用线性回归的原因是该结果的输出为二分类问题，不需要数据的连续性，只需要输出 0 和 1 即可，同时该问题不是简单地线性问题，即很难用一条直线直接模拟该队触地得分次数与输赢的关系，同时受离群值的影响（当 x 值特别大，超过了正常的范围，就会影响正常值的分类），使用线性回归有很大的几率分类错误，所以所以使用逻辑回归方法进行分类。\n\n逻辑回归使用 Sigmoid 函数，将函数的输入范围是负无穷到正无穷的定义域规定为 0-1 之内的范围，这样就解决了由于离群值对于阈值的影响作用。\n\n## 参数定义（用于 F1 score 计算）\n**True Positives (TP)**: Correct positive predictions\n预测 yes，真实 yes\n**False Positives (FP)**: Incorrect positive predictions (false alarm)\n预测 yes，真实 no\n**True Negatives (TN)**: Correct negative predictions\n预测 no，真实 no\n**False Negatives (FN)**: Incorrect negative predictions (a miss)\n预测 no，真实 yes\n\n## F1 score\n用来衡量二分类模型精确的一种指标\n**精确率**：TP/所有预测的 yes（所有预测 yes 中真实为 yes 的比率）\n**召回率**：TP/所有真实的 yes（所有真实 yes 中预测为 yes 的比率）\n**F1 score**：2/(1/P+1/C)=2TP(2TP+FN+FP)\n\n## 决策树\n利用 if-then 原则，按照树状结构的特点，叶节点表示其分类标记，非叶节点表示其各个 feature，利用 feature 进行匹配，直至找到最符合数据的分类。\n\n## 随机森林（Random Forests）\n包含多个决策树的分类器， 并且其输出的类别是由个别树输出的类别的众数而定。，随机森林对回归的结果在内部是取得平均\n\n在得到森林之后，当有一个新的输入样本进入的时候，就让森林中的每一棵决策树分别进行一下判断，看看这个样本应该属于哪一类（对于分类算法），然后看看哪一类被选择最多，就预测这个样本为那一类。\n\n## XGBoost\nXGBoost是boosting算法的其中一种。Boosting算法的思想是将许多弱分类器集成在一起形成一个强分类器。因为XGBoost是一种提升树模型，所以它是将许多树模型集成在一起，形成一个很强的分类器。而所用到的树模型则是CART回归树模型。","source":"_posts/Fake News 学习笔记（一）分类器，f1 score.md","raw":"---\ntitle: Fake News 学习笔记（一）分类器，f1 score\ntags: [NLP, Python]\noriginContent: ''\ncategories: [FakeNews]\ntoc: false\ndate: 2019-07-20 18:28:57\nthumbnail: https://images.unsplash.com/photo-1434030216411-0b793f4b4173?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n## NFL data\n美国职业橄榄球大联盟（National Football League，简称NFL）<!--more-->\n你妹的，这教授我佛了。\n\n## 逻辑回归\n在第一节课中，x 轴代表该队触地得分的次数，y 轴代表该队是否胜利，输为 0，赢为 1，不使用线性回归的原因是该结果的输出为二分类问题，不需要数据的连续性，只需要输出 0 和 1 即可，同时该问题不是简单地线性问题，即很难用一条直线直接模拟该队触地得分次数与输赢的关系，同时受离群值的影响（当 x 值特别大，超过了正常的范围，就会影响正常值的分类），使用线性回归有很大的几率分类错误，所以所以使用逻辑回归方法进行分类。\n\n逻辑回归使用 Sigmoid 函数，将函数的输入范围是负无穷到正无穷的定义域规定为 0-1 之内的范围，这样就解决了由于离群值对于阈值的影响作用。\n\n## 参数定义（用于 F1 score 计算）\n**True Positives (TP)**: Correct positive predictions\n预测 yes，真实 yes\n**False Positives (FP)**: Incorrect positive predictions (false alarm)\n预测 yes，真实 no\n**True Negatives (TN)**: Correct negative predictions\n预测 no，真实 no\n**False Negatives (FN)**: Incorrect negative predictions (a miss)\n预测 no，真实 yes\n\n## F1 score\n用来衡量二分类模型精确的一种指标\n**精确率**：TP/所有预测的 yes（所有预测 yes 中真实为 yes 的比率）\n**召回率**：TP/所有真实的 yes（所有真实 yes 中预测为 yes 的比率）\n**F1 score**：2/(1/P+1/C)=2TP(2TP+FN+FP)\n\n## 决策树\n利用 if-then 原则，按照树状结构的特点，叶节点表示其分类标记，非叶节点表示其各个 feature，利用 feature 进行匹配，直至找到最符合数据的分类。\n\n## 随机森林（Random Forests）\n包含多个决策树的分类器， 并且其输出的类别是由个别树输出的类别的众数而定。，随机森林对回归的结果在内部是取得平均\n\n在得到森林之后，当有一个新的输入样本进入的时候，就让森林中的每一棵决策树分别进行一下判断，看看这个样本应该属于哪一类（对于分类算法），然后看看哪一类被选择最多，就预测这个样本为那一类。\n\n## XGBoost\nXGBoost是boosting算法的其中一种。Boosting算法的思想是将许多弱分类器集成在一起形成一个强分类器。因为XGBoost是一种提升树模型，所以它是将许多树模型集成在一起，形成一个很强的分类器。而所用到的树模型则是CART回归树模型。","slug":"Fake News 学习笔记（一）分类器，f1 score","published":1,"updated":"2019-11-16T12:11:09.429Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkp6000jk3x67ri6cao0","content":"<h2 id=\"NFL-data\"><a href=\"#NFL-data\" class=\"headerlink\" title=\"NFL data\"></a>NFL data</h2><p>美国职业橄榄球大联盟（National Football League，简称NFL）<a id=\"more\"></a><br>你妹的，这教授我佛了。</p>\n<h2 id=\"逻辑回归\"><a href=\"#逻辑回归\" class=\"headerlink\" title=\"逻辑回归\"></a>逻辑回归</h2><p>在第一节课中，x 轴代表该队触地得分的次数，y 轴代表该队是否胜利，输为 0，赢为 1，不使用线性回归的原因是该结果的输出为二分类问题，不需要数据的连续性，只需要输出 0 和 1 即可，同时该问题不是简单地线性问题，即很难用一条直线直接模拟该队触地得分次数与输赢的关系，同时受离群值的影响（当 x 值特别大，超过了正常的范围，就会影响正常值的分类），使用线性回归有很大的几率分类错误，所以所以使用逻辑回归方法进行分类。</p>\n<p>逻辑回归使用 Sigmoid 函数，将函数的输入范围是负无穷到正无穷的定义域规定为 0-1 之内的范围，这样就解决了由于离群值对于阈值的影响作用。</p>\n<h2 id=\"参数定义（用于-F1-score-计算）\"><a href=\"#参数定义（用于-F1-score-计算）\" class=\"headerlink\" title=\"参数定义（用于 F1 score 计算）\"></a>参数定义（用于 F1 score 计算）</h2><p><strong>True Positives (TP)</strong>: Correct positive predictions<br>预测 yes，真实 yes<br><strong>False Positives (FP)</strong>: Incorrect positive predictions (false alarm)<br>预测 yes，真实 no<br><strong>True Negatives (TN)</strong>: Correct negative predictions<br>预测 no，真实 no<br><strong>False Negatives (FN)</strong>: Incorrect negative predictions (a miss)<br>预测 no，真实 yes</p>\n<h2 id=\"F1-score\"><a href=\"#F1-score\" class=\"headerlink\" title=\"F1 score\"></a>F1 score</h2><p>用来衡量二分类模型精确的一种指标<br><strong>精确率</strong>：TP/所有预测的 yes（所有预测 yes 中真实为 yes 的比率）<br><strong>召回率</strong>：TP/所有真实的 yes（所有真实 yes 中预测为 yes 的比率）<br><strong>F1 score</strong>：2/(1/P+1/C)=2TP(2TP+FN+FP)</p>\n<h2 id=\"决策树\"><a href=\"#决策树\" class=\"headerlink\" title=\"决策树\"></a>决策树</h2><p>利用 if-then 原则，按照树状结构的特点，叶节点表示其分类标记，非叶节点表示其各个 feature，利用 feature 进行匹配，直至找到最符合数据的分类。</p>\n<h2 id=\"随机森林（Random-Forests）\"><a href=\"#随机森林（Random-Forests）\" class=\"headerlink\" title=\"随机森林（Random Forests）\"></a>随机森林（Random Forests）</h2><p>包含多个决策树的分类器， 并且其输出的类别是由个别树输出的类别的众数而定。，随机森林对回归的结果在内部是取得平均</p>\n<p>在得到森林之后，当有一个新的输入样本进入的时候，就让森林中的每一棵决策树分别进行一下判断，看看这个样本应该属于哪一类（对于分类算法），然后看看哪一类被选择最多，就预测这个样本为那一类。</p>\n<h2 id=\"XGBoost\"><a href=\"#XGBoost\" class=\"headerlink\" title=\"XGBoost\"></a>XGBoost</h2><p>XGBoost是boosting算法的其中一种。Boosting算法的思想是将许多弱分类器集成在一起形成一个强分类器。因为XGBoost是一种提升树模型，所以它是将许多树模型集成在一起，形成一个很强的分类器。而所用到的树模型则是CART回归树模型。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"NFL-data\"><a href=\"#NFL-data\" class=\"headerlink\" title=\"NFL data\"></a>NFL data</h2><p>美国职业橄榄球大联盟（National Football League，简称NFL）</p>","more":"<br>你妹的，这教授我佛了。</p>\n<h2 id=\"逻辑回归\"><a href=\"#逻辑回归\" class=\"headerlink\" title=\"逻辑回归\"></a>逻辑回归</h2><p>在第一节课中，x 轴代表该队触地得分的次数，y 轴代表该队是否胜利，输为 0，赢为 1，不使用线性回归的原因是该结果的输出为二分类问题，不需要数据的连续性，只需要输出 0 和 1 即可，同时该问题不是简单地线性问题，即很难用一条直线直接模拟该队触地得分次数与输赢的关系，同时受离群值的影响（当 x 值特别大，超过了正常的范围，就会影响正常值的分类），使用线性回归有很大的几率分类错误，所以所以使用逻辑回归方法进行分类。</p>\n<p>逻辑回归使用 Sigmoid 函数，将函数的输入范围是负无穷到正无穷的定义域规定为 0-1 之内的范围，这样就解决了由于离群值对于阈值的影响作用。</p>\n<h2 id=\"参数定义（用于-F1-score-计算）\"><a href=\"#参数定义（用于-F1-score-计算）\" class=\"headerlink\" title=\"参数定义（用于 F1 score 计算）\"></a>参数定义（用于 F1 score 计算）</h2><p><strong>True Positives (TP)</strong>: Correct positive predictions<br>预测 yes，真实 yes<br><strong>False Positives (FP)</strong>: Incorrect positive predictions (false alarm)<br>预测 yes，真实 no<br><strong>True Negatives (TN)</strong>: Correct negative predictions<br>预测 no，真实 no<br><strong>False Negatives (FN)</strong>: Incorrect negative predictions (a miss)<br>预测 no，真实 yes</p>\n<h2 id=\"F1-score\"><a href=\"#F1-score\" class=\"headerlink\" title=\"F1 score\"></a>F1 score</h2><p>用来衡量二分类模型精确的一种指标<br><strong>精确率</strong>：TP/所有预测的 yes（所有预测 yes 中真实为 yes 的比率）<br><strong>召回率</strong>：TP/所有真实的 yes（所有真实 yes 中预测为 yes 的比率）<br><strong>F1 score</strong>：2/(1/P+1/C)=2TP(2TP+FN+FP)</p>\n<h2 id=\"决策树\"><a href=\"#决策树\" class=\"headerlink\" title=\"决策树\"></a>决策树</h2><p>利用 if-then 原则，按照树状结构的特点，叶节点表示其分类标记，非叶节点表示其各个 feature，利用 feature 进行匹配，直至找到最符合数据的分类。</p>\n<h2 id=\"随机森林（Random-Forests）\"><a href=\"#随机森林（Random-Forests）\" class=\"headerlink\" title=\"随机森林（Random Forests）\"></a>随机森林（Random Forests）</h2><p>包含多个决策树的分类器， 并且其输出的类别是由个别树输出的类别的众数而定。，随机森林对回归的结果在内部是取得平均</p>\n<p>在得到森林之后，当有一个新的输入样本进入的时候，就让森林中的每一棵决策树分别进行一下判断，看看这个样本应该属于哪一类（对于分类算法），然后看看哪一类被选择最多，就预测这个样本为那一类。</p>\n<h2 id=\"XGBoost\"><a href=\"#XGBoost\" class=\"headerlink\" title=\"XGBoost\"></a>XGBoost</h2><p>XGBoost是boosting算法的其中一种。Boosting算法的思想是将许多弱分类器集成在一起形成一个强分类器。因为XGBoost是一种提升树模型，所以它是将许多树模型集成在一起，形成一个很强的分类器。而所用到的树模型则是CART回归树模型。</p>"},{"title":"Fake News 学习笔记（四）Project-Summary NLP-Summary","toc":false,"date":"2019-08-16T10:03:57.000Z","thumbnail":"https://images.unsplash.com/photo-1434030216411-0b793f4b4173?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n转载大佬的博客，写的太牛逼了: [从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史]\n<!--more-->\n## 牢骚\n为期6周的项目终于结束了，从昨天晚上连夜训练跑代码到今天的 Presentation，虽然还有点紧张，但更多的是对项目的无奈，一组4 个人，连带 Q&A 共 15min，平均下来每个人只有 2 分半的时间去展示自己做的东西。我实话说吧，就光 Bert，我都可以讲5min，一共 9 个组，难道就不能分来？？哪怕 3 个 3 个来也行，说起来我是真的烦，既然就是收钱那推荐信的项目了，掏了几万块钱就不能让这个钱花的值一点？其实我在小组分工方面是有点偏心的，我是想做文字处理的部分，而且最后选择了 Bert ，因为我想尝试一些不一样的东西，分类器之前大三下有上过课，虽然学的不是特别懂，但总算是有接触过，大学也不就是通识教育吗，我也没有希望我能有多么深入的学习，只希望我可以多学一点不会的东西，对于 NLP，我之前是一点都没有接触，当然原理性的东西就根本不可能知道，得知了项目是做关于自然语言处理的，我有蛮感兴趣，通过课上的学习，教授说了很多新兴的自然语言处理工具，其中就包括了 Bert，Bert 是 18 年底提出的知识，总感觉是我在大学学习的最新的知识了吧，相比于 11 年的 C++课本。。。不管了，知识是学给自己的，谁也偷不走，最后我还是总结一下我总的学到的知识吧。下面英文的部分是 “官方要求的项目总结”，就不再多说了，关于 Bert 的实现在另外一篇博客中有所展示，这里就不再一一赘述了。\n\n## 个人理解 从 Word2Vec 到 Bert\n从最开始的 Word2Vec，到 GloVe，一直到最新的 Bert，无非是将文字转化为一个可以让机器识别的数据格式-矩阵。在最开始的模型中，也就是 Word 和 Glove，存在一个初始的矩阵，里面包含了该方法所用的文字 token 以及对应的 value，只需要将文字输入到模型中，即可得到每个文字所对应的向量值，也就是矩阵值(相乘)，这样就涉及到了如何得到初始矩阵的问题，Word 和 Glove 使用的方法当然是不同的，在我们项目小组中，我们尝试了用 Glove 代替 Word，并取得了较好的效果，但实质还是没有变化，存在的问题也是显然的。我们都知道每个单词在句子中的意思是依附于上下文的，就比如所有博客中提到的 Bank 这个单词，有银行和河岸的意思，所以将所有的意思用一个矩阵去表示显得有失偏颇，所以基于两者提出了更多的模型。\n\n这就要提到 Elmo了（我学的不是很深，只是把大概的思想了解了一下）：根据上下文关系进行向量的生成，但是有别于前面两者，什么意思。Word 和 Glove 只是把初始矩阵给你，你并不可以改变其中的值，但是在 Elmo 中，应该是使用了迁移学习的思想，在初始矩阵的基础上根据训练集进行相关的更新，也就是矩阵值的更新，但是怎么生成初始矩阵我并没有怎么学习，Bert 倒是了解了一点，反正对于我来说，Elmo 的意义就是矩阵的动态更新，使得矩阵里面的值可以更贴切训练集中特定的文本。而且从训练效果看，具有很大的提高，说到这里，其实有点鄙视最开始的 Word 和 Glove 了，因为考虑的东西太少，这也是为什么我看到别人用 Word2Vec 可以达到0.9多正确率而直呼牛逼的原因。\n\n从 Elmo 到 Bert，又是一个飞跃，当然不能否认，Bert 是基于前人的工作而提出的新型的模型，因为很多思想和前者都有很多相似之处，可以说是站在巨人的肩膀上看世界。Bert 采用了更为高效的网络结构-Transformer来更新初始矩阵, 以及巨大的预训练模型用来生成初始矩阵。同样是考虑到了文章的上下文关系，在 Bert 中共有 3 个不同的变量作为模型的输入，每个单词的 Embedding，位置的 Embedding 和句子的 Embedding（可以理解为和初始矩阵的乘积？），这些都是依附于初始矩阵得到的结果，但是有文章说 Word 的 Embedding 不依附于初始矩阵，那我就不是很懂了，anyway，有三种不同的输入进行网络模型。\n在模型中只使用到了 Transformer 的 Encode 部分，具体的工作流程我就不懂了，反正经过了多层的 Encode，伴随着矩阵的更新（fune-tuning），最终可以得到很多个向量的结果，再加上 linear 和 softmax 层即可解决分类问题。有人会问了，那 Bert 是如何得到初始矩阵的。这就是 Bert 牛逼之处了，通过 mask 遮盖句子中的单词来训练单个单词，通过遮盖整个句子来训练整个句子，听过 Google 训练了整个 Wikipedia，真的牛逼。最终通过矩阵的更新得到了相应的结果。利用 Transformer 加上强大的与训练模型使得 Bert 脱颖而出，摘得了 NLP 的头牌，有人说 Bert 是 NLP 的顶峰，我看了几篇文章，一个是清华大学的，一个是斯坦福大学的，都是基于 Bert 的现有模型，要么是修改网络结构，要么是增加模型的输入以提高文章的 Contextual 属性，也得到了比初始模型更好的结果，可以说是炼丹成功的典范了。\n\n## 总结\n说到这里，项目也就结束了，从最开始的打开 FakeNewsTutorial 到写下这最后一篇博客，完成了项目所有的工作，还8.23 下午赶了 Github 的 repo 作为展示，修改中介关于项目的细节，以及项目的总结书，感谢组员的配合和合作，我感觉我们在最后的 Pre 发挥的很好，希望给教授留下不错的印象吧，希望大家都好好努力，前程似锦。\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t——王依凡 08/24/2019 华科东 11 栋\n\n\n\n## Project Summary\n### 1. Contribution\n 1. My job in our group is to use Google Bert to classify the text and complete a pipeline.\n 2. Use various word processing methods for specific text to improve the final f1 score (0.986)\n 3. I arrange member’s work within the group and meeting time. Three rehearsals were completed through communication with members before the final pre.\n 4. Use my own server to build a python environment for team members\n 5. Check out the relevant information and code about Glove on the Internet and use it as a demo for other members.\n\n### 2. Idea\n 1. Specific text optimization for specific texts, such as fake_or_real_news.csv. Because Bert learns each sentence and the relationship between the sentences, using regular expressions to process non-sentences in the article (such as #hashtag) is necessary.\n 2. By checking out the relevant information, I learned that EDA (Easiest Data Augmentation) can improve the classification in the case of small text, so I tried two methods of EDA, one is Random Insertion, the other is Synonym Replacement)\n 3. Use Google Bert as a method of text classification. Google Bert is a cutting-edge approach to do NLP tasks with excellent and efficient classification and I use the Bert model with the softmax layer to complete text classification.\n\n### 3. Something I want to share\nThe initial idea of our group was to use Google Bert to generate vectors for downstream text classification tasks. However, through code testing, the output includes word vectors and sentence vectors with high dimensions and huge time consumption. Therefore, extracting vectors separately from the Bert model is a bit hard. If the vector can be extracted, the output also includes the word vector and the sentence vector, which is difficult to handle. Thus, we used the method mentioned in the article- adding softmax layer to finish the text. Then, I begin my work to use a completed Bert pipeline to finish the job. \n\nAt the beginning, I spent a lot of time collecting various information about Bert. Because Bert is based on the existing NLP model, I started with the history of NLP and learned the principles of multiple models, from GloVe to LSTM and ELMo, and finally to Bert. I finally got a glimpse of how Bert works and wrote a blog to my URL: https://nave.work . \n\nIn fact, I used the original data to feed the model and got a 0.98 f1 score, so how to optimize on this basis becomes a problem. I observed a lot of content that was not a sentence by observing the text, including the URL and #hashtag, so I used regular expressions to remove specific content to improve the f1 score, and finally reached the score of 0.986.\n\nIn the final training process, due to the tight time and heavy tasks, I rented 1080ti to complete all the tasks. Of course, I am satisfied with the final result. This is based on the powerful per-training model of Google Bert. Anyway, I gained a lot of knowledge through this project and learned a lot of debugging skills, I love NLP!! (Finally attach my Contribution chart: \n![](https://i.loli.net/2019/08/23/1dpgIJrTla3Uq6w.png)\nand Github repo: https://github.com/NavePnow/Google-BERT-on-fake_or_real-news-dataset#5-part4-reference","source":"_posts/Fake-News-学习笔记（四）.md","raw":"---\ntitle: Fake News 学习笔记（四）Project-Summary NLP-Summary\ntags: [NLP, Python]\ncategories:\n  - FakeNews\ntoc: false\ndate: 2019-08-16 18:03:57\nthumbnail: https://images.unsplash.com/photo-1434030216411-0b793f4b4173?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n转载大佬的博客，写的太牛逼了: [从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史]\n<!--more-->\n## 牢骚\n为期6周的项目终于结束了，从昨天晚上连夜训练跑代码到今天的 Presentation，虽然还有点紧张，但更多的是对项目的无奈，一组4 个人，连带 Q&A 共 15min，平均下来每个人只有 2 分半的时间去展示自己做的东西。我实话说吧，就光 Bert，我都可以讲5min，一共 9 个组，难道就不能分来？？哪怕 3 个 3 个来也行，说起来我是真的烦，既然就是收钱那推荐信的项目了，掏了几万块钱就不能让这个钱花的值一点？其实我在小组分工方面是有点偏心的，我是想做文字处理的部分，而且最后选择了 Bert ，因为我想尝试一些不一样的东西，分类器之前大三下有上过课，虽然学的不是特别懂，但总算是有接触过，大学也不就是通识教育吗，我也没有希望我能有多么深入的学习，只希望我可以多学一点不会的东西，对于 NLP，我之前是一点都没有接触，当然原理性的东西就根本不可能知道，得知了项目是做关于自然语言处理的，我有蛮感兴趣，通过课上的学习，教授说了很多新兴的自然语言处理工具，其中就包括了 Bert，Bert 是 18 年底提出的知识，总感觉是我在大学学习的最新的知识了吧，相比于 11 年的 C++课本。。。不管了，知识是学给自己的，谁也偷不走，最后我还是总结一下我总的学到的知识吧。下面英文的部分是 “官方要求的项目总结”，就不再多说了，关于 Bert 的实现在另外一篇博客中有所展示，这里就不再一一赘述了。\n\n## 个人理解 从 Word2Vec 到 Bert\n从最开始的 Word2Vec，到 GloVe，一直到最新的 Bert，无非是将文字转化为一个可以让机器识别的数据格式-矩阵。在最开始的模型中，也就是 Word 和 Glove，存在一个初始的矩阵，里面包含了该方法所用的文字 token 以及对应的 value，只需要将文字输入到模型中，即可得到每个文字所对应的向量值，也就是矩阵值(相乘)，这样就涉及到了如何得到初始矩阵的问题，Word 和 Glove 使用的方法当然是不同的，在我们项目小组中，我们尝试了用 Glove 代替 Word，并取得了较好的效果，但实质还是没有变化，存在的问题也是显然的。我们都知道每个单词在句子中的意思是依附于上下文的，就比如所有博客中提到的 Bank 这个单词，有银行和河岸的意思，所以将所有的意思用一个矩阵去表示显得有失偏颇，所以基于两者提出了更多的模型。\n\n这就要提到 Elmo了（我学的不是很深，只是把大概的思想了解了一下）：根据上下文关系进行向量的生成，但是有别于前面两者，什么意思。Word 和 Glove 只是把初始矩阵给你，你并不可以改变其中的值，但是在 Elmo 中，应该是使用了迁移学习的思想，在初始矩阵的基础上根据训练集进行相关的更新，也就是矩阵值的更新，但是怎么生成初始矩阵我并没有怎么学习，Bert 倒是了解了一点，反正对于我来说，Elmo 的意义就是矩阵的动态更新，使得矩阵里面的值可以更贴切训练集中特定的文本。而且从训练效果看，具有很大的提高，说到这里，其实有点鄙视最开始的 Word 和 Glove 了，因为考虑的东西太少，这也是为什么我看到别人用 Word2Vec 可以达到0.9多正确率而直呼牛逼的原因。\n\n从 Elmo 到 Bert，又是一个飞跃，当然不能否认，Bert 是基于前人的工作而提出的新型的模型，因为很多思想和前者都有很多相似之处，可以说是站在巨人的肩膀上看世界。Bert 采用了更为高效的网络结构-Transformer来更新初始矩阵, 以及巨大的预训练模型用来生成初始矩阵。同样是考虑到了文章的上下文关系，在 Bert 中共有 3 个不同的变量作为模型的输入，每个单词的 Embedding，位置的 Embedding 和句子的 Embedding（可以理解为和初始矩阵的乘积？），这些都是依附于初始矩阵得到的结果，但是有文章说 Word 的 Embedding 不依附于初始矩阵，那我就不是很懂了，anyway，有三种不同的输入进行网络模型。\n在模型中只使用到了 Transformer 的 Encode 部分，具体的工作流程我就不懂了，反正经过了多层的 Encode，伴随着矩阵的更新（fune-tuning），最终可以得到很多个向量的结果，再加上 linear 和 softmax 层即可解决分类问题。有人会问了，那 Bert 是如何得到初始矩阵的。这就是 Bert 牛逼之处了，通过 mask 遮盖句子中的单词来训练单个单词，通过遮盖整个句子来训练整个句子，听过 Google 训练了整个 Wikipedia，真的牛逼。最终通过矩阵的更新得到了相应的结果。利用 Transformer 加上强大的与训练模型使得 Bert 脱颖而出，摘得了 NLP 的头牌，有人说 Bert 是 NLP 的顶峰，我看了几篇文章，一个是清华大学的，一个是斯坦福大学的，都是基于 Bert 的现有模型，要么是修改网络结构，要么是增加模型的输入以提高文章的 Contextual 属性，也得到了比初始模型更好的结果，可以说是炼丹成功的典范了。\n\n## 总结\n说到这里，项目也就结束了，从最开始的打开 FakeNewsTutorial 到写下这最后一篇博客，完成了项目所有的工作，还8.23 下午赶了 Github 的 repo 作为展示，修改中介关于项目的细节，以及项目的总结书，感谢组员的配合和合作，我感觉我们在最后的 Pre 发挥的很好，希望给教授留下不错的印象吧，希望大家都好好努力，前程似锦。\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t——王依凡 08/24/2019 华科东 11 栋\n\n\n\n## Project Summary\n### 1. Contribution\n 1. My job in our group is to use Google Bert to classify the text and complete a pipeline.\n 2. Use various word processing methods for specific text to improve the final f1 score (0.986)\n 3. I arrange member’s work within the group and meeting time. Three rehearsals were completed through communication with members before the final pre.\n 4. Use my own server to build a python environment for team members\n 5. Check out the relevant information and code about Glove on the Internet and use it as a demo for other members.\n\n### 2. Idea\n 1. Specific text optimization for specific texts, such as fake_or_real_news.csv. Because Bert learns each sentence and the relationship between the sentences, using regular expressions to process non-sentences in the article (such as #hashtag) is necessary.\n 2. By checking out the relevant information, I learned that EDA (Easiest Data Augmentation) can improve the classification in the case of small text, so I tried two methods of EDA, one is Random Insertion, the other is Synonym Replacement)\n 3. Use Google Bert as a method of text classification. Google Bert is a cutting-edge approach to do NLP tasks with excellent and efficient classification and I use the Bert model with the softmax layer to complete text classification.\n\n### 3. Something I want to share\nThe initial idea of our group was to use Google Bert to generate vectors for downstream text classification tasks. However, through code testing, the output includes word vectors and sentence vectors with high dimensions and huge time consumption. Therefore, extracting vectors separately from the Bert model is a bit hard. If the vector can be extracted, the output also includes the word vector and the sentence vector, which is difficult to handle. Thus, we used the method mentioned in the article- adding softmax layer to finish the text. Then, I begin my work to use a completed Bert pipeline to finish the job. \n\nAt the beginning, I spent a lot of time collecting various information about Bert. Because Bert is based on the existing NLP model, I started with the history of NLP and learned the principles of multiple models, from GloVe to LSTM and ELMo, and finally to Bert. I finally got a glimpse of how Bert works and wrote a blog to my URL: https://nave.work . \n\nIn fact, I used the original data to feed the model and got a 0.98 f1 score, so how to optimize on this basis becomes a problem. I observed a lot of content that was not a sentence by observing the text, including the URL and #hashtag, so I used regular expressions to remove specific content to improve the f1 score, and finally reached the score of 0.986.\n\nIn the final training process, due to the tight time and heavy tasks, I rented 1080ti to complete all the tasks. Of course, I am satisfied with the final result. This is based on the powerful per-training model of Google Bert. Anyway, I gained a lot of knowledge through this project and learned a lot of debugging skills, I love NLP!! (Finally attach my Contribution chart: \n![](https://i.loli.net/2019/08/23/1dpgIJrTla3Uq6w.png)\nand Github repo: https://github.com/NavePnow/Google-BERT-on-fake_or_real-news-dataset#5-part4-reference","slug":"Fake-News-学习笔记（四）","published":1,"updated":"2019-11-16T12:11:27.358Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkp8000nk3x6aiekfdg6","content":"<p>转载大佬的博客，写的太牛逼了: [从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史]</p>\n<a id=\"more\"></a>\n<h2 id=\"牢骚\"><a href=\"#牢骚\" class=\"headerlink\" title=\"牢骚\"></a>牢骚</h2><p>为期6周的项目终于结束了，从昨天晚上连夜训练跑代码到今天的 Presentation，虽然还有点紧张，但更多的是对项目的无奈，一组4 个人，连带 Q&amp;A 共 15min，平均下来每个人只有 2 分半的时间去展示自己做的东西。我实话说吧，就光 Bert，我都可以讲5min，一共 9 个组，难道就不能分来？？哪怕 3 个 3 个来也行，说起来我是真的烦，既然就是收钱那推荐信的项目了，掏了几万块钱就不能让这个钱花的值一点？其实我在小组分工方面是有点偏心的，我是想做文字处理的部分，而且最后选择了 Bert ，因为我想尝试一些不一样的东西，分类器之前大三下有上过课，虽然学的不是特别懂，但总算是有接触过，大学也不就是通识教育吗，我也没有希望我能有多么深入的学习，只希望我可以多学一点不会的东西，对于 NLP，我之前是一点都没有接触，当然原理性的东西就根本不可能知道，得知了项目是做关于自然语言处理的，我有蛮感兴趣，通过课上的学习，教授说了很多新兴的自然语言处理工具，其中就包括了 Bert，Bert 是 18 年底提出的知识，总感觉是我在大学学习的最新的知识了吧，相比于 11 年的 C++课本。。。不管了，知识是学给自己的，谁也偷不走，最后我还是总结一下我总的学到的知识吧。下面英文的部分是 “官方要求的项目总结”，就不再多说了，关于 Bert 的实现在另外一篇博客中有所展示，这里就不再一一赘述了。</p>\n<h2 id=\"个人理解-从-Word2Vec-到-Bert\"><a href=\"#个人理解-从-Word2Vec-到-Bert\" class=\"headerlink\" title=\"个人理解 从 Word2Vec 到 Bert\"></a>个人理解 从 Word2Vec 到 Bert</h2><p>从最开始的 Word2Vec，到 GloVe，一直到最新的 Bert，无非是将文字转化为一个可以让机器识别的数据格式-矩阵。在最开始的模型中，也就是 Word 和 Glove，存在一个初始的矩阵，里面包含了该方法所用的文字 token 以及对应的 value，只需要将文字输入到模型中，即可得到每个文字所对应的向量值，也就是矩阵值(相乘)，这样就涉及到了如何得到初始矩阵的问题，Word 和 Glove 使用的方法当然是不同的，在我们项目小组中，我们尝试了用 Glove 代替 Word，并取得了较好的效果，但实质还是没有变化，存在的问题也是显然的。我们都知道每个单词在句子中的意思是依附于上下文的，就比如所有博客中提到的 Bank 这个单词，有银行和河岸的意思，所以将所有的意思用一个矩阵去表示显得有失偏颇，所以基于两者提出了更多的模型。</p>\n<p>这就要提到 Elmo了（我学的不是很深，只是把大概的思想了解了一下）：根据上下文关系进行向量的生成，但是有别于前面两者，什么意思。Word 和 Glove 只是把初始矩阵给你，你并不可以改变其中的值，但是在 Elmo 中，应该是使用了迁移学习的思想，在初始矩阵的基础上根据训练集进行相关的更新，也就是矩阵值的更新，但是怎么生成初始矩阵我并没有怎么学习，Bert 倒是了解了一点，反正对于我来说，Elmo 的意义就是矩阵的动态更新，使得矩阵里面的值可以更贴切训练集中特定的文本。而且从训练效果看，具有很大的提高，说到这里，其实有点鄙视最开始的 Word 和 Glove 了，因为考虑的东西太少，这也是为什么我看到别人用 Word2Vec 可以达到0.9多正确率而直呼牛逼的原因。</p>\n<p>从 Elmo 到 Bert，又是一个飞跃，当然不能否认，Bert 是基于前人的工作而提出的新型的模型，因为很多思想和前者都有很多相似之处，可以说是站在巨人的肩膀上看世界。Bert 采用了更为高效的网络结构-Transformer来更新初始矩阵, 以及巨大的预训练模型用来生成初始矩阵。同样是考虑到了文章的上下文关系，在 Bert 中共有 3 个不同的变量作为模型的输入，每个单词的 Embedding，位置的 Embedding 和句子的 Embedding（可以理解为和初始矩阵的乘积？），这些都是依附于初始矩阵得到的结果，但是有文章说 Word 的 Embedding 不依附于初始矩阵，那我就不是很懂了，anyway，有三种不同的输入进行网络模型。<br>在模型中只使用到了 Transformer 的 Encode 部分，具体的工作流程我就不懂了，反正经过了多层的 Encode，伴随着矩阵的更新（fune-tuning），最终可以得到很多个向量的结果，再加上 linear 和 softmax 层即可解决分类问题。有人会问了，那 Bert 是如何得到初始矩阵的。这就是 Bert 牛逼之处了，通过 mask 遮盖句子中的单词来训练单个单词，通过遮盖整个句子来训练整个句子，听过 Google 训练了整个 Wikipedia，真的牛逼。最终通过矩阵的更新得到了相应的结果。利用 Transformer 加上强大的与训练模型使得 Bert 脱颖而出，摘得了 NLP 的头牌，有人说 Bert 是 NLP 的顶峰，我看了几篇文章，一个是清华大学的，一个是斯坦福大学的，都是基于 Bert 的现有模型，要么是修改网络结构，要么是增加模型的输入以提高文章的 Contextual 属性，也得到了比初始模型更好的结果，可以说是炼丹成功的典范了。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>说到这里，项目也就结束了，从最开始的打开 FakeNewsTutorial 到写下这最后一篇博客，完成了项目所有的工作，还8.23 下午赶了 Github 的 repo 作为展示，修改中介关于项目的细节，以及项目的总结书，感谢组员的配合和合作，我感觉我们在最后的 Pre 发挥的很好，希望给教授留下不错的印象吧，希望大家都好好努力，前程似锦。<br>                                                                ——王依凡 08/24/2019 华科东 11 栋</p>\n<h2 id=\"Project-Summary\"><a href=\"#Project-Summary\" class=\"headerlink\" title=\"Project Summary\"></a>Project Summary</h2><h3 id=\"1-Contribution\"><a href=\"#1-Contribution\" class=\"headerlink\" title=\"1. Contribution\"></a>1. Contribution</h3><ol>\n<li>My job in our group is to use Google Bert to classify the text and complete a pipeline.</li>\n<li>Use various word processing methods for specific text to improve the final f1 score (0.986)</li>\n<li>I arrange member’s work within the group and meeting time. Three rehearsals were completed through communication with members before the final pre.</li>\n<li>Use my own server to build a python environment for team members</li>\n<li>Check out the relevant information and code about Glove on the Internet and use it as a demo for other members.</li>\n</ol>\n<h3 id=\"2-Idea\"><a href=\"#2-Idea\" class=\"headerlink\" title=\"2. Idea\"></a>2. Idea</h3><ol>\n<li>Specific text optimization for specific texts, such as fake_or_real_news.csv. Because Bert learns each sentence and the relationship between the sentences, using regular expressions to process non-sentences in the article (such as #hashtag) is necessary.</li>\n<li>By checking out the relevant information, I learned that EDA (Easiest Data Augmentation) can improve the classification in the case of small text, so I tried two methods of EDA, one is Random Insertion, the other is Synonym Replacement)</li>\n<li>Use Google Bert as a method of text classification. Google Bert is a cutting-edge approach to do NLP tasks with excellent and efficient classification and I use the Bert model with the softmax layer to complete text classification.</li>\n</ol>\n<h3 id=\"3-Something-I-want-to-share\"><a href=\"#3-Something-I-want-to-share\" class=\"headerlink\" title=\"3. Something I want to share\"></a>3. Something I want to share</h3><p>The initial idea of our group was to use Google Bert to generate vectors for downstream text classification tasks. However, through code testing, the output includes word vectors and sentence vectors with high dimensions and huge time consumption. Therefore, extracting vectors separately from the Bert model is a bit hard. If the vector can be extracted, the output also includes the word vector and the sentence vector, which is difficult to handle. Thus, we used the method mentioned in the article- adding softmax layer to finish the text. Then, I begin my work to use a completed Bert pipeline to finish the job. </p>\n<p>At the beginning, I spent a lot of time collecting various information about Bert. Because Bert is based on the existing NLP model, I started with the history of NLP and learned the principles of multiple models, from GloVe to LSTM and ELMo, and finally to Bert. I finally got a glimpse of how Bert works and wrote a blog to my URL: <a href=\"https://nave.work\">https://nave.work</a> . </p>\n<p>In fact, I used the original data to feed the model and got a 0.98 f1 score, so how to optimize on this basis becomes a problem. I observed a lot of content that was not a sentence by observing the text, including the URL and #hashtag, so I used regular expressions to remove specific content to improve the f1 score, and finally reached the score of 0.986.</p>\n<p>In the final training process, due to the tight time and heavy tasks, I rented 1080ti to complete all the tasks. Of course, I am satisfied with the final result. This is based on the powerful per-training model of Google Bert. Anyway, I gained a lot of knowledge through this project and learned a lot of debugging skills, I love NLP!! (Finally attach my Contribution chart:<br><img src=\"https://i.loli.net/2019/08/23/1dpgIJrTla3Uq6w.png\" alt><br>and Github repo: <a href=\"https://github.com/NavePnow/Google-BERT-on-fake_or_real-news-dataset#5-part4-reference\" target=\"_blank\" rel=\"noopener\">https://github.com/NavePnow/Google-BERT-on-fake_or_real-news-dataset#5-part4-reference</a></p>\n","site":{"data":{}},"excerpt":"<p>转载大佬的博客，写的太牛逼了: [从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史]</p>","more":"<h2 id=\"牢骚\"><a href=\"#牢骚\" class=\"headerlink\" title=\"牢骚\"></a>牢骚</h2><p>为期6周的项目终于结束了，从昨天晚上连夜训练跑代码到今天的 Presentation，虽然还有点紧张，但更多的是对项目的无奈，一组4 个人，连带 Q&amp;A 共 15min，平均下来每个人只有 2 分半的时间去展示自己做的东西。我实话说吧，就光 Bert，我都可以讲5min，一共 9 个组，难道就不能分来？？哪怕 3 个 3 个来也行，说起来我是真的烦，既然就是收钱那推荐信的项目了，掏了几万块钱就不能让这个钱花的值一点？其实我在小组分工方面是有点偏心的，我是想做文字处理的部分，而且最后选择了 Bert ，因为我想尝试一些不一样的东西，分类器之前大三下有上过课，虽然学的不是特别懂，但总算是有接触过，大学也不就是通识教育吗，我也没有希望我能有多么深入的学习，只希望我可以多学一点不会的东西，对于 NLP，我之前是一点都没有接触，当然原理性的东西就根本不可能知道，得知了项目是做关于自然语言处理的，我有蛮感兴趣，通过课上的学习，教授说了很多新兴的自然语言处理工具，其中就包括了 Bert，Bert 是 18 年底提出的知识，总感觉是我在大学学习的最新的知识了吧，相比于 11 年的 C++课本。。。不管了，知识是学给自己的，谁也偷不走，最后我还是总结一下我总的学到的知识吧。下面英文的部分是 “官方要求的项目总结”，就不再多说了，关于 Bert 的实现在另外一篇博客中有所展示，这里就不再一一赘述了。</p>\n<h2 id=\"个人理解-从-Word2Vec-到-Bert\"><a href=\"#个人理解-从-Word2Vec-到-Bert\" class=\"headerlink\" title=\"个人理解 从 Word2Vec 到 Bert\"></a>个人理解 从 Word2Vec 到 Bert</h2><p>从最开始的 Word2Vec，到 GloVe，一直到最新的 Bert，无非是将文字转化为一个可以让机器识别的数据格式-矩阵。在最开始的模型中，也就是 Word 和 Glove，存在一个初始的矩阵，里面包含了该方法所用的文字 token 以及对应的 value，只需要将文字输入到模型中，即可得到每个文字所对应的向量值，也就是矩阵值(相乘)，这样就涉及到了如何得到初始矩阵的问题，Word 和 Glove 使用的方法当然是不同的，在我们项目小组中，我们尝试了用 Glove 代替 Word，并取得了较好的效果，但实质还是没有变化，存在的问题也是显然的。我们都知道每个单词在句子中的意思是依附于上下文的，就比如所有博客中提到的 Bank 这个单词，有银行和河岸的意思，所以将所有的意思用一个矩阵去表示显得有失偏颇，所以基于两者提出了更多的模型。</p>\n<p>这就要提到 Elmo了（我学的不是很深，只是把大概的思想了解了一下）：根据上下文关系进行向量的生成，但是有别于前面两者，什么意思。Word 和 Glove 只是把初始矩阵给你，你并不可以改变其中的值，但是在 Elmo 中，应该是使用了迁移学习的思想，在初始矩阵的基础上根据训练集进行相关的更新，也就是矩阵值的更新，但是怎么生成初始矩阵我并没有怎么学习，Bert 倒是了解了一点，反正对于我来说，Elmo 的意义就是矩阵的动态更新，使得矩阵里面的值可以更贴切训练集中特定的文本。而且从训练效果看，具有很大的提高，说到这里，其实有点鄙视最开始的 Word 和 Glove 了，因为考虑的东西太少，这也是为什么我看到别人用 Word2Vec 可以达到0.9多正确率而直呼牛逼的原因。</p>\n<p>从 Elmo 到 Bert，又是一个飞跃，当然不能否认，Bert 是基于前人的工作而提出的新型的模型，因为很多思想和前者都有很多相似之处，可以说是站在巨人的肩膀上看世界。Bert 采用了更为高效的网络结构-Transformer来更新初始矩阵, 以及巨大的预训练模型用来生成初始矩阵。同样是考虑到了文章的上下文关系，在 Bert 中共有 3 个不同的变量作为模型的输入，每个单词的 Embedding，位置的 Embedding 和句子的 Embedding（可以理解为和初始矩阵的乘积？），这些都是依附于初始矩阵得到的结果，但是有文章说 Word 的 Embedding 不依附于初始矩阵，那我就不是很懂了，anyway，有三种不同的输入进行网络模型。<br>在模型中只使用到了 Transformer 的 Encode 部分，具体的工作流程我就不懂了，反正经过了多层的 Encode，伴随着矩阵的更新（fune-tuning），最终可以得到很多个向量的结果，再加上 linear 和 softmax 层即可解决分类问题。有人会问了，那 Bert 是如何得到初始矩阵的。这就是 Bert 牛逼之处了，通过 mask 遮盖句子中的单词来训练单个单词，通过遮盖整个句子来训练整个句子，听过 Google 训练了整个 Wikipedia，真的牛逼。最终通过矩阵的更新得到了相应的结果。利用 Transformer 加上强大的与训练模型使得 Bert 脱颖而出，摘得了 NLP 的头牌，有人说 Bert 是 NLP 的顶峰，我看了几篇文章，一个是清华大学的，一个是斯坦福大学的，都是基于 Bert 的现有模型，要么是修改网络结构，要么是增加模型的输入以提高文章的 Contextual 属性，也得到了比初始模型更好的结果，可以说是炼丹成功的典范了。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>说到这里，项目也就结束了，从最开始的打开 FakeNewsTutorial 到写下这最后一篇博客，完成了项目所有的工作，还8.23 下午赶了 Github 的 repo 作为展示，修改中介关于项目的细节，以及项目的总结书，感谢组员的配合和合作，我感觉我们在最后的 Pre 发挥的很好，希望给教授留下不错的印象吧，希望大家都好好努力，前程似锦。<br>                                                                ——王依凡 08/24/2019 华科东 11 栋</p>\n<h2 id=\"Project-Summary\"><a href=\"#Project-Summary\" class=\"headerlink\" title=\"Project Summary\"></a>Project Summary</h2><h3 id=\"1-Contribution\"><a href=\"#1-Contribution\" class=\"headerlink\" title=\"1. Contribution\"></a>1. Contribution</h3><ol>\n<li>My job in our group is to use Google Bert to classify the text and complete a pipeline.</li>\n<li>Use various word processing methods for specific text to improve the final f1 score (0.986)</li>\n<li>I arrange member’s work within the group and meeting time. Three rehearsals were completed through communication with members before the final pre.</li>\n<li>Use my own server to build a python environment for team members</li>\n<li>Check out the relevant information and code about Glove on the Internet and use it as a demo for other members.</li>\n</ol>\n<h3 id=\"2-Idea\"><a href=\"#2-Idea\" class=\"headerlink\" title=\"2. Idea\"></a>2. Idea</h3><ol>\n<li>Specific text optimization for specific texts, such as fake_or_real_news.csv. Because Bert learns each sentence and the relationship between the sentences, using regular expressions to process non-sentences in the article (such as #hashtag) is necessary.</li>\n<li>By checking out the relevant information, I learned that EDA (Easiest Data Augmentation) can improve the classification in the case of small text, so I tried two methods of EDA, one is Random Insertion, the other is Synonym Replacement)</li>\n<li>Use Google Bert as a method of text classification. Google Bert is a cutting-edge approach to do NLP tasks with excellent and efficient classification and I use the Bert model with the softmax layer to complete text classification.</li>\n</ol>\n<h3 id=\"3-Something-I-want-to-share\"><a href=\"#3-Something-I-want-to-share\" class=\"headerlink\" title=\"3. Something I want to share\"></a>3. Something I want to share</h3><p>The initial idea of our group was to use Google Bert to generate vectors for downstream text classification tasks. However, through code testing, the output includes word vectors and sentence vectors with high dimensions and huge time consumption. Therefore, extracting vectors separately from the Bert model is a bit hard. If the vector can be extracted, the output also includes the word vector and the sentence vector, which is difficult to handle. Thus, we used the method mentioned in the article- adding softmax layer to finish the text. Then, I begin my work to use a completed Bert pipeline to finish the job. </p>\n<p>At the beginning, I spent a lot of time collecting various information about Bert. Because Bert is based on the existing NLP model, I started with the history of NLP and learned the principles of multiple models, from GloVe to LSTM and ELMo, and finally to Bert. I finally got a glimpse of how Bert works and wrote a blog to my URL: <a href=\"https://nave.work\">https://nave.work</a> . </p>\n<p>In fact, I used the original data to feed the model and got a 0.98 f1 score, so how to optimize on this basis becomes a problem. I observed a lot of content that was not a sentence by observing the text, including the URL and #hashtag, so I used regular expressions to remove specific content to improve the f1 score, and finally reached the score of 0.986.</p>\n<p>In the final training process, due to the tight time and heavy tasks, I rented 1080ti to complete all the tasks. Of course, I am satisfied with the final result. This is based on the powerful per-training model of Google Bert. Anyway, I gained a lot of knowledge through this project and learned a lot of debugging skills, I love NLP!! (Finally attach my Contribution chart:<br><img src=\"https://i.loli.net/2019/08/23/1dpgIJrTla3Uq6w.png\" alt=\"\"><br>and Github repo: <a href=\"https://github.com/NavePnow/Google-BERT-on-fake_or_real-news-dataset#5-part4-reference\" target=\"_blank\" rel=\"noopener\">https://github.com/NavePnow/Google-BERT-on-fake_or_real-news-dataset#5-part4-reference</a></p>"},{"title":"Fake News 学习笔记（二） one-hot-coding Stem-and-Lem Word2Vec","toc":false,"date":"2019-07-30T09:14:16.000Z","thumbnail":"https://images.unsplash.com/photo-1434030216411-0b793f4b4173?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n# One-hot coding(独热编码)\n<!--more-->\n果然又是 1个半小时只记住专有名字的课程。\n**target**:将非数值类型量化数值类型，以便于模型的输入\n**process**:N位状态寄存器来对N个状态进行编码就是将所有状态排列，具有哪些状态就将状态进行标记\n**instance**:\nface = ['handsome','ugly']\nstature = ['tall','middle','short']\ncountry = ['Chinese','American,'Japan','korea']\n共有 9 种状态，用 9 位数字表示。\n['handsome','tall','Japan'] 表示为 101000010\n['ugly','short','Japan'] 表示为 010010010\n\n# Bag of words\n不考虑单词在文章中的顺序，只考虑单词在文章中的词频率(occurence)\n\n# Stemming and Lemmatizing\n**cliche**:normalize different forms of the same word to a single root token before indexing\nstemming can often create non-existent words, whereas lemmas are actual words.\n\n## Stemming\n找词根(chops off the endings of different forms of words) \"derivational affixes\"\n**questions**:some decorations like ir or un, some of them will be deleted? eg:unchange to change (not implentation)\n## Lemmatizing\n根据词典找单词本身的形式 eg: saw to see\n\n# Word2Vec\n**cliche**:Word2Vec使用一层神经网络将one-hot（独热编码）形式的词向量映射到分布式形式的词向量。使用了Hierarchical softmax， negative sampling等技巧进行训练速度上的优化.\n在前文中介绍了 one-hot coding，但是由于英文单词词汇量巨大的特征，每一个单词都对应上文例子中的 feature，可想而知，会造成维度灾难和数据稀疏的问题（妈的，上课这个东西讲了近 40min），所以使用Word2Vec能够解决这些问题。\n\n## TD-IDF\n评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度，TF意思是词频(Term Frequency)，IDF意思是逆文本频率指数(Inverse Document Frequency)。\n## softmax\n把一些输入映射为0-1之间的实数，并且归一化保证和为1\n## CBOW(Continous Bag of Words)\n已知词w上下文context(w)前提下，预测当前词w\n## skip-gram\n已知当前词w，预测其上下文context(w)\n## distributed representation\n通过训练得到每个词k 维实数向量，通过词间距离来计算词间相似度。\n通过训练，将每一个词映射到一个固定长度的短向量中，把词的信息分布到各个分量中，并且语义相近的词向量见距离越近\n## 参数设置\nsize: Number of dimensions for the word embedding model\nwindow: Number of context words to observe in each direction\nmin_count: Minimum frequency for words included in model\nsg (Skip-Gram): '0' indicates CBOW model; '1' indicates Skip-Gram\nalpha: Learning rate (initial); prevents model from over-correcting, enables finer tuning\niterations: Number of passes through dataset\nbatch_words: Number of words to sample from data during each pass","source":"_posts/Fake News 学习笔记（二） one-hot-coding Stem-and-Lem Word2Vec.md","raw":"---\ntitle: Fake News 学习笔记（二） one-hot-coding Stem-and-Lem Word2Vec\ntags: [NLP, Python]\ncategories: [FakeNews]\ntoc: false\ndate: 2019-07-30 17:14:16\nthumbnail: https://images.unsplash.com/photo-1434030216411-0b793f4b4173?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n# One-hot coding(独热编码)\n<!--more-->\n果然又是 1个半小时只记住专有名字的课程。\n**target**:将非数值类型量化数值类型，以便于模型的输入\n**process**:N位状态寄存器来对N个状态进行编码就是将所有状态排列，具有哪些状态就将状态进行标记\n**instance**:\nface = ['handsome','ugly']\nstature = ['tall','middle','short']\ncountry = ['Chinese','American,'Japan','korea']\n共有 9 种状态，用 9 位数字表示。\n['handsome','tall','Japan'] 表示为 101000010\n['ugly','short','Japan'] 表示为 010010010\n\n# Bag of words\n不考虑单词在文章中的顺序，只考虑单词在文章中的词频率(occurence)\n\n# Stemming and Lemmatizing\n**cliche**:normalize different forms of the same word to a single root token before indexing\nstemming can often create non-existent words, whereas lemmas are actual words.\n\n## Stemming\n找词根(chops off the endings of different forms of words) \"derivational affixes\"\n**questions**:some decorations like ir or un, some of them will be deleted? eg:unchange to change (not implentation)\n## Lemmatizing\n根据词典找单词本身的形式 eg: saw to see\n\n# Word2Vec\n**cliche**:Word2Vec使用一层神经网络将one-hot（独热编码）形式的词向量映射到分布式形式的词向量。使用了Hierarchical softmax， negative sampling等技巧进行训练速度上的优化.\n在前文中介绍了 one-hot coding，但是由于英文单词词汇量巨大的特征，每一个单词都对应上文例子中的 feature，可想而知，会造成维度灾难和数据稀疏的问题（妈的，上课这个东西讲了近 40min），所以使用Word2Vec能够解决这些问题。\n\n## TD-IDF\n评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度，TF意思是词频(Term Frequency)，IDF意思是逆文本频率指数(Inverse Document Frequency)。\n## softmax\n把一些输入映射为0-1之间的实数，并且归一化保证和为1\n## CBOW(Continous Bag of Words)\n已知词w上下文context(w)前提下，预测当前词w\n## skip-gram\n已知当前词w，预测其上下文context(w)\n## distributed representation\n通过训练得到每个词k 维实数向量，通过词间距离来计算词间相似度。\n通过训练，将每一个词映射到一个固定长度的短向量中，把词的信息分布到各个分量中，并且语义相近的词向量见距离越近\n## 参数设置\nsize: Number of dimensions for the word embedding model\nwindow: Number of context words to observe in each direction\nmin_count: Minimum frequency for words included in model\nsg (Skip-Gram): '0' indicates CBOW model; '1' indicates Skip-Gram\nalpha: Learning rate (initial); prevents model from over-correcting, enables finer tuning\niterations: Number of passes through dataset\nbatch_words: Number of words to sample from data during each pass","slug":"Fake News 学习笔记（二） one-hot-coding Stem-and-Lem Word2Vec","published":1,"updated":"2019-11-16T12:11:12.339Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkpe000rk3x6c8wjhr0y","content":"<h1 id=\"One-hot-coding-独热编码\"><a href=\"#One-hot-coding-独热编码\" class=\"headerlink\" title=\"One-hot coding(独热编码)\"></a>One-hot coding(独热编码)</h1><a id=\"more\"></a>\n<p>果然又是 1个半小时只记住专有名字的课程。<br><strong>target</strong>:将非数值类型量化数值类型，以便于模型的输入<br><strong>process</strong>:N位状态寄存器来对N个状态进行编码就是将所有状态排列，具有哪些状态就将状态进行标记<br><strong>instance</strong>:<br>face = [‘handsome’,’ugly’]<br>stature = [‘tall’,’middle’,’short’]<br>country = [‘Chinese’,’American,’Japan’,’korea’]<br>共有 9 种状态，用 9 位数字表示。<br>[‘handsome’,’tall’,’Japan’] 表示为 101000010<br>[‘ugly’,’short’,’Japan’] 表示为 010010010</p>\n<h1 id=\"Bag-of-words\"><a href=\"#Bag-of-words\" class=\"headerlink\" title=\"Bag of words\"></a>Bag of words</h1><p>不考虑单词在文章中的顺序，只考虑单词在文章中的词频率(occurence)</p>\n<h1 id=\"Stemming-and-Lemmatizing\"><a href=\"#Stemming-and-Lemmatizing\" class=\"headerlink\" title=\"Stemming and Lemmatizing\"></a>Stemming and Lemmatizing</h1><p><strong>cliche</strong>:normalize different forms of the same word to a single root token before indexing<br>stemming can often create non-existent words, whereas lemmas are actual words.</p>\n<h2 id=\"Stemming\"><a href=\"#Stemming\" class=\"headerlink\" title=\"Stemming\"></a>Stemming</h2><p>找词根(chops off the endings of different forms of words) “derivational affixes”<br><strong>questions</strong>:some decorations like ir or un, some of them will be deleted? eg:unchange to change (not implentation)</p>\n<h2 id=\"Lemmatizing\"><a href=\"#Lemmatizing\" class=\"headerlink\" title=\"Lemmatizing\"></a>Lemmatizing</h2><p>根据词典找单词本身的形式 eg: saw to see</p>\n<h1 id=\"Word2Vec\"><a href=\"#Word2Vec\" class=\"headerlink\" title=\"Word2Vec\"></a>Word2Vec</h1><p><strong>cliche</strong>:Word2Vec使用一层神经网络将one-hot（独热编码）形式的词向量映射到分布式形式的词向量。使用了Hierarchical softmax， negative sampling等技巧进行训练速度上的优化.<br>在前文中介绍了 one-hot coding，但是由于英文单词词汇量巨大的特征，每一个单词都对应上文例子中的 feature，可想而知，会造成维度灾难和数据稀疏的问题（妈的，上课这个东西讲了近 40min），所以使用Word2Vec能够解决这些问题。</p>\n<h2 id=\"TD-IDF\"><a href=\"#TD-IDF\" class=\"headerlink\" title=\"TD-IDF\"></a>TD-IDF</h2><p>评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度，TF意思是词频(Term Frequency)，IDF意思是逆文本频率指数(Inverse Document Frequency)。</p>\n<h2 id=\"softmax\"><a href=\"#softmax\" class=\"headerlink\" title=\"softmax\"></a>softmax</h2><p>把一些输入映射为0-1之间的实数，并且归一化保证和为1</p>\n<h2 id=\"CBOW-Continous-Bag-of-Words\"><a href=\"#CBOW-Continous-Bag-of-Words\" class=\"headerlink\" title=\"CBOW(Continous Bag of Words)\"></a>CBOW(Continous Bag of Words)</h2><p>已知词w上下文context(w)前提下，预测当前词w</p>\n<h2 id=\"skip-gram\"><a href=\"#skip-gram\" class=\"headerlink\" title=\"skip-gram\"></a>skip-gram</h2><p>已知当前词w，预测其上下文context(w)</p>\n<h2 id=\"distributed-representation\"><a href=\"#distributed-representation\" class=\"headerlink\" title=\"distributed representation\"></a>distributed representation</h2><p>通过训练得到每个词k 维实数向量，通过词间距离来计算词间相似度。<br>通过训练，将每一个词映射到一个固定长度的短向量中，把词的信息分布到各个分量中，并且语义相近的词向量见距离越近</p>\n<h2 id=\"参数设置\"><a href=\"#参数设置\" class=\"headerlink\" title=\"参数设置\"></a>参数设置</h2><p>size: Number of dimensions for the word embedding model<br>window: Number of context words to observe in each direction<br>min_count: Minimum frequency for words included in model<br>sg (Skip-Gram): ‘0’ indicates CBOW model; ‘1’ indicates Skip-Gram<br>alpha: Learning rate (initial); prevents model from over-correcting, enables finer tuning<br>iterations: Number of passes through dataset<br>batch_words: Number of words to sample from data during each pass</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"One-hot-coding-独热编码\"><a href=\"#One-hot-coding-独热编码\" class=\"headerlink\" title=\"One-hot coding(独热编码)\"></a>One-hot coding(独热编码)</h1>","more":"<p>果然又是 1个半小时只记住专有名字的课程。<br><strong>target</strong>:将非数值类型量化数值类型，以便于模型的输入<br><strong>process</strong>:N位状态寄存器来对N个状态进行编码就是将所有状态排列，具有哪些状态就将状态进行标记<br><strong>instance</strong>:<br>face = [‘handsome’,’ugly’]<br>stature = [‘tall’,’middle’,’short’]<br>country = [‘Chinese’,’American,’Japan’,’korea’]<br>共有 9 种状态，用 9 位数字表示。<br>[‘handsome’,’tall’,’Japan’] 表示为 101000010<br>[‘ugly’,’short’,’Japan’] 表示为 010010010</p>\n<h1 id=\"Bag-of-words\"><a href=\"#Bag-of-words\" class=\"headerlink\" title=\"Bag of words\"></a>Bag of words</h1><p>不考虑单词在文章中的顺序，只考虑单词在文章中的词频率(occurence)</p>\n<h1 id=\"Stemming-and-Lemmatizing\"><a href=\"#Stemming-and-Lemmatizing\" class=\"headerlink\" title=\"Stemming and Lemmatizing\"></a>Stemming and Lemmatizing</h1><p><strong>cliche</strong>:normalize different forms of the same word to a single root token before indexing<br>stemming can often create non-existent words, whereas lemmas are actual words.</p>\n<h2 id=\"Stemming\"><a href=\"#Stemming\" class=\"headerlink\" title=\"Stemming\"></a>Stemming</h2><p>找词根(chops off the endings of different forms of words) “derivational affixes”<br><strong>questions</strong>:some decorations like ir or un, some of them will be deleted? eg:unchange to change (not implentation)</p>\n<h2 id=\"Lemmatizing\"><a href=\"#Lemmatizing\" class=\"headerlink\" title=\"Lemmatizing\"></a>Lemmatizing</h2><p>根据词典找单词本身的形式 eg: saw to see</p>\n<h1 id=\"Word2Vec\"><a href=\"#Word2Vec\" class=\"headerlink\" title=\"Word2Vec\"></a>Word2Vec</h1><p><strong>cliche</strong>:Word2Vec使用一层神经网络将one-hot（独热编码）形式的词向量映射到分布式形式的词向量。使用了Hierarchical softmax， negative sampling等技巧进行训练速度上的优化.<br>在前文中介绍了 one-hot coding，但是由于英文单词词汇量巨大的特征，每一个单词都对应上文例子中的 feature，可想而知，会造成维度灾难和数据稀疏的问题（妈的，上课这个东西讲了近 40min），所以使用Word2Vec能够解决这些问题。</p>\n<h2 id=\"TD-IDF\"><a href=\"#TD-IDF\" class=\"headerlink\" title=\"TD-IDF\"></a>TD-IDF</h2><p>评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度，TF意思是词频(Term Frequency)，IDF意思是逆文本频率指数(Inverse Document Frequency)。</p>\n<h2 id=\"softmax\"><a href=\"#softmax\" class=\"headerlink\" title=\"softmax\"></a>softmax</h2><p>把一些输入映射为0-1之间的实数，并且归一化保证和为1</p>\n<h2 id=\"CBOW-Continous-Bag-of-Words\"><a href=\"#CBOW-Continous-Bag-of-Words\" class=\"headerlink\" title=\"CBOW(Continous Bag of Words)\"></a>CBOW(Continous Bag of Words)</h2><p>已知词w上下文context(w)前提下，预测当前词w</p>\n<h2 id=\"skip-gram\"><a href=\"#skip-gram\" class=\"headerlink\" title=\"skip-gram\"></a>skip-gram</h2><p>已知当前词w，预测其上下文context(w)</p>\n<h2 id=\"distributed-representation\"><a href=\"#distributed-representation\" class=\"headerlink\" title=\"distributed representation\"></a>distributed representation</h2><p>通过训练得到每个词k 维实数向量，通过词间距离来计算词间相似度。<br>通过训练，将每一个词映射到一个固定长度的短向量中，把词的信息分布到各个分量中，并且语义相近的词向量见距离越近</p>\n<h2 id=\"参数设置\"><a href=\"#参数设置\" class=\"headerlink\" title=\"参数设置\"></a>参数设置</h2><p>size: Number of dimensions for the word embedding model<br>window: Number of context words to observe in each direction<br>min_count: Minimum frequency for words included in model<br>sg (Skip-Gram): ‘0’ indicates CBOW model; ‘1’ indicates Skip-Gram<br>alpha: Learning rate (initial); prevents model from over-correcting, enables finer tuning<br>iterations: Number of passes through dataset<br>batch_words: Number of words to sample from data during each pass</p>"},{"title":"Google-BERT-on-fake_or_real-news-dataset","toc":false,"date":"2019-08-23T03:59:01.000Z","thumbnail":"https://images.unsplash.com/photo-1542827866-3e48c943da0f?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n**Description**: Use Google BERT on fake_or_real news dataset with best f1 score: 0.986\n<!--more-->\n## Showcase\n### 1. Pipeline\n![Pipeline](https://i.loli.net/2019/08/23/P8Seo5EvmpZfAOT.png)\n\nFirst, we got the raw text with title, text and label. Then we use some methods of data processing to operate the text. After the data processing, we put them into the Bert model to train the data, which includes the Bert itself and the Classifier, here I used the feed-forward neural network and add a softmax layer to normalize the output. In the end, we got the predication and other details.\n\n### 2. Part1: Data processing\n(1) **Drop non-sentence**\n \n    • Type1: http[s]://www.claritypress.com/LendmanIII.html\n    • Type2: [email protected]\n    • Type3: @EP_President #EP_President \n    • Type4: **Want FOX News First * in your inbox every day? Sign up here.**\n    • Type5: ☮️ 💚 🌍 etc\n\n(2) **EDA methods**\n\n\t• Insert word by BERT similarity (Random Insertion)\n\t• Substitute word by BERT similarity (Synonym Replacement)\n\nAS for the first part, I use two methods: drop non-sentence and some EDA methods. I read some text within the fake_or_real news and I find that it contains various type of non-sentence, so I use the regular expression to drop them. And then, I use random insertion and synonym replacement to augment the text.\n\n### 3. Part2: Bert Model\n![Bert model](https://i.loli.net/2019/08/23/pFv1K86WUcafyDI.png)\n\nAs for the second part, we put the text which we got from the first part into the bert model. The Bert model uses 12 encode layers and finally classifier to get the output.\n\n### 4. Part3: Result\n![Result](https://i.loli.net/2019/08/23/aGTYdfz2cul1pj3.png)\n\nIn the end, we combine different methods of data processing and u can see the f1 score from the chart. We get the best f1 score(0.986) from Cased text + drop sentence.\n\n### 5. Part4: Reference\n(1) **EDA**: \n\n\t•Knowledge: https://towardsdatascience.com/these-are-the-easiest-data-augmentation-techniques-in-natural-language-processing-you-can-think-of-88e393fd610\n\t•Implemenation: https://github.com/makcedward/nlpaug\n(2) **Can’t remove stopwords**: \n\n\t•Deeper Text Understanding for IR with Contextual NeuralLanguage Modeling: https://arxiv.org/pdf/1905.09217\n\t•Understanding the Behaviors of BERT in Ranking : https://arxiv.org/pdf/1904.07531\n(3) **Bert by Pytorch**:\n\n\t•https://pytorch.org/hub/huggingface_pytorch-pretrained-bert_bert/\n(4) **Bert Demo**:\n\n\thttps://github.com/sugi-chan/custom_bert_pipeline\n(5) **Dataset**:\n\n    https://cbmm.mit.edu/sites/default/files/publications/fake-news-paper-NIPS.pdf\n    \nI learn the EDA from the two web site and through two articles, I learn that we shouldn’t remove Stopwords which otherwise will destroy the context of sentence. The end is implementation of BERT with Pytorch and the Bert model I learned.\n\n## Implementation\n### 1. Preparation\n#### 1.1 Set parameters and install and load required package\n```Python\n### parameters Setting\npar_cased = 0 # default cased, 0 means uncased\npar_cleanup = 1 # default cleanup, 0 means non-cleanup\npar_eda = 0 # default eda, 0 means non-eda\n\npip install pytorch_pretrained_bert nlpaug bert matplotlib sklearn librosa SoundFile nltk pandas\n\nfrom __future__ import print_function, division\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom random import randrange\nimport torch.nn.functional as F\nfrom sklearn.metrics import roc_curve, auc\nimport nlpaug.augmenter.char as nac\n#import nlpaug.augmenter.word as naw\nimport nlpaug.flow as naf\nfrom nlpaug.util import Action\n```\n#### 1.2 Set tokenizer\n```Python\nimport torch\nfrom pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n\n# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\nimport logging\nlogging.basicConfig(level=logging.INFO)\n\n# Load pre-trained model tokenizer (vocabulary)\nif par_cased ==1:\n    tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\nelse:\n    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n```\n#### 1.3 Define Bert Config\n```Python\nclass BertLayerNorm(nn.Module):\n        def __init__(self, hidden_size, eps=1e-12):\n            \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n            \"\"\"\n            super(BertLayerNorm, self).__init__()\n            self.weight = nn.Parameter(torch.ones(hidden_size))\n            self.bias = nn.Parameter(torch.zeros(hidden_size))\n            self.variance_epsilon = eps\n\n        def forward(self, x):\n            u = x.mean(-1, keepdim=True)\n            s = (x - u).pow(2).mean(-1, keepdim=True)\n            x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n            return self.weight * x + self.bias\n        \n\nclass BertForSequenceClassification(nn.Module):\n    \"\"\"BERT model for classification.\n    This module is composed of the BERT model with a linear layer on top of\n    the pooled output.\n    Params:\n        `config`: a BertConfig class instance with the configuration to build a new model.\n        `num_labels`: the number of classes for the classifier. Default = 2.\n    Inputs:\n        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n            with the word token indices in the vocabulary. Items in the batch should begin with the special \"CLS\" token. (see the tokens preprocessing logic in the scripts\n            `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n            a `sentence B` token (see BERT paper for more details).\n        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n            input sequence length in the current batch. It's the mask that we typically use for attention when\n            a batch has varying length sentences.\n        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]\n            with indices selected in [0, ..., num_labels].\n    Outputs:\n        if `labels` is not `None`:\n            Outputs the CrossEntropy classification loss of the output with the labels.\n        if `labels` is `None`:\n            Outputs the classification logits of shape [batch_size, num_labels].\n    Example usage:\n    ```python\n    # Already been converted into WordPiece token ids\n    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n    config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n    num_labels = 2\n    model = BertForSequenceClassification(config, num_labels)\n    logits = model(input_ids, token_type_ids, input_mask)\n\n    def __init__(self, num_labels=2):\n        super(BertForSequenceClassification, self).__init__()\n        self.num_labels = num_labels\n        if par_cased ==1:\n            self.bert = BertModel.from_pretrained('bert-base-cased')\n        else:\n            self.bert = BertModel.from_pretrained('bert-base-uncased')\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.classifier = nn.Linear(config.hidden_size, num_labels)\n        nn.init.xavier_normal_(self.classifier.weight)\n    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n        pooled_output = self.dropout(pooled_output)\n        logits = self.classifier(pooled_output)\n\n        return logits\n    def freeze_bert_encoder(self):\n        for param in self.bert.parameters():\n            param.requires_grad = False\n    \n    def unfreeze_bert_encoder(self):\n        for param in self.bert.parameters():\n            param.requires_grad = True\n\nfrom pytorch_pretrained_bert import BertConfig\n\nconfig = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n\nnum_labels = 2\nmodel = BertForSequenceClassification(num_labels)\n\n# Convert inputs to PyTorch tensors\n#tokens_tensor = torch.tensor([tokenizer.convert_tokens_to_ids(zz)])\n\n#logits = model(tokens_tensor)\n```\n\n### 2. Dataset Processing\n#### 2.1 Read the data and convert label into binary text\n```Python\nimport pandas as pd\n\ndat = pd.read_csv('/data/fake_or_real_news.csv')\ndat.head()\ndat = dat.drop(columns=['Unnamed: 0', 'title_vectors'])\nfor i in range(len(dat)):\n    if dat.loc[i, 'label'] == \"REAL\": #REAL equal 0\n        dat.loc[i, 'label'] = 0\n    elif dat.loc[i, 'label'] == \"FAKE\": #FAKE equal 1\n        dat.loc[i, 'label'] = 1\n    if dat.loc[i, 'text'] == \"\":\n        dat = dat.drop([i])\ndat.head()\n```\n#### 2.2 Combine the title and text\n```Python\ndat_plus = dat.copy()\ndat_plus['title_text']=dat['title']+'. '+dat['text']\ndat_plus = dat_plus.drop(columns=['title', 'text'])\n\ndat_plus['title_text']\n```\n#### 2.3 Use regular expression to drop non-sentence\n```Python\nimport re\ndef cleanup(text):\n    if par_cased == 0: # transfer into lower text if par_cased is false\n        text = text.lower()\n    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','',text) # drop http[s]://*\n    text = re.sub(u\"\\\\{.*?}|\\\\[.*?]\",'',text) # drop [*]\n    text = re.sub(u\"\\(\\@.*?\\s\", '', text) # drop something like (@EP_President)\n    text = re.sub(u\"\\@.*?\\s\", '', text) # drop soething liek @EP_President\n    text = re.sub(u\"\\#.*?\\s\", '', text) # drop something like #EP_President (maybe hashtag)\n    text = re.sub(u\"\\© .*?\\s\", '', text) # drop something like © EP_President\n    text = re.sub(r'pic.tw(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','',text) # drop pic.twitter.com/*\n    text = re.sub(u\"\\*\\*\", '', text) # drop something like **Want FOX News First * in your inbox every day? Sign up here.**\n    text = re.sub(u\"|•|☮️|💚|🌍|😍|♦|☢\", '', text) # drop something like  and • etc\n    return(text)\n```\n#### 2.4 Use EDA method to augment the text\n```Python\nimport nlpaug.augmenter.char as nac\nimport nlpaug.augmenter.word as naw\nimport nlpaug.flow as nafc\n\nfrom nlpaug.util import Action\nimport nltk\nnltk.download('punkt')\n\nif par_cased ==1:\n    aug = naf.Sequential([\n        naw.BertAug(action=\"substitute\", aug_p=0.8, aug_n=20,model_path='bert-base-cased',tokenizer_path='bert-base-cased'),\n        naw.BertAug(action=\"insert\", aug_p=0.1)\n    ])\nelse:\n    aug = naf.Sequential([\n        naw.BertAug(action=\"substitute\", aug_p=0.8, aug_n=20,model_path='bert-base-uncased',tokenizer_path='bert-base-uncased'),\n        naw.BertAug(action=\"insert\", aug_p=0.1)\n    ])\ndef aug_text(text):\n    text = aug.augment(text)\n    return(text)\nfrom nltk.tokenize import sent_tokenize\ndef sentence_token_nltk(text):\n    sent_tokenize_list = sent_tokenize(text)\n    return sent_tokenize_list\ndef eda_text(text):\n    if len(text) < 2:\n        return(text)\n    # split text into sentences\n    text = sentence_token_nltk(text)\n    if len(text) <= 1:\n        return(text)\n    if len(text) == 2:\n        for i in range(len(text)):\n            if i == 0:\n                tmp_text = text[i]\n            else:\n                tmp_text += text[i]\n        return(tmp_text)\n    # operate prior 3 sentences\n    for i in range(3):\n        if i == 0:\n            tmp_text = text[i]\n        else:\n            tmp_text += text[i]\n    zz = tokenizer.tokenize(tmp_text)\n    # operate proper sentences\n    if len(zz) <= 500:\n    #print(len(zz))\n        tmp_text = aug_text(tmp_text)\n    # conbine prior 3 sentences and rest sentences\n    for j in range(len(text)-3):\n        tmp_text += text[j+3]\n    return(tmp_text)\n\nif par_eda == 1: # use eda to operate sentences when par_eda is true\n  for i in range(len(dat_plus['title_text'])):\n      if i%6 == 1:       \n          #print(i)\n          dat_plus['title_text'][i] = copy.deepcopy(eda_text(dat_plus['title_text'][i]))\n          dat_plus['title_text'][i] = \"\".join(dat_plus['title_text'][i])\n```\n### 3. Google Bert\n```Python\nimport torch.nn.functional as F\n\n#F.softmax(logits,dim=1)\n\nfrom sklearn.model_selection import train_test_split\nif par_cleanup == 1:\n    X = dat_plus['title_text'].apply(cleanup)\nelse:\n    X = dat_plus['title_text']\ny = dat_plus['label']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nX_train = X_train.values.tolist()\nX_test = X_test.values.tolist()\n\ny_train = pd.get_dummies(y_train).values.tolist() # convert to one-hot encoding\ny_test = pd.get_dummies(y_test).values.tolist()\n\nmax_seq_length = 256\nclass text_dataset(Dataset):\n    def __init__(self,x_y_list, transform=None):\n        \n        self.x_y_list = x_y_list\n        self.transform = transform\n        \n    def __getitem__(self,index):\n        \n        tokenized_title_text = tokenizer.tokenize(self.x_y_list[0][index])\n        \n        if len(tokenized_title_text) > max_seq_length:\n            tokenized_title_text = tokenized_title_text[:max_seq_length]\n            \n        ids_title_text  = tokenizer.convert_tokens_to_ids(tokenized_title_text) #tokens->input_ids\n\n        padding = [0] * (max_seq_length - len(ids_title_text))\n        \n        ids_title_text += padding # use padding to make the same ids\n        \n        assert len(ids_title_text) == max_seq_length\n        \n        #print(ids_title_text)\n        ids_title_text = torch.tensor(ids_title_text)\n        \n        label = self.x_y_list[1][index] # color        \n        list_of_labels = [torch.from_numpy(np.array(label))]\n        \n        \n        return ids_title_text, list_of_labels[0]\n    \n    def __len__(self):\n        return len(self.x_y_list[0])\n```\n#### 3.1 Create data dictionary\n```Python\nbatch_size = 16 # divide into 16 batches\n\ntrain_lists = [X_train, y_train]\ntest_lists = [X_test, y_test]\n\ntraining_dataset = text_dataset(x_y_list = train_lists )\n\ntest_dataset = text_dataset(x_y_list = test_lists )\n\ndataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True, num_workers=0),\n                   'val':torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n                  }                \ndataset_sizes = {'train':len(train_lists[0]),\n                'val':len(test_lists[0])}\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n```\n\n#### 3.2 Define the train model\n\n```Python\n def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n    print('starting')\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_loss = 100\n    best_f1 = 0.978\n    best_acc_test = 0.96\n    best_acc_train = 0.96\n    best_auc = 0.96\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            \n            label_corrects = 0\n            TP = 0\n            TN = 0\n            FN = 0\n            FP = 0\n            total_scores = []\n            total_tar = []\n            # Iterate over data.\n            for inputs, label in dataloaders_dict[phase]:\n                #inputs = inputs\n                #print(len(inputs),type(inputs),inputs)\n                #inputs = torch.from_numpy(np.array(inputs)).to(device) \n                inputs = inputs.to(device) \n                label = label.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    # acquire output\n                    outputs = model(inputs)\n\n                    outputs = F.softmax(outputs,dim=1)\n                    \n                    loss = criterion(outputs, torch.max(label.float(), 1)[1])\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        \n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                label_corrects += torch.sum(torch.max(outputs, 1)[1] == torch.max(label, 1)[1]) #返回每一行中最大值的那个元素，且返回其索引（返回最大元素在这一行的列索引）\n                pred_choice = torch.max(outputs, 1)[1]\n                target = torch.max(label, 1)[1]\n                scores = pred_choice.cpu().tolist()\n                tar = target.cpu().tolist()\n                total_scores = total_scores + scores\n                total_tar = total_tar + tar\n\n                tmp_tp = 0\n                tmp_tn = 0\n                tmp_fn = 0\n                tmp_fp = 0\n                if pred_choice.numel()!= target.numel():\n                    print(\"error\")\n                for i in range(pred_choice.numel()):\n                    if pred_choice[i] == 1 and target[i] == 1 :\n                        tmp_tp = tmp_tp + 1\n                    elif pred_choice[i] == 0 and target[i] == 0 :\n                        tmp_tn = tmp_tn + 1\n                    elif pred_choice[i] == 0 and target[i] == 1 :\n                        tmp_fn = tmp_fn + 1\n                    elif pred_choice[i] == 1 and target[i] == 0 :\n                        tmp_fp = tmp_fp + 1\n                # TP    both predict and label are 1\n                TP += tmp_tp\n                # TN    both predict and label are 0\n                TN += tmp_tn\n                # FN    predict 0 label 1\n                FN += tmp_fn\n                # FP    predict 1 label 0\n                FP += tmp_fp\n            epoch_loss = running_loss / dataset_sizes[phase]\n            p = TP / (TP + FP)\n            r = TP / (TP + FN)\n            F1 = 2 * r * p / (r + p)\n            acc = (TP + TN) / (TP + TN + FP + FN)\n\n            ### draw ROC curce\n            tpr = TP/(TP+FN)\n            fpr = FP/(FP+TN)\n            tnr = TN/(FP+TN)\n\n            total_scores = np.array(total_scores)\n            total_tar = np.array(total_tar)\n            fpr, tpr, thresholds = roc_curve(total_tar, total_scores)\n            roc_auc = auc(fpr, tpr) \n            plt.title('ROC')\n            if roc_auc > best_auc:\n                best_auc = roc_auc\n            if epoch < num_epochs -1:\n                plt.plot(fpr, tpr,'b',label='AUC = %0.4f'% roc_auc)\n            if epoch == num_epochs -1:\n                plt.plot(fpr, tpr, color='darkorange', label='MAX AUC = %0.4f'% best_auc) \n            plt.legend(loc='lower right')\n            plt.plot([0,1],[0,1],'r--')\n            plt.ylabel('TPR')\n            plt.xlabel('FPR')\n            plt.show()\n\n            #print('{} p: {:.4f} '.format(phase,p ))\n            #print('{} r: {:.4f} '.format(phase,r ))\n            print('{} F1: {:.4f} '.format(phase,F1 ))\n            print('{} accuracy: {:.4f} '.format(phase,acc ))\n\n            if phase == 'val' and epoch_loss < best_loss:\n                print('saving with loss of {}'.format(epoch_loss),\n                      'improved over previous {}'.format(best_loss))\n                best_loss = epoch_loss\n                best_model_wts = copy.deepcopy(model.state_dict())\n                #torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/bert_model_test_loss.pth')\n            if F1 > best_f1:\n                best_f1 = F1\n            if phase == 'val' and acc > best_acc_test:\n                best_acc_test = acc\n            if phase == 'train' and acc > best_acc_train:\n                best_acc_train = acc\n                #best_model_wts = copy.deepcopy(model.state_dict())\n                #torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/bert_model_test_f1.pth')\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print(\"Parament setting: \")\n    print(\"cased: \",par_cased)\n    print(\"cleanup: \",par_cleanup)\n    print(\"eda: \",par_eda)\n    print('Best train Acc: {:4f}'.format(float(best_acc_train)))\n    print('Best test Acc: {:4f}'.format(float(best_acc_test)))\n    print('Best f1 score: {:4f}'.format(float(best_f1)))\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model\n```\n### 4. Final output\n#### 4.1 Model details\n```Python\nprint(model)\nmodel.to(device)\n```\n#### 4.2 F1 and other details\n```Python\nmodel_ft1 = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=10)\n```","source":"_posts/Google-BERT-on-fake-or-real-news-dataset.md","raw":"---\ntitle: Google-BERT-on-fake_or_real-news-dataset\ntags: [NLP, Python]\ncategories:\n  - FakeNews\ntoc: false\ndate: 2019-08-23 11:59:01\nthumbnail: https://images.unsplash.com/photo-1542827866-3e48c943da0f?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n**Description**: Use Google BERT on fake_or_real news dataset with best f1 score: 0.986\n<!--more-->\n## Showcase\n### 1. Pipeline\n![Pipeline](https://i.loli.net/2019/08/23/P8Seo5EvmpZfAOT.png)\n\nFirst, we got the raw text with title, text and label. Then we use some methods of data processing to operate the text. After the data processing, we put them into the Bert model to train the data, which includes the Bert itself and the Classifier, here I used the feed-forward neural network and add a softmax layer to normalize the output. In the end, we got the predication and other details.\n\n### 2. Part1: Data processing\n(1) **Drop non-sentence**\n \n    • Type1: http[s]://www.claritypress.com/LendmanIII.html\n    • Type2: [email protected]\n    • Type3: @EP_President #EP_President \n    • Type4: **Want FOX News First * in your inbox every day? Sign up here.**\n    • Type5: ☮️ 💚 🌍 etc\n\n(2) **EDA methods**\n\n\t• Insert word by BERT similarity (Random Insertion)\n\t• Substitute word by BERT similarity (Synonym Replacement)\n\nAS for the first part, I use two methods: drop non-sentence and some EDA methods. I read some text within the fake_or_real news and I find that it contains various type of non-sentence, so I use the regular expression to drop them. And then, I use random insertion and synonym replacement to augment the text.\n\n### 3. Part2: Bert Model\n![Bert model](https://i.loli.net/2019/08/23/pFv1K86WUcafyDI.png)\n\nAs for the second part, we put the text which we got from the first part into the bert model. The Bert model uses 12 encode layers and finally classifier to get the output.\n\n### 4. Part3: Result\n![Result](https://i.loli.net/2019/08/23/aGTYdfz2cul1pj3.png)\n\nIn the end, we combine different methods of data processing and u can see the f1 score from the chart. We get the best f1 score(0.986) from Cased text + drop sentence.\n\n### 5. Part4: Reference\n(1) **EDA**: \n\n\t•Knowledge: https://towardsdatascience.com/these-are-the-easiest-data-augmentation-techniques-in-natural-language-processing-you-can-think-of-88e393fd610\n\t•Implemenation: https://github.com/makcedward/nlpaug\n(2) **Can’t remove stopwords**: \n\n\t•Deeper Text Understanding for IR with Contextual NeuralLanguage Modeling: https://arxiv.org/pdf/1905.09217\n\t•Understanding the Behaviors of BERT in Ranking : https://arxiv.org/pdf/1904.07531\n(3) **Bert by Pytorch**:\n\n\t•https://pytorch.org/hub/huggingface_pytorch-pretrained-bert_bert/\n(4) **Bert Demo**:\n\n\thttps://github.com/sugi-chan/custom_bert_pipeline\n(5) **Dataset**:\n\n    https://cbmm.mit.edu/sites/default/files/publications/fake-news-paper-NIPS.pdf\n    \nI learn the EDA from the two web site and through two articles, I learn that we shouldn’t remove Stopwords which otherwise will destroy the context of sentence. The end is implementation of BERT with Pytorch and the Bert model I learned.\n\n## Implementation\n### 1. Preparation\n#### 1.1 Set parameters and install and load required package\n```Python\n### parameters Setting\npar_cased = 0 # default cased, 0 means uncased\npar_cleanup = 1 # default cleanup, 0 means non-cleanup\npar_eda = 0 # default eda, 0 means non-eda\n\npip install pytorch_pretrained_bert nlpaug bert matplotlib sklearn librosa SoundFile nltk pandas\n\nfrom __future__ import print_function, division\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom random import randrange\nimport torch.nn.functional as F\nfrom sklearn.metrics import roc_curve, auc\nimport nlpaug.augmenter.char as nac\n#import nlpaug.augmenter.word as naw\nimport nlpaug.flow as naf\nfrom nlpaug.util import Action\n```\n#### 1.2 Set tokenizer\n```Python\nimport torch\nfrom pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n\n# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\nimport logging\nlogging.basicConfig(level=logging.INFO)\n\n# Load pre-trained model tokenizer (vocabulary)\nif par_cased ==1:\n    tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\nelse:\n    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n```\n#### 1.3 Define Bert Config\n```Python\nclass BertLayerNorm(nn.Module):\n        def __init__(self, hidden_size, eps=1e-12):\n            \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n            \"\"\"\n            super(BertLayerNorm, self).__init__()\n            self.weight = nn.Parameter(torch.ones(hidden_size))\n            self.bias = nn.Parameter(torch.zeros(hidden_size))\n            self.variance_epsilon = eps\n\n        def forward(self, x):\n            u = x.mean(-1, keepdim=True)\n            s = (x - u).pow(2).mean(-1, keepdim=True)\n            x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n            return self.weight * x + self.bias\n        \n\nclass BertForSequenceClassification(nn.Module):\n    \"\"\"BERT model for classification.\n    This module is composed of the BERT model with a linear layer on top of\n    the pooled output.\n    Params:\n        `config`: a BertConfig class instance with the configuration to build a new model.\n        `num_labels`: the number of classes for the classifier. Default = 2.\n    Inputs:\n        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n            with the word token indices in the vocabulary. Items in the batch should begin with the special \"CLS\" token. (see the tokens preprocessing logic in the scripts\n            `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n            a `sentence B` token (see BERT paper for more details).\n        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n            input sequence length in the current batch. It's the mask that we typically use for attention when\n            a batch has varying length sentences.\n        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]\n            with indices selected in [0, ..., num_labels].\n    Outputs:\n        if `labels` is not `None`:\n            Outputs the CrossEntropy classification loss of the output with the labels.\n        if `labels` is `None`:\n            Outputs the classification logits of shape [batch_size, num_labels].\n    Example usage:\n    ```python\n    # Already been converted into WordPiece token ids\n    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n    config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n    num_labels = 2\n    model = BertForSequenceClassification(config, num_labels)\n    logits = model(input_ids, token_type_ids, input_mask)\n\n    def __init__(self, num_labels=2):\n        super(BertForSequenceClassification, self).__init__()\n        self.num_labels = num_labels\n        if par_cased ==1:\n            self.bert = BertModel.from_pretrained('bert-base-cased')\n        else:\n            self.bert = BertModel.from_pretrained('bert-base-uncased')\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.classifier = nn.Linear(config.hidden_size, num_labels)\n        nn.init.xavier_normal_(self.classifier.weight)\n    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n        pooled_output = self.dropout(pooled_output)\n        logits = self.classifier(pooled_output)\n\n        return logits\n    def freeze_bert_encoder(self):\n        for param in self.bert.parameters():\n            param.requires_grad = False\n    \n    def unfreeze_bert_encoder(self):\n        for param in self.bert.parameters():\n            param.requires_grad = True\n\nfrom pytorch_pretrained_bert import BertConfig\n\nconfig = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n\nnum_labels = 2\nmodel = BertForSequenceClassification(num_labels)\n\n# Convert inputs to PyTorch tensors\n#tokens_tensor = torch.tensor([tokenizer.convert_tokens_to_ids(zz)])\n\n#logits = model(tokens_tensor)\n```\n\n### 2. Dataset Processing\n#### 2.1 Read the data and convert label into binary text\n```Python\nimport pandas as pd\n\ndat = pd.read_csv('/data/fake_or_real_news.csv')\ndat.head()\ndat = dat.drop(columns=['Unnamed: 0', 'title_vectors'])\nfor i in range(len(dat)):\n    if dat.loc[i, 'label'] == \"REAL\": #REAL equal 0\n        dat.loc[i, 'label'] = 0\n    elif dat.loc[i, 'label'] == \"FAKE\": #FAKE equal 1\n        dat.loc[i, 'label'] = 1\n    if dat.loc[i, 'text'] == \"\":\n        dat = dat.drop([i])\ndat.head()\n```\n#### 2.2 Combine the title and text\n```Python\ndat_plus = dat.copy()\ndat_plus['title_text']=dat['title']+'. '+dat['text']\ndat_plus = dat_plus.drop(columns=['title', 'text'])\n\ndat_plus['title_text']\n```\n#### 2.3 Use regular expression to drop non-sentence\n```Python\nimport re\ndef cleanup(text):\n    if par_cased == 0: # transfer into lower text if par_cased is false\n        text = text.lower()\n    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','',text) # drop http[s]://*\n    text = re.sub(u\"\\\\{.*?}|\\\\[.*?]\",'',text) # drop [*]\n    text = re.sub(u\"\\(\\@.*?\\s\", '', text) # drop something like (@EP_President)\n    text = re.sub(u\"\\@.*?\\s\", '', text) # drop soething liek @EP_President\n    text = re.sub(u\"\\#.*?\\s\", '', text) # drop something like #EP_President (maybe hashtag)\n    text = re.sub(u\"\\© .*?\\s\", '', text) # drop something like © EP_President\n    text = re.sub(r'pic.tw(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','',text) # drop pic.twitter.com/*\n    text = re.sub(u\"\\*\\*\", '', text) # drop something like **Want FOX News First * in your inbox every day? Sign up here.**\n    text = re.sub(u\"|•|☮️|💚|🌍|😍|♦|☢\", '', text) # drop something like  and • etc\n    return(text)\n```\n#### 2.4 Use EDA method to augment the text\n```Python\nimport nlpaug.augmenter.char as nac\nimport nlpaug.augmenter.word as naw\nimport nlpaug.flow as nafc\n\nfrom nlpaug.util import Action\nimport nltk\nnltk.download('punkt')\n\nif par_cased ==1:\n    aug = naf.Sequential([\n        naw.BertAug(action=\"substitute\", aug_p=0.8, aug_n=20,model_path='bert-base-cased',tokenizer_path='bert-base-cased'),\n        naw.BertAug(action=\"insert\", aug_p=0.1)\n    ])\nelse:\n    aug = naf.Sequential([\n        naw.BertAug(action=\"substitute\", aug_p=0.8, aug_n=20,model_path='bert-base-uncased',tokenizer_path='bert-base-uncased'),\n        naw.BertAug(action=\"insert\", aug_p=0.1)\n    ])\ndef aug_text(text):\n    text = aug.augment(text)\n    return(text)\nfrom nltk.tokenize import sent_tokenize\ndef sentence_token_nltk(text):\n    sent_tokenize_list = sent_tokenize(text)\n    return sent_tokenize_list\ndef eda_text(text):\n    if len(text) < 2:\n        return(text)\n    # split text into sentences\n    text = sentence_token_nltk(text)\n    if len(text) <= 1:\n        return(text)\n    if len(text) == 2:\n        for i in range(len(text)):\n            if i == 0:\n                tmp_text = text[i]\n            else:\n                tmp_text += text[i]\n        return(tmp_text)\n    # operate prior 3 sentences\n    for i in range(3):\n        if i == 0:\n            tmp_text = text[i]\n        else:\n            tmp_text += text[i]\n    zz = tokenizer.tokenize(tmp_text)\n    # operate proper sentences\n    if len(zz) <= 500:\n    #print(len(zz))\n        tmp_text = aug_text(tmp_text)\n    # conbine prior 3 sentences and rest sentences\n    for j in range(len(text)-3):\n        tmp_text += text[j+3]\n    return(tmp_text)\n\nif par_eda == 1: # use eda to operate sentences when par_eda is true\n  for i in range(len(dat_plus['title_text'])):\n      if i%6 == 1:       \n          #print(i)\n          dat_plus['title_text'][i] = copy.deepcopy(eda_text(dat_plus['title_text'][i]))\n          dat_plus['title_text'][i] = \"\".join(dat_plus['title_text'][i])\n```\n### 3. Google Bert\n```Python\nimport torch.nn.functional as F\n\n#F.softmax(logits,dim=1)\n\nfrom sklearn.model_selection import train_test_split\nif par_cleanup == 1:\n    X = dat_plus['title_text'].apply(cleanup)\nelse:\n    X = dat_plus['title_text']\ny = dat_plus['label']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nX_train = X_train.values.tolist()\nX_test = X_test.values.tolist()\n\ny_train = pd.get_dummies(y_train).values.tolist() # convert to one-hot encoding\ny_test = pd.get_dummies(y_test).values.tolist()\n\nmax_seq_length = 256\nclass text_dataset(Dataset):\n    def __init__(self,x_y_list, transform=None):\n        \n        self.x_y_list = x_y_list\n        self.transform = transform\n        \n    def __getitem__(self,index):\n        \n        tokenized_title_text = tokenizer.tokenize(self.x_y_list[0][index])\n        \n        if len(tokenized_title_text) > max_seq_length:\n            tokenized_title_text = tokenized_title_text[:max_seq_length]\n            \n        ids_title_text  = tokenizer.convert_tokens_to_ids(tokenized_title_text) #tokens->input_ids\n\n        padding = [0] * (max_seq_length - len(ids_title_text))\n        \n        ids_title_text += padding # use padding to make the same ids\n        \n        assert len(ids_title_text) == max_seq_length\n        \n        #print(ids_title_text)\n        ids_title_text = torch.tensor(ids_title_text)\n        \n        label = self.x_y_list[1][index] # color        \n        list_of_labels = [torch.from_numpy(np.array(label))]\n        \n        \n        return ids_title_text, list_of_labels[0]\n    \n    def __len__(self):\n        return len(self.x_y_list[0])\n```\n#### 3.1 Create data dictionary\n```Python\nbatch_size = 16 # divide into 16 batches\n\ntrain_lists = [X_train, y_train]\ntest_lists = [X_test, y_test]\n\ntraining_dataset = text_dataset(x_y_list = train_lists )\n\ntest_dataset = text_dataset(x_y_list = test_lists )\n\ndataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True, num_workers=0),\n                   'val':torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n                  }                \ndataset_sizes = {'train':len(train_lists[0]),\n                'val':len(test_lists[0])}\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n```\n\n#### 3.2 Define the train model\n\n```Python\n def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n    print('starting')\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_loss = 100\n    best_f1 = 0.978\n    best_acc_test = 0.96\n    best_acc_train = 0.96\n    best_auc = 0.96\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            \n            label_corrects = 0\n            TP = 0\n            TN = 0\n            FN = 0\n            FP = 0\n            total_scores = []\n            total_tar = []\n            # Iterate over data.\n            for inputs, label in dataloaders_dict[phase]:\n                #inputs = inputs\n                #print(len(inputs),type(inputs),inputs)\n                #inputs = torch.from_numpy(np.array(inputs)).to(device) \n                inputs = inputs.to(device) \n                label = label.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    # acquire output\n                    outputs = model(inputs)\n\n                    outputs = F.softmax(outputs,dim=1)\n                    \n                    loss = criterion(outputs, torch.max(label.float(), 1)[1])\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        \n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                label_corrects += torch.sum(torch.max(outputs, 1)[1] == torch.max(label, 1)[1]) #返回每一行中最大值的那个元素，且返回其索引（返回最大元素在这一行的列索引）\n                pred_choice = torch.max(outputs, 1)[1]\n                target = torch.max(label, 1)[1]\n                scores = pred_choice.cpu().tolist()\n                tar = target.cpu().tolist()\n                total_scores = total_scores + scores\n                total_tar = total_tar + tar\n\n                tmp_tp = 0\n                tmp_tn = 0\n                tmp_fn = 0\n                tmp_fp = 0\n                if pred_choice.numel()!= target.numel():\n                    print(\"error\")\n                for i in range(pred_choice.numel()):\n                    if pred_choice[i] == 1 and target[i] == 1 :\n                        tmp_tp = tmp_tp + 1\n                    elif pred_choice[i] == 0 and target[i] == 0 :\n                        tmp_tn = tmp_tn + 1\n                    elif pred_choice[i] == 0 and target[i] == 1 :\n                        tmp_fn = tmp_fn + 1\n                    elif pred_choice[i] == 1 and target[i] == 0 :\n                        tmp_fp = tmp_fp + 1\n                # TP    both predict and label are 1\n                TP += tmp_tp\n                # TN    both predict and label are 0\n                TN += tmp_tn\n                # FN    predict 0 label 1\n                FN += tmp_fn\n                # FP    predict 1 label 0\n                FP += tmp_fp\n            epoch_loss = running_loss / dataset_sizes[phase]\n            p = TP / (TP + FP)\n            r = TP / (TP + FN)\n            F1 = 2 * r * p / (r + p)\n            acc = (TP + TN) / (TP + TN + FP + FN)\n\n            ### draw ROC curce\n            tpr = TP/(TP+FN)\n            fpr = FP/(FP+TN)\n            tnr = TN/(FP+TN)\n\n            total_scores = np.array(total_scores)\n            total_tar = np.array(total_tar)\n            fpr, tpr, thresholds = roc_curve(total_tar, total_scores)\n            roc_auc = auc(fpr, tpr) \n            plt.title('ROC')\n            if roc_auc > best_auc:\n                best_auc = roc_auc\n            if epoch < num_epochs -1:\n                plt.plot(fpr, tpr,'b',label='AUC = %0.4f'% roc_auc)\n            if epoch == num_epochs -1:\n                plt.plot(fpr, tpr, color='darkorange', label='MAX AUC = %0.4f'% best_auc) \n            plt.legend(loc='lower right')\n            plt.plot([0,1],[0,1],'r--')\n            plt.ylabel('TPR')\n            plt.xlabel('FPR')\n            plt.show()\n\n            #print('{} p: {:.4f} '.format(phase,p ))\n            #print('{} r: {:.4f} '.format(phase,r ))\n            print('{} F1: {:.4f} '.format(phase,F1 ))\n            print('{} accuracy: {:.4f} '.format(phase,acc ))\n\n            if phase == 'val' and epoch_loss < best_loss:\n                print('saving with loss of {}'.format(epoch_loss),\n                      'improved over previous {}'.format(best_loss))\n                best_loss = epoch_loss\n                best_model_wts = copy.deepcopy(model.state_dict())\n                #torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/bert_model_test_loss.pth')\n            if F1 > best_f1:\n                best_f1 = F1\n            if phase == 'val' and acc > best_acc_test:\n                best_acc_test = acc\n            if phase == 'train' and acc > best_acc_train:\n                best_acc_train = acc\n                #best_model_wts = copy.deepcopy(model.state_dict())\n                #torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/bert_model_test_f1.pth')\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print(\"Parament setting: \")\n    print(\"cased: \",par_cased)\n    print(\"cleanup: \",par_cleanup)\n    print(\"eda: \",par_eda)\n    print('Best train Acc: {:4f}'.format(float(best_acc_train)))\n    print('Best test Acc: {:4f}'.format(float(best_acc_test)))\n    print('Best f1 score: {:4f}'.format(float(best_f1)))\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model\n```\n### 4. Final output\n#### 4.1 Model details\n```Python\nprint(model)\nmodel.to(device)\n```\n#### 4.2 F1 and other details\n```Python\nmodel_ft1 = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=10)\n```","slug":"Google-BERT-on-fake-or-real-news-dataset","published":1,"updated":"2019-11-16T12:11:41.199Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkpg000tk3x64vqxcifk","content":"<p><strong>Description</strong>: Use Google BERT on fake_or_real news dataset with best f1 score: 0.986</p>\n<a id=\"more\"></a>\n<h2 id=\"Showcase\"><a href=\"#Showcase\" class=\"headerlink\" title=\"Showcase\"></a>Showcase</h2><h3 id=\"1-Pipeline\"><a href=\"#1-Pipeline\" class=\"headerlink\" title=\"1. Pipeline\"></a>1. Pipeline</h3><p><img src=\"https://i.loli.net/2019/08/23/P8Seo5EvmpZfAOT.png\" alt=\"Pipeline\"></p>\n<p>First, we got the raw text with title, text and label. Then we use some methods of data processing to operate the text. After the data processing, we put them into the Bert model to train the data, which includes the Bert itself and the Classifier, here I used the feed-forward neural network and add a softmax layer to normalize the output. In the end, we got the predication and other details.</p>\n<h3 id=\"2-Part1-Data-processing\"><a href=\"#2-Part1-Data-processing\" class=\"headerlink\" title=\"2. Part1: Data processing\"></a>2. Part1: Data processing</h3><p>(1) <strong>Drop non-sentence</strong></p>\n<pre><code>• Type1: http[s]://www.claritypress.com/LendmanIII.html\n• Type2: [email protected]\n• Type3: @EP_President #EP_President \n• Type4: **Want FOX News First * in your inbox every day? Sign up here.**\n• Type5: ☮️ 💚 🌍 etc</code></pre><p>(2) <strong>EDA methods</strong></p>\n<pre><code>• Insert word by BERT similarity (Random Insertion)\n• Substitute word by BERT similarity (Synonym Replacement)</code></pre><p>AS for the first part, I use two methods: drop non-sentence and some EDA methods. I read some text within the fake_or_real news and I find that it contains various type of non-sentence, so I use the regular expression to drop them. And then, I use random insertion and synonym replacement to augment the text.</p>\n<h3 id=\"3-Part2-Bert-Model\"><a href=\"#3-Part2-Bert-Model\" class=\"headerlink\" title=\"3. Part2: Bert Model\"></a>3. Part2: Bert Model</h3><p><img src=\"https://i.loli.net/2019/08/23/pFv1K86WUcafyDI.png\" alt=\"Bert model\"></p>\n<p>As for the second part, we put the text which we got from the first part into the bert model. The Bert model uses 12 encode layers and finally classifier to get the output.</p>\n<h3 id=\"4-Part3-Result\"><a href=\"#4-Part3-Result\" class=\"headerlink\" title=\"4. Part3: Result\"></a>4. Part3: Result</h3><p><img src=\"https://i.loli.net/2019/08/23/aGTYdfz2cul1pj3.png\" alt=\"Result\"></p>\n<p>In the end, we combine different methods of data processing and u can see the f1 score from the chart. We get the best f1 score(0.986) from Cased text + drop sentence.</p>\n<h3 id=\"5-Part4-Reference\"><a href=\"#5-Part4-Reference\" class=\"headerlink\" title=\"5. Part4: Reference\"></a>5. Part4: Reference</h3><p>(1) <strong>EDA</strong>: </p>\n<pre><code>•Knowledge: https://towardsdatascience.com/these-are-the-easiest-data-augmentation-techniques-in-natural-language-processing-you-can-think-of-88e393fd610\n•Implemenation: https://github.com/makcedward/nlpaug</code></pre><p>(2) <strong>Can’t remove stopwords</strong>: </p>\n<pre><code>•Deeper Text Understanding for IR with Contextual NeuralLanguage Modeling: https://arxiv.org/pdf/1905.09217\n•Understanding the Behaviors of BERT in Ranking : https://arxiv.org/pdf/1904.07531</code></pre><p>(3) <strong>Bert by Pytorch</strong>:</p>\n<pre><code>•https://pytorch.org/hub/huggingface_pytorch-pretrained-bert_bert/</code></pre><p>(4) <strong>Bert Demo</strong>:</p>\n<pre><code>https://github.com/sugi-chan/custom_bert_pipeline</code></pre><p>(5) <strong>Dataset</strong>:</p>\n<pre><code>https://cbmm.mit.edu/sites/default/files/publications/fake-news-paper-NIPS.pdf</code></pre><p>I learn the EDA from the two web site and through two articles, I learn that we shouldn’t remove Stopwords which otherwise will destroy the context of sentence. The end is implementation of BERT with Pytorch and the Bert model I learned.</p>\n<h2 id=\"Implementation\"><a href=\"#Implementation\" class=\"headerlink\" title=\"Implementation\"></a>Implementation</h2><h3 id=\"1-Preparation\"><a href=\"#1-Preparation\" class=\"headerlink\" title=\"1. Preparation\"></a>1. Preparation</h3><h4 id=\"1-1-Set-parameters-and-install-and-load-required-package\"><a href=\"#1-1-Set-parameters-and-install-and-load-required-package\" class=\"headerlink\" title=\"1.1 Set parameters and install and load required package\"></a>1.1 Set parameters and install and load required package</h4><figure class=\"highlight python hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-comment\">### parameters Setting</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">par_cased = <span class=\"hljs-number\">0</span> <span class=\"hljs-comment\"># default cased, 0 means uncased</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">par_cleanup = <span class=\"hljs-number\">1</span> <span class=\"hljs-comment\"># default cleanup, 0 means non-cleanup</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">par_eda = <span class=\"hljs-number\">0</span> <span class=\"hljs-comment\"># default eda, 0 means non-eda</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">pip install pytorch_pretrained_bert nlpaug bert matplotlib sklearn librosa SoundFile nltk pandas</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">from</span> __future__ <span class=\"hljs-keyword\">import</span> print_function, division</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> torch</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> torch.optim <span class=\"hljs-keyword\">as</span> optim</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">from</span> torch.optim <span class=\"hljs-keyword\">import</span> lr_scheduler</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">14</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> torchvision</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">15</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">from</span> torchvision <span class=\"hljs-keyword\">import</span> datasets, models, transforms</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">16</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> plt</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">17</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> time</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">18</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> os</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">19</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> copy</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">20</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> Dataset, DataLoader</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">21</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">from</span> PIL <span class=\"hljs-keyword\">import</span> Image</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">22</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">from</span> random <span class=\"hljs-keyword\">import</span> randrange</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">23</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">24</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">from</span> sklearn.metrics <span class=\"hljs-keyword\">import</span> roc_curve, auc</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">25</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> nlpaug.augmenter.char <span class=\"hljs-keyword\">as</span> nac</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">26</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-comment\">#import nlpaug.augmenter.word as naw</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">27</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> nlpaug.flow <span class=\"hljs-keyword\">as</span> naf</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">28</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">from</span> nlpaug.util <span class=\"hljs-keyword\">import</span> Action</span></pre></td></tr></table></figure>\n<h4 id=\"1-2-Set-tokenizer\"><a href=\"#1-2-Set-tokenizer\" class=\"headerlink\" title=\"1.2 Set tokenizer\"></a>1.2 Set tokenizer</h4><figure class=\"highlight python hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> torch</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">from</span> pytorch_pretrained_bert <span class=\"hljs-keyword\">import</span> BertTokenizer, BertModel, BertForMaskedLM</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-comment\"># OPTIONAL: if you want to have more information on what's happening, activate the logger as follows</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> logging</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">logging.basicConfig(level=logging.INFO)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-comment\"># Load pre-trained model tokenizer (vocabulary)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">if</span> par_cased ==<span class=\"hljs-number\">1</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">    tokenizer = BertTokenizer.from_pretrained(<span class=\"hljs-string\">'bert-base-cased'</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">else</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">    tokenizer = BertTokenizer.from_pretrained(<span class=\"hljs-string\">'bert-base-uncased'</span>)</span></pre></td></tr></table></figure>\n<h4 id=\"1-3-Define-Bert-Config\"><a href=\"#1-3-Define-Bert-Config\" class=\"headerlink\" title=\"1.3 Define Bert Config\"></a>1.3 Define Bert Config</h4><figure class=\"highlight python hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">BertLayerNorm</span><span class=\"hljs-params\">(nn.Module)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span><span class=\"hljs-params\">(self, hidden_size, eps=<span class=\"hljs-number\">1e-12</span>)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">            <span class=\"hljs-string\">\"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">            \"\"\"</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">            super(BertLayerNorm, self).__init__()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">            self.weight = nn.Parameter(torch.ones(hidden_size))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">            self.bias = nn.Parameter(torch.zeros(hidden_size))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">            self.variance_epsilon = eps</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">forward</span><span class=\"hljs-params\">(self, x)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">            u = x.mean(<span class=\"hljs-number\">-1</span>, keepdim=<span class=\"hljs-literal\">True</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">            s = (x - u).pow(<span class=\"hljs-number\">2</span>).mean(<span class=\"hljs-number\">-1</span>, keepdim=<span class=\"hljs-literal\">True</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\">            x = (x - u) / torch.sqrt(s + self.variance_epsilon)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">14</span></pre></td><td class=\"code\"><pre><span class=\"line\">            <span class=\"hljs-keyword\">return</span> self.weight * x + self.bias</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">15</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">16</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">17</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">BertForSequenceClassification</span><span class=\"hljs-params\">(nn.Module)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">18</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-string\">\"\"\"BERT model for classification.</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">19</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">    This module is composed of the BERT model with a linear layer on top of</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">20</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">    the pooled output.</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">21</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">    Params:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">22</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        `config`: a BertConfig class instance with the configuration to build a new model.</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">23</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        `num_labels`: the number of classes for the classifier. Default = 2.</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">24</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">    Inputs:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">25</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">26</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">            with the word token indices in the vocabulary. Items in the batch should begin with the special \"CLS\" token. (see the tokens preprocessing logic in the scripts</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">27</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">28</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">29</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">30</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">            a `sentence B` token (see BERT paper for more details).</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">31</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">32</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">33</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">            input sequence length in the current batch. It's the mask that we typically use for attention when</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">34</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">            a batch has varying length sentences.</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">35</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">36</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">            with indices selected in [0, ..., num_labels].</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">37</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">    Outputs:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">38</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        if `labels` is not `None`:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">39</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">            Outputs the CrossEntropy classification loss of the output with the labels.</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">40</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        if `labels` is `None`:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">41</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">            Outputs the classification logits of shape [batch_size, num_labels].</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">42</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">    Example usage:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">43</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">    ```python</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">44</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">    # Already been converted into WordPiece token ids</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">45</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">46</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">47</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">48</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">    config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">49</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">50</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">    num_labels = 2</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">51</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">    model = BertForSequenceClassification(config, num_labels)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">52</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">    logits = model(input_ids, token_type_ids, input_mask)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">53</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\"></span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">54</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">    def __init__(self, num_labels=2):</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">55</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        super(BertForSequenceClassification, self).__init__()</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">56</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        self.num_labels = num_labels</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">57</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        if par_cased ==1:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">58</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">            self.bert = BertModel.from_pretrained('bert-base-cased')</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">59</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        else:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">60</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">            self.bert = BertModel.from_pretrained('bert-base-uncased')</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">61</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        self.dropout = nn.Dropout(config.hidden_dropout_prob)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">62</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        self.classifier = nn.Linear(config.hidden_size, num_labels)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">63</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        nn.init.xavier_normal_(self.classifier.weight)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">64</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">65</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">66</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        pooled_output = self.dropout(pooled_output)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">67</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        logits = self.classifier(pooled_output)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">68</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\"></span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">69</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        return logits</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">70</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">    def freeze_bert_encoder(self):</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">71</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        for param in self.bert.parameters():</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">72</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">            param.requires_grad = False</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">73</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">    </span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">74</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">    def unfreeze_bert_encoder(self):</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">75</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        for param in self.bert.parameters():</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">76</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">            param.requires_grad = True</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">77</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\"></span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">78</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">from pytorch_pretrained_bert import BertConfig</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">79</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\"></span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">80</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">81</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">82</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\"></span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">83</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">num_labels = 2</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">84</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">model = BertForSequenceClassification(num_labels)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">85</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\"></span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">86</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\"># Convert inputs to PyTorch tensors</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">87</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">#tokens_tensor = torch.tensor([tokenizer.convert_tokens_to_ids(zz)])</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">88</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\"></span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">89</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-string\">#logits = model(tokens_tensor)</span></span></pre></td></tr></table></figure>\n\n<h3 id=\"2-Dataset-Processing\"><a href=\"#2-Dataset-Processing\" class=\"headerlink\" title=\"2. Dataset Processing\"></a>2. Dataset Processing</h3><h4 id=\"2-1-Read-the-data-and-convert-label-into-binary-text\"><a href=\"#2-1-Read-the-data-and-convert-label-into-binary-text\" class=\"headerlink\" title=\"2.1 Read the data and convert label into binary text\"></a>2.1 Read the data and convert label into binary text</h4><figure class=\"highlight python hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">dat = pd.read_csv(<span class=\"hljs-string\">'/data/fake_or_real_news.csv'</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">dat.head()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">dat = dat.drop(columns=[<span class=\"hljs-string\">'Unnamed: 0'</span>, <span class=\"hljs-string\">'title_vectors'</span>])</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> range(len(dat)):</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-keyword\">if</span> dat.loc[i, <span class=\"hljs-string\">'label'</span>] == <span class=\"hljs-string\">\"REAL\"</span>: <span class=\"hljs-comment\">#REAL equal 0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">        dat.loc[i, <span class=\"hljs-string\">'label'</span>] = <span class=\"hljs-number\">0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-keyword\">elif</span> dat.loc[i, <span class=\"hljs-string\">'label'</span>] == <span class=\"hljs-string\">\"FAKE\"</span>: <span class=\"hljs-comment\">#FAKE equal 1</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">        dat.loc[i, <span class=\"hljs-string\">'label'</span>] = <span class=\"hljs-number\">1</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-keyword\">if</span> dat.loc[i, <span class=\"hljs-string\">'text'</span>] == <span class=\"hljs-string\">\"\"</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">        dat = dat.drop([i])</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\">dat.head()</span></pre></td></tr></table></figure>\n<h4 id=\"2-2-Combine-the-title-and-text\"><a href=\"#2-2-Combine-the-title-and-text\" class=\"headerlink\" title=\"2.2 Combine the title and text\"></a>2.2 Combine the title and text</h4><figure class=\"highlight python hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">dat_plus = dat.copy()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">dat_plus[<span class=\"hljs-string\">'title_text'</span>]=dat[<span class=\"hljs-string\">'title'</span>]+<span class=\"hljs-string\">'. '</span>+dat[<span class=\"hljs-string\">'text'</span>]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">dat_plus = dat_plus.drop(columns=[<span class=\"hljs-string\">'title'</span>, <span class=\"hljs-string\">'text'</span>])</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">dat_plus[<span class=\"hljs-string\">'title_text'</span>]</span></pre></td></tr></table></figure>\n<h4 id=\"2-3-Use-regular-expression-to-drop-non-sentence\"><a href=\"#2-3-Use-regular-expression-to-drop-non-sentence\" class=\"headerlink\" title=\"2.3 Use regular expression to drop non-sentence\"></a>2.3 Use regular expression to drop non-sentence</h4><figure class=\"highlight python hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> re</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">cleanup</span><span class=\"hljs-params\">(text)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-keyword\">if</span> par_cased == <span class=\"hljs-number\">0</span>: <span class=\"hljs-comment\"># transfer into lower text if par_cased is false</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">        text = text.lower()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = re.sub(<span class=\"hljs-string\">r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'</span>,<span class=\"hljs-string\">''</span>,text) <span class=\"hljs-comment\"># drop http[s]://*</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = re.sub(<span class=\"hljs-string\">u\"\\\\&#123;.*?&#125;|\\\\[.*?]\"</span>,<span class=\"hljs-string\">''</span>,text) <span class=\"hljs-comment\"># drop [*]</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = re.sub(<span class=\"hljs-string\">u\"\\(\\@.*?\\s\"</span>, <span class=\"hljs-string\">''</span>, text) <span class=\"hljs-comment\"># drop something like (@EP_President)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = re.sub(<span class=\"hljs-string\">u\"\\@.*?\\s\"</span>, <span class=\"hljs-string\">''</span>, text) <span class=\"hljs-comment\"># drop soething liek @EP_President</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = re.sub(<span class=\"hljs-string\">u\"\\#.*?\\s\"</span>, <span class=\"hljs-string\">''</span>, text) <span class=\"hljs-comment\"># drop something like #EP_President (maybe hashtag)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = re.sub(<span class=\"hljs-string\">u\"\\© .*?\\s\"</span>, <span class=\"hljs-string\">''</span>, text) <span class=\"hljs-comment\"># drop something like © EP_President</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = re.sub(<span class=\"hljs-string\">r'pic.tw(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+#]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'</span>,<span class=\"hljs-string\">''</span>,text) <span class=\"hljs-comment\"># drop pic.twitter.com/*</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = re.sub(<span class=\"hljs-string\">u\"\\*\\*\"</span>, <span class=\"hljs-string\">''</span>, text) <span class=\"hljs-comment\"># drop something like **Want FOX News First * in your inbox every day? Sign up here.**</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = re.sub(<span class=\"hljs-string\">u\"|•|☮️|💚|🌍|😍|♦|☢\"</span>, <span class=\"hljs-string\">''</span>, text) <span class=\"hljs-comment\"># drop something like  and • etc</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">14</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-keyword\">return</span>(text)</span></pre></td></tr></table></figure>\n<h4 id=\"2-4-Use-EDA-method-to-augment-the-text\"><a href=\"#2-4-Use-EDA-method-to-augment-the-text\" class=\"headerlink\" title=\"2.4 Use EDA method to augment the text\"></a>2.4 Use EDA method to augment the text</h4><figure class=\"highlight python hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> nlpaug.augmenter.char <span class=\"hljs-keyword\">as</span> nac</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> nlpaug.augmenter.word <span class=\"hljs-keyword\">as</span> naw</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> nlpaug.flow <span class=\"hljs-keyword\">as</span> nafc</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">from</span> nlpaug.util <span class=\"hljs-keyword\">import</span> Action</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> nltk</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">nltk.download(<span class=\"hljs-string\">'punkt'</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">if</span> par_cased ==<span class=\"hljs-number\">1</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">    aug = naf.Sequential([</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">        naw.BertAug(action=<span class=\"hljs-string\">\"substitute\"</span>, aug_p=<span class=\"hljs-number\">0.8</span>, aug_n=<span class=\"hljs-number\">20</span>,model_path=<span class=\"hljs-string\">'bert-base-cased'</span>,tokenizer_path=<span class=\"hljs-string\">'bert-base-cased'</span>),</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">        naw.BertAug(action=<span class=\"hljs-string\">\"insert\"</span>, aug_p=<span class=\"hljs-number\">0.1</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\">    ])</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">14</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">else</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">15</span></pre></td><td class=\"code\"><pre><span class=\"line\">    aug = naf.Sequential([</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">16</span></pre></td><td class=\"code\"><pre><span class=\"line\">        naw.BertAug(action=<span class=\"hljs-string\">\"substitute\"</span>, aug_p=<span class=\"hljs-number\">0.8</span>, aug_n=<span class=\"hljs-number\">20</span>,model_path=<span class=\"hljs-string\">'bert-base-uncased'</span>,tokenizer_path=<span class=\"hljs-string\">'bert-base-uncased'</span>),</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">17</span></pre></td><td class=\"code\"><pre><span class=\"line\">        naw.BertAug(action=<span class=\"hljs-string\">\"insert\"</span>, aug_p=<span class=\"hljs-number\">0.1</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">18</span></pre></td><td class=\"code\"><pre><span class=\"line\">    ])</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">19</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">aug_text</span><span class=\"hljs-params\">(text)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">20</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = aug.augment(text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">21</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-keyword\">return</span>(text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">22</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">from</span> nltk.tokenize <span class=\"hljs-keyword\">import</span> sent_tokenize</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">23</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">sentence_token_nltk</span><span class=\"hljs-params\">(text)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">24</span></pre></td><td class=\"code\"><pre><span class=\"line\">    sent_tokenize_list = sent_tokenize(text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">25</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-keyword\">return</span> sent_tokenize_list</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">26</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">eda_text</span><span class=\"hljs-params\">(text)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">27</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-keyword\">if</span> len(text) &lt; <span class=\"hljs-number\">2</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">28</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"hljs-keyword\">return</span>(text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">29</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-comment\"># split text into sentences</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">30</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = sentence_token_nltk(text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">31</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-keyword\">if</span> len(text) &lt;= <span class=\"hljs-number\">1</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">32</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"hljs-keyword\">return</span>(text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">33</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-keyword\">if</span> len(text) == <span class=\"hljs-number\">2</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">34</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> range(len(text)):</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">35</span></pre></td><td class=\"code\"><pre><span class=\"line\">            <span class=\"hljs-keyword\">if</span> i == <span class=\"hljs-number\">0</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">36</span></pre></td><td class=\"code\"><pre><span class=\"line\">                tmp_text = text[i]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">37</span></pre></td><td class=\"code\"><pre><span class=\"line\">            <span class=\"hljs-keyword\">else</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">38</span></pre></td><td class=\"code\"><pre><span class=\"line\">                tmp_text += text[i]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">39</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"hljs-keyword\">return</span>(tmp_text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">40</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-comment\"># operate prior 3 sentences</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">41</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> range(<span class=\"hljs-number\">3</span>):</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">42</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"hljs-keyword\">if</span> i == <span class=\"hljs-number\">0</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">43</span></pre></td><td class=\"code\"><pre><span class=\"line\">            tmp_text = text[i]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">44</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"hljs-keyword\">else</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">45</span></pre></td><td class=\"code\"><pre><span class=\"line\">            tmp_text += text[i]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">46</span></pre></td><td class=\"code\"><pre><span class=\"line\">    zz = tokenizer.tokenize(tmp_text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">47</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-comment\"># operate proper sentences</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">48</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-keyword\">if</span> len(zz) &lt;= <span class=\"hljs-number\">500</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">49</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-comment\">#print(len(zz))</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">50</span></pre></td><td class=\"code\"><pre><span class=\"line\">        tmp_text = aug_text(tmp_text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">51</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-comment\"># conbine prior 3 sentences and rest sentences</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">52</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-keyword\">for</span> j <span class=\"hljs-keyword\">in</span> range(len(text)<span class=\"hljs-number\">-3</span>):</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">53</span></pre></td><td class=\"code\"><pre><span class=\"line\">        tmp_text += text[j+<span class=\"hljs-number\">3</span>]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">54</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-keyword\">return</span>(tmp_text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">55</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">56</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">if</span> par_eda == <span class=\"hljs-number\">1</span>: <span class=\"hljs-comment\"># use eda to operate sentences when par_eda is true</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">57</span></pre></td><td class=\"code\"><pre><span class=\"line\">  <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> range(len(dat_plus[<span class=\"hljs-string\">'title_text'</span>])):</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">58</span></pre></td><td class=\"code\"><pre><span class=\"line\">      <span class=\"hljs-keyword\">if</span> i%<span class=\"hljs-number\">6</span> == <span class=\"hljs-number\">1</span>:       </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">59</span></pre></td><td class=\"code\"><pre><span class=\"line\">          <span class=\"hljs-comment\">#print(i)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">60</span></pre></td><td class=\"code\"><pre><span class=\"line\">          dat_plus[<span class=\"hljs-string\">'title_text'</span>][i] = copy.deepcopy(eda_text(dat_plus[<span class=\"hljs-string\">'title_text'</span>][i]))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">61</span></pre></td><td class=\"code\"><pre><span class=\"line\">          dat_plus[<span class=\"hljs-string\">'title_text'</span>][i] = <span class=\"hljs-string\">\"\"</span>.join(dat_plus[<span class=\"hljs-string\">'title_text'</span>][i])</span></pre></td></tr></table></figure>\n<h3 id=\"3-Google-Bert\"><a href=\"#3-Google-Bert\" class=\"headerlink\" title=\"3. Google Bert\"></a>3. Google Bert</h3><figure class=\"highlight python hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-comment\">#F.softmax(logits,dim=1)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">from</span> sklearn.model_selection <span class=\"hljs-keyword\">import</span> train_test_split</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">if</span> par_cleanup == <span class=\"hljs-number\">1</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">    X = dat_plus[<span class=\"hljs-string\">'title_text'</span>].apply(cleanup)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">else</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">    X = dat_plus[<span class=\"hljs-string\">'title_text'</span>]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">y = dat_plus[<span class=\"hljs-string\">'label'</span>]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class=\"hljs-number\">0.3</span>, random_state=<span class=\"hljs-number\">42</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\">X_train = X_train.values.tolist()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">14</span></pre></td><td class=\"code\"><pre><span class=\"line\">X_test = X_test.values.tolist()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">15</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">16</span></pre></td><td class=\"code\"><pre><span class=\"line\">y_train = pd.get_dummies(y_train).values.tolist() <span class=\"hljs-comment\"># convert to one-hot encoding</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">17</span></pre></td><td class=\"code\"><pre><span class=\"line\">y_test = pd.get_dummies(y_test).values.tolist()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">18</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">19</span></pre></td><td class=\"code\"><pre><span class=\"line\">max_seq_length = <span class=\"hljs-number\">256</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">20</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">text_dataset</span><span class=\"hljs-params\">(Dataset)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">21</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span><span class=\"hljs-params\">(self,x_y_list, transform=None)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">22</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">23</span></pre></td><td class=\"code\"><pre><span class=\"line\">        self.x_y_list = x_y_list</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">24</span></pre></td><td class=\"code\"><pre><span class=\"line\">        self.transform = transform</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">25</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">26</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__getitem__</span><span class=\"hljs-params\">(self,index)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">27</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">28</span></pre></td><td class=\"code\"><pre><span class=\"line\">        tokenized_title_text = tokenizer.tokenize(self.x_y_list[<span class=\"hljs-number\">0</span>][index])</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">29</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">30</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"hljs-keyword\">if</span> len(tokenized_title_text) &gt; max_seq_length:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">31</span></pre></td><td class=\"code\"><pre><span class=\"line\">            tokenized_title_text = tokenized_title_text[:max_seq_length]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">32</span></pre></td><td class=\"code\"><pre><span class=\"line\">            </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">33</span></pre></td><td class=\"code\"><pre><span class=\"line\">        ids_title_text  = tokenizer.convert_tokens_to_ids(tokenized_title_text) <span class=\"hljs-comment\">#tokens-&gt;input_ids</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">34</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">35</span></pre></td><td class=\"code\"><pre><span class=\"line\">        padding = [<span class=\"hljs-number\">0</span>] * (max_seq_length - len(ids_title_text))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">36</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">37</span></pre></td><td class=\"code\"><pre><span class=\"line\">        ids_title_text += padding <span class=\"hljs-comment\"># use padding to make the same ids</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">38</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">39</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"hljs-keyword\">assert</span> len(ids_title_text) == max_seq_length</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">40</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">41</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"hljs-comment\">#print(ids_title_text)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">42</span></pre></td><td class=\"code\"><pre><span class=\"line\">        ids_title_text = torch.tensor(ids_title_text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">43</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">44</span></pre></td><td class=\"code\"><pre><span class=\"line\">        label = self.x_y_list[<span class=\"hljs-number\">1</span>][index] <span class=\"hljs-comment\"># color        </span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">45</span></pre></td><td class=\"code\"><pre><span class=\"line\">        list_of_labels = [torch.from_numpy(np.array(label))]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">46</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">47</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">48</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"hljs-keyword\">return</span> ids_title_text, list_of_labels[<span class=\"hljs-number\">0</span>]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">49</span></pre></td><td class=\"code\"><pre><span class=\"line\">    </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">50</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__len__</span><span class=\"hljs-params\">(self)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">51</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"hljs-keyword\">return</span> len(self.x_y_list[<span class=\"hljs-number\">0</span>])</span></pre></td></tr></table></figure>\n<h4 id=\"3-1-Create-data-dictionary\"><a href=\"#3-1-Create-data-dictionary\" class=\"headerlink\" title=\"3.1 Create data dictionary\"></a>3.1 Create data dictionary</h4><figure class=\"highlight python hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">batch_size = <span class=\"hljs-number\">16</span> <span class=\"hljs-comment\"># divide into 16 batches</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">train_lists = [X_train, y_train]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">test_lists = [X_test, y_test]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">training_dataset = text_dataset(x_y_list = train_lists )</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">test_dataset = text_dataset(x_y_list = test_lists )</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">dataloaders_dict = &#123;<span class=\"hljs-string\">'train'</span>: torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=<span class=\"hljs-literal\">True</span>, num_workers=<span class=\"hljs-number\">0</span>),</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   <span class=\"hljs-string\">'val'</span>:torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=<span class=\"hljs-literal\">True</span>, num_workers=<span class=\"hljs-number\">0</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">                  &#125;                </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\">dataset_sizes = &#123;<span class=\"hljs-string\">'train'</span>:len(train_lists[<span class=\"hljs-number\">0</span>]),</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">14</span></pre></td><td class=\"code\"><pre><span class=\"line\">                <span class=\"hljs-string\">'val'</span>:len(test_lists[<span class=\"hljs-number\">0</span>])&#125;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">15</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">16</span></pre></td><td class=\"code\"><pre><span class=\"line\">device = torch.device(<span class=\"hljs-string\">\"cuda:0\"</span> <span class=\"hljs-keyword\">if</span> torch.cuda.is_available() <span class=\"hljs-keyword\">else</span> <span class=\"hljs-string\">\"cpu\"</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">17</span></pre></td><td class=\"code\"><pre><span class=\"line\">print(device)</span></pre></td></tr></table></figure>\n\n<h4 id=\"3-2-Define-the-train-model\"><a href=\"#3-2-Define-the-train-model\" class=\"headerlink\" title=\"3.2 Define the train model\"></a>3.2 Define the train model</h4><figure class=\"highlight python hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">train_model</span><span class=\"hljs-params\">(model, criterion, optimizer, scheduler, num_epochs=<span class=\"hljs-number\">25</span>)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">   since = time.time()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">   print(<span class=\"hljs-string\">'starting'</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">   best_model_wts = copy.deepcopy(model.state_dict())</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">   best_loss = <span class=\"hljs-number\">100</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">   best_f1 = <span class=\"hljs-number\">0.978</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">   best_acc_test = <span class=\"hljs-number\">0.96</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">   best_acc_train = <span class=\"hljs-number\">0.96</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">   best_auc = <span class=\"hljs-number\">0.96</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">   <span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> range(num_epochs):</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">       print(<span class=\"hljs-string\">'Epoch &#123;&#125;/&#123;&#125;'</span>.format(epoch, num_epochs - <span class=\"hljs-number\">1</span>))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">       print(<span class=\"hljs-string\">'-'</span> * <span class=\"hljs-number\">10</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">14</span></pre></td><td class=\"code\"><pre><span class=\"line\">       <span class=\"hljs-comment\"># Each epoch has a training and validation phase</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">15</span></pre></td><td class=\"code\"><pre><span class=\"line\">       <span class=\"hljs-keyword\">for</span> phase <span class=\"hljs-keyword\">in</span> [<span class=\"hljs-string\">'train'</span>, <span class=\"hljs-string\">'val'</span>]:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">16</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"hljs-keyword\">if</span> phase == <span class=\"hljs-string\">'train'</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">17</span></pre></td><td class=\"code\"><pre><span class=\"line\">               scheduler.step()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">18</span></pre></td><td class=\"code\"><pre><span class=\"line\">               model.train()  <span class=\"hljs-comment\"># Set model to training mode</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">19</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"hljs-keyword\">else</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">20</span></pre></td><td class=\"code\"><pre><span class=\"line\">               model.eval()   <span class=\"hljs-comment\"># Set model to evaluate mode</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">21</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">22</span></pre></td><td class=\"code\"><pre><span class=\"line\">           running_loss = <span class=\"hljs-number\">0.0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">23</span></pre></td><td class=\"code\"><pre><span class=\"line\">           </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">24</span></pre></td><td class=\"code\"><pre><span class=\"line\">           label_corrects = <span class=\"hljs-number\">0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">25</span></pre></td><td class=\"code\"><pre><span class=\"line\">           TP = <span class=\"hljs-number\">0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">26</span></pre></td><td class=\"code\"><pre><span class=\"line\">           TN = <span class=\"hljs-number\">0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">27</span></pre></td><td class=\"code\"><pre><span class=\"line\">           FN = <span class=\"hljs-number\">0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">28</span></pre></td><td class=\"code\"><pre><span class=\"line\">           FP = <span class=\"hljs-number\">0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">29</span></pre></td><td class=\"code\"><pre><span class=\"line\">           total_scores = []</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">30</span></pre></td><td class=\"code\"><pre><span class=\"line\">           total_tar = []</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">31</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"hljs-comment\"># Iterate over data.</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">32</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"hljs-keyword\">for</span> inputs, label <span class=\"hljs-keyword\">in</span> dataloaders_dict[phase]:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">33</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"hljs-comment\">#inputs = inputs</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">34</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"hljs-comment\">#print(len(inputs),type(inputs),inputs)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">35</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"hljs-comment\">#inputs = torch.from_numpy(np.array(inputs)).to(device) </span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">36</span></pre></td><td class=\"code\"><pre><span class=\"line\">               inputs = inputs.to(device) </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">37</span></pre></td><td class=\"code\"><pre><span class=\"line\">               label = label.to(device)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">38</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">39</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"hljs-comment\"># zero the parameter gradients</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">40</span></pre></td><td class=\"code\"><pre><span class=\"line\">               optimizer.zero_grad()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">41</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">42</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"hljs-comment\"># forward</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">43</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"hljs-comment\"># track history if only in train</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">44</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"hljs-keyword\">with</span> torch.set_grad_enabled(phase == <span class=\"hljs-string\">'train'</span>):</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">45</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   <span class=\"hljs-comment\"># acquire output</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">46</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   outputs = model(inputs)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">47</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">48</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   outputs = F.softmax(outputs,dim=<span class=\"hljs-number\">1</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">49</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">50</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   loss = criterion(outputs, torch.max(label.float(), <span class=\"hljs-number\">1</span>)[<span class=\"hljs-number\">1</span>])</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">51</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   <span class=\"hljs-comment\"># backward + optimize only if in training phase</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">52</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   <span class=\"hljs-keyword\">if</span> phase == <span class=\"hljs-string\">'train'</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">53</span></pre></td><td class=\"code\"><pre><span class=\"line\">                       </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">54</span></pre></td><td class=\"code\"><pre><span class=\"line\">                       loss.backward()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">55</span></pre></td><td class=\"code\"><pre><span class=\"line\">                       optimizer.step()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">56</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">57</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"hljs-comment\"># statistics</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">58</span></pre></td><td class=\"code\"><pre><span class=\"line\">               running_loss += loss.item() * inputs.size(<span class=\"hljs-number\">0</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">59</span></pre></td><td class=\"code\"><pre><span class=\"line\">               label_corrects += torch.sum(torch.max(outputs, <span class=\"hljs-number\">1</span>)[<span class=\"hljs-number\">1</span>] == torch.max(label, <span class=\"hljs-number\">1</span>)[<span class=\"hljs-number\">1</span>]) <span class=\"hljs-comment\">#返回每一行中最大值的那个元素，且返回其索引（返回最大元素在这一行的列索引）</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">60</span></pre></td><td class=\"code\"><pre><span class=\"line\">               pred_choice = torch.max(outputs, <span class=\"hljs-number\">1</span>)[<span class=\"hljs-number\">1</span>]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">61</span></pre></td><td class=\"code\"><pre><span class=\"line\">               target = torch.max(label, <span class=\"hljs-number\">1</span>)[<span class=\"hljs-number\">1</span>]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">62</span></pre></td><td class=\"code\"><pre><span class=\"line\">               scores = pred_choice.cpu().tolist()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">63</span></pre></td><td class=\"code\"><pre><span class=\"line\">               tar = target.cpu().tolist()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">64</span></pre></td><td class=\"code\"><pre><span class=\"line\">               total_scores = total_scores + scores</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">65</span></pre></td><td class=\"code\"><pre><span class=\"line\">               total_tar = total_tar + tar</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">66</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">67</span></pre></td><td class=\"code\"><pre><span class=\"line\">               tmp_tp = <span class=\"hljs-number\">0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">68</span></pre></td><td class=\"code\"><pre><span class=\"line\">               tmp_tn = <span class=\"hljs-number\">0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">69</span></pre></td><td class=\"code\"><pre><span class=\"line\">               tmp_fn = <span class=\"hljs-number\">0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">70</span></pre></td><td class=\"code\"><pre><span class=\"line\">               tmp_fp = <span class=\"hljs-number\">0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">71</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"hljs-keyword\">if</span> pred_choice.numel()!= target.numel():</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">72</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   print(<span class=\"hljs-string\">\"error\"</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">73</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> range(pred_choice.numel()):</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">74</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   <span class=\"hljs-keyword\">if</span> pred_choice[i] == <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">and</span> target[i] == <span class=\"hljs-number\">1</span> :</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">75</span></pre></td><td class=\"code\"><pre><span class=\"line\">                       tmp_tp = tmp_tp + <span class=\"hljs-number\">1</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">76</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   <span class=\"hljs-keyword\">elif</span> pred_choice[i] == <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">and</span> target[i] == <span class=\"hljs-number\">0</span> :</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">77</span></pre></td><td class=\"code\"><pre><span class=\"line\">                       tmp_tn = tmp_tn + <span class=\"hljs-number\">1</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">78</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   <span class=\"hljs-keyword\">elif</span> pred_choice[i] == <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">and</span> target[i] == <span class=\"hljs-number\">1</span> :</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">79</span></pre></td><td class=\"code\"><pre><span class=\"line\">                       tmp_fn = tmp_fn + <span class=\"hljs-number\">1</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">80</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   <span class=\"hljs-keyword\">elif</span> pred_choice[i] == <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">and</span> target[i] == <span class=\"hljs-number\">0</span> :</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">81</span></pre></td><td class=\"code\"><pre><span class=\"line\">                       tmp_fp = tmp_fp + <span class=\"hljs-number\">1</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">82</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"hljs-comment\"># TP    both predict and label are 1</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">83</span></pre></td><td class=\"code\"><pre><span class=\"line\">               TP += tmp_tp</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">84</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"hljs-comment\"># TN    both predict and label are 0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">85</span></pre></td><td class=\"code\"><pre><span class=\"line\">               TN += tmp_tn</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">86</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"hljs-comment\"># FN    predict 0 label 1</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">87</span></pre></td><td class=\"code\"><pre><span class=\"line\">               FN += tmp_fn</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">88</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"hljs-comment\"># FP    predict 1 label 0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">89</span></pre></td><td class=\"code\"><pre><span class=\"line\">               FP += tmp_fp</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">90</span></pre></td><td class=\"code\"><pre><span class=\"line\">           epoch_loss = running_loss / dataset_sizes[phase]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">91</span></pre></td><td class=\"code\"><pre><span class=\"line\">           p = TP / (TP + FP)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">92</span></pre></td><td class=\"code\"><pre><span class=\"line\">           r = TP / (TP + FN)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">93</span></pre></td><td class=\"code\"><pre><span class=\"line\">           F1 = <span class=\"hljs-number\">2</span> * r * p / (r + p)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">94</span></pre></td><td class=\"code\"><pre><span class=\"line\">           acc = (TP + TN) / (TP + TN + FP + FN)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">95</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">96</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"hljs-comment\">### draw ROC curce</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">97</span></pre></td><td class=\"code\"><pre><span class=\"line\">           tpr = TP/(TP+FN)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">98</span></pre></td><td class=\"code\"><pre><span class=\"line\">           fpr = FP/(FP+TN)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">99</span></pre></td><td class=\"code\"><pre><span class=\"line\">           tnr = TN/(FP+TN)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">100</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">101</span></pre></td><td class=\"code\"><pre><span class=\"line\">           total_scores = np.array(total_scores)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">102</span></pre></td><td class=\"code\"><pre><span class=\"line\">           total_tar = np.array(total_tar)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">103</span></pre></td><td class=\"code\"><pre><span class=\"line\">           fpr, tpr, thresholds = roc_curve(total_tar, total_scores)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">104</span></pre></td><td class=\"code\"><pre><span class=\"line\">           roc_auc = auc(fpr, tpr) </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">105</span></pre></td><td class=\"code\"><pre><span class=\"line\">           plt.title(<span class=\"hljs-string\">'ROC'</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">106</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"hljs-keyword\">if</span> roc_auc &gt; best_auc:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">107</span></pre></td><td class=\"code\"><pre><span class=\"line\">               best_auc = roc_auc</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">108</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"hljs-keyword\">if</span> epoch &lt; num_epochs <span class=\"hljs-number\">-1</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">109</span></pre></td><td class=\"code\"><pre><span class=\"line\">               plt.plot(fpr, tpr,<span class=\"hljs-string\">'b'</span>,label=<span class=\"hljs-string\">'AUC = %0.4f'</span>% roc_auc)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">110</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"hljs-keyword\">if</span> epoch == num_epochs <span class=\"hljs-number\">-1</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">111</span></pre></td><td class=\"code\"><pre><span class=\"line\">               plt.plot(fpr, tpr, color=<span class=\"hljs-string\">'darkorange'</span>, label=<span class=\"hljs-string\">'MAX AUC = %0.4f'</span>% best_auc) </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">112</span></pre></td><td class=\"code\"><pre><span class=\"line\">           plt.legend(loc=<span class=\"hljs-string\">'lower right'</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">113</span></pre></td><td class=\"code\"><pre><span class=\"line\">           plt.plot([<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">1</span>],[<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">1</span>],<span class=\"hljs-string\">'r--'</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">114</span></pre></td><td class=\"code\"><pre><span class=\"line\">           plt.ylabel(<span class=\"hljs-string\">'TPR'</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">115</span></pre></td><td class=\"code\"><pre><span class=\"line\">           plt.xlabel(<span class=\"hljs-string\">'FPR'</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">116</span></pre></td><td class=\"code\"><pre><span class=\"line\">           plt.show()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">117</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">118</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"hljs-comment\">#print('&#123;&#125; p: &#123;:.4f&#125; '.format(phase,p ))</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">119</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"hljs-comment\">#print('&#123;&#125; r: &#123;:.4f&#125; '.format(phase,r ))</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">120</span></pre></td><td class=\"code\"><pre><span class=\"line\">           print(<span class=\"hljs-string\">'&#123;&#125; F1: &#123;:.4f&#125; '</span>.format(phase,F1 ))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">121</span></pre></td><td class=\"code\"><pre><span class=\"line\">           print(<span class=\"hljs-string\">'&#123;&#125; accuracy: &#123;:.4f&#125; '</span>.format(phase,acc ))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">122</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">123</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"hljs-keyword\">if</span> phase == <span class=\"hljs-string\">'val'</span> <span class=\"hljs-keyword\">and</span> epoch_loss &lt; best_loss:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">124</span></pre></td><td class=\"code\"><pre><span class=\"line\">               print(<span class=\"hljs-string\">'saving with loss of &#123;&#125;'</span>.format(epoch_loss),</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">125</span></pre></td><td class=\"code\"><pre><span class=\"line\">                     <span class=\"hljs-string\">'improved over previous &#123;&#125;'</span>.format(best_loss))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">126</span></pre></td><td class=\"code\"><pre><span class=\"line\">               best_loss = epoch_loss</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">127</span></pre></td><td class=\"code\"><pre><span class=\"line\">               best_model_wts = copy.deepcopy(model.state_dict())</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">128</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"hljs-comment\">#torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/bert_model_test_loss.pth')</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">129</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"hljs-keyword\">if</span> F1 &gt; best_f1:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">130</span></pre></td><td class=\"code\"><pre><span class=\"line\">               best_f1 = F1</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">131</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"hljs-keyword\">if</span> phase == <span class=\"hljs-string\">'val'</span> <span class=\"hljs-keyword\">and</span> acc &gt; best_acc_test:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">132</span></pre></td><td class=\"code\"><pre><span class=\"line\">               best_acc_test = acc</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">133</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"hljs-keyword\">if</span> phase == <span class=\"hljs-string\">'train'</span> <span class=\"hljs-keyword\">and</span> acc &gt; best_acc_train:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">134</span></pre></td><td class=\"code\"><pre><span class=\"line\">               best_acc_train = acc</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">135</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"hljs-comment\">#best_model_wts = copy.deepcopy(model.state_dict())</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">136</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"hljs-comment\">#torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/bert_model_test_f1.pth')</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">137</span></pre></td><td class=\"code\"><pre><span class=\"line\">       print()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">138</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">139</span></pre></td><td class=\"code\"><pre><span class=\"line\">   time_elapsed = time.time() - since</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">140</span></pre></td><td class=\"code\"><pre><span class=\"line\">   print(<span class=\"hljs-string\">'Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s'</span>.format(</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">141</span></pre></td><td class=\"code\"><pre><span class=\"line\">       time_elapsed // <span class=\"hljs-number\">60</span>, time_elapsed % <span class=\"hljs-number\">60</span>))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">142</span></pre></td><td class=\"code\"><pre><span class=\"line\">   print(<span class=\"hljs-string\">\"Parament setting: \"</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">143</span></pre></td><td class=\"code\"><pre><span class=\"line\">   print(<span class=\"hljs-string\">\"cased: \"</span>,par_cased)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">144</span></pre></td><td class=\"code\"><pre><span class=\"line\">   print(<span class=\"hljs-string\">\"cleanup: \"</span>,par_cleanup)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">145</span></pre></td><td class=\"code\"><pre><span class=\"line\">   print(<span class=\"hljs-string\">\"eda: \"</span>,par_eda)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">146</span></pre></td><td class=\"code\"><pre><span class=\"line\">   print(<span class=\"hljs-string\">'Best train Acc: &#123;:4f&#125;'</span>.format(float(best_acc_train)))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">147</span></pre></td><td class=\"code\"><pre><span class=\"line\">   print(<span class=\"hljs-string\">'Best test Acc: &#123;:4f&#125;'</span>.format(float(best_acc_test)))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">148</span></pre></td><td class=\"code\"><pre><span class=\"line\">   print(<span class=\"hljs-string\">'Best f1 score: &#123;:4f&#125;'</span>.format(float(best_f1)))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">149</span></pre></td><td class=\"code\"><pre><span class=\"line\">   <span class=\"hljs-comment\"># load best model weights</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">150</span></pre></td><td class=\"code\"><pre><span class=\"line\">   model.load_state_dict(best_model_wts)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">151</span></pre></td><td class=\"code\"><pre><span class=\"line\">   <span class=\"hljs-keyword\">return</span> model</span></pre></td></tr></table></figure>\n<h3 id=\"4-Final-output\"><a href=\"#4-Final-output\" class=\"headerlink\" title=\"4. Final output\"></a>4. Final output</h3><h4 id=\"4-1-Model-details\"><a href=\"#4-1-Model-details\" class=\"headerlink\" title=\"4.1 Model details\"></a>4.1 Model details</h4><figure class=\"highlight python hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">print(model)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">model.to(device)</span></pre></td></tr></table></figure>\n<h4 id=\"4-2-F1-and-other-details\"><a href=\"#4-2-F1-and-other-details\" class=\"headerlink\" title=\"4.2 F1 and other details\"></a>4.2 F1 and other details</h4><figure class=\"highlight python hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">model_ft1 = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=<span class=\"hljs-number\">10</span>)</span></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<p><strong>Description</strong>: Use Google BERT on fake_or_real news dataset with best f1 score: 0.986</p>","more":"<h2 id=\"Showcase\"><a href=\"#Showcase\" class=\"headerlink\" title=\"Showcase\"></a>Showcase</h2><h3 id=\"1-Pipeline\"><a href=\"#1-Pipeline\" class=\"headerlink\" title=\"1. Pipeline\"></a>1. Pipeline</h3><p><img src=\"https://i.loli.net/2019/08/23/P8Seo5EvmpZfAOT.png\" alt=\"Pipeline\"></p>\n<p>First, we got the raw text with title, text and label. Then we use some methods of data processing to operate the text. After the data processing, we put them into the Bert model to train the data, which includes the Bert itself and the Classifier, here I used the feed-forward neural network and add a softmax layer to normalize the output. In the end, we got the predication and other details.</p>\n<h3 id=\"2-Part1-Data-processing\"><a href=\"#2-Part1-Data-processing\" class=\"headerlink\" title=\"2. Part1: Data processing\"></a>2. Part1: Data processing</h3><p>(1) <strong>Drop non-sentence</strong></p>\n<pre><code>• Type1: http[s]://www.claritypress.com/LendmanIII.html\n• Type2: [email protected]\n• Type3: @EP_President #EP_President \n• Type4: **Want FOX News First * in your inbox every day? Sign up here.**\n• Type5: ☮️ 💚 🌍 etc</code></pre><p>(2) <strong>EDA methods</strong></p>\n<pre><code>• Insert word by BERT similarity (Random Insertion)\n• Substitute word by BERT similarity (Synonym Replacement)</code></pre><p>AS for the first part, I use two methods: drop non-sentence and some EDA methods. I read some text within the fake_or_real news and I find that it contains various type of non-sentence, so I use the regular expression to drop them. And then, I use random insertion and synonym replacement to augment the text.</p>\n<h3 id=\"3-Part2-Bert-Model\"><a href=\"#3-Part2-Bert-Model\" class=\"headerlink\" title=\"3. Part2: Bert Model\"></a>3. Part2: Bert Model</h3><p><img src=\"https://i.loli.net/2019/08/23/pFv1K86WUcafyDI.png\" alt=\"Bert model\"></p>\n<p>As for the second part, we put the text which we got from the first part into the bert model. The Bert model uses 12 encode layers and finally classifier to get the output.</p>\n<h3 id=\"4-Part3-Result\"><a href=\"#4-Part3-Result\" class=\"headerlink\" title=\"4. Part3: Result\"></a>4. Part3: Result</h3><p><img src=\"https://i.loli.net/2019/08/23/aGTYdfz2cul1pj3.png\" alt=\"Result\"></p>\n<p>In the end, we combine different methods of data processing and u can see the f1 score from the chart. We get the best f1 score(0.986) from Cased text + drop sentence.</p>\n<h3 id=\"5-Part4-Reference\"><a href=\"#5-Part4-Reference\" class=\"headerlink\" title=\"5. Part4: Reference\"></a>5. Part4: Reference</h3><p>(1) <strong>EDA</strong>: </p>\n<pre><code>•Knowledge: https://towardsdatascience.com/these-are-the-easiest-data-augmentation-techniques-in-natural-language-processing-you-can-think-of-88e393fd610\n•Implemenation: https://github.com/makcedward/nlpaug</code></pre><p>(2) <strong>Can’t remove stopwords</strong>: </p>\n<pre><code>•Deeper Text Understanding for IR with Contextual NeuralLanguage Modeling: https://arxiv.org/pdf/1905.09217\n•Understanding the Behaviors of BERT in Ranking : https://arxiv.org/pdf/1904.07531</code></pre><p>(3) <strong>Bert by Pytorch</strong>:</p>\n<pre><code>•https://pytorch.org/hub/huggingface_pytorch-pretrained-bert_bert/</code></pre><p>(4) <strong>Bert Demo</strong>:</p>\n<pre><code>https://github.com/sugi-chan/custom_bert_pipeline</code></pre><p>(5) <strong>Dataset</strong>:</p>\n<pre><code>https://cbmm.mit.edu/sites/default/files/publications/fake-news-paper-NIPS.pdf</code></pre><p>I learn the EDA from the two web site and through two articles, I learn that we shouldn’t remove Stopwords which otherwise will destroy the context of sentence. The end is implementation of BERT with Pytorch and the Bert model I learned.</p>\n<h2 id=\"Implementation\"><a href=\"#Implementation\" class=\"headerlink\" title=\"Implementation\"></a>Implementation</h2><h3 id=\"1-Preparation\"><a href=\"#1-Preparation\" class=\"headerlink\" title=\"1. Preparation\"></a>1. Preparation</h3><h4 id=\"1-1-Set-parameters-and-install-and-load-required-package\"><a href=\"#1-1-Set-parameters-and-install-and-load-required-package\" class=\"headerlink\" title=\"1.1 Set parameters and install and load required package\"></a>1.1 Set parameters and install and load required package</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">### parameters Setting</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">par_cased = <span class=\"number\">0</span> <span class=\"comment\"># default cased, 0 means uncased</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">par_cleanup = <span class=\"number\">1</span> <span class=\"comment\"># default cleanup, 0 means non-cleanup</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">par_eda = <span class=\"number\">0</span> <span class=\"comment\"># default eda, 0 means non-eda</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">pip install pytorch_pretrained_bert nlpaug bert matplotlib sklearn librosa SoundFile nltk pandas</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> __future__ <span class=\"keyword\">import</span> print_function, division</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torch.optim <span class=\"keyword\">import</span> lr_scheduler</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">14</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">15</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> datasets, models, transforms</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">16</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">17</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> time</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">18</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">19</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> copy</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">20</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset, DataLoader</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">21</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">22</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> random <span class=\"keyword\">import</span> randrange</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">23</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">24</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> roc_curve, auc</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">25</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> nlpaug.augmenter.char <span class=\"keyword\">as</span> nac</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">26</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#import nlpaug.augmenter.word as naw</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">27</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> nlpaug.flow <span class=\"keyword\">as</span> naf</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">28</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> nlpaug.util <span class=\"keyword\">import</span> Action</span></pre></td></tr></table></figure>\n<h4 id=\"1-2-Set-tokenizer\"><a href=\"#1-2-Set-tokenizer\" class=\"headerlink\" title=\"1.2 Set tokenizer\"></a>1.2 Set tokenizer</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> pytorch_pretrained_bert <span class=\"keyword\">import</span> BertTokenizer, BertModel, BertForMaskedLM</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># OPTIONAL: if you want to have more information on what's happening, activate the logger as follows</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> logging</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">logging.basicConfig(level=logging.INFO)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Load pre-trained model tokenizer (vocabulary)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> par_cased ==<span class=\"number\">1</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">    tokenizer = BertTokenizer.from_pretrained(<span class=\"string\">'bert-base-cased'</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">else</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">    tokenizer = BertTokenizer.from_pretrained(<span class=\"string\">'bert-base-uncased'</span>)</span></pre></td></tr></table></figure>\n<h4 id=\"1-3-Define-Bert-Config\"><a href=\"#1-3-Define-Bert-Config\" class=\"headerlink\" title=\"1.3 Define Bert Config\"></a>1.3 Define Bert Config</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BertLayerNorm</span><span class=\"params\">(nn.Module)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, hidden_size, eps=<span class=\"number\">1e-12</span>)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">            <span class=\"string\">\"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">            \"\"\"</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">            super(BertLayerNorm, self).__init__()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">            self.weight = nn.Parameter(torch.ones(hidden_size))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">            self.bias = nn.Parameter(torch.zeros(hidden_size))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">            self.variance_epsilon = eps</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">            u = x.mean(<span class=\"number\">-1</span>, keepdim=<span class=\"literal\">True</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">            s = (x - u).pow(<span class=\"number\">2</span>).mean(<span class=\"number\">-1</span>, keepdim=<span class=\"literal\">True</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\">            x = (x - u) / torch.sqrt(s + self.variance_epsilon)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">14</span></pre></td><td class=\"code\"><pre><span class=\"line\">            <span class=\"keyword\">return</span> self.weight * x + self.bias</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">15</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">16</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">17</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BertForSequenceClassification</span><span class=\"params\">(nn.Module)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">18</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"string\">\"\"\"BERT model for classification.</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">19</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">    This module is composed of the BERT model with a linear layer on top of</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">20</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">    the pooled output.</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">21</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">    Params:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">22</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        `config`: a BertConfig class instance with the configuration to build a new model.</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">23</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        `num_labels`: the number of classes for the classifier. Default = 2.</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">24</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">    Inputs:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">25</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">26</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">            with the word token indices in the vocabulary. Items in the batch should begin with the special \"CLS\" token. (see the tokens preprocessing logic in the scripts</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">27</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">28</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">29</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">30</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">            a `sentence B` token (see BERT paper for more details).</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">31</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">32</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">33</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">            input sequence length in the current batch. It's the mask that we typically use for attention when</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">34</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">            a batch has varying length sentences.</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">35</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">36</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">            with indices selected in [0, ..., num_labels].</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">37</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">    Outputs:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">38</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        if `labels` is not `None`:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">39</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">            Outputs the CrossEntropy classification loss of the output with the labels.</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">40</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        if `labels` is `None`:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">41</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">            Outputs the classification logits of shape [batch_size, num_labels].</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">42</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">    Example usage:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">43</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">    ```python</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">44</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">    # Already been converted into WordPiece token ids</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">45</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">46</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">47</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">48</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">    config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">49</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">50</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">    num_labels = 2</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">51</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">    model = BertForSequenceClassification(config, num_labels)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">52</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">    logits = model(input_ids, token_type_ids, input_mask)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">53</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\"></span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">54</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">    def __init__(self, num_labels=2):</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">55</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        super(BertForSequenceClassification, self).__init__()</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">56</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        self.num_labels = num_labels</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">57</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        if par_cased ==1:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">58</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">            self.bert = BertModel.from_pretrained('bert-base-cased')</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">59</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        else:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">60</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">            self.bert = BertModel.from_pretrained('bert-base-uncased')</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">61</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        self.dropout = nn.Dropout(config.hidden_dropout_prob)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">62</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        self.classifier = nn.Linear(config.hidden_size, num_labels)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">63</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        nn.init.xavier_normal_(self.classifier.weight)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">64</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">65</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">66</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        pooled_output = self.dropout(pooled_output)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">67</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        logits = self.classifier(pooled_output)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">68</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\"></span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">69</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        return logits</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">70</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">    def freeze_bert_encoder(self):</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">71</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        for param in self.bert.parameters():</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">72</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">            param.requires_grad = False</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">73</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">    </span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">74</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">    def unfreeze_bert_encoder(self):</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">75</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        for param in self.bert.parameters():</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">76</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">            param.requires_grad = True</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">77</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\"></span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">78</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">from pytorch_pretrained_bert import BertConfig</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">79</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\"></span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">80</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">81</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">82</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\"></span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">83</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">num_labels = 2</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">84</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">model = BertForSequenceClassification(num_labels)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">85</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\"></span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">86</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\"># Convert inputs to PyTorch tensors</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">87</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">#tokens_tensor = torch.tensor([tokenizer.convert_tokens_to_ids(zz)])</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">88</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\"></span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">89</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">#logits = model(tokens_tensor)</span></span></pre></td></tr></table></figure>\n\n<h3 id=\"2-Dataset-Processing\"><a href=\"#2-Dataset-Processing\" class=\"headerlink\" title=\"2. Dataset Processing\"></a>2. Dataset Processing</h3><h4 id=\"2-1-Read-the-data-and-convert-label-into-binary-text\"><a href=\"#2-1-Read-the-data-and-convert-label-into-binary-text\" class=\"headerlink\" title=\"2.1 Read the data and convert label into binary text\"></a>2.1 Read the data and convert label into binary text</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">dat = pd.read_csv(<span class=\"string\">'/data/fake_or_real_news.csv'</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">dat.head()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">dat = dat.drop(columns=[<span class=\"string\">'Unnamed: 0'</span>, <span class=\"string\">'title_vectors'</span>])</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(dat)):</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"keyword\">if</span> dat.loc[i, <span class=\"string\">'label'</span>] == <span class=\"string\">\"REAL\"</span>: <span class=\"comment\">#REAL equal 0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">        dat.loc[i, <span class=\"string\">'label'</span>] = <span class=\"number\">0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"keyword\">elif</span> dat.loc[i, <span class=\"string\">'label'</span>] == <span class=\"string\">\"FAKE\"</span>: <span class=\"comment\">#FAKE equal 1</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">        dat.loc[i, <span class=\"string\">'label'</span>] = <span class=\"number\">1</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"keyword\">if</span> dat.loc[i, <span class=\"string\">'text'</span>] == <span class=\"string\">\"\"</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">        dat = dat.drop([i])</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\">dat.head()</span></pre></td></tr></table></figure>\n<h4 id=\"2-2-Combine-the-title-and-text\"><a href=\"#2-2-Combine-the-title-and-text\" class=\"headerlink\" title=\"2.2 Combine the title and text\"></a>2.2 Combine the title and text</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">dat_plus = dat.copy()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">dat_plus[<span class=\"string\">'title_text'</span>]=dat[<span class=\"string\">'title'</span>]+<span class=\"string\">'. '</span>+dat[<span class=\"string\">'text'</span>]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">dat_plus = dat_plus.drop(columns=[<span class=\"string\">'title'</span>, <span class=\"string\">'text'</span>])</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">dat_plus[<span class=\"string\">'title_text'</span>]</span></pre></td></tr></table></figure>\n<h4 id=\"2-3-Use-regular-expression-to-drop-non-sentence\"><a href=\"#2-3-Use-regular-expression-to-drop-non-sentence\" class=\"headerlink\" title=\"2.3 Use regular expression to drop non-sentence\"></a>2.3 Use regular expression to drop non-sentence</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> re</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">cleanup</span><span class=\"params\">(text)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"keyword\">if</span> par_cased == <span class=\"number\">0</span>: <span class=\"comment\"># transfer into lower text if par_cased is false</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">        text = text.lower()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = re.sub(<span class=\"string\">r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'</span>,<span class=\"string\">''</span>,text) <span class=\"comment\"># drop http[s]://*</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = re.sub(<span class=\"string\">u\"\\\\&#123;.*?&#125;|\\\\[.*?]\"</span>,<span class=\"string\">''</span>,text) <span class=\"comment\"># drop [*]</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = re.sub(<span class=\"string\">u\"\\(\\@.*?\\s\"</span>, <span class=\"string\">''</span>, text) <span class=\"comment\"># drop something like (@EP_President)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = re.sub(<span class=\"string\">u\"\\@.*?\\s\"</span>, <span class=\"string\">''</span>, text) <span class=\"comment\"># drop soething liek @EP_President</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = re.sub(<span class=\"string\">u\"\\#.*?\\s\"</span>, <span class=\"string\">''</span>, text) <span class=\"comment\"># drop something like #EP_President (maybe hashtag)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = re.sub(<span class=\"string\">u\"\\© .*?\\s\"</span>, <span class=\"string\">''</span>, text) <span class=\"comment\"># drop something like © EP_President</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = re.sub(<span class=\"string\">r'pic.tw(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+#]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'</span>,<span class=\"string\">''</span>,text) <span class=\"comment\"># drop pic.twitter.com/*</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = re.sub(<span class=\"string\">u\"\\*\\*\"</span>, <span class=\"string\">''</span>, text) <span class=\"comment\"># drop something like **Want FOX News First * in your inbox every day? Sign up here.**</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = re.sub(<span class=\"string\">u\"|•|☮️|💚|🌍|😍|♦|☢\"</span>, <span class=\"string\">''</span>, text) <span class=\"comment\"># drop something like  and • etc</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">14</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"keyword\">return</span>(text)</span></pre></td></tr></table></figure>\n<h4 id=\"2-4-Use-EDA-method-to-augment-the-text\"><a href=\"#2-4-Use-EDA-method-to-augment-the-text\" class=\"headerlink\" title=\"2.4 Use EDA method to augment the text\"></a>2.4 Use EDA method to augment the text</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> nlpaug.augmenter.char <span class=\"keyword\">as</span> nac</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> nlpaug.augmenter.word <span class=\"keyword\">as</span> naw</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> nlpaug.flow <span class=\"keyword\">as</span> nafc</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> nlpaug.util <span class=\"keyword\">import</span> Action</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> nltk</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">nltk.download(<span class=\"string\">'punkt'</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> par_cased ==<span class=\"number\">1</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">    aug = naf.Sequential([</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">        naw.BertAug(action=<span class=\"string\">\"substitute\"</span>, aug_p=<span class=\"number\">0.8</span>, aug_n=<span class=\"number\">20</span>,model_path=<span class=\"string\">'bert-base-cased'</span>,tokenizer_path=<span class=\"string\">'bert-base-cased'</span>),</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">        naw.BertAug(action=<span class=\"string\">\"insert\"</span>, aug_p=<span class=\"number\">0.1</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\">    ])</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">14</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">else</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">15</span></pre></td><td class=\"code\"><pre><span class=\"line\">    aug = naf.Sequential([</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">16</span></pre></td><td class=\"code\"><pre><span class=\"line\">        naw.BertAug(action=<span class=\"string\">\"substitute\"</span>, aug_p=<span class=\"number\">0.8</span>, aug_n=<span class=\"number\">20</span>,model_path=<span class=\"string\">'bert-base-uncased'</span>,tokenizer_path=<span class=\"string\">'bert-base-uncased'</span>),</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">17</span></pre></td><td class=\"code\"><pre><span class=\"line\">        naw.BertAug(action=<span class=\"string\">\"insert\"</span>, aug_p=<span class=\"number\">0.1</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">18</span></pre></td><td class=\"code\"><pre><span class=\"line\">    ])</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">19</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">aug_text</span><span class=\"params\">(text)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">20</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = aug.augment(text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">21</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"keyword\">return</span>(text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">22</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> nltk.tokenize <span class=\"keyword\">import</span> sent_tokenize</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">23</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sentence_token_nltk</span><span class=\"params\">(text)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">24</span></pre></td><td class=\"code\"><pre><span class=\"line\">    sent_tokenize_list = sent_tokenize(text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">25</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"keyword\">return</span> sent_tokenize_list</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">26</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">eda_text</span><span class=\"params\">(text)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">27</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"keyword\">if</span> len(text) &lt; <span class=\"number\">2</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">28</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"keyword\">return</span>(text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">29</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"comment\"># split text into sentences</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">30</span></pre></td><td class=\"code\"><pre><span class=\"line\">    text = sentence_token_nltk(text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">31</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"keyword\">if</span> len(text) &lt;= <span class=\"number\">1</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">32</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"keyword\">return</span>(text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">33</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"keyword\">if</span> len(text) == <span class=\"number\">2</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">34</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(text)):</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">35</span></pre></td><td class=\"code\"><pre><span class=\"line\">            <span class=\"keyword\">if</span> i == <span class=\"number\">0</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">36</span></pre></td><td class=\"code\"><pre><span class=\"line\">                tmp_text = text[i]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">37</span></pre></td><td class=\"code\"><pre><span class=\"line\">            <span class=\"keyword\">else</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">38</span></pre></td><td class=\"code\"><pre><span class=\"line\">                tmp_text += text[i]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">39</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"keyword\">return</span>(tmp_text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">40</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"comment\"># operate prior 3 sentences</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">41</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">3</span>):</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">42</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"keyword\">if</span> i == <span class=\"number\">0</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">43</span></pre></td><td class=\"code\"><pre><span class=\"line\">            tmp_text = text[i]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">44</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"keyword\">else</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">45</span></pre></td><td class=\"code\"><pre><span class=\"line\">            tmp_text += text[i]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">46</span></pre></td><td class=\"code\"><pre><span class=\"line\">    zz = tokenizer.tokenize(tmp_text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">47</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"comment\"># operate proper sentences</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">48</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"keyword\">if</span> len(zz) &lt;= <span class=\"number\">500</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">49</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"comment\">#print(len(zz))</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">50</span></pre></td><td class=\"code\"><pre><span class=\"line\">        tmp_text = aug_text(tmp_text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">51</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"comment\"># conbine prior 3 sentences and rest sentences</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">52</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(len(text)<span class=\"number\">-3</span>):</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">53</span></pre></td><td class=\"code\"><pre><span class=\"line\">        tmp_text += text[j+<span class=\"number\">3</span>]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">54</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"keyword\">return</span>(tmp_text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">55</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">56</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> par_eda == <span class=\"number\">1</span>: <span class=\"comment\"># use eda to operate sentences when par_eda is true</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">57</span></pre></td><td class=\"code\"><pre><span class=\"line\">  <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(dat_plus[<span class=\"string\">'title_text'</span>])):</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">58</span></pre></td><td class=\"code\"><pre><span class=\"line\">      <span class=\"keyword\">if</span> i%<span class=\"number\">6</span> == <span class=\"number\">1</span>:       </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">59</span></pre></td><td class=\"code\"><pre><span class=\"line\">          <span class=\"comment\">#print(i)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">60</span></pre></td><td class=\"code\"><pre><span class=\"line\">          dat_plus[<span class=\"string\">'title_text'</span>][i] = copy.deepcopy(eda_text(dat_plus[<span class=\"string\">'title_text'</span>][i]))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">61</span></pre></td><td class=\"code\"><pre><span class=\"line\">          dat_plus[<span class=\"string\">'title_text'</span>][i] = <span class=\"string\">\"\"</span>.join(dat_plus[<span class=\"string\">'title_text'</span>][i])</span></pre></td></tr></table></figure>\n<h3 id=\"3-Google-Bert\"><a href=\"#3-Google-Bert\" class=\"headerlink\" title=\"3. Google Bert\"></a>3. Google Bert</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#F.softmax(logits,dim=1)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> par_cleanup == <span class=\"number\">1</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">    X = dat_plus[<span class=\"string\">'title_text'</span>].apply(cleanup)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">else</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">    X = dat_plus[<span class=\"string\">'title_text'</span>]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">y = dat_plus[<span class=\"string\">'label'</span>]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class=\"number\">0.3</span>, random_state=<span class=\"number\">42</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\">X_train = X_train.values.tolist()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">14</span></pre></td><td class=\"code\"><pre><span class=\"line\">X_test = X_test.values.tolist()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">15</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">16</span></pre></td><td class=\"code\"><pre><span class=\"line\">y_train = pd.get_dummies(y_train).values.tolist() <span class=\"comment\"># convert to one-hot encoding</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">17</span></pre></td><td class=\"code\"><pre><span class=\"line\">y_test = pd.get_dummies(y_test).values.tolist()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">18</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">19</span></pre></td><td class=\"code\"><pre><span class=\"line\">max_seq_length = <span class=\"number\">256</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">20</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">text_dataset</span><span class=\"params\">(Dataset)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">21</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self,x_y_list, transform=None)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">22</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">23</span></pre></td><td class=\"code\"><pre><span class=\"line\">        self.x_y_list = x_y_list</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">24</span></pre></td><td class=\"code\"><pre><span class=\"line\">        self.transform = transform</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">25</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">26</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__getitem__</span><span class=\"params\">(self,index)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">27</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">28</span></pre></td><td class=\"code\"><pre><span class=\"line\">        tokenized_title_text = tokenizer.tokenize(self.x_y_list[<span class=\"number\">0</span>][index])</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">29</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">30</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"keyword\">if</span> len(tokenized_title_text) &gt; max_seq_length:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">31</span></pre></td><td class=\"code\"><pre><span class=\"line\">            tokenized_title_text = tokenized_title_text[:max_seq_length]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">32</span></pre></td><td class=\"code\"><pre><span class=\"line\">            </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">33</span></pre></td><td class=\"code\"><pre><span class=\"line\">        ids_title_text  = tokenizer.convert_tokens_to_ids(tokenized_title_text) <span class=\"comment\">#tokens-&gt;input_ids</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">34</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">35</span></pre></td><td class=\"code\"><pre><span class=\"line\">        padding = [<span class=\"number\">0</span>] * (max_seq_length - len(ids_title_text))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">36</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">37</span></pre></td><td class=\"code\"><pre><span class=\"line\">        ids_title_text += padding <span class=\"comment\"># use padding to make the same ids</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">38</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">39</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"keyword\">assert</span> len(ids_title_text) == max_seq_length</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">40</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">41</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"comment\">#print(ids_title_text)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">42</span></pre></td><td class=\"code\"><pre><span class=\"line\">        ids_title_text = torch.tensor(ids_title_text)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">43</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">44</span></pre></td><td class=\"code\"><pre><span class=\"line\">        label = self.x_y_list[<span class=\"number\">1</span>][index] <span class=\"comment\"># color        </span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">45</span></pre></td><td class=\"code\"><pre><span class=\"line\">        list_of_labels = [torch.from_numpy(np.array(label))]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">46</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">47</span></pre></td><td class=\"code\"><pre><span class=\"line\">        </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">48</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"keyword\">return</span> ids_title_text, list_of_labels[<span class=\"number\">0</span>]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">49</span></pre></td><td class=\"code\"><pre><span class=\"line\">    </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">50</span></pre></td><td class=\"code\"><pre><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__len__</span><span class=\"params\">(self)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">51</span></pre></td><td class=\"code\"><pre><span class=\"line\">        <span class=\"keyword\">return</span> len(self.x_y_list[<span class=\"number\">0</span>])</span></pre></td></tr></table></figure>\n<h4 id=\"3-1-Create-data-dictionary\"><a href=\"#3-1-Create-data-dictionary\" class=\"headerlink\" title=\"3.1 Create data dictionary\"></a>3.1 Create data dictionary</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">batch_size = <span class=\"number\">16</span> <span class=\"comment\"># divide into 16 batches</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">train_lists = [X_train, y_train]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">test_lists = [X_test, y_test]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">training_dataset = text_dataset(x_y_list = train_lists )</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">test_dataset = text_dataset(x_y_list = test_lists )</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">dataloaders_dict = &#123;<span class=\"string\">'train'</span>: torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=<span class=\"literal\">True</span>, num_workers=<span class=\"number\">0</span>),</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   <span class=\"string\">'val'</span>:torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=<span class=\"literal\">True</span>, num_workers=<span class=\"number\">0</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">                  &#125;                </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\">dataset_sizes = &#123;<span class=\"string\">'train'</span>:len(train_lists[<span class=\"number\">0</span>]),</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">14</span></pre></td><td class=\"code\"><pre><span class=\"line\">                <span class=\"string\">'val'</span>:len(test_lists[<span class=\"number\">0</span>])&#125;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">15</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">16</span></pre></td><td class=\"code\"><pre><span class=\"line\">device = torch.device(<span class=\"string\">\"cuda:0\"</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">\"cpu\"</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">17</span></pre></td><td class=\"code\"><pre><span class=\"line\">print(device)</span></pre></td></tr></table></figure>\n\n<h4 id=\"3-2-Define-the-train-model\"><a href=\"#3-2-Define-the-train-model\" class=\"headerlink\" title=\"3.2 Define the train model\"></a>3.2 Define the train model</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">train_model</span><span class=\"params\">(model, criterion, optimizer, scheduler, num_epochs=<span class=\"number\">25</span>)</span>:</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">   since = time.time()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">   print(<span class=\"string\">'starting'</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">   best_model_wts = copy.deepcopy(model.state_dict())</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">   best_loss = <span class=\"number\">100</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">   best_f1 = <span class=\"number\">0.978</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">   best_acc_test = <span class=\"number\">0.96</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">   best_acc_train = <span class=\"number\">0.96</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">   best_auc = <span class=\"number\">0.96</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">   <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range(num_epochs):</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">       print(<span class=\"string\">'Epoch &#123;&#125;/&#123;&#125;'</span>.format(epoch, num_epochs - <span class=\"number\">1</span>))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">       print(<span class=\"string\">'-'</span> * <span class=\"number\">10</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">14</span></pre></td><td class=\"code\"><pre><span class=\"line\">       <span class=\"comment\"># Each epoch has a training and validation phase</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">15</span></pre></td><td class=\"code\"><pre><span class=\"line\">       <span class=\"keyword\">for</span> phase <span class=\"keyword\">in</span> [<span class=\"string\">'train'</span>, <span class=\"string\">'val'</span>]:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">16</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"keyword\">if</span> phase == <span class=\"string\">'train'</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">17</span></pre></td><td class=\"code\"><pre><span class=\"line\">               scheduler.step()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">18</span></pre></td><td class=\"code\"><pre><span class=\"line\">               model.train()  <span class=\"comment\"># Set model to training mode</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">19</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"keyword\">else</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">20</span></pre></td><td class=\"code\"><pre><span class=\"line\">               model.eval()   <span class=\"comment\"># Set model to evaluate mode</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">21</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">22</span></pre></td><td class=\"code\"><pre><span class=\"line\">           running_loss = <span class=\"number\">0.0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">23</span></pre></td><td class=\"code\"><pre><span class=\"line\">           </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">24</span></pre></td><td class=\"code\"><pre><span class=\"line\">           label_corrects = <span class=\"number\">0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">25</span></pre></td><td class=\"code\"><pre><span class=\"line\">           TP = <span class=\"number\">0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">26</span></pre></td><td class=\"code\"><pre><span class=\"line\">           TN = <span class=\"number\">0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">27</span></pre></td><td class=\"code\"><pre><span class=\"line\">           FN = <span class=\"number\">0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">28</span></pre></td><td class=\"code\"><pre><span class=\"line\">           FP = <span class=\"number\">0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">29</span></pre></td><td class=\"code\"><pre><span class=\"line\">           total_scores = []</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">30</span></pre></td><td class=\"code\"><pre><span class=\"line\">           total_tar = []</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">31</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"comment\"># Iterate over data.</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">32</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"keyword\">for</span> inputs, label <span class=\"keyword\">in</span> dataloaders_dict[phase]:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">33</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"comment\">#inputs = inputs</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">34</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"comment\">#print(len(inputs),type(inputs),inputs)</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">35</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"comment\">#inputs = torch.from_numpy(np.array(inputs)).to(device) </span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">36</span></pre></td><td class=\"code\"><pre><span class=\"line\">               inputs = inputs.to(device) </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">37</span></pre></td><td class=\"code\"><pre><span class=\"line\">               label = label.to(device)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">38</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">39</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"comment\"># zero the parameter gradients</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">40</span></pre></td><td class=\"code\"><pre><span class=\"line\">               optimizer.zero_grad()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">41</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">42</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"comment\"># forward</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">43</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"comment\"># track history if only in train</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">44</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"keyword\">with</span> torch.set_grad_enabled(phase == <span class=\"string\">'train'</span>):</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">45</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   <span class=\"comment\"># acquire output</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">46</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   outputs = model(inputs)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">47</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">48</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   outputs = F.softmax(outputs,dim=<span class=\"number\">1</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">49</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">50</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   loss = criterion(outputs, torch.max(label.float(), <span class=\"number\">1</span>)[<span class=\"number\">1</span>])</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">51</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   <span class=\"comment\"># backward + optimize only if in training phase</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">52</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   <span class=\"keyword\">if</span> phase == <span class=\"string\">'train'</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">53</span></pre></td><td class=\"code\"><pre><span class=\"line\">                       </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">54</span></pre></td><td class=\"code\"><pre><span class=\"line\">                       loss.backward()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">55</span></pre></td><td class=\"code\"><pre><span class=\"line\">                       optimizer.step()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">56</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">57</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"comment\"># statistics</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">58</span></pre></td><td class=\"code\"><pre><span class=\"line\">               running_loss += loss.item() * inputs.size(<span class=\"number\">0</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">59</span></pre></td><td class=\"code\"><pre><span class=\"line\">               label_corrects += torch.sum(torch.max(outputs, <span class=\"number\">1</span>)[<span class=\"number\">1</span>] == torch.max(label, <span class=\"number\">1</span>)[<span class=\"number\">1</span>]) <span class=\"comment\">#返回每一行中最大值的那个元素，且返回其索引（返回最大元素在这一行的列索引）</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">60</span></pre></td><td class=\"code\"><pre><span class=\"line\">               pred_choice = torch.max(outputs, <span class=\"number\">1</span>)[<span class=\"number\">1</span>]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">61</span></pre></td><td class=\"code\"><pre><span class=\"line\">               target = torch.max(label, <span class=\"number\">1</span>)[<span class=\"number\">1</span>]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">62</span></pre></td><td class=\"code\"><pre><span class=\"line\">               scores = pred_choice.cpu().tolist()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">63</span></pre></td><td class=\"code\"><pre><span class=\"line\">               tar = target.cpu().tolist()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">64</span></pre></td><td class=\"code\"><pre><span class=\"line\">               total_scores = total_scores + scores</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">65</span></pre></td><td class=\"code\"><pre><span class=\"line\">               total_tar = total_tar + tar</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">66</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">67</span></pre></td><td class=\"code\"><pre><span class=\"line\">               tmp_tp = <span class=\"number\">0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">68</span></pre></td><td class=\"code\"><pre><span class=\"line\">               tmp_tn = <span class=\"number\">0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">69</span></pre></td><td class=\"code\"><pre><span class=\"line\">               tmp_fn = <span class=\"number\">0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">70</span></pre></td><td class=\"code\"><pre><span class=\"line\">               tmp_fp = <span class=\"number\">0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">71</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"keyword\">if</span> pred_choice.numel()!= target.numel():</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">72</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   print(<span class=\"string\">\"error\"</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">73</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(pred_choice.numel()):</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">74</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   <span class=\"keyword\">if</span> pred_choice[i] == <span class=\"number\">1</span> <span class=\"keyword\">and</span> target[i] == <span class=\"number\">1</span> :</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">75</span></pre></td><td class=\"code\"><pre><span class=\"line\">                       tmp_tp = tmp_tp + <span class=\"number\">1</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">76</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   <span class=\"keyword\">elif</span> pred_choice[i] == <span class=\"number\">0</span> <span class=\"keyword\">and</span> target[i] == <span class=\"number\">0</span> :</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">77</span></pre></td><td class=\"code\"><pre><span class=\"line\">                       tmp_tn = tmp_tn + <span class=\"number\">1</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">78</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   <span class=\"keyword\">elif</span> pred_choice[i] == <span class=\"number\">0</span> <span class=\"keyword\">and</span> target[i] == <span class=\"number\">1</span> :</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">79</span></pre></td><td class=\"code\"><pre><span class=\"line\">                       tmp_fn = tmp_fn + <span class=\"number\">1</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">80</span></pre></td><td class=\"code\"><pre><span class=\"line\">                   <span class=\"keyword\">elif</span> pred_choice[i] == <span class=\"number\">1</span> <span class=\"keyword\">and</span> target[i] == <span class=\"number\">0</span> :</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">81</span></pre></td><td class=\"code\"><pre><span class=\"line\">                       tmp_fp = tmp_fp + <span class=\"number\">1</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">82</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"comment\"># TP    both predict and label are 1</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">83</span></pre></td><td class=\"code\"><pre><span class=\"line\">               TP += tmp_tp</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">84</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"comment\"># TN    both predict and label are 0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">85</span></pre></td><td class=\"code\"><pre><span class=\"line\">               TN += tmp_tn</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">86</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"comment\"># FN    predict 0 label 1</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">87</span></pre></td><td class=\"code\"><pre><span class=\"line\">               FN += tmp_fn</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">88</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"comment\"># FP    predict 1 label 0</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">89</span></pre></td><td class=\"code\"><pre><span class=\"line\">               FP += tmp_fp</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">90</span></pre></td><td class=\"code\"><pre><span class=\"line\">           epoch_loss = running_loss / dataset_sizes[phase]</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">91</span></pre></td><td class=\"code\"><pre><span class=\"line\">           p = TP / (TP + FP)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">92</span></pre></td><td class=\"code\"><pre><span class=\"line\">           r = TP / (TP + FN)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">93</span></pre></td><td class=\"code\"><pre><span class=\"line\">           F1 = <span class=\"number\">2</span> * r * p / (r + p)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">94</span></pre></td><td class=\"code\"><pre><span class=\"line\">           acc = (TP + TN) / (TP + TN + FP + FN)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">95</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">96</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"comment\">### draw ROC curce</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">97</span></pre></td><td class=\"code\"><pre><span class=\"line\">           tpr = TP/(TP+FN)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">98</span></pre></td><td class=\"code\"><pre><span class=\"line\">           fpr = FP/(FP+TN)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">99</span></pre></td><td class=\"code\"><pre><span class=\"line\">           tnr = TN/(FP+TN)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">100</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">101</span></pre></td><td class=\"code\"><pre><span class=\"line\">           total_scores = np.array(total_scores)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">102</span></pre></td><td class=\"code\"><pre><span class=\"line\">           total_tar = np.array(total_tar)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">103</span></pre></td><td class=\"code\"><pre><span class=\"line\">           fpr, tpr, thresholds = roc_curve(total_tar, total_scores)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">104</span></pre></td><td class=\"code\"><pre><span class=\"line\">           roc_auc = auc(fpr, tpr) </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">105</span></pre></td><td class=\"code\"><pre><span class=\"line\">           plt.title(<span class=\"string\">'ROC'</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">106</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"keyword\">if</span> roc_auc &gt; best_auc:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">107</span></pre></td><td class=\"code\"><pre><span class=\"line\">               best_auc = roc_auc</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">108</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"keyword\">if</span> epoch &lt; num_epochs <span class=\"number\">-1</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">109</span></pre></td><td class=\"code\"><pre><span class=\"line\">               plt.plot(fpr, tpr,<span class=\"string\">'b'</span>,label=<span class=\"string\">'AUC = %0.4f'</span>% roc_auc)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">110</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"keyword\">if</span> epoch == num_epochs <span class=\"number\">-1</span>:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">111</span></pre></td><td class=\"code\"><pre><span class=\"line\">               plt.plot(fpr, tpr, color=<span class=\"string\">'darkorange'</span>, label=<span class=\"string\">'MAX AUC = %0.4f'</span>% best_auc) </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">112</span></pre></td><td class=\"code\"><pre><span class=\"line\">           plt.legend(loc=<span class=\"string\">'lower right'</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">113</span></pre></td><td class=\"code\"><pre><span class=\"line\">           plt.plot([<span class=\"number\">0</span>,<span class=\"number\">1</span>],[<span class=\"number\">0</span>,<span class=\"number\">1</span>],<span class=\"string\">'r--'</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">114</span></pre></td><td class=\"code\"><pre><span class=\"line\">           plt.ylabel(<span class=\"string\">'TPR'</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">115</span></pre></td><td class=\"code\"><pre><span class=\"line\">           plt.xlabel(<span class=\"string\">'FPR'</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">116</span></pre></td><td class=\"code\"><pre><span class=\"line\">           plt.show()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">117</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">118</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"comment\">#print('&#123;&#125; p: &#123;:.4f&#125; '.format(phase,p ))</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">119</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"comment\">#print('&#123;&#125; r: &#123;:.4f&#125; '.format(phase,r ))</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">120</span></pre></td><td class=\"code\"><pre><span class=\"line\">           print(<span class=\"string\">'&#123;&#125; F1: &#123;:.4f&#125; '</span>.format(phase,F1 ))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">121</span></pre></td><td class=\"code\"><pre><span class=\"line\">           print(<span class=\"string\">'&#123;&#125; accuracy: &#123;:.4f&#125; '</span>.format(phase,acc ))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">122</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">123</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"keyword\">if</span> phase == <span class=\"string\">'val'</span> <span class=\"keyword\">and</span> epoch_loss &lt; best_loss:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">124</span></pre></td><td class=\"code\"><pre><span class=\"line\">               print(<span class=\"string\">'saving with loss of &#123;&#125;'</span>.format(epoch_loss),</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">125</span></pre></td><td class=\"code\"><pre><span class=\"line\">                     <span class=\"string\">'improved over previous &#123;&#125;'</span>.format(best_loss))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">126</span></pre></td><td class=\"code\"><pre><span class=\"line\">               best_loss = epoch_loss</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">127</span></pre></td><td class=\"code\"><pre><span class=\"line\">               best_model_wts = copy.deepcopy(model.state_dict())</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">128</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"comment\">#torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/bert_model_test_loss.pth')</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">129</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"keyword\">if</span> F1 &gt; best_f1:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">130</span></pre></td><td class=\"code\"><pre><span class=\"line\">               best_f1 = F1</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">131</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"keyword\">if</span> phase == <span class=\"string\">'val'</span> <span class=\"keyword\">and</span> acc &gt; best_acc_test:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">132</span></pre></td><td class=\"code\"><pre><span class=\"line\">               best_acc_test = acc</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">133</span></pre></td><td class=\"code\"><pre><span class=\"line\">           <span class=\"keyword\">if</span> phase == <span class=\"string\">'train'</span> <span class=\"keyword\">and</span> acc &gt; best_acc_train:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">134</span></pre></td><td class=\"code\"><pre><span class=\"line\">               best_acc_train = acc</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">135</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"comment\">#best_model_wts = copy.deepcopy(model.state_dict())</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">136</span></pre></td><td class=\"code\"><pre><span class=\"line\">               <span class=\"comment\">#torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/bert_model_test_f1.pth')</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">137</span></pre></td><td class=\"code\"><pre><span class=\"line\">       print()</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">138</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">139</span></pre></td><td class=\"code\"><pre><span class=\"line\">   time_elapsed = time.time() - since</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">140</span></pre></td><td class=\"code\"><pre><span class=\"line\">   print(<span class=\"string\">'Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s'</span>.format(</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">141</span></pre></td><td class=\"code\"><pre><span class=\"line\">       time_elapsed // <span class=\"number\">60</span>, time_elapsed % <span class=\"number\">60</span>))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">142</span></pre></td><td class=\"code\"><pre><span class=\"line\">   print(<span class=\"string\">\"Parament setting: \"</span>)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">143</span></pre></td><td class=\"code\"><pre><span class=\"line\">   print(<span class=\"string\">\"cased: \"</span>,par_cased)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">144</span></pre></td><td class=\"code\"><pre><span class=\"line\">   print(<span class=\"string\">\"cleanup: \"</span>,par_cleanup)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">145</span></pre></td><td class=\"code\"><pre><span class=\"line\">   print(<span class=\"string\">\"eda: \"</span>,par_eda)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">146</span></pre></td><td class=\"code\"><pre><span class=\"line\">   print(<span class=\"string\">'Best train Acc: &#123;:4f&#125;'</span>.format(float(best_acc_train)))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">147</span></pre></td><td class=\"code\"><pre><span class=\"line\">   print(<span class=\"string\">'Best test Acc: &#123;:4f&#125;'</span>.format(float(best_acc_test)))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">148</span></pre></td><td class=\"code\"><pre><span class=\"line\">   print(<span class=\"string\">'Best f1 score: &#123;:4f&#125;'</span>.format(float(best_f1)))</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">149</span></pre></td><td class=\"code\"><pre><span class=\"line\">   <span class=\"comment\"># load best model weights</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">150</span></pre></td><td class=\"code\"><pre><span class=\"line\">   model.load_state_dict(best_model_wts)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">151</span></pre></td><td class=\"code\"><pre><span class=\"line\">   <span class=\"keyword\">return</span> model</span></pre></td></tr></table></figure>\n<h3 id=\"4-Final-output\"><a href=\"#4-Final-output\" class=\"headerlink\" title=\"4. Final output\"></a>4. Final output</h3><h4 id=\"4-1-Model-details\"><a href=\"#4-1-Model-details\" class=\"headerlink\" title=\"4.1 Model details\"></a>4.1 Model details</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">print(model)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">model.to(device)</span></pre></td></tr></table></figure>\n<h4 id=\"4-2-F1-and-other-details\"><a href=\"#4-2-F1-and-other-details\" class=\"headerlink\" title=\"4.2 F1 and other details\"></a>4.2 F1 and other details</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">model_ft1 = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=<span class=\"number\">10</span>)</span></pre></td></tr></table></figure>"},{"title":"Hexo主题折腾日记(二) 添加豆瓣和聊天插件","thumbnail":"https://images.unsplash.com/photo-1486312338219-ce68d2c6f44d?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=900&q=60","recommend":1,"top":100,"toc":false,"_content":"\n# 前言\n今上午翻看别人的博客，看到了Next主题相关优化的帖子，有关于豆瓣主页和博客聊天插件的内容，<!--more-->于是就想在 icarus 主题内也实现这个功能，折腾了一下午，终于搞好了。\n\n## 豆瓣主页插件\n### 实现效果\n<!--more-->\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-17 at 12.18.22.png\" height=\"60%\" width=\"60%\">\n</center>\n\n### 配置\n1. 安装模块依赖\n    ` $ npm install hexo-douban --save`\n2. 在站点配置文件中添加配置\n    在 `_config.xml` 文件中添加\n    ```\ndouban:\n  user: mythsman\n  builtin: false\n  book:\n    title: 'This is my book title'\n    quote: 'This is my book quote'\n  movie:\n    title: 'This is my movie title'\n    quote: 'This is my movie quote'\n  game:\n    title: 'This is my game title'\n    quote: 'This is my game quote'\n  timeout: 10000\n    ```\n    \n说明:\n- user: 你的豆瓣ID.打开豆瓣，登入账户，然后在右上角点击 \"个人主页\" ，这时候地址栏的URL大概是这样：\"https://www.douban.com/people/xxxxxx/\" ，其中的\"xxxxxx\"就是你的个人ID了。\n- builtin: 是否将生成页面的功能嵌入hexo s和hexo g中，默认是false,另一可选项为true, 如果豆瓣更新频率不高建议选择false，没有必要再每一次部署的时候重新生成豆瓣的页面\n- title: 该页面的标题.\n- quote: 写在页面开头的一段话,支持html语法.\n- timeout: 爬取数据的超时时间，默认是 10000ms ,如果在使用时发现报了超时的错(ETIMEOUT)可以把这个数据设置的大一点。\n如果只想显示某一个页面(比如movie)，那就把其他的配置项注释掉即可。\n3. 修改/layout/common/article.ejs\n ```diff\n<%- list_categories(post.categories, {\n                    class: 'has-link-grey ',\n                    show_count: false,\n                    style: 'none',\n                    separator: '&nbsp;/&nbsp;'\n                }) %>\n                </div>\n                <% } %>\n+               <% if (post._content && word_count(post._content)) { %>\n                    <% if (!has_config('article.readtime') || get_config('article.readtime') === true) { %>\n                    <span class=\"level-item has-text-grey\">\n                        <% const words = word_count(post._content); %>\n                        <% const time = duration((words / 150.0) * 60, 'seconds') %>\n                        <%= `${ time.locale(get_config('language', 'en')).humanize() } ${ __('article.read')} (${ __('article.about') } ${ words } ${ __('article.words') })` %>\n                    </span>\n                <% } %>\n+               <% } %>\n                <% if (!index && (has_config('plugins.busuanzi') ? get_config('plugins.busuanzi') : false)) { %>\n                <span class=\"level-item has-text-grey\" id=\"busuanzi_container_page_pv\">\n                    <i class=\"far fa-eye\"></i>\n                    <%- _p('plugin.visit', '<span id=\"busuanzi_value_page_pv\">0</span>') %>\n ```\n4. 测试并发布\n `hexo douban -bgm && hexo server`\n 如果终端没有报错且网页 `http://localhost:4000/books` `http://localhost:4000/movies`  `http://localhost:4000/movies` 没有问题，就可以直接发布了，这里注意 bgm = books+ games+ movies, 如果前面的配置中只选择了 books，那这里只需要 `hexo douban -b`即可，其他同理。\n \n5. 主题文件修改\n在对应主题的 `_config.xml` 文件 menu 模块添加对应的配置，示例如下。\n    ```\n    menu:\n        Home: /\n        About: /about\n        Articles: /archives\n        Gallery: /gallery\n        Books: /books\n    ```\n最后测试发布\n\n## 博客聊天插件\n### 实现效果\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-17 at 20.33.21.png\" height=\"40%\" width=\"40%\">\n</center>\n\n### 配置\n1. 首先需要注册 [Tidio](https://www.tidio.com/) 账号，根据引导填写应用信息。\n2. 在个人主页中选择 `Channels -> Live Chat -> Integration` ,复制 JS 代码\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-17 at 20.37.55.png\" height=\"60%\" width=\"60%\">\n</center>\n3. 修改 /layout/layout.ejs, 在文件最后插入对应的代码.\n```diff\n    <% } %>\n+    <script src=\"//code.tidio.co/token.js\" async></script>\n</body>\n</html>\n```\n其中将`token`替换成你对应的token即可，接下来可以在 Tidio 控制台的 `Channel -> Live chat -> Appearance` 中根据提示定制聊天对话框的主题外观和语言包，以适应自己的需求。","source":"_posts/Hexo主题折腾日记-二-添加豆瓣和聊天插件.md","raw":"---\ntitle: Hexo主题折腾日记(二) 添加豆瓣和聊天插件\ntags: []\ncategories:\nthumbnail: https://images.unsplash.com/photo-1486312338219-ce68d2c6f44d?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=900&q=60\nrecommend: 1\ntop: 100\ntoc: false\n---\n\n# 前言\n今上午翻看别人的博客，看到了Next主题相关优化的帖子，有关于豆瓣主页和博客聊天插件的内容，<!--more-->于是就想在 icarus 主题内也实现这个功能，折腾了一下午，终于搞好了。\n\n## 豆瓣主页插件\n### 实现效果\n<!--more-->\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-17 at 12.18.22.png\" height=\"60%\" width=\"60%\">\n</center>\n\n### 配置\n1. 安装模块依赖\n    ` $ npm install hexo-douban --save`\n2. 在站点配置文件中添加配置\n    在 `_config.xml` 文件中添加\n    ```\ndouban:\n  user: mythsman\n  builtin: false\n  book:\n    title: 'This is my book title'\n    quote: 'This is my book quote'\n  movie:\n    title: 'This is my movie title'\n    quote: 'This is my movie quote'\n  game:\n    title: 'This is my game title'\n    quote: 'This is my game quote'\n  timeout: 10000\n    ```\n    \n说明:\n- user: 你的豆瓣ID.打开豆瓣，登入账户，然后在右上角点击 \"个人主页\" ，这时候地址栏的URL大概是这样：\"https://www.douban.com/people/xxxxxx/\" ，其中的\"xxxxxx\"就是你的个人ID了。\n- builtin: 是否将生成页面的功能嵌入hexo s和hexo g中，默认是false,另一可选项为true, 如果豆瓣更新频率不高建议选择false，没有必要再每一次部署的时候重新生成豆瓣的页面\n- title: 该页面的标题.\n- quote: 写在页面开头的一段话,支持html语法.\n- timeout: 爬取数据的超时时间，默认是 10000ms ,如果在使用时发现报了超时的错(ETIMEOUT)可以把这个数据设置的大一点。\n如果只想显示某一个页面(比如movie)，那就把其他的配置项注释掉即可。\n3. 修改/layout/common/article.ejs\n ```diff\n<%- list_categories(post.categories, {\n                    class: 'has-link-grey ',\n                    show_count: false,\n                    style: 'none',\n                    separator: '&nbsp;/&nbsp;'\n                }) %>\n                </div>\n                <% } %>\n+               <% if (post._content && word_count(post._content)) { %>\n                    <% if (!has_config('article.readtime') || get_config('article.readtime') === true) { %>\n                    <span class=\"level-item has-text-grey\">\n                        <% const words = word_count(post._content); %>\n                        <% const time = duration((words / 150.0) * 60, 'seconds') %>\n                        <%= `${ time.locale(get_config('language', 'en')).humanize() } ${ __('article.read')} (${ __('article.about') } ${ words } ${ __('article.words') })` %>\n                    </span>\n                <% } %>\n+               <% } %>\n                <% if (!index && (has_config('plugins.busuanzi') ? get_config('plugins.busuanzi') : false)) { %>\n                <span class=\"level-item has-text-grey\" id=\"busuanzi_container_page_pv\">\n                    <i class=\"far fa-eye\"></i>\n                    <%- _p('plugin.visit', '<span id=\"busuanzi_value_page_pv\">0</span>') %>\n ```\n4. 测试并发布\n `hexo douban -bgm && hexo server`\n 如果终端没有报错且网页 `http://localhost:4000/books` `http://localhost:4000/movies`  `http://localhost:4000/movies` 没有问题，就可以直接发布了，这里注意 bgm = books+ games+ movies, 如果前面的配置中只选择了 books，那这里只需要 `hexo douban -b`即可，其他同理。\n \n5. 主题文件修改\n在对应主题的 `_config.xml` 文件 menu 模块添加对应的配置，示例如下。\n    ```\n    menu:\n        Home: /\n        About: /about\n        Articles: /archives\n        Gallery: /gallery\n        Books: /books\n    ```\n最后测试发布\n\n## 博客聊天插件\n### 实现效果\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-17 at 20.33.21.png\" height=\"40%\" width=\"40%\">\n</center>\n\n### 配置\n1. 首先需要注册 [Tidio](https://www.tidio.com/) 账号，根据引导填写应用信息。\n2. 在个人主页中选择 `Channels -> Live Chat -> Integration` ,复制 JS 代码\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-17 at 20.37.55.png\" height=\"60%\" width=\"60%\">\n</center>\n3. 修改 /layout/layout.ejs, 在文件最后插入对应的代码.\n```diff\n    <% } %>\n+    <script src=\"//code.tidio.co/token.js\" async></script>\n</body>\n</html>\n```\n其中将`token`替换成你对应的token即可，接下来可以在 Tidio 控制台的 `Channel -> Live chat -> Appearance` 中根据提示定制聊天对话框的主题外观和语言包，以适应自己的需求。","slug":"Hexo主题折腾日记-二-添加豆瓣和聊天插件","published":1,"date":"2019-11-17T03:56:51.478Z","updated":"2019-11-18T13:21:20.302Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkpn000yk3x661di5eki","content":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>今上午翻看别人的博客，看到了Next主题相关优化的帖子，有关于豆瓣主页和博客聊天插件的内容，<a id=\"more\"></a>于是就想在 icarus 主题内也实现这个功能，折腾了一下午，终于搞好了。</p>\n<h2 id=\"豆瓣主页插件\"><a href=\"#豆瓣主页插件\" class=\"headerlink\" title=\"豆瓣主页插件\"></a>豆瓣主页插件</h2><h3 id=\"实现效果\"><a href=\"#实现效果\" class=\"headerlink\" title=\"实现效果\"></a>实现效果</h3><!--more-->\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-17 at 12.18.22.png\" height=\"60%\" width=\"60%\">\n</center>\n\n<h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><ol>\n<li>安装模块依赖<br> <code>$ npm install hexo-douban --save</code></li>\n<li>在站点配置文件中添加配置<br> 在 <code>_config.xml</code> 文件中添加 <figure class=\"highlight plain hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">douban:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">  user: mythsman</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">  builtin: false</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">  book:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">    title: &#39;This is my book title&#39;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">    quote: &#39;This is my book quote&#39;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">  movie:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">    title: &#39;This is my movie title&#39;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">    quote: &#39;This is my movie quote&#39;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">  game:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">    title: &#39;This is my game title&#39;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">    quote: &#39;This is my game quote&#39;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\">  timeout: 10000</span></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<p>说明:</p>\n<ul>\n<li>user: 你的豆瓣ID.打开豆瓣，登入账户，然后在右上角点击 “个人主页” ，这时候地址栏的URL大概是这样：”<a href=\"https://www.douban.com/people/xxxxxx/&quot;\" target=\"_blank\" rel=\"noopener\">https://www.douban.com/people/xxxxxx/&quot;</a> ，其中的”xxxxxx”就是你的个人ID了。</li>\n<li>builtin: 是否将生成页面的功能嵌入hexo s和hexo g中，默认是false,另一可选项为true, 如果豆瓣更新频率不高建议选择false，没有必要再每一次部署的时候重新生成豆瓣的页面</li>\n<li>title: 该页面的标题.</li>\n<li>quote: 写在页面开头的一段话,支持html语法.</li>\n<li>timeout: 爬取数据的超时时间，默认是 10000ms ,如果在使用时发现报了超时的错(ETIMEOUT)可以把这个数据设置的大一点。<br>如果只想显示某一个页面(比如movie)，那就把其他的配置项注释掉即可。</li>\n</ul>\n<ol start=\"3\">\n<li><p>修改/layout/common/article.ejs</p>\n<figure class=\"highlight diff hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;%- list_categories(post.categories, &#123;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">                    class: 'has-link-grey ',</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">                    show_count: false,</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">                    style: 'none',</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">                    separator: '&amp;nbsp;/&amp;nbsp;'</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &#125;) %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;/div&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;% &#125; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-addition\">+               &lt;% if (post._content &amp;&amp; word_count(post._content)) &#123; %&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">                    &lt;% if (!has_config('article.readtime') || get_config('article.readtime') <span class=\"hljs-comment\">=== true) &#123; %&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">                    &lt;span class=\"level-item has-text-grey\"&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">                        &lt;% const words = word_count(post._content); %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\">                        &lt;% const time = duration((words / 150.0) * 60, 'seconds') %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">14</span></pre></td><td class=\"code\"><pre><span class=\"line\">                        &lt;%= `$&#123; time.locale(get_config('language', 'en')).humanize() &#125; $&#123; __('article.read')&#125; ($&#123; __('article.about') &#125; $&#123; words &#125; $&#123; __('article.words') &#125;)` %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">15</span></pre></td><td class=\"code\"><pre><span class=\"line\">                    &lt;/span&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">16</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;% &#125; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">17</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-addition\">+               &lt;% &#125; %&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">18</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;% if (!index &amp;&amp; (has_config('plugins.busuanzi') ? get_config('plugins.busuanzi') : false)) &#123; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">19</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;span class=\"level-item has-text-grey\" id=\"busuanzi_container_page_pv\"&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">20</span></pre></td><td class=\"code\"><pre><span class=\"line\">                    &lt;i class=\"far fa-eye\"&gt;&lt;/i&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">21</span></pre></td><td class=\"code\"><pre><span class=\"line\">                    &lt;%- _p('plugin.visit', '&lt;span id=\"busuanzi_value_page_pv\"&gt;0&lt;/span&gt;') %&gt;</span></pre></td></tr></table></figure></li>\n<li><p>测试并发布<br><code>hexo douban -bgm &amp;&amp; hexo server</code><br>如果终端没有报错且网页 <code>http://localhost:4000/books</code> <code>http://localhost:4000/movies</code>  <code>http://localhost:4000/movies</code> 没有问题，就可以直接发布了，这里注意 bgm = books+ games+ movies, 如果前面的配置中只选择了 books，那这里只需要 <code>hexo douban -b</code>即可，其他同理。</p>\n</li>\n<li><p>主题文件修改<br>在对应主题的 <code>_config.xml</code> 文件 menu 模块添加对应的配置，示例如下。</p>\n <figure class=\"highlight plain hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">menu:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">    Home: &#x2F;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">    About: &#x2F;about</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">    Articles: &#x2F;archives</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">    Gallery: &#x2F;gallery</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">    Books: &#x2F;books</span></pre></td></tr></table></figure>\n<p>最后测试发布</p>\n</li>\n</ol>\n<h2 id=\"博客聊天插件\"><a href=\"#博客聊天插件\" class=\"headerlink\" title=\"博客聊天插件\"></a>博客聊天插件</h2><h3 id=\"实现效果-1\"><a href=\"#实现效果-1\" class=\"headerlink\" title=\"实现效果\"></a>实现效果</h3><center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-17 at 20.33.21.png\" height=\"40%\" width=\"40%\">\n</center>\n\n<h3 id=\"配置-1\"><a href=\"#配置-1\" class=\"headerlink\" title=\"配置\"></a>配置</h3><ol>\n<li>首先需要注册 <a href=\"https://www.tidio.com/\" target=\"_blank\" rel=\"noopener\">Tidio</a> 账号，根据引导填写应用信息。</li>\n<li>在个人主页中选择 <code>Channels -&gt; Live Chat -&gt; Integration</code> ,复制 JS 代码<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-17 at 20.37.55.png\" height=\"60%\" width=\"60%\">\n</center></li>\n<li>修改 /layout/layout.ejs, 在文件最后插入对应的代码.<figure class=\"highlight diff hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">    &lt;% &#125; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-addition\">+    &lt;script src=\"//code.tidio.co/token.js\" async&gt;&lt;/script&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;/body&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;/html&gt;</span></pre></td></tr></table></figure>\n其中将<code>token</code>替换成你对应的token即可，接下来可以在 Tidio 控制台的 <code>Channel -&gt; Live chat -&gt; Appearance</code> 中根据提示定制聊天对话框的主题外观和语言包，以适应自己的需求。</li>\n</ol>\n","site":{"data":{}},"excerpt":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>今上午翻看别人的博客，看到了Next主题相关优化的帖子，有关于豆瓣主页和博客聊天插件的内容，</p>","more":"于是就想在 icarus 主题内也实现这个功能，折腾了一下午，终于搞好了。</p>\n<h2 id=\"豆瓣主页插件\"><a href=\"#豆瓣主页插件\" class=\"headerlink\" title=\"豆瓣主页插件\"></a>豆瓣主页插件</h2><h3 id=\"实现效果\"><a href=\"#实现效果\" class=\"headerlink\" title=\"实现效果\"></a>实现效果</h3><!--more-->\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-17 at 12.18.22.png\" height=\"60%\" width=\"60%\">\n</center>\n\n<h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><ol>\n<li>安装模块依赖<br> <code>$ npm install hexo-douban --save</code></li>\n<li>在站点配置文件中添加配置<br> 在 <code>_config.xml</code> 文件中添加 <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">douban:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">  user: mythsman</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">  builtin: false</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">  book:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">    title: &#39;This is my book title&#39;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">    quote: &#39;This is my book quote&#39;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">  movie:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">    title: &#39;This is my movie title&#39;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">    quote: &#39;This is my movie quote&#39;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">  game:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">    title: &#39;This is my game title&#39;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">    quote: &#39;This is my game quote&#39;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\">  timeout: 10000</span></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<p>说明:</p>\n<ul>\n<li>user: 你的豆瓣ID.打开豆瓣，登入账户，然后在右上角点击 “个人主页” ，这时候地址栏的URL大概是这样：”<a href=\"https://www.douban.com/people/xxxxxx/&quot;\" target=\"_blank\" rel=\"noopener\">https://www.douban.com/people/xxxxxx/&quot;</a> ，其中的”xxxxxx”就是你的个人ID了。</li>\n<li>builtin: 是否将生成页面的功能嵌入hexo s和hexo g中，默认是false,另一可选项为true, 如果豆瓣更新频率不高建议选择false，没有必要再每一次部署的时候重新生成豆瓣的页面</li>\n<li>title: 该页面的标题.</li>\n<li>quote: 写在页面开头的一段话,支持html语法.</li>\n<li>timeout: 爬取数据的超时时间，默认是 10000ms ,如果在使用时发现报了超时的错(ETIMEOUT)可以把这个数据设置的大一点。<br>如果只想显示某一个页面(比如movie)，那就把其他的配置项注释掉即可。</li>\n</ul>\n<ol start=\"3\">\n<li><p>修改/layout/common/article.ejs</p>\n<figure class=\"highlight diff\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;%- list_categories(post.categories, &#123;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">                    class: 'has-link-grey ',</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">                    show_count: false,</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">                    style: 'none',</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">                    separator: '&amp;nbsp;/&amp;nbsp;'</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &#125;) %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;/div&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;% &#125; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"addition\">+               &lt;% if (post._content &amp;&amp; word_count(post._content)) &#123; %&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">                    &lt;% if (!has_config('article.readtime') || get_config('article.readtime') <span class=\"comment\">=== true) &#123; %&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">                    &lt;span class=\"level-item has-text-grey\"&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">                        &lt;% const words = word_count(post._content); %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\">                        &lt;% const time = duration((words / 150.0) * 60, 'seconds') %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">14</span></pre></td><td class=\"code\"><pre><span class=\"line\">                        &lt;%= `$&#123; time.locale(get_config('language', 'en')).humanize() &#125; $&#123; __('article.read')&#125; ($&#123; __('article.about') &#125; $&#123; words &#125; $&#123; __('article.words') &#125;)` %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">15</span></pre></td><td class=\"code\"><pre><span class=\"line\">                    &lt;/span&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">16</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;% &#125; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">17</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"addition\">+               &lt;% &#125; %&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">18</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;% if (!index &amp;&amp; (has_config('plugins.busuanzi') ? get_config('plugins.busuanzi') : false)) &#123; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">19</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;span class=\"level-item has-text-grey\" id=\"busuanzi_container_page_pv\"&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">20</span></pre></td><td class=\"code\"><pre><span class=\"line\">                    &lt;i class=\"far fa-eye\"&gt;&lt;/i&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">21</span></pre></td><td class=\"code\"><pre><span class=\"line\">                    &lt;%- _p('plugin.visit', '&lt;span id=\"busuanzi_value_page_pv\"&gt;0&lt;/span&gt;') %&gt;</span></pre></td></tr></table></figure></li>\n<li><p>测试并发布<br><code>hexo douban -bgm &amp;&amp; hexo server</code><br>如果终端没有报错且网页 <code>http://localhost:4000/books</code> <code>http://localhost:4000/movies</code>  <code>http://localhost:4000/movies</code> 没有问题，就可以直接发布了，这里注意 bgm = books+ games+ movies, 如果前面的配置中只选择了 books，那这里只需要 <code>hexo douban -b</code>即可，其他同理。</p>\n</li>\n<li><p>主题文件修改<br>在对应主题的 <code>_config.xml</code> 文件 menu 模块添加对应的配置，示例如下。</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">menu:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">    Home: &#x2F;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">    About: &#x2F;about</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">    Articles: &#x2F;archives</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">    Gallery: &#x2F;gallery</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">    Books: &#x2F;books</span></pre></td></tr></table></figure>\n<p>最后测试发布</p>\n</li>\n</ol>\n<h2 id=\"博客聊天插件\"><a href=\"#博客聊天插件\" class=\"headerlink\" title=\"博客聊天插件\"></a>博客聊天插件</h2><h3 id=\"实现效果-1\"><a href=\"#实现效果-1\" class=\"headerlink\" title=\"实现效果\"></a>实现效果</h3><center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-17 at 20.33.21.png\" height=\"40%\" width=\"40%\">\n</center>\n\n<h3 id=\"配置-1\"><a href=\"#配置-1\" class=\"headerlink\" title=\"配置\"></a>配置</h3><ol>\n<li>首先需要注册 <a href=\"https://www.tidio.com/\" target=\"_blank\" rel=\"noopener\">Tidio</a> 账号，根据引导填写应用信息。</li>\n<li>在个人主页中选择 <code>Channels -&gt; Live Chat -&gt; Integration</code> ,复制 JS 代码<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-17 at 20.37.55.png\" height=\"60%\" width=\"60%\">\n</center></li>\n<li>修改 /layout/layout.ejs, 在文件最后插入对应的代码.<figure class=\"highlight diff\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">    &lt;% &#125; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"addition\">+    &lt;script src=\"//code.tidio.co/token.js\" async&gt;&lt;/script&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;/body&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;/html&gt;</span></pre></td></tr></table></figure>\n其中将<code>token</code>替换成你对应的token即可，接下来可以在 Tidio 控制台的 <code>Channel -&gt; Live chat -&gt; Appearance</code> 中根据提示定制聊天对话框的主题外观和语言包，以适应自己的需求。</li>\n</ol>"},{"title":"March 18, 2019","originContent":"","toc":false,"date":"2019-03-18T02:51:05.000Z","thumbnail":"https://images.unsplash.com/photo-1514449372970-c013485804bd?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n寻找，找寻，生命，相关，起点\n<!--more-->\n二姨，咱们又见面了，可是你这次真的，话好少。\n\n我和老嘟在你设计的密室里面，需要寻找4个16进制数，但我们太笨了，怎么都找不到，最后你到了我们这里，但场景突然变了，我看到了姥爷的床头柜，你就坐在床头柜旁的凳子上，当我翻找柜子里面的东西的时候，你给我说，提示不在里面。很遗憾，我没有看你的脸，不知道你老了没有，但你的声音还是那么好听。梦醒了，我能记住的几个词汇，就是 寻找，找寻，生命，相关，起点。不知道为什么，梦里没有看到童童，是不是看到她，你又开哭了。在那边一个人生活挺苦的吧，但你还是要开心，因为童童生的长大了，给老嘟说了那么多道理，学习的，生活的。其中最令我感动的一句，是她说，你不要像姐姐一样，初中不好好学习，上了一个不好的高中，你要好好学，像哥哥一样，考一个好高中。你在那边听到这句话一定很欣慰吧，童童长大了，会照顾好自己的，你放心好了，这次就聊到这里吧，我要继续睡了。","source":"_posts/March-18-2019.md","raw":"---\ntitle: 'March 18, 2019'\ntags: []\noriginContent: ''\ncategories:\n  - 旧的梦\ntoc: false\ndate: 2019-03-18 10:51:05\nthumbnail: https://images.unsplash.com/photo-1514449372970-c013485804bd?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n寻找，找寻，生命，相关，起点\n<!--more-->\n二姨，咱们又见面了，可是你这次真的，话好少。\n\n我和老嘟在你设计的密室里面，需要寻找4个16进制数，但我们太笨了，怎么都找不到，最后你到了我们这里，但场景突然变了，我看到了姥爷的床头柜，你就坐在床头柜旁的凳子上，当我翻找柜子里面的东西的时候，你给我说，提示不在里面。很遗憾，我没有看你的脸，不知道你老了没有，但你的声音还是那么好听。梦醒了，我能记住的几个词汇，就是 寻找，找寻，生命，相关，起点。不知道为什么，梦里没有看到童童，是不是看到她，你又开哭了。在那边一个人生活挺苦的吧，但你还是要开心，因为童童生的长大了，给老嘟说了那么多道理，学习的，生活的。其中最令我感动的一句，是她说，你不要像姐姐一样，初中不好好学习，上了一个不好的高中，你要好好学，像哥哥一样，考一个好高中。你在那边听到这句话一定很欣慰吧，童童长大了，会照顾好自己的，你放心好了，这次就聊到这里吧，我要继续睡了。","slug":"March-18-2019","published":1,"updated":"2019-11-15T12:52:50.518Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkpp0010k3x6cmm76s10","content":"<p>寻找，找寻，生命，相关，起点</p>\n<a id=\"more\"></a>\n<p>二姨，咱们又见面了，可是你这次真的，话好少。</p>\n<p>我和老嘟在你设计的密室里面，需要寻找4个16进制数，但我们太笨了，怎么都找不到，最后你到了我们这里，但场景突然变了，我看到了姥爷的床头柜，你就坐在床头柜旁的凳子上，当我翻找柜子里面的东西的时候，你给我说，提示不在里面。很遗憾，我没有看你的脸，不知道你老了没有，但你的声音还是那么好听。梦醒了，我能记住的几个词汇，就是 寻找，找寻，生命，相关，起点。不知道为什么，梦里没有看到童童，是不是看到她，你又开哭了。在那边一个人生活挺苦的吧，但你还是要开心，因为童童生的长大了，给老嘟说了那么多道理，学习的，生活的。其中最令我感动的一句，是她说，你不要像姐姐一样，初中不好好学习，上了一个不好的高中，你要好好学，像哥哥一样，考一个好高中。你在那边听到这句话一定很欣慰吧，童童长大了，会照顾好自己的，你放心好了，这次就聊到这里吧，我要继续睡了。</p>\n","site":{"data":{}},"excerpt":"<p>寻找，找寻，生命，相关，起点</p>","more":"<p>二姨，咱们又见面了，可是你这次真的，话好少。</p>\n<p>我和老嘟在你设计的密室里面，需要寻找4个16进制数，但我们太笨了，怎么都找不到，最后你到了我们这里，但场景突然变了，我看到了姥爷的床头柜，你就坐在床头柜旁的凳子上，当我翻找柜子里面的东西的时候，你给我说，提示不在里面。很遗憾，我没有看你的脸，不知道你老了没有，但你的声音还是那么好听。梦醒了，我能记住的几个词汇，就是 寻找，找寻，生命，相关，起点。不知道为什么，梦里没有看到童童，是不是看到她，你又开哭了。在那边一个人生活挺苦的吧，但你还是要开心，因为童童生的长大了，给老嘟说了那么多道理，学习的，生活的。其中最令我感动的一句，是她说，你不要像姐姐一样，初中不好好学习，上了一个不好的高中，你要好好学，像哥哥一样，考一个好高中。你在那边听到这句话一定很欣慰吧，童童长大了，会照顾好自己的，你放心好了，这次就聊到这里吧，我要继续睡了。</p>"},{"title":"Hexo主题折腾日记(一) 从cactus到icarus","date":"2019-11-16T02:59:11.000Z","thumbnail":"https://images.unsplash.com/photo-1486312338219-ce68d2c6f44d?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=900&q=60","recommend":1,"top":100,"toc":true,"_content":"\n# 前言\n从Hexo建站开始，一直是使用的cactus主题，很喜欢那种简约的风格，主页文章预览的都没有的那一种。<!--more-->\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMAGE 2019-11-16 11:11:11.jpg\" height=\"60%\" width=\"60%\">\n</center>\n\n直到昨天心血来潮想搞一个基于ghost的动态博客，同时爱上了他的默认主题casper，心想这不就是我梦寐已久的主题么，结果搜了很多的资料，发现个人维护的建站工具都是至少1年以上的，有一个基于 python 可以通过ghost部署到github pags上的工具还是基于2.7,我直接裂开，最终直接放弃了这套方案，回过头来想能不能把casper移植到hexo上呢，在github上也搜到了相应的项目，但效果emmm，不是特别能让我满意，贴一张demo供大家参考。\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMAGE 2019-11-16 11:10:20.jpg\" height=\"60%\" width=\"60%\">\n</center>\n\n主要还是插件的支持度没有成熟主题的高，然后就又开始google: hexo主题推荐2019类似的关键词，终于发现了这个模版，icarus，没有cactus那么朴素，插件支持度和commit活跃度也比hexo-casper高，所以昨天花了很长很长的时间调整网页布局和文章渲染问题，最终效果我打9分吧，因为还有一点问题没有解决，等写完这个博客我再搞，下面主要把我基于别人修改的模版和自己修改的内容做一下总结，以免以后git pull之后不知道自己做了哪些修改。\n\n# icarus主题之上主要改动\n1. 主页显示两栏widget，文章只显示左边widget\n2. 文章图片居中\n3. 增加profile下面的 bio, 可以放一点自己想说的话\n4. 置顶文章\n5. 文章底部文章详细信息显示以及推荐文章模块配置\n6. 页脚访问人数显示修改\n\n## 主页显示两栏widget，文章只显示左边widget\n主要参考 [水寒blog](https://dp2px.com/2019/06/04/icarus-theme/)\n### 配置\n1. 修改 /includes/helpers/layout.js\n\n    ```diff\n        hexo.extend.helper.register('column_count', function () {\n         let columns = 1;\n        +        if (this.page.__post === true || this.page.__page === true) {\n        +            return 2;\n        +        }\n        const hasColumn = hexo.extend.helper.get('has_column').bind(this);\n        columns += hasColumn('left') ? 1 : 0;\n        columns += hasColumn('right') ? 1 : 0;\n    ```\n    \n2. 修改 /layout/common/widget.ejs\n\n    ```diff\n        <%- partial('widget/' + widget.type, { widget, post: page }) %>\n        <% }) %>\n        <% if (position === 'left') { %>\n        -        <div class=\"column-right-shadow is-hidden-widescreen <%= sticky_class('right') %>\">\n        +        <div class=\"column-right-shadow <%= (page.__page !== true && page.__post !== true) ? 'is-hidden-widescreen' : '' %> <%= sticky_class('right') %>\">\n         <% get_widgets('right').forEach(widget => {%>\n             <%- partial('widget/' + widget.type, { widget, post: page }) %>\n         <% }) %>\n    ```\n3. 修改 /layout/layout.ejs\n\n    ```diff\n         <div class=\"columns\">\n                 <div class=\"column <%= main_column_class() %> has-order-2 column-main\"><%- body %></div>\n                 <%- partial('common/widget', { position: 'left' }) %>\n        +                <% if (page.__page !== true && page.__post !== true) { %>\n                 <%- partial('common/widget', { position: 'right' }) %>\n        +                <% } %>\n             </div>\n         </div>\n         </section>\n    ```\n    \n4. 修改 /source/css/style.styl \n    \n    ```\n    @media screen and (min-width: screen-widescreen)\n        .is-1-column .container\n        .is-2-column .container\n            max-width: screen-widescreen - 2 * gap\n            width: screen-widescreen - 2 * gap\n    @media screen and (min-width: screen-fullhd)\n        .is-2-column .container\n            max-width: screen-fullhd - 2 * gap\n            width: screen-fullhd - 2 * gap\n        .is-1-column .container\n            max-width: screen-desktop - 2 * gap\n            width: screen-desktop - 2 * gapp\n    ```\n\n1. 修改 /layout/layout.ejs\n    ```\n         <% function main_column_class() {\n        switch (column_count()) {\n            case 1:\n                return 'is-12';\n            case 2:\n                return 'is-8-tablet is-9-desktop is-9-widescreen';\n            case 3:\n                return 'is-8-tablet is-8-desktop is-6-widescreen'\n        }\n        return '';\n        } %>\n    ```\n6. 修改 /layout/common/widget.ejs\n    ```\n        <% function side_column_class() {\n        switch (column_count()) {\n        case 2:\n            return 'is-4-tablet is-3-desktop is-3-widescreen';\n        case 3:\n            return 'is-4-tablet is-4-desktop is-3-widescreen';\n        }\n        return '';\n        } %>\n    ```\n\n## 文章图片居中\n最开始尝试了修改 source/js/main.js 和 layout/css/style.styl , 修改的内容也是基于水寒的博客，本地 hexo server没有问题，但是 hexo g -d 之后就总是出问题，最后还是老老实实\n    ```\n    <center> \n    </center>\n    ```\n\n## 增加profile下面的 bio, 可以放一点自己想说的话\n### 实现效果\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-16 at 11.47.59.png\" height=\"40%\" width=\"40%\">\n</center>\n\n### 配置\n修改 /layout/widget/profile.ejs, 在最后加上你想说的话\n    ```diff\n            <% } %>\n        </div>\n        <% } %>\n    +        <hr>\n    +        <p id=\"evan\">修子也好，远野也好，对于情感世界发生的事，很难简单以对和错来衡量，在这样的世界里沉浮，飘落的是情感，不败的总是每年盛开的樱花。    --《情人》</p>\n    </div>\n    </div>\n    ```\n## 置顶文章\n参考文章: `https://removeif.github.io/2019/09/19/%E5%8D%9A%E5%AE%A2%E6%BA%90%E7%A0%81%E5%88%86%E4%BA%AB.html#more`\n\n[github commit history](https://github.com/removeif/hexo-theme-icarus-removeif/commit/a924e02916607ed351904e4833c541199807482d)\n### 实现效果\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-16 at 13.30.30.png\" height=\"40%\" width=\"40%\">\n</center>\n\n### 使用说明\n在每篇文章的top comment部分配置top字段，初始值是100，如果要置顶，需要设置为大于100的值，值越大越靠前。相等时，根据时间降序。具体设置如下  \n    ```\n    title: 一亩三分地自动签到脚本\n    top: 102\n    toc: true\n    recommend: 1 \n    date: 2019-09-19 22:10:43\n    thumbnail: https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2019/20190919221611.png\n    tags: \n    categories: \n    ```\n### 配置\n修改 /layout/common/article.ejs\n    ```diff\n        <% if (post.layout != 'page') { %>\n        <div class=\"level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto\">\n            <div class=\"level-left\">\n        +       <% if(post.top > 100) { %>\n        +       <div class=\"level-item tag is-danger\" style=\"background-color: #3273dc;\">Pin</div>\n        +       <%} %>\n                <time class=\"level-item has-text-grey\" datetime=\"<%= date_xml(post.date) %>\"><%= date(post.date) %></time>\n                <% if (post.categories && post.categories.length) { %>\n                <div class=\"level-item\">\n    ```\n\n## 文章底部文章详细信息显示以及推荐文章模块配置\n参考文章: `https://removeif.github.io/2019/09/19/%E5%8D%9A%E5%AE%A2%E6%BA%90%E7%A0%81%E5%88%86%E4%BA%AB.html#more`\n\n[github commit history](https://github.com/removeif/hexo-theme-icarus-removeif/commit/8fb8c23b8e3861fd56aa983f3eac8b0dbe18162d)\n### 实现效果\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-16 at 11.59.42.png\" height=\"80%\" width=\"80%\">\n</center>\n\n### 使用说明\n在每篇文章的top comment部分配置recommend值（必须大于0），越大越靠前，相等取最新的，最多取5条。具体设置如下  \n    ```\n    title: 一亩三分地自动签到脚本\n    top: 102\n    toc: true\n    recommend: 1 \n    date: 2019-09-19 22:10:43\n    thumbnail: https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2019/20190919221611.png\n    tags: \n    categories: \n    ```\n### 配置\n1. 在 languages/xx.yml 中插入 recommend_posts，具体如下\n    ```diff\n        widget:\n            follow: 'Follow'\n            recents: 'Recent'\n        +   recommend_posts: 'Recommend Posts'\n            links: 'Links'\n            tag_cloud: 'Tag Cloud'\n            catalogue: 'Catalogue'\n    ```\n注意所使用的语言所对应的文件\n\n1. 修改 /layout/common/article.ejs \n    ```diff\n        <div class=\"level-start\">\n            <div class=\"level-item\">\n        -        <span class=\"is-size-6 has-text-grey has-mr-7\">#</span>\n        +        <i class=\"fas fa-tags has-text-grey\"></i>&nbsp;\n                <%- list_tags(post.tags, {\n                    class: 'has-link-grey ',\n                    show_count: false,\n                    \n        ..........\n\n            </div>\n        </div>\n        <% } %>\n        + <!-- 部分参考自https://www.alphalxy.com/2019/03/customize-icarus/ -->\n        + <% if (!index && post.layout === 'post' && post.copyright !== false) { %>\n            + <ul class=\"post-copyright\">\n            + <li><strong>本文标题：</strong><a href=\"<%= post.permalink %>\"><%= page.title %></a></li>\n            + <li><strong>本文作者：</strong><a href=\"<%= theme.url %>\"><%= theme.author %></a></li>\n            + <li><strong>本文链接：</strong><a href=\"<%= post.permalink %>\"><%= post.permalink %></a></li>\n            + <li><strong>版权声明：</strong>本博客所有文章除特别声明外，均采用 <a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh\" rel=\"external nofollow\" target=\"_blank\">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！\n            + </li>\n            + </ul>\n            + <br>\n            + <%- _partial('widget/recommend_posts') %>\n           + <br>\n        + br>\n         + %>\n        <% if (!index && has_config('share.type')) { %>\n        <%- _partial('share/' + get_config('share.type')) %>\n        <% } %>\n    ```\n\n3. /layout/widget 目录下添加 recommend_posts.ejs \n    ```\n        <span class=\"is-size-6 has-text-grey has-mr-7\">#&nbsp;<%= __('widget.recommend_posts') %></span>\n        <br>\n        <% var i = 1;posts.forEach(post => { %>\n        &nbsp;<%=i %>.<a href=\"<%- url_for((post.link?post.link:post.path)) %>\" class=\"is-size-6\" target=\"_blank\"><%= post.title %></a><br>\n        <% i++;}) %> \n    ```\n4. /layout/widget 目录下添加 recommend_posts.locals.js\n    ```\n        module.exports = (ctx, locals) => {\n        const { has_config, get_config, get_thumbnail } = ctx;\n        const { posts } = ctx.site;\n        if (!posts.length) {\n        return null;\n        }\n        const thumbnail = !has_config('article.thumbnail') || get_config('article.thumbnail') !== false;\n        const _posts = posts.filter((item, index, arr) => item.recommend != undefined && item.recommend > 0).sort('recommend',-1).sort('recommend',-1).limit(5).map(post => ({\n        link: post.link,\n        path: post.path,\n        title: post.title,\n        date: post.date,\n        thumbnail: thumbnail ? get_thumbnail(post) : null,\n        // fix circular JSON serialization issue\n        categories: () => post.categories\n        }));\n        return Object.assign(locals, { thumbnail, posts: _posts });\n        } \n    ```\n## 页脚访问人数显示修改\n### 实现效果  \n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-17 at 18.25.58.png\">\n</center>\n### 配置\n修改 /layout/common/footer.ejs 卜算子部分.\n```\n<% if (busuanzi) { %>\n                <br>\n                <span id=\"busuanzi_container_site_uv\">\n                <!-- <%- _p('plugin.visitor', '<span id=\"busuanzi_value_site_uv\">0</span>') %>\n                </span>\n                <br> -->\n                <span id=\"busuanzi_container_site_pv\">\n                    Visited by <span id=\"busuanzi_value_site_uv\"></span> users with <span id=\"busuanzi_value_site_pv\"></span> times\n                </span>\n                </span>\n                <% } %>\n```","source":"_posts/Hexo主题折腾日记-从cactus到icarus.md","raw":"---\ntitle: Hexo主题折腾日记(一) 从cactus到icarus\ndate: 2019-11-16 10:59:11\ntags: [JS]\ncategories:\nthumbnail: https://images.unsplash.com/photo-1486312338219-ce68d2c6f44d?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=900&q=60\nrecommend: 1\ntop: 100\ntoc: true\n---\n\n# 前言\n从Hexo建站开始，一直是使用的cactus主题，很喜欢那种简约的风格，主页文章预览的都没有的那一种。<!--more-->\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMAGE 2019-11-16 11:11:11.jpg\" height=\"60%\" width=\"60%\">\n</center>\n\n直到昨天心血来潮想搞一个基于ghost的动态博客，同时爱上了他的默认主题casper，心想这不就是我梦寐已久的主题么，结果搜了很多的资料，发现个人维护的建站工具都是至少1年以上的，有一个基于 python 可以通过ghost部署到github pags上的工具还是基于2.7,我直接裂开，最终直接放弃了这套方案，回过头来想能不能把casper移植到hexo上呢，在github上也搜到了相应的项目，但效果emmm，不是特别能让我满意，贴一张demo供大家参考。\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMAGE 2019-11-16 11:10:20.jpg\" height=\"60%\" width=\"60%\">\n</center>\n\n主要还是插件的支持度没有成熟主题的高，然后就又开始google: hexo主题推荐2019类似的关键词，终于发现了这个模版，icarus，没有cactus那么朴素，插件支持度和commit活跃度也比hexo-casper高，所以昨天花了很长很长的时间调整网页布局和文章渲染问题，最终效果我打9分吧，因为还有一点问题没有解决，等写完这个博客我再搞，下面主要把我基于别人修改的模版和自己修改的内容做一下总结，以免以后git pull之后不知道自己做了哪些修改。\n\n# icarus主题之上主要改动\n1. 主页显示两栏widget，文章只显示左边widget\n2. 文章图片居中\n3. 增加profile下面的 bio, 可以放一点自己想说的话\n4. 置顶文章\n5. 文章底部文章详细信息显示以及推荐文章模块配置\n6. 页脚访问人数显示修改\n\n## 主页显示两栏widget，文章只显示左边widget\n主要参考 [水寒blog](https://dp2px.com/2019/06/04/icarus-theme/)\n### 配置\n1. 修改 /includes/helpers/layout.js\n\n    ```diff\n        hexo.extend.helper.register('column_count', function () {\n         let columns = 1;\n        +        if (this.page.__post === true || this.page.__page === true) {\n        +            return 2;\n        +        }\n        const hasColumn = hexo.extend.helper.get('has_column').bind(this);\n        columns += hasColumn('left') ? 1 : 0;\n        columns += hasColumn('right') ? 1 : 0;\n    ```\n    \n2. 修改 /layout/common/widget.ejs\n\n    ```diff\n        <%- partial('widget/' + widget.type, { widget, post: page }) %>\n        <% }) %>\n        <% if (position === 'left') { %>\n        -        <div class=\"column-right-shadow is-hidden-widescreen <%= sticky_class('right') %>\">\n        +        <div class=\"column-right-shadow <%= (page.__page !== true && page.__post !== true) ? 'is-hidden-widescreen' : '' %> <%= sticky_class('right') %>\">\n         <% get_widgets('right').forEach(widget => {%>\n             <%- partial('widget/' + widget.type, { widget, post: page }) %>\n         <% }) %>\n    ```\n3. 修改 /layout/layout.ejs\n\n    ```diff\n         <div class=\"columns\">\n                 <div class=\"column <%= main_column_class() %> has-order-2 column-main\"><%- body %></div>\n                 <%- partial('common/widget', { position: 'left' }) %>\n        +                <% if (page.__page !== true && page.__post !== true) { %>\n                 <%- partial('common/widget', { position: 'right' }) %>\n        +                <% } %>\n             </div>\n         </div>\n         </section>\n    ```\n    \n4. 修改 /source/css/style.styl \n    \n    ```\n    @media screen and (min-width: screen-widescreen)\n        .is-1-column .container\n        .is-2-column .container\n            max-width: screen-widescreen - 2 * gap\n            width: screen-widescreen - 2 * gap\n    @media screen and (min-width: screen-fullhd)\n        .is-2-column .container\n            max-width: screen-fullhd - 2 * gap\n            width: screen-fullhd - 2 * gap\n        .is-1-column .container\n            max-width: screen-desktop - 2 * gap\n            width: screen-desktop - 2 * gapp\n    ```\n\n1. 修改 /layout/layout.ejs\n    ```\n         <% function main_column_class() {\n        switch (column_count()) {\n            case 1:\n                return 'is-12';\n            case 2:\n                return 'is-8-tablet is-9-desktop is-9-widescreen';\n            case 3:\n                return 'is-8-tablet is-8-desktop is-6-widescreen'\n        }\n        return '';\n        } %>\n    ```\n6. 修改 /layout/common/widget.ejs\n    ```\n        <% function side_column_class() {\n        switch (column_count()) {\n        case 2:\n            return 'is-4-tablet is-3-desktop is-3-widescreen';\n        case 3:\n            return 'is-4-tablet is-4-desktop is-3-widescreen';\n        }\n        return '';\n        } %>\n    ```\n\n## 文章图片居中\n最开始尝试了修改 source/js/main.js 和 layout/css/style.styl , 修改的内容也是基于水寒的博客，本地 hexo server没有问题，但是 hexo g -d 之后就总是出问题，最后还是老老实实\n    ```\n    <center> \n    </center>\n    ```\n\n## 增加profile下面的 bio, 可以放一点自己想说的话\n### 实现效果\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-16 at 11.47.59.png\" height=\"40%\" width=\"40%\">\n</center>\n\n### 配置\n修改 /layout/widget/profile.ejs, 在最后加上你想说的话\n    ```diff\n            <% } %>\n        </div>\n        <% } %>\n    +        <hr>\n    +        <p id=\"evan\">修子也好，远野也好，对于情感世界发生的事，很难简单以对和错来衡量，在这样的世界里沉浮，飘落的是情感，不败的总是每年盛开的樱花。    --《情人》</p>\n    </div>\n    </div>\n    ```\n## 置顶文章\n参考文章: `https://removeif.github.io/2019/09/19/%E5%8D%9A%E5%AE%A2%E6%BA%90%E7%A0%81%E5%88%86%E4%BA%AB.html#more`\n\n[github commit history](https://github.com/removeif/hexo-theme-icarus-removeif/commit/a924e02916607ed351904e4833c541199807482d)\n### 实现效果\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-16 at 13.30.30.png\" height=\"40%\" width=\"40%\">\n</center>\n\n### 使用说明\n在每篇文章的top comment部分配置top字段，初始值是100，如果要置顶，需要设置为大于100的值，值越大越靠前。相等时，根据时间降序。具体设置如下  \n    ```\n    title: 一亩三分地自动签到脚本\n    top: 102\n    toc: true\n    recommend: 1 \n    date: 2019-09-19 22:10:43\n    thumbnail: https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2019/20190919221611.png\n    tags: \n    categories: \n    ```\n### 配置\n修改 /layout/common/article.ejs\n    ```diff\n        <% if (post.layout != 'page') { %>\n        <div class=\"level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto\">\n            <div class=\"level-left\">\n        +       <% if(post.top > 100) { %>\n        +       <div class=\"level-item tag is-danger\" style=\"background-color: #3273dc;\">Pin</div>\n        +       <%} %>\n                <time class=\"level-item has-text-grey\" datetime=\"<%= date_xml(post.date) %>\"><%= date(post.date) %></time>\n                <% if (post.categories && post.categories.length) { %>\n                <div class=\"level-item\">\n    ```\n\n## 文章底部文章详细信息显示以及推荐文章模块配置\n参考文章: `https://removeif.github.io/2019/09/19/%E5%8D%9A%E5%AE%A2%E6%BA%90%E7%A0%81%E5%88%86%E4%BA%AB.html#more`\n\n[github commit history](https://github.com/removeif/hexo-theme-icarus-removeif/commit/8fb8c23b8e3861fd56aa983f3eac8b0dbe18162d)\n### 实现效果\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-16 at 11.59.42.png\" height=\"80%\" width=\"80%\">\n</center>\n\n### 使用说明\n在每篇文章的top comment部分配置recommend值（必须大于0），越大越靠前，相等取最新的，最多取5条。具体设置如下  \n    ```\n    title: 一亩三分地自动签到脚本\n    top: 102\n    toc: true\n    recommend: 1 \n    date: 2019-09-19 22:10:43\n    thumbnail: https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2019/20190919221611.png\n    tags: \n    categories: \n    ```\n### 配置\n1. 在 languages/xx.yml 中插入 recommend_posts，具体如下\n    ```diff\n        widget:\n            follow: 'Follow'\n            recents: 'Recent'\n        +   recommend_posts: 'Recommend Posts'\n            links: 'Links'\n            tag_cloud: 'Tag Cloud'\n            catalogue: 'Catalogue'\n    ```\n注意所使用的语言所对应的文件\n\n1. 修改 /layout/common/article.ejs \n    ```diff\n        <div class=\"level-start\">\n            <div class=\"level-item\">\n        -        <span class=\"is-size-6 has-text-grey has-mr-7\">#</span>\n        +        <i class=\"fas fa-tags has-text-grey\"></i>&nbsp;\n                <%- list_tags(post.tags, {\n                    class: 'has-link-grey ',\n                    show_count: false,\n                    \n        ..........\n\n            </div>\n        </div>\n        <% } %>\n        + <!-- 部分参考自https://www.alphalxy.com/2019/03/customize-icarus/ -->\n        + <% if (!index && post.layout === 'post' && post.copyright !== false) { %>\n            + <ul class=\"post-copyright\">\n            + <li><strong>本文标题：</strong><a href=\"<%= post.permalink %>\"><%= page.title %></a></li>\n            + <li><strong>本文作者：</strong><a href=\"<%= theme.url %>\"><%= theme.author %></a></li>\n            + <li><strong>本文链接：</strong><a href=\"<%= post.permalink %>\"><%= post.permalink %></a></li>\n            + <li><strong>版权声明：</strong>本博客所有文章除特别声明外，均采用 <a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh\" rel=\"external nofollow\" target=\"_blank\">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！\n            + </li>\n            + </ul>\n            + <br>\n            + <%- _partial('widget/recommend_posts') %>\n           + <br>\n        + br>\n         + %>\n        <% if (!index && has_config('share.type')) { %>\n        <%- _partial('share/' + get_config('share.type')) %>\n        <% } %>\n    ```\n\n3. /layout/widget 目录下添加 recommend_posts.ejs \n    ```\n        <span class=\"is-size-6 has-text-grey has-mr-7\">#&nbsp;<%= __('widget.recommend_posts') %></span>\n        <br>\n        <% var i = 1;posts.forEach(post => { %>\n        &nbsp;<%=i %>.<a href=\"<%- url_for((post.link?post.link:post.path)) %>\" class=\"is-size-6\" target=\"_blank\"><%= post.title %></a><br>\n        <% i++;}) %> \n    ```\n4. /layout/widget 目录下添加 recommend_posts.locals.js\n    ```\n        module.exports = (ctx, locals) => {\n        const { has_config, get_config, get_thumbnail } = ctx;\n        const { posts } = ctx.site;\n        if (!posts.length) {\n        return null;\n        }\n        const thumbnail = !has_config('article.thumbnail') || get_config('article.thumbnail') !== false;\n        const _posts = posts.filter((item, index, arr) => item.recommend != undefined && item.recommend > 0).sort('recommend',-1).sort('recommend',-1).limit(5).map(post => ({\n        link: post.link,\n        path: post.path,\n        title: post.title,\n        date: post.date,\n        thumbnail: thumbnail ? get_thumbnail(post) : null,\n        // fix circular JSON serialization issue\n        categories: () => post.categories\n        }));\n        return Object.assign(locals, { thumbnail, posts: _posts });\n        } \n    ```\n## 页脚访问人数显示修改\n### 实现效果  \n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-17 at 18.25.58.png\">\n</center>\n### 配置\n修改 /layout/common/footer.ejs 卜算子部分.\n```\n<% if (busuanzi) { %>\n                <br>\n                <span id=\"busuanzi_container_site_uv\">\n                <!-- <%- _p('plugin.visitor', '<span id=\"busuanzi_value_site_uv\">0</span>') %>\n                </span>\n                <br> -->\n                <span id=\"busuanzi_container_site_pv\">\n                    Visited by <span id=\"busuanzi_value_site_uv\"></span> users with <span id=\"busuanzi_value_site_pv\"></span> times\n                </span>\n                </span>\n                <% } %>\n```","slug":"Hexo主题折腾日记-从cactus到icarus","published":1,"updated":"2019-11-17T13:00:05.345Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkpr0014k3x6geouat0i","content":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>从Hexo建站开始，一直是使用的cactus主题，很喜欢那种简约的风格，主页文章预览的都没有的那一种。<a id=\"more\"></a></p>\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMAGE 2019-11-16 11:11:11.jpg\" height=\"60%\" width=\"60%\">\n</center>\n\n<p>直到昨天心血来潮想搞一个基于ghost的动态博客，同时爱上了他的默认主题casper，心想这不就是我梦寐已久的主题么，结果搜了很多的资料，发现个人维护的建站工具都是至少1年以上的，有一个基于 python 可以通过ghost部署到github pags上的工具还是基于2.7,我直接裂开，最终直接放弃了这套方案，回过头来想能不能把casper移植到hexo上呢，在github上也搜到了相应的项目，但效果emmm，不是特别能让我满意，贴一张demo供大家参考。</p>\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMAGE 2019-11-16 11:10:20.jpg\" height=\"60%\" width=\"60%\">\n</center>\n\n<p>主要还是插件的支持度没有成熟主题的高，然后就又开始google: hexo主题推荐2019类似的关键词，终于发现了这个模版，icarus，没有cactus那么朴素，插件支持度和commit活跃度也比hexo-casper高，所以昨天花了很长很长的时间调整网页布局和文章渲染问题，最终效果我打9分吧，因为还有一点问题没有解决，等写完这个博客我再搞，下面主要把我基于别人修改的模版和自己修改的内容做一下总结，以免以后git pull之后不知道自己做了哪些修改。</p>\n<h1 id=\"icarus主题之上主要改动\"><a href=\"#icarus主题之上主要改动\" class=\"headerlink\" title=\"icarus主题之上主要改动\"></a>icarus主题之上主要改动</h1><ol>\n<li>主页显示两栏widget，文章只显示左边widget</li>\n<li>文章图片居中</li>\n<li>增加profile下面的 bio, 可以放一点自己想说的话</li>\n<li>置顶文章</li>\n<li>文章底部文章详细信息显示以及推荐文章模块配置</li>\n<li>页脚访问人数显示修改</li>\n</ol>\n<h2 id=\"主页显示两栏widget，文章只显示左边widget\"><a href=\"#主页显示两栏widget，文章只显示左边widget\" class=\"headerlink\" title=\"主页显示两栏widget，文章只显示左边widget\"></a>主页显示两栏widget，文章只显示左边widget</h2><p>主要参考 <a href=\"https://dp2px.com/2019/06/04/icarus-theme/\" target=\"_blank\" rel=\"noopener\">水寒blog</a></p>\n<h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><ol>\n<li><p>修改 /includes/helpers/layout.js</p>\n <figure class=\"highlight diff hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">hexo.extend.helper.register('column_count', function () &#123;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\"> let columns = 1;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-addition\">+        if (this.page.__post === true || this.page.__page === true) &#123;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-addition\">+            return 2;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-addition\">+        &#125;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">const hasColumn = hexo.extend.helper.get('has_column').bind(this);</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">columns += hasColumn('left') ? 1 : 0;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">columns += hasColumn('right') ? 1 : 0;</span></pre></td></tr></table></figure>\n</li>\n<li><p>修改 /layout/common/widget.ejs</p>\n <figure class=\"highlight diff hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;%- partial('widget/' + widget.type, &#123; widget, post: page &#125;) %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% &#125;) %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% if (position <span class=\"hljs-comment\">=== 'left') &#123; %&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-deletion\">-        &lt;div class=\"column-right-shadow is-hidden-widescreen &lt;%= sticky_class('right') %&gt;\"&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-addition\">+        &lt;div class=\"column-right-shadow &lt;%= (page.__page !== true &amp;&amp; page.__post !== true) ? 'is-hidden-widescreen' : '' %&gt; &lt;%= sticky_class('right') %&gt;\"&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\"> &lt;% get_widgets('right').forEach(widget =&gt; &#123;%&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">     &lt;%- partial('widget/' + widget.type, &#123; widget, post: page &#125;) %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\"> &lt;% &#125;) %&gt;</span></pre></td></tr></table></figure></li>\n<li><p>修改 /layout/layout.ejs</p>\n <figure class=\"highlight diff hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\"> &lt;div class=\"columns\"&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">         &lt;div class=\"column &lt;%= main_column_class() %&gt; has-order-2 column-main\"&gt;&lt;%- body %&gt;&lt;/div&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">         &lt;%- partial('common/widget', &#123; position: 'left' &#125;) %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-addition\">+                &lt;% if (page.__page !== true &amp;&amp; page.__post !== true) &#123; %&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">         &lt;%- partial('common/widget', &#123; position: 'right' &#125;) %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-addition\">+                &lt;% &#125; %&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">     &lt;/div&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\"> &lt;/div&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\"> &lt;/section&gt;</span></pre></td></tr></table></figure>\n</li>\n<li><p>修改 /source/css/style.styl </p>\n <figure class=\"highlight plain hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">@media screen and (min-width: screen-widescreen)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">    .is-1-column .container</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">    .is-2-column .container</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">        max-width: screen-widescreen - 2 * gap</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">        width: screen-widescreen - 2 * gap</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">@media screen and (min-width: screen-fullhd)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">    .is-2-column .container</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">        max-width: screen-fullhd - 2 * gap</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">        width: screen-fullhd - 2 * gap</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">    .is-1-column .container</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">        max-width: screen-desktop - 2 * gap</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">        width: screen-desktop - 2 * gapp</span></pre></td></tr></table></figure>\n</li>\n<li><p>修改 /layout/layout.ejs</p>\n <figure class=\"highlight plain hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\"> &lt;% function main_column_class() &#123;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">switch (column_count()) &#123;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">    case 1:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">        return &#39;is-12&#39;;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">    case 2:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">        return &#39;is-8-tablet is-9-desktop is-9-widescreen&#39;;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">    case 3:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">        return &#39;is-8-tablet is-8-desktop is-6-widescreen&#39;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">&#125;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">return &#39;&#39;;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">&#125; %&gt;</span></pre></td></tr></table></figure></li>\n<li><p>修改 /layout/common/widget.ejs</p>\n <figure class=\"highlight plain hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% function side_column_class() &#123;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">switch (column_count()) &#123;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">case 2:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">    return &#39;is-4-tablet is-3-desktop is-3-widescreen&#39;;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">case 3:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">    return &#39;is-4-tablet is-4-desktop is-3-widescreen&#39;;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">&#125;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">return &#39;&#39;;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">&#125; %&gt;</span></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<h2 id=\"文章图片居中\"><a href=\"#文章图片居中\" class=\"headerlink\" title=\"文章图片居中\"></a>文章图片居中</h2><p>最开始尝试了修改 source/js/main.js 和 layout/css/style.styl , 修改的内容也是基于水寒的博客，本地 hexo server没有问题，但是 hexo g -d 之后就总是出问题，最后还是老老实实<br>    <figure class=\"highlight plain hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;center&gt; </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;&#x2F;center&gt;</span></pre></td></tr></table></figure></p>\n<h2 id=\"增加profile下面的-bio-可以放一点自己想说的话\"><a href=\"#增加profile下面的-bio-可以放一点自己想说的话\" class=\"headerlink\" title=\"增加profile下面的 bio, 可以放一点自己想说的话\"></a>增加profile下面的 bio, 可以放一点自己想说的话</h2><h3 id=\"实现效果\"><a href=\"#实现效果\" class=\"headerlink\" title=\"实现效果\"></a>实现效果</h3><center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-16 at 11.47.59.png\" height=\"40%\" width=\"40%\">\n</center>\n\n<h3 id=\"配置-1\"><a href=\"#配置-1\" class=\"headerlink\" title=\"配置\"></a>配置</h3><p>修改 /layout/widget/profile.ejs, 在最后加上你想说的话<br>    <figure class=\"highlight diff hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">        &lt;% &#125; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">    &lt;/div&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">    &lt;% &#125; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-addition\">+        &lt;hr&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-addition\">+        &lt;p id=\"evan\"&gt;修子也好，远野也好，对于情感世界发生的事，很难简单以对和错来衡量，在这样的世界里沉浮，飘落的是情感，不败的总是每年盛开的樱花。    --《情人》&lt;/p&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;/div&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;/div&gt;</span></pre></td></tr></table></figure></p>\n<h2 id=\"置顶文章\"><a href=\"#置顶文章\" class=\"headerlink\" title=\"置顶文章\"></a>置顶文章</h2><p>参考文章: <code>https://removeif.github.io/2019/09/19/%E5%8D%9A%E5%AE%A2%E6%BA%90%E7%A0%81%E5%88%86%E4%BA%AB.html#more</code></p>\n<p><a href=\"https://github.com/removeif/hexo-theme-icarus-removeif/commit/a924e02916607ed351904e4833c541199807482d\" target=\"_blank\" rel=\"noopener\">github commit history</a></p>\n<h3 id=\"实现效果-1\"><a href=\"#实现效果-1\" class=\"headerlink\" title=\"实现效果\"></a>实现效果</h3><center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-16 at 13.30.30.png\" height=\"40%\" width=\"40%\">\n</center>\n\n<h3 id=\"使用说明\"><a href=\"#使用说明\" class=\"headerlink\" title=\"使用说明\"></a>使用说明</h3><p>在每篇文章的top comment部分配置top字段，初始值是100，如果要置顶，需要设置为大于100的值，值越大越靠前。相等时，根据时间降序。具体设置如下<br>    <figure class=\"highlight plain hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">title: 一亩三分地自动签到脚本</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">top: 102</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">toc: true</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">recommend: 1 </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2019-09-19 22:10:43</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">thumbnail: https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;removeif&#x2F;blog_image&#x2F;img&#x2F;2019&#x2F;20190919221611.png</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">tags: </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">categories:</span></pre></td></tr></table></figure></p>\n<h3 id=\"配置-2\"><a href=\"#配置-2\" class=\"headerlink\" title=\"配置\"></a>配置</h3><p>修改 /layout/common/article.ejs<br>    <figure class=\"highlight diff hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% if (post.layout != 'page') &#123; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;div class=\"level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto\"&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">    &lt;div class=\"level-left\"&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-addition\">+       &lt;% if(post.top &gt; 100) &#123; %&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-addition\">+       &lt;div class=\"level-item tag is-danger\" style=\"background-color: #3273dc;\"&gt;Pin&lt;/div&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-addition\">+       &lt;%&#125; %&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">        &lt;time class=\"level-item has-text-grey\" datetime=\"&lt;%= date_xml(post.date) %&gt;\"&gt;&lt;%= date(post.date) %&gt;&lt;/time&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">        &lt;% if (post.categories &amp;&amp; post.categories.length) &#123; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">        &lt;div class=\"level-item\"&gt;</span></pre></td></tr></table></figure></p>\n<h2 id=\"文章底部文章详细信息显示以及推荐文章模块配置\"><a href=\"#文章底部文章详细信息显示以及推荐文章模块配置\" class=\"headerlink\" title=\"文章底部文章详细信息显示以及推荐文章模块配置\"></a>文章底部文章详细信息显示以及推荐文章模块配置</h2><p>参考文章: <code>https://removeif.github.io/2019/09/19/%E5%8D%9A%E5%AE%A2%E6%BA%90%E7%A0%81%E5%88%86%E4%BA%AB.html#more</code></p>\n<p><a href=\"https://github.com/removeif/hexo-theme-icarus-removeif/commit/8fb8c23b8e3861fd56aa983f3eac8b0dbe18162d\" target=\"_blank\" rel=\"noopener\">github commit history</a></p>\n<h3 id=\"实现效果-2\"><a href=\"#实现效果-2\" class=\"headerlink\" title=\"实现效果\"></a>实现效果</h3><center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-16 at 11.59.42.png\" height=\"80%\" width=\"80%\">\n</center>\n\n<h3 id=\"使用说明-1\"><a href=\"#使用说明-1\" class=\"headerlink\" title=\"使用说明\"></a>使用说明</h3><p>在每篇文章的top comment部分配置recommend值（必须大于0），越大越靠前，相等取最新的，最多取5条。具体设置如下<br>    <figure class=\"highlight plain hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">title: 一亩三分地自动签到脚本</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">top: 102</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">toc: true</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">recommend: 1 </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2019-09-19 22:10:43</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">thumbnail: https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;removeif&#x2F;blog_image&#x2F;img&#x2F;2019&#x2F;20190919221611.png</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">tags: </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">categories:</span></pre></td></tr></table></figure></p>\n<h3 id=\"配置-3\"><a href=\"#配置-3\" class=\"headerlink\" title=\"配置\"></a>配置</h3><ol>\n<li><p>在 languages/xx.yml 中插入 recommend_posts，具体如下</p>\n <figure class=\"highlight diff hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">widget:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">    follow: 'Follow'</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">    recents: 'Recent'</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-addition\">+   recommend_posts: 'Recommend Posts'</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">    links: 'Links'</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">    tag_cloud: 'Tag Cloud'</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">    catalogue: 'Catalogue'</span></pre></td></tr></table></figure>\n<p>注意所使用的语言所对应的文件</p>\n</li>\n<li><p>修改 /layout/common/article.ejs </p>\n <figure class=\"highlight diff hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;div class=\"level-start\"&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">    &lt;div class=\"level-item\"&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-deletion\">-        &lt;span class=\"is-size-6 has-text-grey has-mr-7\"&gt;#&lt;/span&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-addition\">+        &lt;i class=\"fas fa-tags has-text-grey\"&gt;&lt;/i&gt;&amp;nbsp;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">        &lt;%- list_tags(post.tags, &#123;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">            class: 'has-link-grey ',</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">            show_count: false,</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">            </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">..........</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">    &lt;/div&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;/div&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% &#125; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">14</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-addition\">+ &lt;!-- 部分参考自https://www.alphalxy.com/2019/03/customize-icarus/ --&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">15</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-addition\">+ &lt;% if (!index &amp;&amp; post.layout === 'post' &amp;&amp; post.copyright !== false) &#123; %&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">16</span></pre></td><td class=\"code\"><pre><span class=\"line\">    + &lt;ul class=\"post-copyright\"&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">17</span></pre></td><td class=\"code\"><pre><span class=\"line\">    + &lt;li&gt;&lt;strong&gt;本文标题：&lt;/strong&gt;&lt;a href=\"&lt;%= post.permalink %&gt;\"&gt;&lt;%= page.title %&gt;&lt;/a&gt;&lt;/li&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">18</span></pre></td><td class=\"code\"><pre><span class=\"line\">    + &lt;li&gt;&lt;strong&gt;本文作者：&lt;/strong&gt;&lt;a href=\"&lt;%= theme.url %&gt;\"&gt;&lt;%= theme.author %&gt;&lt;/a&gt;&lt;/li&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">19</span></pre></td><td class=\"code\"><pre><span class=\"line\">    + &lt;li&gt;&lt;strong&gt;本文链接：&lt;/strong&gt;&lt;a href=\"&lt;%= post.permalink %&gt;\"&gt;&lt;%= post.permalink %&gt;&lt;/a&gt;&lt;/li&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">20</span></pre></td><td class=\"code\"><pre><span class=\"line\">    + &lt;li&gt;&lt;strong&gt;版权声明：&lt;/strong&gt;本博客所有文章除特别声明外，均采用 &lt;a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh\" rel=\"external nofollow\" target=\"_blank\"&gt;CC BY-NC-SA 4.0&lt;/a&gt; 许可协议。转载请注明出处！</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">21</span></pre></td><td class=\"code\"><pre><span class=\"line\">    + &lt;/li&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">22</span></pre></td><td class=\"code\"><pre><span class=\"line\">    + &lt;/ul&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">23</span></pre></td><td class=\"code\"><pre><span class=\"line\">    + &lt;br&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">24</span></pre></td><td class=\"code\"><pre><span class=\"line\">    + &lt;%- _partial('widget/recommend_posts') %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">25</span></pre></td><td class=\"code\"><pre><span class=\"line\">   + &lt;br&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">26</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-addition\">+ br&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">27</span></pre></td><td class=\"code\"><pre><span class=\"line\"> + %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">28</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% if (!index &amp;&amp; has_config('share.type')) &#123; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">29</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;%- _partial('share/' + get_config('share.type')) %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">30</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% &#125; %&gt;</span></pre></td></tr></table></figure>\n</li>\n<li><p>/layout/widget 目录下添加 recommend_posts.ejs </p>\n <figure class=\"highlight plain hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;span class&#x3D;&quot;is-size-6 has-text-grey has-mr-7&quot;&gt;#&amp;nbsp;&lt;%&#x3D; __(&#39;widget.recommend_posts&#39;) %&gt;&lt;&#x2F;span&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;br&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% var i &#x3D; 1;posts.forEach(post &#x3D;&gt; &#123; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">&amp;nbsp;&lt;%&#x3D;i %&gt;.&lt;a href&#x3D;&quot;&lt;%- url_for((post.link?post.link:post.path)) %&gt;&quot; class&#x3D;&quot;is-size-6&quot; target&#x3D;&quot;_blank&quot;&gt;&lt;%&#x3D; post.title %&gt;&lt;&#x2F;a&gt;&lt;br&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% i++;&#125;) %&gt;</span></pre></td></tr></table></figure></li>\n<li><p>/layout/widget 目录下添加 recommend_posts.locals.js</p>\n <figure class=\"highlight plain hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">module.exports &#x3D; (ctx, locals) &#x3D;&gt; &#123;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">const &#123; has_config, get_config, get_thumbnail &#125; &#x3D; ctx;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">const &#123; posts &#125; &#x3D; ctx.site;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">if (!posts.length) &#123;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">return null;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">&#125;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">const thumbnail &#x3D; !has_config(&#39;article.thumbnail&#39;) || get_config(&#39;article.thumbnail&#39;) !&#x3D;&#x3D; false;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">const _posts &#x3D; posts.filter((item, index, arr) &#x3D;&gt; item.recommend !&#x3D; undefined &amp;&amp; item.recommend &gt; 0).sort(&#39;recommend&#39;,-1).sort(&#39;recommend&#39;,-1).limit(5).map(post &#x3D;&gt; (&#123;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">link: post.link,</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">path: post.path,</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">title: post.title,</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">date: post.date,</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\">thumbnail: thumbnail ? get_thumbnail(post) : null,</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">14</span></pre></td><td class=\"code\"><pre><span class=\"line\">&#x2F;&#x2F; fix circular JSON serialization issue</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">15</span></pre></td><td class=\"code\"><pre><span class=\"line\">categories: () &#x3D;&gt; post.categories</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">16</span></pre></td><td class=\"code\"><pre><span class=\"line\">&#125;));</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">17</span></pre></td><td class=\"code\"><pre><span class=\"line\">return Object.assign(locals, &#123; thumbnail, posts: _posts &#125;);</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">18</span></pre></td><td class=\"code\"><pre><span class=\"line\">&#125;</span></pre></td></tr></table></figure>\n<h2 id=\"页脚访问人数显示修改\"><a href=\"#页脚访问人数显示修改\" class=\"headerlink\" title=\"页脚访问人数显示修改\"></a>页脚访问人数显示修改</h2><h3 id=\"实现效果-3\"><a href=\"#实现效果-3\" class=\"headerlink\" title=\"实现效果\"></a>实现效果</h3><center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-17 at 18.25.58.png\">\n</center>\n### 配置\n修改 /layout/common/footer.ejs 卜算子部分.\n<figure class=\"highlight plain hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% if (busuanzi) &#123; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;br&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;span id&#x3D;&quot;busuanzi_container_site_uv&quot;&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;!-- &lt;%- _p(&#39;plugin.visitor&#39;, &#39;&lt;span id&#x3D;&quot;busuanzi_value_site_uv&quot;&gt;0&lt;&#x2F;span&gt;&#39;) %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;&#x2F;span&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;br&gt; --&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;span id&#x3D;&quot;busuanzi_container_site_pv&quot;&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">                    Visited by &lt;span id&#x3D;&quot;busuanzi_value_site_uv&quot;&gt;&lt;&#x2F;span&gt; users with &lt;span id&#x3D;&quot;busuanzi_value_site_pv&quot;&gt;&lt;&#x2F;span&gt; times</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;&#x2F;span&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;&#x2F;span&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;% &#125; %&gt;</span></pre></td></tr></table></figure></li>\n</ol>\n","site":{"data":{}},"excerpt":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>从Hexo建站开始，一直是使用的cactus主题，很喜欢那种简约的风格，主页文章预览的都没有的那一种。</p>","more":"</p>\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMAGE 2019-11-16 11:11:11.jpg\" height=\"60%\" width=\"60%\">\n</center>\n\n<p>直到昨天心血来潮想搞一个基于ghost的动态博客，同时爱上了他的默认主题casper，心想这不就是我梦寐已久的主题么，结果搜了很多的资料，发现个人维护的建站工具都是至少1年以上的，有一个基于 python 可以通过ghost部署到github pags上的工具还是基于2.7,我直接裂开，最终直接放弃了这套方案，回过头来想能不能把casper移植到hexo上呢，在github上也搜到了相应的项目，但效果emmm，不是特别能让我满意，贴一张demo供大家参考。</p>\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMAGE 2019-11-16 11:10:20.jpg\" height=\"60%\" width=\"60%\">\n</center>\n\n<p>主要还是插件的支持度没有成熟主题的高，然后就又开始google: hexo主题推荐2019类似的关键词，终于发现了这个模版，icarus，没有cactus那么朴素，插件支持度和commit活跃度也比hexo-casper高，所以昨天花了很长很长的时间调整网页布局和文章渲染问题，最终效果我打9分吧，因为还有一点问题没有解决，等写完这个博客我再搞，下面主要把我基于别人修改的模版和自己修改的内容做一下总结，以免以后git pull之后不知道自己做了哪些修改。</p>\n<h1 id=\"icarus主题之上主要改动\"><a href=\"#icarus主题之上主要改动\" class=\"headerlink\" title=\"icarus主题之上主要改动\"></a>icarus主题之上主要改动</h1><ol>\n<li>主页显示两栏widget，文章只显示左边widget</li>\n<li>文章图片居中</li>\n<li>增加profile下面的 bio, 可以放一点自己想说的话</li>\n<li>置顶文章</li>\n<li>文章底部文章详细信息显示以及推荐文章模块配置</li>\n<li>页脚访问人数显示修改</li>\n</ol>\n<h2 id=\"主页显示两栏widget，文章只显示左边widget\"><a href=\"#主页显示两栏widget，文章只显示左边widget\" class=\"headerlink\" title=\"主页显示两栏widget，文章只显示左边widget\"></a>主页显示两栏widget，文章只显示左边widget</h2><p>主要参考 <a href=\"https://dp2px.com/2019/06/04/icarus-theme/\" target=\"_blank\" rel=\"noopener\">水寒blog</a></p>\n<h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><ol>\n<li><p>修改 /includes/helpers/layout.js</p>\n <figure class=\"highlight diff\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">hexo.extend.helper.register('column_count', function () &#123;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\"> let columns = 1;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"addition\">+        if (this.page.__post === true || this.page.__page === true) &#123;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"addition\">+            return 2;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"addition\">+        &#125;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">const hasColumn = hexo.extend.helper.get('has_column').bind(this);</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">columns += hasColumn('left') ? 1 : 0;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">columns += hasColumn('right') ? 1 : 0;</span></pre></td></tr></table></figure>\n</li>\n<li><p>修改 /layout/common/widget.ejs</p>\n <figure class=\"highlight diff\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;%- partial('widget/' + widget.type, &#123; widget, post: page &#125;) %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% &#125;) %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% if (position <span class=\"comment\">=== 'left') &#123; %&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"deletion\">-        &lt;div class=\"column-right-shadow is-hidden-widescreen &lt;%= sticky_class('right') %&gt;\"&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"addition\">+        &lt;div class=\"column-right-shadow &lt;%= (page.__page !== true &amp;&amp; page.__post !== true) ? 'is-hidden-widescreen' : '' %&gt; &lt;%= sticky_class('right') %&gt;\"&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\"> &lt;% get_widgets('right').forEach(widget =&gt; &#123;%&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">     &lt;%- partial('widget/' + widget.type, &#123; widget, post: page &#125;) %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\"> &lt;% &#125;) %&gt;</span></pre></td></tr></table></figure></li>\n<li><p>修改 /layout/layout.ejs</p>\n <figure class=\"highlight diff\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\"> &lt;div class=\"columns\"&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">         &lt;div class=\"column &lt;%= main_column_class() %&gt; has-order-2 column-main\"&gt;&lt;%- body %&gt;&lt;/div&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">         &lt;%- partial('common/widget', &#123; position: 'left' &#125;) %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"addition\">+                &lt;% if (page.__page !== true &amp;&amp; page.__post !== true) &#123; %&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">         &lt;%- partial('common/widget', &#123; position: 'right' &#125;) %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"addition\">+                &lt;% &#125; %&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">     &lt;/div&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\"> &lt;/div&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\"> &lt;/section&gt;</span></pre></td></tr></table></figure>\n</li>\n<li><p>修改 /source/css/style.styl </p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">@media screen and (min-width: screen-widescreen)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">    .is-1-column .container</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">    .is-2-column .container</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">        max-width: screen-widescreen - 2 * gap</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">        width: screen-widescreen - 2 * gap</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">@media screen and (min-width: screen-fullhd)</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">    .is-2-column .container</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">        max-width: screen-fullhd - 2 * gap</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">        width: screen-fullhd - 2 * gap</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">    .is-1-column .container</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">        max-width: screen-desktop - 2 * gap</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">        width: screen-desktop - 2 * gapp</span></pre></td></tr></table></figure>\n</li>\n<li><p>修改 /layout/layout.ejs</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\"> &lt;% function main_column_class() &#123;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">switch (column_count()) &#123;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">    case 1:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">        return &#39;is-12&#39;;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">    case 2:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">        return &#39;is-8-tablet is-9-desktop is-9-widescreen&#39;;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">    case 3:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">        return &#39;is-8-tablet is-8-desktop is-6-widescreen&#39;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">&#125;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">return &#39;&#39;;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">&#125; %&gt;</span></pre></td></tr></table></figure></li>\n<li><p>修改 /layout/common/widget.ejs</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% function side_column_class() &#123;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">switch (column_count()) &#123;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">case 2:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">    return &#39;is-4-tablet is-3-desktop is-3-widescreen&#39;;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">case 3:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">    return &#39;is-4-tablet is-4-desktop is-3-widescreen&#39;;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">&#125;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">return &#39;&#39;;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">&#125; %&gt;</span></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<h2 id=\"文章图片居中\"><a href=\"#文章图片居中\" class=\"headerlink\" title=\"文章图片居中\"></a>文章图片居中</h2><p>最开始尝试了修改 source/js/main.js 和 layout/css/style.styl , 修改的内容也是基于水寒的博客，本地 hexo server没有问题，但是 hexo g -d 之后就总是出问题，最后还是老老实实<br>    <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;center&gt; </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;&#x2F;center&gt;</span></pre></td></tr></table></figure></p>\n<h2 id=\"增加profile下面的-bio-可以放一点自己想说的话\"><a href=\"#增加profile下面的-bio-可以放一点自己想说的话\" class=\"headerlink\" title=\"增加profile下面的 bio, 可以放一点自己想说的话\"></a>增加profile下面的 bio, 可以放一点自己想说的话</h2><h3 id=\"实现效果\"><a href=\"#实现效果\" class=\"headerlink\" title=\"实现效果\"></a>实现效果</h3><center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-16 at 11.47.59.png\" height=\"40%\" width=\"40%\">\n</center>\n\n<h3 id=\"配置-1\"><a href=\"#配置-1\" class=\"headerlink\" title=\"配置\"></a>配置</h3><p>修改 /layout/widget/profile.ejs, 在最后加上你想说的话<br>    <figure class=\"highlight diff\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">        &lt;% &#125; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">    &lt;/div&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">    &lt;% &#125; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"addition\">+        &lt;hr&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"addition\">+        &lt;p id=\"evan\"&gt;修子也好，远野也好，对于情感世界发生的事，很难简单以对和错来衡量，在这样的世界里沉浮，飘落的是情感，不败的总是每年盛开的樱花。    --《情人》&lt;/p&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;/div&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;/div&gt;</span></pre></td></tr></table></figure></p>\n<h2 id=\"置顶文章\"><a href=\"#置顶文章\" class=\"headerlink\" title=\"置顶文章\"></a>置顶文章</h2><p>参考文章: <code>https://removeif.github.io/2019/09/19/%E5%8D%9A%E5%AE%A2%E6%BA%90%E7%A0%81%E5%88%86%E4%BA%AB.html#more</code></p>\n<p><a href=\"https://github.com/removeif/hexo-theme-icarus-removeif/commit/a924e02916607ed351904e4833c541199807482d\" target=\"_blank\" rel=\"noopener\">github commit history</a></p>\n<h3 id=\"实现效果-1\"><a href=\"#实现效果-1\" class=\"headerlink\" title=\"实现效果\"></a>实现效果</h3><center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-16 at 13.30.30.png\" height=\"40%\" width=\"40%\">\n</center>\n\n<h3 id=\"使用说明\"><a href=\"#使用说明\" class=\"headerlink\" title=\"使用说明\"></a>使用说明</h3><p>在每篇文章的top comment部分配置top字段，初始值是100，如果要置顶，需要设置为大于100的值，值越大越靠前。相等时，根据时间降序。具体设置如下<br>    <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">title: 一亩三分地自动签到脚本</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">top: 102</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">toc: true</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">recommend: 1 </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2019-09-19 22:10:43</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">thumbnail: https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;removeif&#x2F;blog_image&#x2F;img&#x2F;2019&#x2F;20190919221611.png</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">tags: </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">categories:</span></pre></td></tr></table></figure></p>\n<h3 id=\"配置-2\"><a href=\"#配置-2\" class=\"headerlink\" title=\"配置\"></a>配置</h3><p>修改 /layout/common/article.ejs<br>    <figure class=\"highlight diff\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% if (post.layout != 'page') &#123; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;div class=\"level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto\"&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">    &lt;div class=\"level-left\"&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"addition\">+       &lt;% if(post.top &gt; 100) &#123; %&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"addition\">+       &lt;div class=\"level-item tag is-danger\" style=\"background-color: #3273dc;\"&gt;Pin&lt;/div&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"addition\">+       &lt;%&#125; %&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">        &lt;time class=\"level-item has-text-grey\" datetime=\"&lt;%= date_xml(post.date) %&gt;\"&gt;&lt;%= date(post.date) %&gt;&lt;/time&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">        &lt;% if (post.categories &amp;&amp; post.categories.length) &#123; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">        &lt;div class=\"level-item\"&gt;</span></pre></td></tr></table></figure></p>\n<h2 id=\"文章底部文章详细信息显示以及推荐文章模块配置\"><a href=\"#文章底部文章详细信息显示以及推荐文章模块配置\" class=\"headerlink\" title=\"文章底部文章详细信息显示以及推荐文章模块配置\"></a>文章底部文章详细信息显示以及推荐文章模块配置</h2><p>参考文章: <code>https://removeif.github.io/2019/09/19/%E5%8D%9A%E5%AE%A2%E6%BA%90%E7%A0%81%E5%88%86%E4%BA%AB.html#more</code></p>\n<p><a href=\"https://github.com/removeif/hexo-theme-icarus-removeif/commit/8fb8c23b8e3861fd56aa983f3eac8b0dbe18162d\" target=\"_blank\" rel=\"noopener\">github commit history</a></p>\n<h3 id=\"实现效果-2\"><a href=\"#实现效果-2\" class=\"headerlink\" title=\"实现效果\"></a>实现效果</h3><center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-16 at 11.59.42.png\" height=\"80%\" width=\"80%\">\n</center>\n\n<h3 id=\"使用说明-1\"><a href=\"#使用说明-1\" class=\"headerlink\" title=\"使用说明\"></a>使用说明</h3><p>在每篇文章的top comment部分配置recommend值（必须大于0），越大越靠前，相等取最新的，最多取5条。具体设置如下<br>    <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">title: 一亩三分地自动签到脚本</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">top: 102</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">toc: true</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">recommend: 1 </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2019-09-19 22:10:43</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">thumbnail: https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;removeif&#x2F;blog_image&#x2F;img&#x2F;2019&#x2F;20190919221611.png</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">tags: </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">categories:</span></pre></td></tr></table></figure></p>\n<h3 id=\"配置-3\"><a href=\"#配置-3\" class=\"headerlink\" title=\"配置\"></a>配置</h3><ol>\n<li><p>在 languages/xx.yml 中插入 recommend_posts，具体如下</p>\n <figure class=\"highlight diff\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">widget:</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">    follow: 'Follow'</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">    recents: 'Recent'</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"addition\">+   recommend_posts: 'Recommend Posts'</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">    links: 'Links'</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">    tag_cloud: 'Tag Cloud'</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">    catalogue: 'Catalogue'</span></pre></td></tr></table></figure>\n<p>注意所使用的语言所对应的文件</p>\n</li>\n<li><p>修改 /layout/common/article.ejs </p>\n <figure class=\"highlight diff\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;div class=\"level-start\"&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">    &lt;div class=\"level-item\"&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"deletion\">-        &lt;span class=\"is-size-6 has-text-grey has-mr-7\"&gt;#&lt;/span&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"addition\">+        &lt;i class=\"fas fa-tags has-text-grey\"&gt;&lt;/i&gt;&amp;nbsp;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">        &lt;%- list_tags(post.tags, &#123;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">            class: 'has-link-grey ',</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">            show_count: false,</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">            </span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">..........</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\"></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">    &lt;/div&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;/div&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% &#125; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">14</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"addition\">+ &lt;!-- 部分参考自https://www.alphalxy.com/2019/03/customize-icarus/ --&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">15</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"addition\">+ &lt;% if (!index &amp;&amp; post.layout === 'post' &amp;&amp; post.copyright !== false) &#123; %&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">16</span></pre></td><td class=\"code\"><pre><span class=\"line\">    + &lt;ul class=\"post-copyright\"&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">17</span></pre></td><td class=\"code\"><pre><span class=\"line\">    + &lt;li&gt;&lt;strong&gt;本文标题：&lt;/strong&gt;&lt;a href=\"&lt;%= post.permalink %&gt;\"&gt;&lt;%= page.title %&gt;&lt;/a&gt;&lt;/li&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">18</span></pre></td><td class=\"code\"><pre><span class=\"line\">    + &lt;li&gt;&lt;strong&gt;本文作者：&lt;/strong&gt;&lt;a href=\"&lt;%= theme.url %&gt;\"&gt;&lt;%= theme.author %&gt;&lt;/a&gt;&lt;/li&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">19</span></pre></td><td class=\"code\"><pre><span class=\"line\">    + &lt;li&gt;&lt;strong&gt;本文链接：&lt;/strong&gt;&lt;a href=\"&lt;%= post.permalink %&gt;\"&gt;&lt;%= post.permalink %&gt;&lt;/a&gt;&lt;/li&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">20</span></pre></td><td class=\"code\"><pre><span class=\"line\">    + &lt;li&gt;&lt;strong&gt;版权声明：&lt;/strong&gt;本博客所有文章除特别声明外，均采用 &lt;a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh\" rel=\"external nofollow\" target=\"_blank\"&gt;CC BY-NC-SA 4.0&lt;/a&gt; 许可协议。转载请注明出处！</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">21</span></pre></td><td class=\"code\"><pre><span class=\"line\">    + &lt;/li&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">22</span></pre></td><td class=\"code\"><pre><span class=\"line\">    + &lt;/ul&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">23</span></pre></td><td class=\"code\"><pre><span class=\"line\">    + &lt;br&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">24</span></pre></td><td class=\"code\"><pre><span class=\"line\">    + &lt;%- _partial('widget/recommend_posts') %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">25</span></pre></td><td class=\"code\"><pre><span class=\"line\">   + &lt;br&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">26</span></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"addition\">+ br&gt;</span></span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">27</span></pre></td><td class=\"code\"><pre><span class=\"line\"> + %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">28</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% if (!index &amp;&amp; has_config('share.type')) &#123; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">29</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;%- _partial('share/' + get_config('share.type')) %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">30</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% &#125; %&gt;</span></pre></td></tr></table></figure>\n</li>\n<li><p>/layout/widget 目录下添加 recommend_posts.ejs </p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;span class&#x3D;&quot;is-size-6 has-text-grey has-mr-7&quot;&gt;#&amp;nbsp;&lt;%&#x3D; __(&#39;widget.recommend_posts&#39;) %&gt;&lt;&#x2F;span&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;br&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% var i &#x3D; 1;posts.forEach(post &#x3D;&gt; &#123; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">&amp;nbsp;&lt;%&#x3D;i %&gt;.&lt;a href&#x3D;&quot;&lt;%- url_for((post.link?post.link:post.path)) %&gt;&quot; class&#x3D;&quot;is-size-6&quot; target&#x3D;&quot;_blank&quot;&gt;&lt;%&#x3D; post.title %&gt;&lt;&#x2F;a&gt;&lt;br&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% i++;&#125;) %&gt;</span></pre></td></tr></table></figure></li>\n<li><p>/layout/widget 目录下添加 recommend_posts.locals.js</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">module.exports &#x3D; (ctx, locals) &#x3D;&gt; &#123;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">const &#123; has_config, get_config, get_thumbnail &#125; &#x3D; ctx;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">const &#123; posts &#125; &#x3D; ctx.site;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">if (!posts.length) &#123;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">return null;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">&#125;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">const thumbnail &#x3D; !has_config(&#39;article.thumbnail&#39;) || get_config(&#39;article.thumbnail&#39;) !&#x3D;&#x3D; false;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">const _posts &#x3D; posts.filter((item, index, arr) &#x3D;&gt; item.recommend !&#x3D; undefined &amp;&amp; item.recommend &gt; 0).sort(&#39;recommend&#39;,-1).sort(&#39;recommend&#39;,-1).limit(5).map(post &#x3D;&gt; (&#123;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">link: post.link,</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">path: post.path,</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">title: post.title,</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">12</span></pre></td><td class=\"code\"><pre><span class=\"line\">date: post.date,</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">13</span></pre></td><td class=\"code\"><pre><span class=\"line\">thumbnail: thumbnail ? get_thumbnail(post) : null,</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">14</span></pre></td><td class=\"code\"><pre><span class=\"line\">&#x2F;&#x2F; fix circular JSON serialization issue</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">15</span></pre></td><td class=\"code\"><pre><span class=\"line\">categories: () &#x3D;&gt; post.categories</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">16</span></pre></td><td class=\"code\"><pre><span class=\"line\">&#125;));</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">17</span></pre></td><td class=\"code\"><pre><span class=\"line\">return Object.assign(locals, &#123; thumbnail, posts: _posts &#125;);</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">18</span></pre></td><td class=\"code\"><pre><span class=\"line\">&#125;</span></pre></td></tr></table></figure>\n<h2 id=\"页脚访问人数显示修改\"><a href=\"#页脚访问人数显示修改\" class=\"headerlink\" title=\"页脚访问人数显示修改\"></a>页脚访问人数显示修改</h2><h3 id=\"实现效果-3\"><a href=\"#实现效果-3\" class=\"headerlink\" title=\"实现效果\"></a>实现效果</h3><center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/screenshot 2019-11-17 at 18.25.58.png\">\n</center>\n### 配置\n修改 /layout/common/footer.ejs 卜算子部分.\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% if (busuanzi) &#123; %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">2</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;br&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">3</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;span id&#x3D;&quot;busuanzi_container_site_uv&quot;&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">4</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;!-- &lt;%- _p(&#39;plugin.visitor&#39;, &#39;&lt;span id&#x3D;&quot;busuanzi_value_site_uv&quot;&gt;0&lt;&#x2F;span&gt;&#39;) %&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">5</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;&#x2F;span&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">6</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;br&gt; --&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">7</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;span id&#x3D;&quot;busuanzi_container_site_pv&quot;&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">8</span></pre></td><td class=\"code\"><pre><span class=\"line\">                    Visited by &lt;span id&#x3D;&quot;busuanzi_value_site_uv&quot;&gt;&lt;&#x2F;span&gt; users with &lt;span id&#x3D;&quot;busuanzi_value_site_pv&quot;&gt;&lt;&#x2F;span&gt; times</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">9</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;&#x2F;span&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">10</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;&#x2F;span&gt;</span></pre></td></tr><tr><td class=\"gutter\"><pre><span class=\"line\">11</span></pre></td><td class=\"code\"><pre><span class=\"line\">                &lt;% &#125; %&gt;</span></pre></td></tr></table></figure></li>\n</ol>"},{"title":"March 26, 2019","originContent":"","toc":false,"date":"2019-03-26T02:51:44.000Z","thumbnail":"https://images.unsplash.com/photo-1495539406979-bf61750d38ad?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n二姨，我又梦见你了，好像是看了伊藤润二的视频，人死后很可以通过某种仪式让你的灵魂活在世界中，你就是这样回到我们身边的，虽然看起来很不真实，但我又可以在你的身边了。","source":"_posts/March-26-2019.md","raw":"---\ntitle: 'March 26, 2019'\ntags: []\noriginContent: ''\ncategories:\n  - 旧的梦\ntoc: false\ndate: 2019-03-26 10:51:44\nthumbnail: https://images.unsplash.com/photo-1495539406979-bf61750d38ad?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n二姨，我又梦见你了，好像是看了伊藤润二的视频，人死后很可以通过某种仪式让你的灵魂活在世界中，你就是这样回到我们身边的，虽然看起来很不真实，但我又可以在你的身边了。","slug":"March-26-2019","published":1,"updated":"2019-11-15T12:52:29.677Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkpu0016k3x64yt5fm89","content":"<p>二姨，我又梦见你了，好像是看了伊藤润二的视频，人死后很可以通过某种仪式让你的灵魂活在世界中，你就是这样回到我们身边的，虽然看起来很不真实，但我又可以在你的身边了。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>二姨，我又梦见你了，好像是看了伊藤润二的视频，人死后很可以通过某种仪式让你的灵魂活在世界中，你就是这样回到我们身边的，虽然看起来很不真实，但我又可以在你的身边了。</p>\n"},{"title":"Sep 17，2019 保研","originContent":"","toc":false,"date":"2019-09-17T14:37:18.000Z","thumbnail":"https://images.unsplash.com/photo-1464053939082-8b6b9547838c?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n今天保研名单出来了，蛮多人都如释重负一般，纷纷在朋友圈欢送自己终于有学上了，当然在朋友圈，<!--more-->还是有那么多人在面试的战场上处处碰壁。慢慢的，大学四年真的就要画上句号了，身边的同学考研的考研，保研的保研，出国的出国，还有最后真的就是混吃混喝的“大学生了”。每个人都忙碌着，憧憬着能有一个不错的未来。前几天班长让签放弃保研协议的时候，我还是很随意的表情，妈的，不就是一张纸，几句话的事情。可是今天的我，心情真的没有那天那么潇洒， 仿佛是自己养大的孩子被轻易的送走，而自己没有丝毫的伤心，这种感觉很奇妙，把大学四年的成绩赌在了出国的路上，放弃了国内所有的研究生资源。或许从今天开始，保研的那些同学就开始了暑假生活，迎接属于自己最后的一个暑假？而我们还是被 GT 困扰着，被申请束缚着。申请了大四下的新国大的项目其实就是想让自己逃离这个熟悉的环境，去一个相对陌生的地方学习，休息，生活。\n\n保研的毕竟是少数，更多的是在图书馆奋笔读书备战的考研党，不知道他们的心里是什么感受，看着同学纷纷展示自己大学四年辛苦读书成功保研人生巅峰，而自己还在张宇肖秀荣的书本里苦苦挣扎。我们一起说要出国的一个同学没有签保研协议，在保研的名额里是最后一名，貌似只有国光实验室直博的名额供他选择，也不知道他会不会真香。4 年的生活真的就结束了，昨晚蛮多人还是辗转反则不知道能不能保研，今天就是安安稳稳躺在床上想着接下来的美好生活。日子总要过去啊，谁不是踩着泥泞的道路看着别人开着车驰骋在康庄大道上呢。","source":"_posts/Sep-17，2019-保研.md","raw":"---\ntitle: Sep 17，2019 保研\ntags: []\noriginContent: ''\ncategories:\n  - 旧的文\ntoc: false\ndate: 2019-09-17 22:37:18\nthumbnail: https://images.unsplash.com/photo-1464053939082-8b6b9547838c?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n今天保研名单出来了，蛮多人都如释重负一般，纷纷在朋友圈欢送自己终于有学上了，当然在朋友圈，<!--more-->还是有那么多人在面试的战场上处处碰壁。慢慢的，大学四年真的就要画上句号了，身边的同学考研的考研，保研的保研，出国的出国，还有最后真的就是混吃混喝的“大学生了”。每个人都忙碌着，憧憬着能有一个不错的未来。前几天班长让签放弃保研协议的时候，我还是很随意的表情，妈的，不就是一张纸，几句话的事情。可是今天的我，心情真的没有那天那么潇洒， 仿佛是自己养大的孩子被轻易的送走，而自己没有丝毫的伤心，这种感觉很奇妙，把大学四年的成绩赌在了出国的路上，放弃了国内所有的研究生资源。或许从今天开始，保研的那些同学就开始了暑假生活，迎接属于自己最后的一个暑假？而我们还是被 GT 困扰着，被申请束缚着。申请了大四下的新国大的项目其实就是想让自己逃离这个熟悉的环境，去一个相对陌生的地方学习，休息，生活。\n\n保研的毕竟是少数，更多的是在图书馆奋笔读书备战的考研党，不知道他们的心里是什么感受，看着同学纷纷展示自己大学四年辛苦读书成功保研人生巅峰，而自己还在张宇肖秀荣的书本里苦苦挣扎。我们一起说要出国的一个同学没有签保研协议，在保研的名额里是最后一名，貌似只有国光实验室直博的名额供他选择，也不知道他会不会真香。4 年的生活真的就结束了，昨晚蛮多人还是辗转反则不知道能不能保研，今天就是安安稳稳躺在床上想着接下来的美好生活。日子总要过去啊，谁不是踩着泥泞的道路看着别人开着车驰骋在康庄大道上呢。","slug":"Sep-17，2019-保研","published":1,"updated":"2019-11-15T12:51:35.383Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkq2001bk3x62iiycm5u","content":"<p>今天保研名单出来了，蛮多人都如释重负一般，纷纷在朋友圈欢送自己终于有学上了，当然在朋友圈，<a id=\"more\"></a>还是有那么多人在面试的战场上处处碰壁。慢慢的，大学四年真的就要画上句号了，身边的同学考研的考研，保研的保研，出国的出国，还有最后真的就是混吃混喝的“大学生了”。每个人都忙碌着，憧憬着能有一个不错的未来。前几天班长让签放弃保研协议的时候，我还是很随意的表情，妈的，不就是一张纸，几句话的事情。可是今天的我，心情真的没有那天那么潇洒， 仿佛是自己养大的孩子被轻易的送走，而自己没有丝毫的伤心，这种感觉很奇妙，把大学四年的成绩赌在了出国的路上，放弃了国内所有的研究生资源。或许从今天开始，保研的那些同学就开始了暑假生活，迎接属于自己最后的一个暑假？而我们还是被 GT 困扰着，被申请束缚着。申请了大四下的新国大的项目其实就是想让自己逃离这个熟悉的环境，去一个相对陌生的地方学习，休息，生活。</p>\n<p>保研的毕竟是少数，更多的是在图书馆奋笔读书备战的考研党，不知道他们的心里是什么感受，看着同学纷纷展示自己大学四年辛苦读书成功保研人生巅峰，而自己还在张宇肖秀荣的书本里苦苦挣扎。我们一起说要出国的一个同学没有签保研协议，在保研的名额里是最后一名，貌似只有国光实验室直博的名额供他选择，也不知道他会不会真香。4 年的生活真的就结束了，昨晚蛮多人还是辗转反则不知道能不能保研，今天就是安安稳稳躺在床上想着接下来的美好生活。日子总要过去啊，谁不是踩着泥泞的道路看着别人开着车驰骋在康庄大道上呢。</p>\n","site":{"data":{}},"excerpt":"<p>今天保研名单出来了，蛮多人都如释重负一般，纷纷在朋友圈欢送自己终于有学上了，当然在朋友圈，</p>","more":"还是有那么多人在面试的战场上处处碰壁。慢慢的，大学四年真的就要画上句号了，身边的同学考研的考研，保研的保研，出国的出国，还有最后真的就是混吃混喝的“大学生了”。每个人都忙碌着，憧憬着能有一个不错的未来。前几天班长让签放弃保研协议的时候，我还是很随意的表情，妈的，不就是一张纸，几句话的事情。可是今天的我，心情真的没有那天那么潇洒， 仿佛是自己养大的孩子被轻易的送走，而自己没有丝毫的伤心，这种感觉很奇妙，把大学四年的成绩赌在了出国的路上，放弃了国内所有的研究生资源。或许从今天开始，保研的那些同学就开始了暑假生活，迎接属于自己最后的一个暑假？而我们还是被 GT 困扰着，被申请束缚着。申请了大四下的新国大的项目其实就是想让自己逃离这个熟悉的环境，去一个相对陌生的地方学习，休息，生活。</p>\n<p>保研的毕竟是少数，更多的是在图书馆奋笔读书备战的考研党，不知道他们的心里是什么感受，看着同学纷纷展示自己大学四年辛苦读书成功保研人生巅峰，而自己还在张宇肖秀荣的书本里苦苦挣扎。我们一起说要出国的一个同学没有签保研协议，在保研的名额里是最后一名，貌似只有国光实验室直博的名额供他选择，也不知道他会不会真香。4 年的生活真的就结束了，昨晚蛮多人还是辗转反则不知道能不能保研，今天就是安安稳稳躺在床上想着接下来的美好生活。日子总要过去啊，谁不是踩着泥泞的道路看着别人开着车驰骋在康庄大道上呢。</p>"},{"title":"The Post","originContent":"","toc":false,"date":"2019-08-11T02:32:52.000Z","thumbnail":"https://images.unsplash.com/photo-1505664194779-8beaceb93744?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n历史题材电影，涉及美国新闻自由、反战等话题。。。。电影讲述的是在“水门事件”的前夕，一群新闻媒体人为了捍卫新闻的原则，不惜舍弃前途而与尼克松政府对抗的故事。《The Post》和电影《1987》一样，虽说时代背景不同，但是都反映了新闻工作者对于个人安危和国家存亡的方面的取舍问题。\n<!--more-->\n摘录电影里面最后一句：\nThe founding fathers gave the free press, the protection it must have to fulfill its essential role in our democracy. The press was to serve the governed, not the governors.\n\nimdb7.4分 斯皮尔伯格导演的电影还是值得观看的","source":"_posts/The-Post.md","raw":"---\ntitle: The Post\ntags: []\noriginContent: ''\ncategories:\n  - 旧的文\ntoc: false\ndate: 2019-08-11 10:32:52\nthumbnail: https://images.unsplash.com/photo-1505664194779-8beaceb93744?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n历史题材电影，涉及美国新闻自由、反战等话题。。。。电影讲述的是在“水门事件”的前夕，一群新闻媒体人为了捍卫新闻的原则，不惜舍弃前途而与尼克松政府对抗的故事。《The Post》和电影《1987》一样，虽说时代背景不同，但是都反映了新闻工作者对于个人安危和国家存亡的方面的取舍问题。\n<!--more-->\n摘录电影里面最后一句：\nThe founding fathers gave the free press, the protection it must have to fulfill its essential role in our democracy. The press was to serve the governed, not the governors.\n\nimdb7.4分 斯皮尔伯格导演的电影还是值得观看的","slug":"The-Post","published":1,"updated":"2019-11-15T12:50:56.418Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkq3001dk3x6582u6jnj","content":"<p>历史题材电影，涉及美国新闻自由、反战等话题。。。。电影讲述的是在“水门事件”的前夕，一群新闻媒体人为了捍卫新闻的原则，不惜舍弃前途而与尼克松政府对抗的故事。《The Post》和电影《1987》一样，虽说时代背景不同，但是都反映了新闻工作者对于个人安危和国家存亡的方面的取舍问题。</p>\n<a id=\"more\"></a>\n<p>摘录电影里面最后一句：<br>The founding fathers gave the free press, the protection it must have to fulfill its essential role in our democracy. The press was to serve the governed, not the governors.</p>\n<p>imdb7.4分 斯皮尔伯格导演的电影还是值得观看的</p>\n","site":{"data":{}},"excerpt":"<p>历史题材电影，涉及美国新闻自由、反战等话题。。。。电影讲述的是在“水门事件”的前夕，一群新闻媒体人为了捍卫新闻的原则，不惜舍弃前途而与尼克松政府对抗的故事。《The Post》和电影《1987》一样，虽说时代背景不同，但是都反映了新闻工作者对于个人安危和国家存亡的方面的取舍问题。</p>","more":"<p>摘录电影里面最后一句：<br>The founding fathers gave the free press, the protection it must have to fulfill its essential role in our democracy. The press was to serve the governed, not the governors.</p>\n<p>imdb7.4分 斯皮尔伯格导演的电影还是值得观看的</p>"},{"title":"Sep 2, 2019","originContent":"","toc":false,"date":"2019-09-02T00:48:53.000Z","thumbnail":"https://images.unsplash.com/photo-1534413298607-48ba59e8a06d?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n昨天真的挺巧的，9 月1 号是我托福考试，也正好又梦见二姨了。<!--more-->虽然梦早已经记不清了，但我早上起来，还是打开了笔记本写了 老二姨 三个字，因为我怕我忘记，我梦见了二姨。不知道我哭了没有，不知道你在那里过得怎么样，但真的，我好久没有梦见过你了，真的想再摸摸你的手，告诉你童童现在挺好的，也很努力，现在已经高三了，再过一年也跟我一样上了大学，到那个时候我也就毕业嘞，童童一定可以的。姥爷最近去拔牙了，好像是全拔了吧，这样就可以直接带假牙吃硬一点，好一点的东西了。说真的，我以后回家的时间真的很少了，那天三姨告诉你，你以后还有多长时间在郑州待着，是啊，真的就没有多少天了。感觉每个人都忙碌着，下半年挺忙的，GRE，托福，文书，申请，事情接踵而来，而我还没有完成一件事，托福学了不知道多久了，还是因为听力而没有实质的进步，GRE 因为做题没有多少，所以几斤几两也不是很清楚。身边挺多人都去考研了，天天 7 点多起床。忙点好啊，忙点就不会去想那些伤心的事了。你在那边记得多吃一点，hh，我最近还在减肥呢，不过等我瘦下去之后就去吃好吃的！那天我闻热水杯的热气，突然想起你呢，眼睛都突然湿掉了，hh。不管怎么样，都要身体健康嘞，也一定要开心呀。","source":"_posts/Sep-2-2019.md","raw":"---\ntitle: 'Sep 2, 2019'\ntags: []\noriginContent: ''\ncategories:\n  - 旧的梦\ntoc: false\ndate: 2019-09-02 08:48:53\nthumbnail: https://images.unsplash.com/photo-1534413298607-48ba59e8a06d?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n昨天真的挺巧的，9 月1 号是我托福考试，也正好又梦见二姨了。<!--more-->虽然梦早已经记不清了，但我早上起来，还是打开了笔记本写了 老二姨 三个字，因为我怕我忘记，我梦见了二姨。不知道我哭了没有，不知道你在那里过得怎么样，但真的，我好久没有梦见过你了，真的想再摸摸你的手，告诉你童童现在挺好的，也很努力，现在已经高三了，再过一年也跟我一样上了大学，到那个时候我也就毕业嘞，童童一定可以的。姥爷最近去拔牙了，好像是全拔了吧，这样就可以直接带假牙吃硬一点，好一点的东西了。说真的，我以后回家的时间真的很少了，那天三姨告诉你，你以后还有多长时间在郑州待着，是啊，真的就没有多少天了。感觉每个人都忙碌着，下半年挺忙的，GRE，托福，文书，申请，事情接踵而来，而我还没有完成一件事，托福学了不知道多久了，还是因为听力而没有实质的进步，GRE 因为做题没有多少，所以几斤几两也不是很清楚。身边挺多人都去考研了，天天 7 点多起床。忙点好啊，忙点就不会去想那些伤心的事了。你在那边记得多吃一点，hh，我最近还在减肥呢，不过等我瘦下去之后就去吃好吃的！那天我闻热水杯的热气，突然想起你呢，眼睛都突然湿掉了，hh。不管怎么样，都要身体健康嘞，也一定要开心呀。","slug":"Sep-2-2019","published":1,"updated":"2019-11-15T12:52:05.527Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkq6001hk3x64iz2fpnt","content":"<p>昨天真的挺巧的，9 月1 号是我托福考试，也正好又梦见二姨了。<a id=\"more\"></a>虽然梦早已经记不清了，但我早上起来，还是打开了笔记本写了 老二姨 三个字，因为我怕我忘记，我梦见了二姨。不知道我哭了没有，不知道你在那里过得怎么样，但真的，我好久没有梦见过你了，真的想再摸摸你的手，告诉你童童现在挺好的，也很努力，现在已经高三了，再过一年也跟我一样上了大学，到那个时候我也就毕业嘞，童童一定可以的。姥爷最近去拔牙了，好像是全拔了吧，这样就可以直接带假牙吃硬一点，好一点的东西了。说真的，我以后回家的时间真的很少了，那天三姨告诉你，你以后还有多长时间在郑州待着，是啊，真的就没有多少天了。感觉每个人都忙碌着，下半年挺忙的，GRE，托福，文书，申请，事情接踵而来，而我还没有完成一件事，托福学了不知道多久了，还是因为听力而没有实质的进步，GRE 因为做题没有多少，所以几斤几两也不是很清楚。身边挺多人都去考研了，天天 7 点多起床。忙点好啊，忙点就不会去想那些伤心的事了。你在那边记得多吃一点，hh，我最近还在减肥呢，不过等我瘦下去之后就去吃好吃的！那天我闻热水杯的热气，突然想起你呢，眼睛都突然湿掉了，hh。不管怎么样，都要身体健康嘞，也一定要开心呀。</p>\n","site":{"data":{}},"excerpt":"<p>昨天真的挺巧的，9 月1 号是我托福考试，也正好又梦见二姨了。</p>","more":"虽然梦早已经记不清了，但我早上起来，还是打开了笔记本写了 老二姨 三个字，因为我怕我忘记，我梦见了二姨。不知道我哭了没有，不知道你在那里过得怎么样，但真的，我好久没有梦见过你了，真的想再摸摸你的手，告诉你童童现在挺好的，也很努力，现在已经高三了，再过一年也跟我一样上了大学，到那个时候我也就毕业嘞，童童一定可以的。姥爷最近去拔牙了，好像是全拔了吧，这样就可以直接带假牙吃硬一点，好一点的东西了。说真的，我以后回家的时间真的很少了，那天三姨告诉你，你以后还有多长时间在郑州待着，是啊，真的就没有多少天了。感觉每个人都忙碌着，下半年挺忙的，GRE，托福，文书，申请，事情接踵而来，而我还没有完成一件事，托福学了不知道多久了，还是因为听力而没有实质的进步，GRE 因为做题没有多少，所以几斤几两也不是很清楚。身边挺多人都去考研了，天天 7 点多起床。忙点好啊，忙点就不会去想那些伤心的事了。你在那边记得多吃一点，hh，我最近还在减肥呢，不过等我瘦下去之后就去吃好吃的！那天我闻热水杯的热气，突然想起你呢，眼睛都突然湿掉了，hh。不管怎么样，都要身体健康嘞，也一定要开心呀。</p>"},{"title":"一亩三分地自动签到脚本","date":"2019-11-07T13:14:23.000Z","thumbnail":"https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMG_604.jpg","recommend":1,"top":null,"toc":true,"_content":"\n# 脚本介绍\n前一段时间接触到了Surge，也间接接触到了js脚本的使用。群里很多人通过脚本实现了譬如天气提醒，百度贴吧签到，甚至是去除广告的功能，虽说之前没有接触过js，只写过一点python的脚本，但鉴于js脚本的使用范围实在太大，<!--more-->这几天就动手学习了一点js的语法，修改了点脚本，前天花了点时间修改了作者 [Neurogram](https://github.com/Neurogram-R) 定点签到的脚本，适配了特定的html格式，以及增加了到期时间的显示，成就感还是蛮强的。由于到了申请季，很多同学都需要在比如一亩三分地的留学论坛上逛帖，所以出于兴趣，写了一亩三分地的自动签到脚本。\n\n## Check in for Shortcuts\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMG_593.JPG\" height=\"60%\" width=\"60%\">\n</center>\n\n运行 Shortcuts 版时，需要先进入编辑页面，在URL_提交登陆模块填写账号信息，账号信息分为 **用户名、密码、问题编号，问题答案** 4个 DICTIONARY（字典），其中如果没有问题，**问题编号写0，问题答案留空。**\n\n## Check in for Surge\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMG_604.JPG\" height=\"60%\" width=\"60%\">\n</center>\n\n- **填写账号信息**\n\n        const accounts = [\n        [\"username@xxx.com\", \"xxx\",\"x\",\"xxxx\"]\n        ]\n\n    账号信息的填写要严谨按照代码示例的格式填写，内容顺序依次为 **用户名、密码、问题编号，问题答案**，4个内容用双引号\"\"括起来，且不需要urlencode，直接原文显示。其中如果没有问题，**问题编号写0，问题答案留空。**\n- **安装脚本**\n    云端：自己的服务器或其他可生成文件直链的地方(github记得使用点raw进入直链)\n    本地： iCloud / Dropbox 的 Surge 文件夹下\n- **配置脚本**\n\n    进入 配置文件 的文本编辑模式，在 `[Script]` （如无 [Script]，编辑一个即可）下新建一行\n\n        [Script]\n        cron \"30 8 * * *\" script-path=checkin_1point.js\n\n    以上实例为 每天早上 8:30 运行存放于 本地的 checkin_1point.js 脚本（如脚本存放于云端，则 `script-path=脚本直链`）自定义触发时间配置使用的是 crontab 样式，api可参考 [Scripting](https://community.nssurge.com/d/33-scripting) 的介绍\n- **代码逻辑**\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/Untitled.jpg\" height=\"40%\" width=\"40%\">\n</center>\n\n#  问题\n由于hash和cookie有关联，登陆的cookie有较长的使用期，而签到的cookie在每一次登陆之后都会更新，所以不能直接通过抓签到的包直接进行POST操作。同时在后期的测试过程中，如果想同时进行多账号的签到，由于登陆cookie在本机有保存，很可能出现提示了签到成功但账号实际没有签到成功的情况，所以建议大家只使用一个账号，或者签到完成后清除Safari的缓存，再进行另外一个账号的签到操作。\n细心的同学看完代码会发现最后签到的函数正则里面包含了乱码字符，因为最后抓包之后返回的html是gbk编码的，处理起来不是特别方便，于是暂时就用了比较笨的方法进行了字符匹配。\n这也是我第一个完整的写一个js脚本，业务逻辑方面包括函数，字典格式的使用或多或少存在不合理的地方，如果大家有更好的意见，欢迎给我联系。\n- **反馈**\n\n    💡 如果大家运行不了脚本或者运行出错，[反馈](https://t.me/Leped_Bot)的时候一定要带上报错的截图，有能力的同学在代码里面取消对应的`console.log(data)`的注释，并附上surge log的对应截图，感谢大家。\n    \n# 脚本下载\n👉 [Check in for Shortcuts](https://www.icloud.com/shortcuts/36f6b3423b9c413386e70b44e1c11a21) (feat @wangfei021325)\n👉 [Check in for Surge](https://github.com/NavePnow/Profiles/blob/master/Scripts/checkin_1point.js)\n\n# 关于作者\nTelegram: [Leped_Bot](https://t.me/Leped_Bot)\nGitHub: [NavePnow](https://github.com/NavePnow)\n\n# Reference\n🔗 [Check-in Demo](https://raw.githubusercontent.com/Neurogram-R/Surge/master/checkin.js)\n🔗 [Tutorial Demo](https://www.notion.so/Check-in-0797ec9f9f3f445aae241d7762cf9d8b#a7821336c0bf414ba44f430f38147f5a)\n👨‍🏫 [Advisor](https://t.me/wangfei021325)\n\n\n\n","source":"_posts/一亩三分地自动签到脚本.md","raw":"---\ntitle: 一亩三分地自动签到脚本\ndate: 2019-11-07 21:14:23\ntags: [JS]\ncategories:\nthumbnail: https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMG_604.jpg\nrecommend: 1\ntop: \ntoc: true\n---\n\n# 脚本介绍\n前一段时间接触到了Surge，也间接接触到了js脚本的使用。群里很多人通过脚本实现了譬如天气提醒，百度贴吧签到，甚至是去除广告的功能，虽说之前没有接触过js，只写过一点python的脚本，但鉴于js脚本的使用范围实在太大，<!--more-->这几天就动手学习了一点js的语法，修改了点脚本，前天花了点时间修改了作者 [Neurogram](https://github.com/Neurogram-R) 定点签到的脚本，适配了特定的html格式，以及增加了到期时间的显示，成就感还是蛮强的。由于到了申请季，很多同学都需要在比如一亩三分地的留学论坛上逛帖，所以出于兴趣，写了一亩三分地的自动签到脚本。\n\n## Check in for Shortcuts\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMG_593.JPG\" height=\"60%\" width=\"60%\">\n</center>\n\n运行 Shortcuts 版时，需要先进入编辑页面，在URL_提交登陆模块填写账号信息，账号信息分为 **用户名、密码、问题编号，问题答案** 4个 DICTIONARY（字典），其中如果没有问题，**问题编号写0，问题答案留空。**\n\n## Check in for Surge\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMG_604.JPG\" height=\"60%\" width=\"60%\">\n</center>\n\n- **填写账号信息**\n\n        const accounts = [\n        [\"username@xxx.com\", \"xxx\",\"x\",\"xxxx\"]\n        ]\n\n    账号信息的填写要严谨按照代码示例的格式填写，内容顺序依次为 **用户名、密码、问题编号，问题答案**，4个内容用双引号\"\"括起来，且不需要urlencode，直接原文显示。其中如果没有问题，**问题编号写0，问题答案留空。**\n- **安装脚本**\n    云端：自己的服务器或其他可生成文件直链的地方(github记得使用点raw进入直链)\n    本地： iCloud / Dropbox 的 Surge 文件夹下\n- **配置脚本**\n\n    进入 配置文件 的文本编辑模式，在 `[Script]` （如无 [Script]，编辑一个即可）下新建一行\n\n        [Script]\n        cron \"30 8 * * *\" script-path=checkin_1point.js\n\n    以上实例为 每天早上 8:30 运行存放于 本地的 checkin_1point.js 脚本（如脚本存放于云端，则 `script-path=脚本直链`）自定义触发时间配置使用的是 crontab 样式，api可参考 [Scripting](https://community.nssurge.com/d/33-scripting) 的介绍\n- **代码逻辑**\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/Untitled.jpg\" height=\"40%\" width=\"40%\">\n</center>\n\n#  问题\n由于hash和cookie有关联，登陆的cookie有较长的使用期，而签到的cookie在每一次登陆之后都会更新，所以不能直接通过抓签到的包直接进行POST操作。同时在后期的测试过程中，如果想同时进行多账号的签到，由于登陆cookie在本机有保存，很可能出现提示了签到成功但账号实际没有签到成功的情况，所以建议大家只使用一个账号，或者签到完成后清除Safari的缓存，再进行另外一个账号的签到操作。\n细心的同学看完代码会发现最后签到的函数正则里面包含了乱码字符，因为最后抓包之后返回的html是gbk编码的，处理起来不是特别方便，于是暂时就用了比较笨的方法进行了字符匹配。\n这也是我第一个完整的写一个js脚本，业务逻辑方面包括函数，字典格式的使用或多或少存在不合理的地方，如果大家有更好的意见，欢迎给我联系。\n- **反馈**\n\n    💡 如果大家运行不了脚本或者运行出错，[反馈](https://t.me/Leped_Bot)的时候一定要带上报错的截图，有能力的同学在代码里面取消对应的`console.log(data)`的注释，并附上surge log的对应截图，感谢大家。\n    \n# 脚本下载\n👉 [Check in for Shortcuts](https://www.icloud.com/shortcuts/36f6b3423b9c413386e70b44e1c11a21) (feat @wangfei021325)\n👉 [Check in for Surge](https://github.com/NavePnow/Profiles/blob/master/Scripts/checkin_1point.js)\n\n# 关于作者\nTelegram: [Leped_Bot](https://t.me/Leped_Bot)\nGitHub: [NavePnow](https://github.com/NavePnow)\n\n# Reference\n🔗 [Check-in Demo](https://raw.githubusercontent.com/Neurogram-R/Surge/master/checkin.js)\n🔗 [Tutorial Demo](https://www.notion.so/Check-in-0797ec9f9f3f445aae241d7762cf9d8b#a7821336c0bf414ba44f430f38147f5a)\n👨‍🏫 [Advisor](https://t.me/wangfei021325)\n\n\n\n","slug":"一亩三分地自动签到脚本","published":1,"updated":"2019-11-16T12:13:19.835Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkq7001kk3x61pge47tx","content":"<h1 id=\"脚本介绍\"><a href=\"#脚本介绍\" class=\"headerlink\" title=\"脚本介绍\"></a>脚本介绍</h1><p>前一段时间接触到了Surge，也间接接触到了js脚本的使用。群里很多人通过脚本实现了譬如天气提醒，百度贴吧签到，甚至是去除广告的功能，虽说之前没有接触过js，只写过一点python的脚本，但鉴于js脚本的使用范围实在太大，<a id=\"more\"></a>这几天就动手学习了一点js的语法，修改了点脚本，前天花了点时间修改了作者 <a href=\"https://github.com/Neurogram-R\" target=\"_blank\" rel=\"noopener\">Neurogram</a> 定点签到的脚本，适配了特定的html格式，以及增加了到期时间的显示，成就感还是蛮强的。由于到了申请季，很多同学都需要在比如一亩三分地的留学论坛上逛帖，所以出于兴趣，写了一亩三分地的自动签到脚本。</p>\n<h2 id=\"Check-in-for-Shortcuts\"><a href=\"#Check-in-for-Shortcuts\" class=\"headerlink\" title=\"Check in for Shortcuts\"></a>Check in for Shortcuts</h2><center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMG_593.JPG\" height=\"60%\" width=\"60%\">\n</center>\n\n<p>运行 Shortcuts 版时，需要先进入编辑页面，在URL_提交登陆模块填写账号信息，账号信息分为 <strong>用户名、密码、问题编号，问题答案</strong> 4个 DICTIONARY（字典），其中如果没有问题，<strong>问题编号写0，问题答案留空。</strong></p>\n<h2 id=\"Check-in-for-Surge\"><a href=\"#Check-in-for-Surge\" class=\"headerlink\" title=\"Check in for Surge\"></a>Check in for Surge</h2><center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMG_604.JPG\" height=\"60%\" width=\"60%\">\n</center>\n\n<ul>\n<li><p><strong>填写账号信息</strong></p>\n<pre><code>const accounts = [\n[&quot;username@xxx.com&quot;, &quot;xxx&quot;,&quot;x&quot;,&quot;xxxx&quot;]\n]</code></pre><p>  账号信息的填写要严谨按照代码示例的格式填写，内容顺序依次为 <strong>用户名、密码、问题编号，问题答案</strong>，4个内容用双引号””括起来，且不需要urlencode，直接原文显示。其中如果没有问题，<strong>问题编号写0，问题答案留空。</strong></p>\n</li>\n<li><p><strong>安装脚本</strong><br>  云端：自己的服务器或其他可生成文件直链的地方(github记得使用点raw进入直链)<br>  本地： iCloud / Dropbox 的 Surge 文件夹下</p>\n</li>\n<li><p><strong>配置脚本</strong></p>\n<p>  进入 配置文件 的文本编辑模式，在 <code>[Script]</code> （如无 [Script]，编辑一个即可）下新建一行</p>\n<pre><code>[Script]\ncron &quot;30 8 * * *&quot; script-path=checkin_1point.js</code></pre><p>  以上实例为 每天早上 8:30 运行存放于 本地的 checkin_1point.js 脚本（如脚本存放于云端，则 <code>script-path=脚本直链</code>）自定义触发时间配置使用的是 crontab 样式，api可参考 <a href=\"https://community.nssurge.com/d/33-scripting\" target=\"_blank\" rel=\"noopener\">Scripting</a> 的介绍</p>\n</li>\n<li><p><strong>代码逻辑</strong></p>\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/Untitled.jpg\" height=\"40%\" width=\"40%\">\n</center>\n\n</li>\n</ul>\n<h1 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h1><p>由于hash和cookie有关联，登陆的cookie有较长的使用期，而签到的cookie在每一次登陆之后都会更新，所以不能直接通过抓签到的包直接进行POST操作。同时在后期的测试过程中，如果想同时进行多账号的签到，由于登陆cookie在本机有保存，很可能出现提示了签到成功但账号实际没有签到成功的情况，所以建议大家只使用一个账号，或者签到完成后清除Safari的缓存，再进行另外一个账号的签到操作。<br>细心的同学看完代码会发现最后签到的函数正则里面包含了乱码字符，因为最后抓包之后返回的html是gbk编码的，处理起来不是特别方便，于是暂时就用了比较笨的方法进行了字符匹配。<br>这也是我第一个完整的写一个js脚本，业务逻辑方面包括函数，字典格式的使用或多或少存在不合理的地方，如果大家有更好的意见，欢迎给我联系。</p>\n<ul>\n<li><p><strong>反馈</strong></p>\n<p>  💡 如果大家运行不了脚本或者运行出错，<a href=\"https://t.me/Leped_Bot\" target=\"_blank\" rel=\"noopener\">反馈</a>的时候一定要带上报错的截图，有能力的同学在代码里面取消对应的<code>console.log(data)</code>的注释，并附上surge log的对应截图，感谢大家。</p>\n</li>\n</ul>\n<h1 id=\"脚本下载\"><a href=\"#脚本下载\" class=\"headerlink\" title=\"脚本下载\"></a>脚本下载</h1><p>👉 <a href=\"https://www.icloud.com/shortcuts/36f6b3423b9c413386e70b44e1c11a21\" target=\"_blank\" rel=\"noopener\">Check in for Shortcuts</a> (feat @wangfei021325)<br>👉 <a href=\"https://github.com/NavePnow/Profiles/blob/master/Scripts/checkin_1point.js\" target=\"_blank\" rel=\"noopener\">Check in for Surge</a></p>\n<h1 id=\"关于作者\"><a href=\"#关于作者\" class=\"headerlink\" title=\"关于作者\"></a>关于作者</h1><p>Telegram: <a href=\"https://t.me/Leped_Bot\" target=\"_blank\" rel=\"noopener\">Leped_Bot</a><br>GitHub: <a href=\"https://github.com/NavePnow\" target=\"_blank\" rel=\"noopener\">NavePnow</a></p>\n<h1 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h1><p>🔗 <a href=\"https://raw.githubusercontent.com/Neurogram-R/Surge/master/checkin.js\" target=\"_blank\" rel=\"noopener\">Check-in Demo</a><br>🔗 <a href=\"https://www.notion.so/Check-in-0797ec9f9f3f445aae241d7762cf9d8b#a7821336c0bf414ba44f430f38147f5a\" target=\"_blank\" rel=\"noopener\">Tutorial Demo</a><br>👨‍🏫 <a href=\"https://t.me/wangfei021325\" target=\"_blank\" rel=\"noopener\">Advisor</a></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"脚本介绍\"><a href=\"#脚本介绍\" class=\"headerlink\" title=\"脚本介绍\"></a>脚本介绍</h1><p>前一段时间接触到了Surge，也间接接触到了js脚本的使用。群里很多人通过脚本实现了譬如天气提醒，百度贴吧签到，甚至是去除广告的功能，虽说之前没有接触过js，只写过一点python的脚本，但鉴于js脚本的使用范围实在太大，</p>","more":"这几天就动手学习了一点js的语法，修改了点脚本，前天花了点时间修改了作者 <a href=\"https://github.com/Neurogram-R\" target=\"_blank\" rel=\"noopener\">Neurogram</a> 定点签到的脚本，适配了特定的html格式，以及增加了到期时间的显示，成就感还是蛮强的。由于到了申请季，很多同学都需要在比如一亩三分地的留学论坛上逛帖，所以出于兴趣，写了一亩三分地的自动签到脚本。</p>\n<h2 id=\"Check-in-for-Shortcuts\"><a href=\"#Check-in-for-Shortcuts\" class=\"headerlink\" title=\"Check in for Shortcuts\"></a>Check in for Shortcuts</h2><center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMG_593.JPG\" height=\"60%\" width=\"60%\">\n</center>\n\n<p>运行 Shortcuts 版时，需要先进入编辑页面，在URL_提交登陆模块填写账号信息，账号信息分为 <strong>用户名、密码、问题编号，问题答案</strong> 4个 DICTIONARY（字典），其中如果没有问题，<strong>问题编号写0，问题答案留空。</strong></p>\n<h2 id=\"Check-in-for-Surge\"><a href=\"#Check-in-for-Surge\" class=\"headerlink\" title=\"Check in for Surge\"></a>Check in for Surge</h2><center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMG_604.JPG\" height=\"60%\" width=\"60%\">\n</center>\n\n<ul>\n<li><p><strong>填写账号信息</strong></p>\n<pre><code>const accounts = [\n[&quot;username@xxx.com&quot;, &quot;xxx&quot;,&quot;x&quot;,&quot;xxxx&quot;]\n]</code></pre><p>  账号信息的填写要严谨按照代码示例的格式填写，内容顺序依次为 <strong>用户名、密码、问题编号，问题答案</strong>，4个内容用双引号””括起来，且不需要urlencode，直接原文显示。其中如果没有问题，<strong>问题编号写0，问题答案留空。</strong></p>\n</li>\n<li><p><strong>安装脚本</strong><br>  云端：自己的服务器或其他可生成文件直链的地方(github记得使用点raw进入直链)<br>  本地： iCloud / Dropbox 的 Surge 文件夹下</p>\n</li>\n<li><p><strong>配置脚本</strong></p>\n<p>  进入 配置文件 的文本编辑模式，在 <code>[Script]</code> （如无 [Script]，编辑一个即可）下新建一行</p>\n<pre><code>[Script]\ncron &quot;30 8 * * *&quot; script-path=checkin_1point.js</code></pre><p>  以上实例为 每天早上 8:30 运行存放于 本地的 checkin_1point.js 脚本（如脚本存放于云端，则 <code>script-path=脚本直链</code>）自定义触发时间配置使用的是 crontab 样式，api可参考 <a href=\"https://community.nssurge.com/d/33-scripting\" target=\"_blank\" rel=\"noopener\">Scripting</a> 的介绍</p>\n</li>\n<li><p><strong>代码逻辑</strong></p>\n<center>\n<img src=\"https://raw.githubusercontent.com/NavePnow/blog_photo/master/Untitled.jpg\" height=\"40%\" width=\"40%\">\n</center>\n\n</li>\n</ul>\n<h1 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h1><p>由于hash和cookie有关联，登陆的cookie有较长的使用期，而签到的cookie在每一次登陆之后都会更新，所以不能直接通过抓签到的包直接进行POST操作。同时在后期的测试过程中，如果想同时进行多账号的签到，由于登陆cookie在本机有保存，很可能出现提示了签到成功但账号实际没有签到成功的情况，所以建议大家只使用一个账号，或者签到完成后清除Safari的缓存，再进行另外一个账号的签到操作。<br>细心的同学看完代码会发现最后签到的函数正则里面包含了乱码字符，因为最后抓包之后返回的html是gbk编码的，处理起来不是特别方便，于是暂时就用了比较笨的方法进行了字符匹配。<br>这也是我第一个完整的写一个js脚本，业务逻辑方面包括函数，字典格式的使用或多或少存在不合理的地方，如果大家有更好的意见，欢迎给我联系。</p>\n<ul>\n<li><p><strong>反馈</strong></p>\n<p>  💡 如果大家运行不了脚本或者运行出错，<a href=\"https://t.me/Leped_Bot\" target=\"_blank\" rel=\"noopener\">反馈</a>的时候一定要带上报错的截图，有能力的同学在代码里面取消对应的<code>console.log(data)</code>的注释，并附上surge log的对应截图，感谢大家。</p>\n</li>\n</ul>\n<h1 id=\"脚本下载\"><a href=\"#脚本下载\" class=\"headerlink\" title=\"脚本下载\"></a>脚本下载</h1><p>👉 <a href=\"https://www.icloud.com/shortcuts/36f6b3423b9c413386e70b44e1c11a21\" target=\"_blank\" rel=\"noopener\">Check in for Shortcuts</a> (feat @wangfei021325)<br>👉 <a href=\"https://github.com/NavePnow/Profiles/blob/master/Scripts/checkin_1point.js\" target=\"_blank\" rel=\"noopener\">Check in for Surge</a></p>\n<h1 id=\"关于作者\"><a href=\"#关于作者\" class=\"headerlink\" title=\"关于作者\"></a>关于作者</h1><p>Telegram: <a href=\"https://t.me/Leped_Bot\" target=\"_blank\" rel=\"noopener\">Leped_Bot</a><br>GitHub: <a href=\"https://github.com/NavePnow\" target=\"_blank\" rel=\"noopener\">NavePnow</a></p>\n<h1 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h1><p>🔗 <a href=\"https://raw.githubusercontent.com/Neurogram-R/Surge/master/checkin.js\" target=\"_blank\" rel=\"noopener\">Check-in Demo</a><br>🔗 <a href=\"https://www.notion.so/Check-in-0797ec9f9f3f445aae241d7762cf9d8b#a7821336c0bf414ba44f430f38147f5a\" target=\"_blank\" rel=\"noopener\">Tutorial Demo</a><br>👨‍🏫 <a href=\"https://t.me/wangfei021325\" target=\"_blank\" rel=\"noopener\">Advisor</a></p>"},{"title":"Hello World","originContent":"","toc":true,"date":"2019-08-11T02:33:38.000Z","thumbnail":"https://images.unsplash.com/photo-1461532257246-777de18cd58b?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\nWelcome to [Hexo](https://hexo.io/)<!--more-->! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\ntags: []\noriginContent: ''\ncategories:\n  - \ntoc: true\ndate: 2019-08-11 10:33:38\nthumbnail: https://images.unsplash.com/photo-1461532257246-777de18cd58b?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\nWelcome to [Hexo](https://hexo.io/)<!--more-->! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","slug":"hello-world","published":1,"updated":"2019-11-15T13:02:46.895Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkqa001pk3x65gqzfcp7","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a><a id=\"more\"></a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"hljs-string\">\"My New Post\"</span></span></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash hljs\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n","site":{"data":{}},"excerpt":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a></p>","more":"! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>"},{"title":"分布式计算学习笔记(二) Ray","date":"2019-11-21T03:01:35.000Z","thumbnail":"https://images.unsplash.com/photo-1434030216411-0b793f4b4173?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","recommend":0,"top":100,"toc":true,"_content":"# Ray\n## 前言\n<!--more-->\n下学期去新加坡做毕设，老师给我订的主题是关于Ray-分布式执行框架的内容，其实就是想让我在这个框架中做一些应用，也可以说是大众化？前几天和HUST的挂名老师聊了聊，她也没有听说过这个框架，在网上搜了一下，说让我尝试一下在这个分布式执行框架中实现一个聚类算法，关键词有 Ray Tensor Clustering, 说实话，不懂，真的，看一个名次就会蹦出5个之前没见过的，多个名字叠加直接把我搞懵逼了。所以这个系列也算是我的学习笔记吧。\n## 概述\nRay是UC Berkeley RISELab新推出的高性能分布式执行框架，它使用了和传统分布式计算系统不一样的架构和对分布式计算的抽象方式，具有比Spark更优异的计算性能。\n- 优点:\n\t- 海量任务调度能力。\n\t- 毫秒级别的延迟。\n\t- 异构任务的支持。\n\t- 任务拓扑图动态修改的能力。\n- 缺点：\n\t- API层以上的部分还比较薄弱，Core模块核心逻辑估需要时间打磨。\n\t- 国内目前除了蚂蚁金服和RISELab有针对性的合作以外，关注程度还很低，没有实际的应用实例看到，整体来说还处于比较早期的框架构建阶段。\n- 用途：  \n\t增强学习\n\t- 分类\n\t- 聚类\n\t- 图像识别\n\t- 推荐系统\n\t- 文本翻译\n\t- Application: deep reinforcement learning using RLlib, scalable hyperparameter search using Ray Tune, automatic program synthesis using AutoPandas, etc. (advanced library from tutorial)\n\n\n# Reference\n- [https://blog.csdn.net/lzc4869/article/details/94663616][1]\n- \n\n[1]:\thttps://blog.csdn.net/lzc4869/article/details/94663616","source":"_posts/分布式计算学习笔记-二-Ray.md","raw":"---\ntitle: 分布式计算学习笔记(二) Ray\ndate: 2019-11-21 11:01:35\ncategories:\nthumbnail: https://images.unsplash.com/photo-1434030216411-0b793f4b4173?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\nrecommend: 0\ntop: 100\ntoc: true\n---\n# Ray\n## 前言\n<!--more-->\n下学期去新加坡做毕设，老师给我订的主题是关于Ray-分布式执行框架的内容，其实就是想让我在这个框架中做一些应用，也可以说是大众化？前几天和HUST的挂名老师聊了聊，她也没有听说过这个框架，在网上搜了一下，说让我尝试一下在这个分布式执行框架中实现一个聚类算法，关键词有 Ray Tensor Clustering, 说实话，不懂，真的，看一个名次就会蹦出5个之前没见过的，多个名字叠加直接把我搞懵逼了。所以这个系列也算是我的学习笔记吧。\n## 概述\nRay是UC Berkeley RISELab新推出的高性能分布式执行框架，它使用了和传统分布式计算系统不一样的架构和对分布式计算的抽象方式，具有比Spark更优异的计算性能。\n- 优点:\n\t- 海量任务调度能力。\n\t- 毫秒级别的延迟。\n\t- 异构任务的支持。\n\t- 任务拓扑图动态修改的能力。\n- 缺点：\n\t- API层以上的部分还比较薄弱，Core模块核心逻辑估需要时间打磨。\n\t- 国内目前除了蚂蚁金服和RISELab有针对性的合作以外，关注程度还很低，没有实际的应用实例看到，整体来说还处于比较早期的框架构建阶段。\n- 用途：  \n\t增强学习\n\t- 分类\n\t- 聚类\n\t- 图像识别\n\t- 推荐系统\n\t- 文本翻译\n\t- Application: deep reinforcement learning using RLlib, scalable hyperparameter search using Ray Tune, automatic program synthesis using AutoPandas, etc. (advanced library from tutorial)\n\n\n# Reference\n- [https://blog.csdn.net/lzc4869/article/details/94663616][1]\n- \n\n[1]:\thttps://blog.csdn.net/lzc4869/article/details/94663616","slug":"分布式计算学习笔记-二-Ray","published":1,"updated":"2019-11-24T11:32:51.709Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkqc001rk3x61u0l54b6","content":"<h1 id=\"Ray\"><a href=\"#Ray\" class=\"headerlink\" title=\"Ray\"></a>Ray</h1><h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><a id=\"more\"></a>\n<p>下学期去新加坡做毕设，老师给我订的主题是关于Ray-分布式执行框架的内容，其实就是想让我在这个框架中做一些应用，也可以说是大众化？前几天和HUST的挂名老师聊了聊，她也没有听说过这个框架，在网上搜了一下，说让我尝试一下在这个分布式执行框架中实现一个聚类算法，关键词有 Ray Tensor Clustering, 说实话，不懂，真的，看一个名次就会蹦出5个之前没见过的，多个名字叠加直接把我搞懵逼了。所以这个系列也算是我的学习笔记吧。</p>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>Ray是UC Berkeley RISELab新推出的高性能分布式执行框架，它使用了和传统分布式计算系统不一样的架构和对分布式计算的抽象方式，具有比Spark更优异的计算性能。</p>\n<ul>\n<li>优点:<ul>\n<li>海量任务调度能力。</li>\n<li>毫秒级别的延迟。</li>\n<li>异构任务的支持。</li>\n<li>任务拓扑图动态修改的能力。</li>\n</ul>\n</li>\n<li>缺点：<ul>\n<li>API层以上的部分还比较薄弱，Core模块核心逻辑估需要时间打磨。</li>\n<li>国内目前除了蚂蚁金服和RISELab有针对性的合作以外，关注程度还很低，没有实际的应用实例看到，整体来说还处于比较早期的框架构建阶段。</li>\n</ul>\n</li>\n<li>用途：<br>  增强学习<ul>\n<li>分类</li>\n<li>聚类</li>\n<li>图像识别</li>\n<li>推荐系统</li>\n<li>文本翻译</li>\n<li>Application: deep reinforcement learning using RLlib, scalable hyperparameter search using Ray Tune, automatic program synthesis using AutoPandas, etc. (advanced library from tutorial)</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h1><ul>\n<li><a href=\"https://blog.csdn.net/lzc4869/article/details/94663616\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/lzc4869/article/details/94663616</a></li>\n<li></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"Ray\"><a href=\"#Ray\" class=\"headerlink\" title=\"Ray\"></a>Ray</h1><h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2>","more":"<p>下学期去新加坡做毕设，老师给我订的主题是关于Ray-分布式执行框架的内容，其实就是想让我在这个框架中做一些应用，也可以说是大众化？前几天和HUST的挂名老师聊了聊，她也没有听说过这个框架，在网上搜了一下，说让我尝试一下在这个分布式执行框架中实现一个聚类算法，关键词有 Ray Tensor Clustering, 说实话，不懂，真的，看一个名次就会蹦出5个之前没见过的，多个名字叠加直接把我搞懵逼了。所以这个系列也算是我的学习笔记吧。</p>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>Ray是UC Berkeley RISELab新推出的高性能分布式执行框架，它使用了和传统分布式计算系统不一样的架构和对分布式计算的抽象方式，具有比Spark更优异的计算性能。</p>\n<ul>\n<li>优点:<ul>\n<li>海量任务调度能力。</li>\n<li>毫秒级别的延迟。</li>\n<li>异构任务的支持。</li>\n<li>任务拓扑图动态修改的能力。</li>\n</ul>\n</li>\n<li>缺点：<ul>\n<li>API层以上的部分还比较薄弱，Core模块核心逻辑估需要时间打磨。</li>\n<li>国内目前除了蚂蚁金服和RISELab有针对性的合作以外，关注程度还很低，没有实际的应用实例看到，整体来说还处于比较早期的框架构建阶段。</li>\n</ul>\n</li>\n<li>用途：<br>  增强学习<ul>\n<li>分类</li>\n<li>聚类</li>\n<li>图像识别</li>\n<li>推荐系统</li>\n<li>文本翻译</li>\n<li>Application: deep reinforcement learning using RLlib, scalable hyperparameter search using Ray Tune, automatic program synthesis using AutoPandas, etc. (advanced library from tutorial)</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h1><ul>\n<li><a href=\"https://blog.csdn.net/lzc4869/article/details/94663616\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/lzc4869/article/details/94663616</a></li>\n<li></li>\n</ul>"},{"title":"如父如子","originContent":"","toc":false,"date":"2019-08-11T02:49:18.000Z","thumbnail":"https://images.unsplash.com/photo-1557176278-3326a3193580?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n当金钱作为交换亲情的筹码\n\n在穿梭城市的巴士上完成了本书的阅读，<!--more-->大概3个多小时的时间，估计看完这部电影，也差不多需要这么长时间吧。\n\n两个全然不同的家庭环境塑造了庆多、琉晴两个小孩迥异的性格，庆多懂得待人接物的道理，是家长眼里的“好孩子”，当然这和他的生长环境有关，父亲忙于工作，母亲也习惯了一个人安安静静地带孩子长大，严格的家规，三点一线的日常生活，所有的一切在庆多父母眼里早已成为理所应当的东西，但因为孩子抱错的事情，日常的生活节奏被打乱，庆多仿佛是导火索，点燃了这个破碎的家庭最后的救命稻草。琉晴出生在乡下，或许是身边都是小孩的缘故，他很会玩，当然，是父母眼里所谓的“调皮捣蛋”的孩子，没有那么多的规矩，小时候的琉晴充满了和父母快乐的回忆。他们两个因为血缘而需要被交换，不停的交换生活没有给琉晴带来多大的“进步”，反倒让庆多从原来的胆小，变得更加开朗活泼，同样的，庆多的家庭也因为这件事，从支离破碎的感情中逐渐找到属于自己的亲情。\n\n庆多的父亲良多工作顺利，家庭“美满”，是外人只要提起就会羡慕的“好男人”形象，但他将对工作中的态度放到了日常的生活中，不允许自己和其他人有任何的过错。因为他对于工作有近乎痴迷的状态，这导致了他没有过多参与到庆多成长的片段中，进而，他没有理解庆多母亲绿的辛苦就显得有那么几分合理，当他知道了庆多不是自己的血肉的时候，他的态度开始变得冷淡，想象所有庆多做的不好的地方，嘴里冒出了那句另绿最为痛心的一句话“果然就是这样啊”，他把所有不好的东西都归结为绿的不对和血缘，把所有对的事情都当是理所应当，当他想用金钱收买琉晴，将两个孩子都占为己有的时候，绿开始意识到，在他眼里，一个母亲对一个孩子情感的付出是可以用金钱去交换的。\n\n故事和我预想的结果不太一样，在我眼里，良多是不应该有孩子的，庆多和琉晴应该都属于他们，但这对于绿的打击太大了，太大了，她对于庆多倾注了太多太多感情，故事的最后庆多还是属于良多和绿，但这次，良多从琉晴身上，学到了很多为人父应该有的样子，同样都是父亲，同样都是一份工作，有些人，可以和孩子结下深厚的友情，而有些人，只是披着“父亲”的外衣罢了。\n\n这是我完成的第三本是枝裕和的作品，我蛮喜欢他这种，近乎平淡的手法把生活描写的那么深入人心，如此真实的生活在现实生活中，哪怕在中国，恐怕也是每天都在都在上演吧。","source":"_posts/如父如子.md","raw":"---\ntitle: 如父如子\ntags: []\noriginContent: ''\ncategories:\n  - 旧的文\ntoc: false\ndate: 2019-08-11 10:49:18\nthumbnail: https://images.unsplash.com/photo-1557176278-3326a3193580?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n当金钱作为交换亲情的筹码\n\n在穿梭城市的巴士上完成了本书的阅读，<!--more-->大概3个多小时的时间，估计看完这部电影，也差不多需要这么长时间吧。\n\n两个全然不同的家庭环境塑造了庆多、琉晴两个小孩迥异的性格，庆多懂得待人接物的道理，是家长眼里的“好孩子”，当然这和他的生长环境有关，父亲忙于工作，母亲也习惯了一个人安安静静地带孩子长大，严格的家规，三点一线的日常生活，所有的一切在庆多父母眼里早已成为理所应当的东西，但因为孩子抱错的事情，日常的生活节奏被打乱，庆多仿佛是导火索，点燃了这个破碎的家庭最后的救命稻草。琉晴出生在乡下，或许是身边都是小孩的缘故，他很会玩，当然，是父母眼里所谓的“调皮捣蛋”的孩子，没有那么多的规矩，小时候的琉晴充满了和父母快乐的回忆。他们两个因为血缘而需要被交换，不停的交换生活没有给琉晴带来多大的“进步”，反倒让庆多从原来的胆小，变得更加开朗活泼，同样的，庆多的家庭也因为这件事，从支离破碎的感情中逐渐找到属于自己的亲情。\n\n庆多的父亲良多工作顺利，家庭“美满”，是外人只要提起就会羡慕的“好男人”形象，但他将对工作中的态度放到了日常的生活中，不允许自己和其他人有任何的过错。因为他对于工作有近乎痴迷的状态，这导致了他没有过多参与到庆多成长的片段中，进而，他没有理解庆多母亲绿的辛苦就显得有那么几分合理，当他知道了庆多不是自己的血肉的时候，他的态度开始变得冷淡，想象所有庆多做的不好的地方，嘴里冒出了那句另绿最为痛心的一句话“果然就是这样啊”，他把所有不好的东西都归结为绿的不对和血缘，把所有对的事情都当是理所应当，当他想用金钱收买琉晴，将两个孩子都占为己有的时候，绿开始意识到，在他眼里，一个母亲对一个孩子情感的付出是可以用金钱去交换的。\n\n故事和我预想的结果不太一样，在我眼里，良多是不应该有孩子的，庆多和琉晴应该都属于他们，但这对于绿的打击太大了，太大了，她对于庆多倾注了太多太多感情，故事的最后庆多还是属于良多和绿，但这次，良多从琉晴身上，学到了很多为人父应该有的样子，同样都是父亲，同样都是一份工作，有些人，可以和孩子结下深厚的友情，而有些人，只是披着“父亲”的外衣罢了。\n\n这是我完成的第三本是枝裕和的作品，我蛮喜欢他这种，近乎平淡的手法把生活描写的那么深入人心，如此真实的生活在现实生活中，哪怕在中国，恐怕也是每天都在都在上演吧。","slug":"如父如子","published":1,"updated":"2019-11-15T12:56:12.800Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkqe001vk3x67h9l2h2y","content":"<p>当金钱作为交换亲情的筹码</p>\n<p>在穿梭城市的巴士上完成了本书的阅读，<a id=\"more\"></a>大概3个多小时的时间，估计看完这部电影，也差不多需要这么长时间吧。</p>\n<p>两个全然不同的家庭环境塑造了庆多、琉晴两个小孩迥异的性格，庆多懂得待人接物的道理，是家长眼里的“好孩子”，当然这和他的生长环境有关，父亲忙于工作，母亲也习惯了一个人安安静静地带孩子长大，严格的家规，三点一线的日常生活，所有的一切在庆多父母眼里早已成为理所应当的东西，但因为孩子抱错的事情，日常的生活节奏被打乱，庆多仿佛是导火索，点燃了这个破碎的家庭最后的救命稻草。琉晴出生在乡下，或许是身边都是小孩的缘故，他很会玩，当然，是父母眼里所谓的“调皮捣蛋”的孩子，没有那么多的规矩，小时候的琉晴充满了和父母快乐的回忆。他们两个因为血缘而需要被交换，不停的交换生活没有给琉晴带来多大的“进步”，反倒让庆多从原来的胆小，变得更加开朗活泼，同样的，庆多的家庭也因为这件事，从支离破碎的感情中逐渐找到属于自己的亲情。</p>\n<p>庆多的父亲良多工作顺利，家庭“美满”，是外人只要提起就会羡慕的“好男人”形象，但他将对工作中的态度放到了日常的生活中，不允许自己和其他人有任何的过错。因为他对于工作有近乎痴迷的状态，这导致了他没有过多参与到庆多成长的片段中，进而，他没有理解庆多母亲绿的辛苦就显得有那么几分合理，当他知道了庆多不是自己的血肉的时候，他的态度开始变得冷淡，想象所有庆多做的不好的地方，嘴里冒出了那句另绿最为痛心的一句话“果然就是这样啊”，他把所有不好的东西都归结为绿的不对和血缘，把所有对的事情都当是理所应当，当他想用金钱收买琉晴，将两个孩子都占为己有的时候，绿开始意识到，在他眼里，一个母亲对一个孩子情感的付出是可以用金钱去交换的。</p>\n<p>故事和我预想的结果不太一样，在我眼里，良多是不应该有孩子的，庆多和琉晴应该都属于他们，但这对于绿的打击太大了，太大了，她对于庆多倾注了太多太多感情，故事的最后庆多还是属于良多和绿，但这次，良多从琉晴身上，学到了很多为人父应该有的样子，同样都是父亲，同样都是一份工作，有些人，可以和孩子结下深厚的友情，而有些人，只是披着“父亲”的外衣罢了。</p>\n<p>这是我完成的第三本是枝裕和的作品，我蛮喜欢他这种，近乎平淡的手法把生活描写的那么深入人心，如此真实的生活在现实生活中，哪怕在中国，恐怕也是每天都在都在上演吧。</p>\n","site":{"data":{}},"excerpt":"<p>当金钱作为交换亲情的筹码</p>\n<p>在穿梭城市的巴士上完成了本书的阅读，</p>","more":"大概3个多小时的时间，估计看完这部电影，也差不多需要这么长时间吧。</p>\n<p>两个全然不同的家庭环境塑造了庆多、琉晴两个小孩迥异的性格，庆多懂得待人接物的道理，是家长眼里的“好孩子”，当然这和他的生长环境有关，父亲忙于工作，母亲也习惯了一个人安安静静地带孩子长大，严格的家规，三点一线的日常生活，所有的一切在庆多父母眼里早已成为理所应当的东西，但因为孩子抱错的事情，日常的生活节奏被打乱，庆多仿佛是导火索，点燃了这个破碎的家庭最后的救命稻草。琉晴出生在乡下，或许是身边都是小孩的缘故，他很会玩，当然，是父母眼里所谓的“调皮捣蛋”的孩子，没有那么多的规矩，小时候的琉晴充满了和父母快乐的回忆。他们两个因为血缘而需要被交换，不停的交换生活没有给琉晴带来多大的“进步”，反倒让庆多从原来的胆小，变得更加开朗活泼，同样的，庆多的家庭也因为这件事，从支离破碎的感情中逐渐找到属于自己的亲情。</p>\n<p>庆多的父亲良多工作顺利，家庭“美满”，是外人只要提起就会羡慕的“好男人”形象，但他将对工作中的态度放到了日常的生活中，不允许自己和其他人有任何的过错。因为他对于工作有近乎痴迷的状态，这导致了他没有过多参与到庆多成长的片段中，进而，他没有理解庆多母亲绿的辛苦就显得有那么几分合理，当他知道了庆多不是自己的血肉的时候，他的态度开始变得冷淡，想象所有庆多做的不好的地方，嘴里冒出了那句另绿最为痛心的一句话“果然就是这样啊”，他把所有不好的东西都归结为绿的不对和血缘，把所有对的事情都当是理所应当，当他想用金钱收买琉晴，将两个孩子都占为己有的时候，绿开始意识到，在他眼里，一个母亲对一个孩子情感的付出是可以用金钱去交换的。</p>\n<p>故事和我预想的结果不太一样，在我眼里，良多是不应该有孩子的，庆多和琉晴应该都属于他们，但这对于绿的打击太大了，太大了，她对于庆多倾注了太多太多感情，故事的最后庆多还是属于良多和绿，但这次，良多从琉晴身上，学到了很多为人父应该有的样子，同样都是父亲，同样都是一份工作，有些人，可以和孩子结下深厚的友情，而有些人，只是披着“父亲”的外衣罢了。</p>\n<p>这是我完成的第三本是枝裕和的作品，我蛮喜欢他这种，近乎平淡的手法把生活描写的那么深入人心，如此真实的生活在现实生活中，哪怕在中国，恐怕也是每天都在都在上演吧。</p>"},{"title":"分布式计算学习笔记(一) 从分布式系统到分布式计算","date":"2019-11-18T11:22:27.000Z","thumbnail":"https://images.unsplash.com/photo-1434030216411-0b793f4b4173?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","recommend":0,"top":100,"toc":true,"_content":"\n# 专有名字\n## ACID\n<!--more-->\n- Atomicity（原子性）：一個事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。\n- Consistency（一致性）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。\n- Isolation（隔离性）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。\n- Durability（持久性）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。\n## CAP\n- Consistency 中文叫做\"一致性\"。意思是，写操作之后的读操作，必须返回该值。\n- Availability 中文叫做\"可用性\"，意思是只要收到用户的请求，服务器就必须给出回应。\n- Partition tolerance，中文叫做\"分区容错”, 区间通信可能失败，服务器之间通信失败\n## 负载均衡\n有点 SDN 的感觉，作为南北向的数据接口，连接用户和后端服务器，用户请求首先到达负载均衡器，由负载均衡器分配可用资源（服务器），通常情况下，所有的后端服务器会保证提供相同的内容，以便用户无论哪个服务器响应，都能收到一致的内容（通过冗余提高可靠性），以达到最佳化资源使用、最大化吞吐率、最小化响应时间、同时避免过载的目的。\n## 协调中心\n一个用户请求包含多个服务，每个服务又包含多个节点，不同服务之间的转接需要节点间协同配合，提供服务的节点向一个协调中心注册自己的地址，使用服务的节点去协调中心拉取地址，不同节点通过协调中心完成服务的交接。\n## RPC\nRemote Produce Call, 用于服务内不同节点间的远程通信和相互调用\n## 分布式系统\n分布式系统是一组电子计算机（computer），通过计算机网络相互链接与通信后形成的系统。把需要进行大量计算的工程数据分区成小块，由多台计算机分别计算，在上传运算结果后，将结果统一合并得出数据结论的科学。分布式系统由分布式计算和分布式存储组成，受限于 CAP 特性。\n## 分布式计算\n核心问题： 如何将任务进行分解，如何整合，也就是先Map后Reduce，参考中间件课上所学习的 Word-Count 过程。\n\n# Reference\n- [ https://zhuanlan.zhihu.com/p/32841479][1]\n- [https://zh.wikipedia.org/wiki/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1][2]\n- [https://zh.wikipedia.org/wiki/ACID][3]\n- [https://www.ruanyifeng.com/blog/2018/07/cap.html][4]\n- [https://blog.csdn.net/trochiluses/article/details/19327639][5]\n\n[1]:\thttps://zhuanlan.zhihu.com/p/32841479\n[2]:\thttps://zh.wikipedia.org/wiki/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1\n[3]:\thttps://zh.wikipedia.org/wiki/ACID\n[4]:\thttps://www.ruanyifeng.com/blog/2018/07/cap.html\n[5]:\thttps://blog.csdn.net/trochiluses/article/details/19327639","source":"_posts/分布式计算学习笔记-一-从分布式系统到分布式计算.md","raw":"---\ntitle: 分布式计算学习笔记(一) 从分布式系统到分布式计算\ndate: 2019-11-18 19:22:27\ncategories:\nthumbnail: https://images.unsplash.com/photo-1434030216411-0b793f4b4173?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\nrecommend: 0\ntop: 100\ntoc: true\n---\n\n# 专有名字\n## ACID\n<!--more-->\n- Atomicity（原子性）：一個事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。\n- Consistency（一致性）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。\n- Isolation（隔离性）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。\n- Durability（持久性）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。\n## CAP\n- Consistency 中文叫做\"一致性\"。意思是，写操作之后的读操作，必须返回该值。\n- Availability 中文叫做\"可用性\"，意思是只要收到用户的请求，服务器就必须给出回应。\n- Partition tolerance，中文叫做\"分区容错”, 区间通信可能失败，服务器之间通信失败\n## 负载均衡\n有点 SDN 的感觉，作为南北向的数据接口，连接用户和后端服务器，用户请求首先到达负载均衡器，由负载均衡器分配可用资源（服务器），通常情况下，所有的后端服务器会保证提供相同的内容，以便用户无论哪个服务器响应，都能收到一致的内容（通过冗余提高可靠性），以达到最佳化资源使用、最大化吞吐率、最小化响应时间、同时避免过载的目的。\n## 协调中心\n一个用户请求包含多个服务，每个服务又包含多个节点，不同服务之间的转接需要节点间协同配合，提供服务的节点向一个协调中心注册自己的地址，使用服务的节点去协调中心拉取地址，不同节点通过协调中心完成服务的交接。\n## RPC\nRemote Produce Call, 用于服务内不同节点间的远程通信和相互调用\n## 分布式系统\n分布式系统是一组电子计算机（computer），通过计算机网络相互链接与通信后形成的系统。把需要进行大量计算的工程数据分区成小块，由多台计算机分别计算，在上传运算结果后，将结果统一合并得出数据结论的科学。分布式系统由分布式计算和分布式存储组成，受限于 CAP 特性。\n## 分布式计算\n核心问题： 如何将任务进行分解，如何整合，也就是先Map后Reduce，参考中间件课上所学习的 Word-Count 过程。\n\n# Reference\n- [ https://zhuanlan.zhihu.com/p/32841479][1]\n- [https://zh.wikipedia.org/wiki/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1][2]\n- [https://zh.wikipedia.org/wiki/ACID][3]\n- [https://www.ruanyifeng.com/blog/2018/07/cap.html][4]\n- [https://blog.csdn.net/trochiluses/article/details/19327639][5]\n\n[1]:\thttps://zhuanlan.zhihu.com/p/32841479\n[2]:\thttps://zh.wikipedia.org/wiki/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1\n[3]:\thttps://zh.wikipedia.org/wiki/ACID\n[4]:\thttps://www.ruanyifeng.com/blog/2018/07/cap.html\n[5]:\thttps://blog.csdn.net/trochiluses/article/details/19327639","slug":"分布式计算学习笔记-一-从分布式系统到分布式计算","published":1,"updated":"2019-11-21T03:00:19.897Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkqi001yk3x60lm48y6c","content":"<h1 id=\"专有名字\"><a href=\"#专有名字\" class=\"headerlink\" title=\"专有名字\"></a>专有名字</h1><h2 id=\"ACID\"><a href=\"#ACID\" class=\"headerlink\" title=\"ACID\"></a>ACID</h2><a id=\"more\"></a>\n<ul>\n<li>Atomicity（原子性）：一個事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。</li>\n<li>Consistency（一致性）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。</li>\n<li>Isolation（隔离性）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。</li>\n<li>Durability（持久性）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。<h2 id=\"CAP\"><a href=\"#CAP\" class=\"headerlink\" title=\"CAP\"></a>CAP</h2></li>\n<li>Consistency 中文叫做”一致性”。意思是，写操作之后的读操作，必须返回该值。</li>\n<li>Availability 中文叫做”可用性”，意思是只要收到用户的请求，服务器就必须给出回应。</li>\n<li>Partition tolerance，中文叫做”分区容错”, 区间通信可能失败，服务器之间通信失败<h2 id=\"负载均衡\"><a href=\"#负载均衡\" class=\"headerlink\" title=\"负载均衡\"></a>负载均衡</h2>有点 SDN 的感觉，作为南北向的数据接口，连接用户和后端服务器，用户请求首先到达负载均衡器，由负载均衡器分配可用资源（服务器），通常情况下，所有的后端服务器会保证提供相同的内容，以便用户无论哪个服务器响应，都能收到一致的内容（通过冗余提高可靠性），以达到最佳化资源使用、最大化吞吐率、最小化响应时间、同时避免过载的目的。<h2 id=\"协调中心\"><a href=\"#协调中心\" class=\"headerlink\" title=\"协调中心\"></a>协调中心</h2>一个用户请求包含多个服务，每个服务又包含多个节点，不同服务之间的转接需要节点间协同配合，提供服务的节点向一个协调中心注册自己的地址，使用服务的节点去协调中心拉取地址，不同节点通过协调中心完成服务的交接。<h2 id=\"RPC\"><a href=\"#RPC\" class=\"headerlink\" title=\"RPC\"></a>RPC</h2>Remote Produce Call, 用于服务内不同节点间的远程通信和相互调用<h2 id=\"分布式系统\"><a href=\"#分布式系统\" class=\"headerlink\" title=\"分布式系统\"></a>分布式系统</h2>分布式系统是一组电子计算机（computer），通过计算机网络相互链接与通信后形成的系统。把需要进行大量计算的工程数据分区成小块，由多台计算机分别计算，在上传运算结果后，将结果统一合并得出数据结论的科学。分布式系统由分布式计算和分布式存储组成，受限于 CAP 特性。<h2 id=\"分布式计算\"><a href=\"#分布式计算\" class=\"headerlink\" title=\"分布式计算\"></a>分布式计算</h2>核心问题： 如何将任务进行分解，如何整合，也就是先Map后Reduce，参考中间件课上所学习的 Word-Count 过程。</li>\n</ul>\n<h1 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h1><ul>\n<li><a href=\"https://zhuanlan.zhihu.com/p/32841479\" target=\"_blank\" rel=\"noopener\"> https://zhuanlan.zhihu.com/p/32841479</a></li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1\" target=\"_blank\" rel=\"noopener\">https://zh.wikipedia.org/wiki/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1</a></li>\n<li><a href=\"https://zh.wikipedia.org/wiki/ACID\" target=\"_blank\" rel=\"noopener\">https://zh.wikipedia.org/wiki/ACID</a></li>\n<li><a href=\"https://www.ruanyifeng.com/blog/2018/07/cap.html\" target=\"_blank\" rel=\"noopener\">https://www.ruanyifeng.com/blog/2018/07/cap.html</a></li>\n<li><a href=\"https://blog.csdn.net/trochiluses/article/details/19327639\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/trochiluses/article/details/19327639</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"专有名字\"><a href=\"#专有名字\" class=\"headerlink\" title=\"专有名字\"></a>专有名字</h1><h2 id=\"ACID\"><a href=\"#ACID\" class=\"headerlink\" title=\"ACID\"></a>ACID</h2>","more":"<ul>\n<li>Atomicity（原子性）：一個事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。</li>\n<li>Consistency（一致性）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。</li>\n<li>Isolation（隔离性）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。</li>\n<li>Durability（持久性）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。<h2 id=\"CAP\"><a href=\"#CAP\" class=\"headerlink\" title=\"CAP\"></a>CAP</h2></li>\n<li>Consistency 中文叫做”一致性”。意思是，写操作之后的读操作，必须返回该值。</li>\n<li>Availability 中文叫做”可用性”，意思是只要收到用户的请求，服务器就必须给出回应。</li>\n<li>Partition tolerance，中文叫做”分区容错”, 区间通信可能失败，服务器之间通信失败<h2 id=\"负载均衡\"><a href=\"#负载均衡\" class=\"headerlink\" title=\"负载均衡\"></a>负载均衡</h2>有点 SDN 的感觉，作为南北向的数据接口，连接用户和后端服务器，用户请求首先到达负载均衡器，由负载均衡器分配可用资源（服务器），通常情况下，所有的后端服务器会保证提供相同的内容，以便用户无论哪个服务器响应，都能收到一致的内容（通过冗余提高可靠性），以达到最佳化资源使用、最大化吞吐率、最小化响应时间、同时避免过载的目的。<h2 id=\"协调中心\"><a href=\"#协调中心\" class=\"headerlink\" title=\"协调中心\"></a>协调中心</h2>一个用户请求包含多个服务，每个服务又包含多个节点，不同服务之间的转接需要节点间协同配合，提供服务的节点向一个协调中心注册自己的地址，使用服务的节点去协调中心拉取地址，不同节点通过协调中心完成服务的交接。<h2 id=\"RPC\"><a href=\"#RPC\" class=\"headerlink\" title=\"RPC\"></a>RPC</h2>Remote Produce Call, 用于服务内不同节点间的远程通信和相互调用<h2 id=\"分布式系统\"><a href=\"#分布式系统\" class=\"headerlink\" title=\"分布式系统\"></a>分布式系统</h2>分布式系统是一组电子计算机（computer），通过计算机网络相互链接与通信后形成的系统。把需要进行大量计算的工程数据分区成小块，由多台计算机分别计算，在上传运算结果后，将结果统一合并得出数据结论的科学。分布式系统由分布式计算和分布式存储组成，受限于 CAP 特性。<h2 id=\"分布式计算\"><a href=\"#分布式计算\" class=\"headerlink\" title=\"分布式计算\"></a>分布式计算</h2>核心问题： 如何将任务进行分解，如何整合，也就是先Map后Reduce，参考中间件课上所学习的 Word-Count 过程。</li>\n</ul>\n<h1 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h1><ul>\n<li><a href=\"https://zhuanlan.zhihu.com/p/32841479\" target=\"_blank\" rel=\"noopener\"> https://zhuanlan.zhihu.com/p/32841479</a></li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1\" target=\"_blank\" rel=\"noopener\">https://zh.wikipedia.org/wiki/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1</a></li>\n<li><a href=\"https://zh.wikipedia.org/wiki/ACID\" target=\"_blank\" rel=\"noopener\">https://zh.wikipedia.org/wiki/ACID</a></li>\n<li><a href=\"https://www.ruanyifeng.com/blog/2018/07/cap.html\" target=\"_blank\" rel=\"noopener\">https://www.ruanyifeng.com/blog/2018/07/cap.html</a></li>\n<li><a href=\"https://blog.csdn.net/trochiluses/article/details/19327639\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/trochiluses/article/details/19327639</a></li>\n</ul>"},{"title":"奇迹唱片行","originContent":"","toc":false,"date":"2019-08-11T02:48:07.000Z","thumbnail":"https://images.unsplash.com/photo-1458560871784-56d23406c091?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n被许许多多微小又平凡的事物装点过的生活本身，一直鲜活而灿烂，闪耀到让我们无论如何，都看得到。\n                             —smarttree（来自豆瓣）\n<!--more-->                             \n《奇迹唱片行》 \n估计这是2018年能完成的最后一本书了，当然我并没有指望在接下来的4天能看完一本书。\n\n我蛮享受在城市穿梭的过程中仍有一段静默的时光，也很庆幸最后在地铁上完成了本书的阅读，上一次有同样的经历还是在飞机上。巧了，这次是送朋友去坐飞机。\n\n这本书我蛮喜欢两个元素 1.音乐 2.自由（爱情这玩意暂且不谈）\n\n或许佩格（男主母亲）并不能称之为一个“合格”的母亲，她没有给男主弗兰克足够的母爱？或者足够的照顾？但重要的是，他给了她欣赏音乐的技巧和和寻找音乐的能力。或许是因为从小的家教不同于传统的家庭，他的一生注定不会和普通人一样，仿佛他的一生，就为了追求人们所抛弃的东西：唱片。或说是，他所理解的音乐。他是一个优秀的聆听者，倾听他人的欢喜和苦楚，利用弗兰克自己所理解的音乐，推荐给别人，通过音乐治愈心灵。我看这本书，固定的bgm是Loving Vincent的OST，这个专辑很符合那种安静的氛围，不知道为什么，我总感觉歌和书是一样的，有很多的想象空间，能让我在图书馆哭成泪人，也能让我在困难的时候强挤出一个温暖的笑容。在看这本书的时候，我曾想到之前在国家大剧院听到的音乐会，那种震撼力，哪怕音质最高的音乐也难以望其项背。\n\n自由，书中每个个体，心灵上都是自由的。哪怕是再平凡的生活，也能乐在其中，但社会变化太快了，一把火的功夫，烧毁了唱片行，断了弗兰克的梦，他也不得不为了生活，放弃了自己希望一辈子都能从事的工作-唱片行老板。若不是那短短的一次邂逅，如今的他早已过上“普通人”的生活。全书仿佛就是围绕两个词 CD和黑胶唱片 来刻画弗兰克的人生，他崇尚唱片，认为CD没有灵魂，哪怕是所有的零售商断了他的财路，他也为了心中的梦想，一点一点努力着。很快的，CD被数字化的生活所取代，人们纷纷戴上耳机，只要手指轻轻一动，想要播放的音乐就自动流进耳朵。本书的最后，得到他人帮助后的弗兰克，重新经营起了唱片行，可这次，他的身边多了一个可以一直陪伴他的人。\n\n不知道为什么，感觉这本书有些地方和《岛上书店》蛮像，或许因为书和音乐？\n\n不管了，又一段精彩的旅程画上句号，地铁快到站了，我要收拾收拾下车了。\n\n以下内容摘自《奇迹唱片行》\n黑胶唱片是有生命的，你只能等待。\n\n各种不同的音乐之中都可以看见不同的画面，只要你肯驻足聆听。\n\n机会已失，就像错过火车或某种更重要的东西一样——某种再也不会出现的东西。\n\n二十一年的岁月可以浓缩成多么简短的字句啊。这究竟是好事还是坏事呢？也或许人生本就是这样。","source":"_posts/奇迹唱片行.md","raw":"---\ntitle: 奇迹唱片行\ntags: []\noriginContent: ''\ncategories:\n  - 旧的文\ntoc: false\ndate: 2019-08-11 10:48:07\nthumbnail: https://images.unsplash.com/photo-1458560871784-56d23406c091?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n被许许多多微小又平凡的事物装点过的生活本身，一直鲜活而灿烂，闪耀到让我们无论如何，都看得到。\n                             —smarttree（来自豆瓣）\n<!--more-->                             \n《奇迹唱片行》 \n估计这是2018年能完成的最后一本书了，当然我并没有指望在接下来的4天能看完一本书。\n\n我蛮享受在城市穿梭的过程中仍有一段静默的时光，也很庆幸最后在地铁上完成了本书的阅读，上一次有同样的经历还是在飞机上。巧了，这次是送朋友去坐飞机。\n\n这本书我蛮喜欢两个元素 1.音乐 2.自由（爱情这玩意暂且不谈）\n\n或许佩格（男主母亲）并不能称之为一个“合格”的母亲，她没有给男主弗兰克足够的母爱？或者足够的照顾？但重要的是，他给了她欣赏音乐的技巧和和寻找音乐的能力。或许是因为从小的家教不同于传统的家庭，他的一生注定不会和普通人一样，仿佛他的一生，就为了追求人们所抛弃的东西：唱片。或说是，他所理解的音乐。他是一个优秀的聆听者，倾听他人的欢喜和苦楚，利用弗兰克自己所理解的音乐，推荐给别人，通过音乐治愈心灵。我看这本书，固定的bgm是Loving Vincent的OST，这个专辑很符合那种安静的氛围，不知道为什么，我总感觉歌和书是一样的，有很多的想象空间，能让我在图书馆哭成泪人，也能让我在困难的时候强挤出一个温暖的笑容。在看这本书的时候，我曾想到之前在国家大剧院听到的音乐会，那种震撼力，哪怕音质最高的音乐也难以望其项背。\n\n自由，书中每个个体，心灵上都是自由的。哪怕是再平凡的生活，也能乐在其中，但社会变化太快了，一把火的功夫，烧毁了唱片行，断了弗兰克的梦，他也不得不为了生活，放弃了自己希望一辈子都能从事的工作-唱片行老板。若不是那短短的一次邂逅，如今的他早已过上“普通人”的生活。全书仿佛就是围绕两个词 CD和黑胶唱片 来刻画弗兰克的人生，他崇尚唱片，认为CD没有灵魂，哪怕是所有的零售商断了他的财路，他也为了心中的梦想，一点一点努力着。很快的，CD被数字化的生活所取代，人们纷纷戴上耳机，只要手指轻轻一动，想要播放的音乐就自动流进耳朵。本书的最后，得到他人帮助后的弗兰克，重新经营起了唱片行，可这次，他的身边多了一个可以一直陪伴他的人。\n\n不知道为什么，感觉这本书有些地方和《岛上书店》蛮像，或许因为书和音乐？\n\n不管了，又一段精彩的旅程画上句号，地铁快到站了，我要收拾收拾下车了。\n\n以下内容摘自《奇迹唱片行》\n黑胶唱片是有生命的，你只能等待。\n\n各种不同的音乐之中都可以看见不同的画面，只要你肯驻足聆听。\n\n机会已失，就像错过火车或某种更重要的东西一样——某种再也不会出现的东西。\n\n二十一年的岁月可以浓缩成多么简短的字句啊。这究竟是好事还是坏事呢？也或许人生本就是这样。","slug":"奇迹唱片行","published":1,"updated":"2019-11-15T12:49:49.962Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkql0022k3x64ttv3rml","content":"<p>被许许多多微小又平凡的事物装点过的生活本身，一直鲜活而灿烂，闪耀到让我们无论如何，都看得到。<br>                             —smarttree（来自豆瓣）</p>\n<a id=\"more\"></a>                             \n<p>《奇迹唱片行》<br>估计这是2018年能完成的最后一本书了，当然我并没有指望在接下来的4天能看完一本书。</p>\n<p>我蛮享受在城市穿梭的过程中仍有一段静默的时光，也很庆幸最后在地铁上完成了本书的阅读，上一次有同样的经历还是在飞机上。巧了，这次是送朋友去坐飞机。</p>\n<p>这本书我蛮喜欢两个元素 1.音乐 2.自由（爱情这玩意暂且不谈）</p>\n<p>或许佩格（男主母亲）并不能称之为一个“合格”的母亲，她没有给男主弗兰克足够的母爱？或者足够的照顾？但重要的是，他给了她欣赏音乐的技巧和和寻找音乐的能力。或许是因为从小的家教不同于传统的家庭，他的一生注定不会和普通人一样，仿佛他的一生，就为了追求人们所抛弃的东西：唱片。或说是，他所理解的音乐。他是一个优秀的聆听者，倾听他人的欢喜和苦楚，利用弗兰克自己所理解的音乐，推荐给别人，通过音乐治愈心灵。我看这本书，固定的bgm是Loving Vincent的OST，这个专辑很符合那种安静的氛围，不知道为什么，我总感觉歌和书是一样的，有很多的想象空间，能让我在图书馆哭成泪人，也能让我在困难的时候强挤出一个温暖的笑容。在看这本书的时候，我曾想到之前在国家大剧院听到的音乐会，那种震撼力，哪怕音质最高的音乐也难以望其项背。</p>\n<p>自由，书中每个个体，心灵上都是自由的。哪怕是再平凡的生活，也能乐在其中，但社会变化太快了，一把火的功夫，烧毁了唱片行，断了弗兰克的梦，他也不得不为了生活，放弃了自己希望一辈子都能从事的工作-唱片行老板。若不是那短短的一次邂逅，如今的他早已过上“普通人”的生活。全书仿佛就是围绕两个词 CD和黑胶唱片 来刻画弗兰克的人生，他崇尚唱片，认为CD没有灵魂，哪怕是所有的零售商断了他的财路，他也为了心中的梦想，一点一点努力着。很快的，CD被数字化的生活所取代，人们纷纷戴上耳机，只要手指轻轻一动，想要播放的音乐就自动流进耳朵。本书的最后，得到他人帮助后的弗兰克，重新经营起了唱片行，可这次，他的身边多了一个可以一直陪伴他的人。</p>\n<p>不知道为什么，感觉这本书有些地方和《岛上书店》蛮像，或许因为书和音乐？</p>\n<p>不管了，又一段精彩的旅程画上句号，地铁快到站了，我要收拾收拾下车了。</p>\n<p>以下内容摘自《奇迹唱片行》<br>黑胶唱片是有生命的，你只能等待。</p>\n<p>各种不同的音乐之中都可以看见不同的画面，只要你肯驻足聆听。</p>\n<p>机会已失，就像错过火车或某种更重要的东西一样——某种再也不会出现的东西。</p>\n<p>二十一年的岁月可以浓缩成多么简短的字句啊。这究竟是好事还是坏事呢？也或许人生本就是这样。</p>\n","site":{"data":{}},"excerpt":"<p>被许许多多微小又平凡的事物装点过的生活本身，一直鲜活而灿烂，闪耀到让我们无论如何，都看得到。<br>                             —smarttree（来自豆瓣）</p>","more":"<p>《奇迹唱片行》<br>估计这是2018年能完成的最后一本书了，当然我并没有指望在接下来的4天能看完一本书。</p>\n<p>我蛮享受在城市穿梭的过程中仍有一段静默的时光，也很庆幸最后在地铁上完成了本书的阅读，上一次有同样的经历还是在飞机上。巧了，这次是送朋友去坐飞机。</p>\n<p>这本书我蛮喜欢两个元素 1.音乐 2.自由（爱情这玩意暂且不谈）</p>\n<p>或许佩格（男主母亲）并不能称之为一个“合格”的母亲，她没有给男主弗兰克足够的母爱？或者足够的照顾？但重要的是，他给了她欣赏音乐的技巧和和寻找音乐的能力。或许是因为从小的家教不同于传统的家庭，他的一生注定不会和普通人一样，仿佛他的一生，就为了追求人们所抛弃的东西：唱片。或说是，他所理解的音乐。他是一个优秀的聆听者，倾听他人的欢喜和苦楚，利用弗兰克自己所理解的音乐，推荐给别人，通过音乐治愈心灵。我看这本书，固定的bgm是Loving Vincent的OST，这个专辑很符合那种安静的氛围，不知道为什么，我总感觉歌和书是一样的，有很多的想象空间，能让我在图书馆哭成泪人，也能让我在困难的时候强挤出一个温暖的笑容。在看这本书的时候，我曾想到之前在国家大剧院听到的音乐会，那种震撼力，哪怕音质最高的音乐也难以望其项背。</p>\n<p>自由，书中每个个体，心灵上都是自由的。哪怕是再平凡的生活，也能乐在其中，但社会变化太快了，一把火的功夫，烧毁了唱片行，断了弗兰克的梦，他也不得不为了生活，放弃了自己希望一辈子都能从事的工作-唱片行老板。若不是那短短的一次邂逅，如今的他早已过上“普通人”的生活。全书仿佛就是围绕两个词 CD和黑胶唱片 来刻画弗兰克的人生，他崇尚唱片，认为CD没有灵魂，哪怕是所有的零售商断了他的财路，他也为了心中的梦想，一点一点努力着。很快的，CD被数字化的生活所取代，人们纷纷戴上耳机，只要手指轻轻一动，想要播放的音乐就自动流进耳朵。本书的最后，得到他人帮助后的弗兰克，重新经营起了唱片行，可这次，他的身边多了一个可以一直陪伴他的人。</p>\n<p>不知道为什么，感觉这本书有些地方和《岛上书店》蛮像，或许因为书和音乐？</p>\n<p>不管了，又一段精彩的旅程画上句号，地铁快到站了，我要收拾收拾下车了。</p>\n<p>以下内容摘自《奇迹唱片行》<br>黑胶唱片是有生命的，你只能等待。</p>\n<p>各种不同的音乐之中都可以看见不同的画面，只要你肯驻足聆听。</p>\n<p>机会已失，就像错过火车或某种更重要的东西一样——某种再也不会出现的东西。</p>\n<p>二十一年的岁月可以浓缩成多么简短的字句啊。这究竟是好事还是坏事呢？也或许人生本就是这样。</p>"},{"title":"岛上书店","originContent":"","toc":false,"date":"2019-08-11T02:31:39.000Z","thumbnail":"https://images.unsplash.com/photo-1507842217343-583bb7270b66?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n寒假书单2\n独自生活的真正难处在于没人在乎你是否心烦意乱\n<!--more-->\n昨天的托福课实在上得心烦意乱，甚至在阅读《岛上书店》时都产生了一种负面的情感。不管怎么样，我还是完成了对这本书的阅读。《岛上书店》是关于“爱与被爱”的故事，书中关于爱情的观点我在互联网中见过相似的描写，但还没有做到亲身经历，所以暂不评论。所以对于这本书，我能感受到的最大的遗憾就是。书中提到的所有书目，我基本上没有看过一本，作者对于情感的把握，很多是依附于其他小说的角色上面，所以说，我还有很长一段路要走。最后引用书中小女孩对纸质书的形容结束这段评论\t（东西）\n\n“爸爸的香皂，青草，大海，厨房里的餐桌，及奶酪。”","source":"_posts/岛上书店.md","raw":"---\ntitle: 岛上书店\ntags: []\noriginContent: ''\ncategories:\n  - 旧的文\ntoc: false\ndate: 2019-08-11 10:31:39\nthumbnail: https://images.unsplash.com/photo-1507842217343-583bb7270b66?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n寒假书单2\n独自生活的真正难处在于没人在乎你是否心烦意乱\n<!--more-->\n昨天的托福课实在上得心烦意乱，甚至在阅读《岛上书店》时都产生了一种负面的情感。不管怎么样，我还是完成了对这本书的阅读。《岛上书店》是关于“爱与被爱”的故事，书中关于爱情的观点我在互联网中见过相似的描写，但还没有做到亲身经历，所以暂不评论。所以对于这本书，我能感受到的最大的遗憾就是。书中提到的所有书目，我基本上没有看过一本，作者对于情感的把握，很多是依附于其他小说的角色上面，所以说，我还有很长一段路要走。最后引用书中小女孩对纸质书的形容结束这段评论\t（东西）\n\n“爸爸的香皂，青草，大海，厨房里的餐桌，及奶酪。”","slug":"岛上书店","published":1,"updated":"2019-11-15T12:55:46.632Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkqn0025k3x6dl04biwb","content":"<p>寒假书单2<br>独自生活的真正难处在于没人在乎你是否心烦意乱</p>\n<a id=\"more\"></a>\n<p>昨天的托福课实在上得心烦意乱，甚至在阅读《岛上书店》时都产生了一种负面的情感。不管怎么样，我还是完成了对这本书的阅读。《岛上书店》是关于“爱与被爱”的故事，书中关于爱情的观点我在互联网中见过相似的描写，但还没有做到亲身经历，所以暂不评论。所以对于这本书，我能感受到的最大的遗憾就是。书中提到的所有书目，我基本上没有看过一本，作者对于情感的把握，很多是依附于其他小说的角色上面，所以说，我还有很长一段路要走。最后引用书中小女孩对纸质书的形容结束这段评论    （东西）</p>\n<p>“爸爸的香皂，青草，大海，厨房里的餐桌，及奶酪。”</p>\n","site":{"data":{}},"excerpt":"<p>寒假书单2<br>独自生活的真正难处在于没人在乎你是否心烦意乱</p>","more":"<p>昨天的托福课实在上得心烦意乱，甚至在阅读《岛上书店》时都产生了一种负面的情感。不管怎么样，我还是完成了对这本书的阅读。《岛上书店》是关于“爱与被爱”的故事，书中关于爱情的观点我在互联网中见过相似的描写，但还没有做到亲身经历，所以暂不评论。所以对于这本书，我能感受到的最大的遗憾就是。书中提到的所有书目，我基本上没有看过一本，作者对于情感的把握，很多是依附于其他小说的角色上面，所以说，我还有很长一段路要走。最后引用书中小女孩对纸质书的形容结束这段评论    （东西）</p>\n<p>“爸爸的香皂，青草，大海，厨房里的餐桌，及奶酪。”</p>"},{"title":"房思琪的初恋乐园","originContent":"","toc":false,"date":"2019-08-11T02:30:39.000Z","thumbnail":"https://images.unsplash.com/photo-1526725702345-bdda2b97ef73?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n寒假书单1\n痛苦的际遇是如此难以分享，好险这个世界还有文学。\n<!--more-->\n我是知道了本书作者自杀的消息后才开始了解这本书，仿佛是为了进行某种宗教仪式一样，迫使我完成对本书的阅读。本书讲述的内容大家可以百度，我就不愿再次揭开林的痛苦，如果说你对本书有兴趣，那你可以继续往下看了：\n\n我不知道初恋对于一个女生的重要性，也当然不知道，一个中年有家室的老师的花言巧语和行为上的放纵竟能对一个女生的影响会那么大。这本书就像是梦魇一样，折磨着我。\n\n老师们说道“我们会老去，可她们不会老去”，无限的美好的心灵在老师眼下就只是还没有失去并等待剥夺的童真的美丽而又充满诱惑的少女。房思琪的爱情和人生在高中就静止了；另外一个女生在网站上哭诉，收获的却是网友们的千刀万剐，“要爽就直说”的句子我不是没有在中国的网站上看到过。房思琪的“死”不只是由简简单单一个老师的功劳，而是整个社会对于性的回避和对性暴力的漠视所造成的。\n\n看完整本书，我翻看了林的fb，有句话我蛮触动 “我突然发现我对B做的最残忍的事情就是让他明白，身为重度精神病患者的伴侣，他无论如何都无法让我真正幸福”\n\n如果说你是一名男生，我会告诉你，这本书的内容会有画面感，产生生理作用不要觉得害羞，因为我就是；如果是一名女生，我要说一声抱歉，因为我是不愿让你去看清这个世界的黑暗面的。\n\n东西写到这里也要结束了。有科学文章表明，人们在网上看长篇东西是呈F形状的，不为内容，也要看了结尾。既然这是最后，那我希望你，能好好对待每一场恋爱，对以前真心爱过的人说声“我真的有爱过你”…以及，对那些社会上的“幸存者”抱以宽容的态度，有些痛你是不会经历的……..anyway我又多了一个再去一次台湾的理由","source":"_posts/房思琪的初恋乐园.md","raw":"---\ntitle: 房思琪的初恋乐园\ntags: []\noriginContent: ''\ncategories:\n  - 旧的文\ntoc: false\ndate: 2019-08-11 10:30:39\nthumbnail: https://images.unsplash.com/photo-1526725702345-bdda2b97ef73?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n寒假书单1\n痛苦的际遇是如此难以分享，好险这个世界还有文学。\n<!--more-->\n我是知道了本书作者自杀的消息后才开始了解这本书，仿佛是为了进行某种宗教仪式一样，迫使我完成对本书的阅读。本书讲述的内容大家可以百度，我就不愿再次揭开林的痛苦，如果说你对本书有兴趣，那你可以继续往下看了：\n\n我不知道初恋对于一个女生的重要性，也当然不知道，一个中年有家室的老师的花言巧语和行为上的放纵竟能对一个女生的影响会那么大。这本书就像是梦魇一样，折磨着我。\n\n老师们说道“我们会老去，可她们不会老去”，无限的美好的心灵在老师眼下就只是还没有失去并等待剥夺的童真的美丽而又充满诱惑的少女。房思琪的爱情和人生在高中就静止了；另外一个女生在网站上哭诉，收获的却是网友们的千刀万剐，“要爽就直说”的句子我不是没有在中国的网站上看到过。房思琪的“死”不只是由简简单单一个老师的功劳，而是整个社会对于性的回避和对性暴力的漠视所造成的。\n\n看完整本书，我翻看了林的fb，有句话我蛮触动 “我突然发现我对B做的最残忍的事情就是让他明白，身为重度精神病患者的伴侣，他无论如何都无法让我真正幸福”\n\n如果说你是一名男生，我会告诉你，这本书的内容会有画面感，产生生理作用不要觉得害羞，因为我就是；如果是一名女生，我要说一声抱歉，因为我是不愿让你去看清这个世界的黑暗面的。\n\n东西写到这里也要结束了。有科学文章表明，人们在网上看长篇东西是呈F形状的，不为内容，也要看了结尾。既然这是最后，那我希望你，能好好对待每一场恋爱，对以前真心爱过的人说声“我真的有爱过你”…以及，对那些社会上的“幸存者”抱以宽容的态度，有些痛你是不会经历的……..anyway我又多了一个再去一次台湾的理由","slug":"房思琪的初恋乐园","published":1,"updated":"2019-11-15T12:58:22.121Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkqp0029k3x62eox2lot","content":"<p>寒假书单1<br>痛苦的际遇是如此难以分享，好险这个世界还有文学。</p>\n<a id=\"more\"></a>\n<p>我是知道了本书作者自杀的消息后才开始了解这本书，仿佛是为了进行某种宗教仪式一样，迫使我完成对本书的阅读。本书讲述的内容大家可以百度，我就不愿再次揭开林的痛苦，如果说你对本书有兴趣，那你可以继续往下看了：</p>\n<p>我不知道初恋对于一个女生的重要性，也当然不知道，一个中年有家室的老师的花言巧语和行为上的放纵竟能对一个女生的影响会那么大。这本书就像是梦魇一样，折磨着我。</p>\n<p>老师们说道“我们会老去，可她们不会老去”，无限的美好的心灵在老师眼下就只是还没有失去并等待剥夺的童真的美丽而又充满诱惑的少女。房思琪的爱情和人生在高中就静止了；另外一个女生在网站上哭诉，收获的却是网友们的千刀万剐，“要爽就直说”的句子我不是没有在中国的网站上看到过。房思琪的“死”不只是由简简单单一个老师的功劳，而是整个社会对于性的回避和对性暴力的漠视所造成的。</p>\n<p>看完整本书，我翻看了林的fb，有句话我蛮触动 “我突然发现我对B做的最残忍的事情就是让他明白，身为重度精神病患者的伴侣，他无论如何都无法让我真正幸福”</p>\n<p>如果说你是一名男生，我会告诉你，这本书的内容会有画面感，产生生理作用不要觉得害羞，因为我就是；如果是一名女生，我要说一声抱歉，因为我是不愿让你去看清这个世界的黑暗面的。</p>\n<p>东西写到这里也要结束了。有科学文章表明，人们在网上看长篇东西是呈F形状的，不为内容，也要看了结尾。既然这是最后，那我希望你，能好好对待每一场恋爱，对以前真心爱过的人说声“我真的有爱过你”…以及，对那些社会上的“幸存者”抱以宽容的态度，有些痛你是不会经历的……..anyway我又多了一个再去一次台湾的理由</p>\n","site":{"data":{}},"excerpt":"<p>寒假书单1<br>痛苦的际遇是如此难以分享，好险这个世界还有文学。</p>","more":"<p>我是知道了本书作者自杀的消息后才开始了解这本书，仿佛是为了进行某种宗教仪式一样，迫使我完成对本书的阅读。本书讲述的内容大家可以百度，我就不愿再次揭开林的痛苦，如果说你对本书有兴趣，那你可以继续往下看了：</p>\n<p>我不知道初恋对于一个女生的重要性，也当然不知道，一个中年有家室的老师的花言巧语和行为上的放纵竟能对一个女生的影响会那么大。这本书就像是梦魇一样，折磨着我。</p>\n<p>老师们说道“我们会老去，可她们不会老去”，无限的美好的心灵在老师眼下就只是还没有失去并等待剥夺的童真的美丽而又充满诱惑的少女。房思琪的爱情和人生在高中就静止了；另外一个女生在网站上哭诉，收获的却是网友们的千刀万剐，“要爽就直说”的句子我不是没有在中国的网站上看到过。房思琪的“死”不只是由简简单单一个老师的功劳，而是整个社会对于性的回避和对性暴力的漠视所造成的。</p>\n<p>看完整本书，我翻看了林的fb，有句话我蛮触动 “我突然发现我对B做的最残忍的事情就是让他明白，身为重度精神病患者的伴侣，他无论如何都无法让我真正幸福”</p>\n<p>如果说你是一名男生，我会告诉你，这本书的内容会有画面感，产生生理作用不要觉得害羞，因为我就是；如果是一名女生，我要说一声抱歉，因为我是不愿让你去看清这个世界的黑暗面的。</p>\n<p>东西写到这里也要结束了。有科学文章表明，人们在网上看长篇东西是呈F形状的，不为内容，也要看了结尾。既然这是最后，那我希望你，能好好对待每一场恋爱，对以前真心爱过的人说声“我真的有爱过你”…以及，对那些社会上的“幸存者”抱以宽容的态度，有些痛你是不会经历的……..anyway我又多了一个再去一次台湾的理由</p>"},{"title":"无声告白","date":"2019-05-10T10:16:43.000Z","thumbnail":"https://images.unsplash.com/photo-1466108333137-d66f5e31b052?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n别让人生从你身旁溜走\n断断续续看了将近一个月，最后还是在图书馆完成了本书的阅读。<!--more-->本怀着期待的心情，告诉她所有的故事的情节，但当我接起电话，才发现，我很难去梳理出一条简单的逻辑线给她讲清楚所有的故事梗概，或许，她永远都不会理解吧。\n\n我认为书里描绘了两个重点，一个是相同，而另一个，是不同。\n\n詹姆斯，作为第一批到达美国的中国人，皮肤，眼睛的颜色，服饰都与当地人格格不入，而且詹姆斯的父母都是蓝领，干着詹姆斯不愿提及的工作。一心想要寻求“相同”的詹姆斯努力学习，教育孩子一定要融入集体，找到小伙伴，可终其一生，还逃不过一句：中国佬找不到中国了。\n\n玛丽琳是美国出生的正牌美国人，接受着相同的学校教育，家庭教育。从小就被母亲教育要做好饭，照顾好未来丈夫，孩子的她内心深处其实是排斥这些东西的。她想要获得自己的生活，不愿成为人们眼中相同的女人。即使是有了孩子，她也愿意远离孩子和丈夫，为了完成自己的梦想。\n\n就是这么两个人生道路完全不同的人，走到了一起。或许是詹姆斯想要寻求融入，而玛丽琳想要寻求不同罢了。冥冥中，有些事情就已开始改变。他们有三个孩子，内斯，莉迪亚和汉娜。作为家里的大女儿，莉迪亚寄托了母亲太多的期待，即使是违背了自己的意愿，当母亲从离家出走到回到家的那一刻，莉迪亚知道了，自己一定要听母亲的，为了她不再离开这个家。慢慢的，莉迪亚身上的担子越来越多，生物，物理，母亲根本没有了解真正的莉迪亚，只是在心中构想了一个自己希望的莉迪亚罢了。当詹姆斯知道了这一切有些奇怪并告诉莉迪亚要融入集体的时候，一切都晚了。由于注意力的转移，身为老大的内斯可以沉浸在自己的世界中，即使这个世界并没有被父母所关心。他明白这个家庭的问题并一心想要逃离，但他还是爱莉迪亚的，了解她，照顾她。但，当内斯去了哈佛，没有了家庭的羁绊，他就像破茧而出的蝴蝶，不再回头看望自己遗留下的东西，而是展开翅膀迎接新的生活。作为家中唯一了解莉迪亚的人，他走了。莉迪亚没有了依靠，她想要解脱，想要逃离，当她跃入水中，现实的世界正远离她的时候，她找到了真正的归宿。\n\n本书无声告白，乍一看还以为真的是告白。Everything I never told you是本书的原名。莉迪亚自始至终都没有告诉父母她真正想要的，一味地答应毁了她的一生。谁不是这样呢，人总是充满幻想，可以以后活成自己想要的模样，但现实是，绝大部分都成为了别人眼中的“相同”。遵循自己内心的想法真的很难，但或许当你想着，人死了，总要留下点什么的时候，你或许就会多一点在意自己的想法了吧。\n\n以上这些，或许就是我想对你说的，但机会已经过去了，重新提起未免有些突兀，当然，我也不是很想分享给你，因为你不会去理会，或许我这辈子，只能和自己去分享读过的书了吧。对你，我真的不知道该怎么办，真的。\n\n和莉迪亚一样，他们没有真正的朋友。\n","source":"_posts/无声告白.md","raw":"---\ntitle: 无声告白\ndate: 2019-05-10 18:16:43\ncategories: \n- 旧的文\ntags:\nthumbnail: https://images.unsplash.com/photo-1466108333137-d66f5e31b052?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n别让人生从你身旁溜走\n断断续续看了将近一个月，最后还是在图书馆完成了本书的阅读。<!--more-->本怀着期待的心情，告诉她所有的故事的情节，但当我接起电话，才发现，我很难去梳理出一条简单的逻辑线给她讲清楚所有的故事梗概，或许，她永远都不会理解吧。\n\n我认为书里描绘了两个重点，一个是相同，而另一个，是不同。\n\n詹姆斯，作为第一批到达美国的中国人，皮肤，眼睛的颜色，服饰都与当地人格格不入，而且詹姆斯的父母都是蓝领，干着詹姆斯不愿提及的工作。一心想要寻求“相同”的詹姆斯努力学习，教育孩子一定要融入集体，找到小伙伴，可终其一生，还逃不过一句：中国佬找不到中国了。\n\n玛丽琳是美国出生的正牌美国人，接受着相同的学校教育，家庭教育。从小就被母亲教育要做好饭，照顾好未来丈夫，孩子的她内心深处其实是排斥这些东西的。她想要获得自己的生活，不愿成为人们眼中相同的女人。即使是有了孩子，她也愿意远离孩子和丈夫，为了完成自己的梦想。\n\n就是这么两个人生道路完全不同的人，走到了一起。或许是詹姆斯想要寻求融入，而玛丽琳想要寻求不同罢了。冥冥中，有些事情就已开始改变。他们有三个孩子，内斯，莉迪亚和汉娜。作为家里的大女儿，莉迪亚寄托了母亲太多的期待，即使是违背了自己的意愿，当母亲从离家出走到回到家的那一刻，莉迪亚知道了，自己一定要听母亲的，为了她不再离开这个家。慢慢的，莉迪亚身上的担子越来越多，生物，物理，母亲根本没有了解真正的莉迪亚，只是在心中构想了一个自己希望的莉迪亚罢了。当詹姆斯知道了这一切有些奇怪并告诉莉迪亚要融入集体的时候，一切都晚了。由于注意力的转移，身为老大的内斯可以沉浸在自己的世界中，即使这个世界并没有被父母所关心。他明白这个家庭的问题并一心想要逃离，但他还是爱莉迪亚的，了解她，照顾她。但，当内斯去了哈佛，没有了家庭的羁绊，他就像破茧而出的蝴蝶，不再回头看望自己遗留下的东西，而是展开翅膀迎接新的生活。作为家中唯一了解莉迪亚的人，他走了。莉迪亚没有了依靠，她想要解脱，想要逃离，当她跃入水中，现实的世界正远离她的时候，她找到了真正的归宿。\n\n本书无声告白，乍一看还以为真的是告白。Everything I never told you是本书的原名。莉迪亚自始至终都没有告诉父母她真正想要的，一味地答应毁了她的一生。谁不是这样呢，人总是充满幻想，可以以后活成自己想要的模样，但现实是，绝大部分都成为了别人眼中的“相同”。遵循自己内心的想法真的很难，但或许当你想着，人死了，总要留下点什么的时候，你或许就会多一点在意自己的想法了吧。\n\n以上这些，或许就是我想对你说的，但机会已经过去了，重新提起未免有些突兀，当然，我也不是很想分享给你，因为你不会去理会，或许我这辈子，只能和自己去分享读过的书了吧。对你，我真的不知道该怎么办，真的。\n\n和莉迪亚一样，他们没有真正的朋友。\n","slug":"无声告白","published":1,"updated":"2019-11-15T12:59:55.099Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkqq002ck3x6cxxt6xny","content":"<p>别让人生从你身旁溜走<br>断断续续看了将近一个月，最后还是在图书馆完成了本书的阅读。<a id=\"more\"></a>本怀着期待的心情，告诉她所有的故事的情节，但当我接起电话，才发现，我很难去梳理出一条简单的逻辑线给她讲清楚所有的故事梗概，或许，她永远都不会理解吧。</p>\n<p>我认为书里描绘了两个重点，一个是相同，而另一个，是不同。</p>\n<p>詹姆斯，作为第一批到达美国的中国人，皮肤，眼睛的颜色，服饰都与当地人格格不入，而且詹姆斯的父母都是蓝领，干着詹姆斯不愿提及的工作。一心想要寻求“相同”的詹姆斯努力学习，教育孩子一定要融入集体，找到小伙伴，可终其一生，还逃不过一句：中国佬找不到中国了。</p>\n<p>玛丽琳是美国出生的正牌美国人，接受着相同的学校教育，家庭教育。从小就被母亲教育要做好饭，照顾好未来丈夫，孩子的她内心深处其实是排斥这些东西的。她想要获得自己的生活，不愿成为人们眼中相同的女人。即使是有了孩子，她也愿意远离孩子和丈夫，为了完成自己的梦想。</p>\n<p>就是这么两个人生道路完全不同的人，走到了一起。或许是詹姆斯想要寻求融入，而玛丽琳想要寻求不同罢了。冥冥中，有些事情就已开始改变。他们有三个孩子，内斯，莉迪亚和汉娜。作为家里的大女儿，莉迪亚寄托了母亲太多的期待，即使是违背了自己的意愿，当母亲从离家出走到回到家的那一刻，莉迪亚知道了，自己一定要听母亲的，为了她不再离开这个家。慢慢的，莉迪亚身上的担子越来越多，生物，物理，母亲根本没有了解真正的莉迪亚，只是在心中构想了一个自己希望的莉迪亚罢了。当詹姆斯知道了这一切有些奇怪并告诉莉迪亚要融入集体的时候，一切都晚了。由于注意力的转移，身为老大的内斯可以沉浸在自己的世界中，即使这个世界并没有被父母所关心。他明白这个家庭的问题并一心想要逃离，但他还是爱莉迪亚的，了解她，照顾她。但，当内斯去了哈佛，没有了家庭的羁绊，他就像破茧而出的蝴蝶，不再回头看望自己遗留下的东西，而是展开翅膀迎接新的生活。作为家中唯一了解莉迪亚的人，他走了。莉迪亚没有了依靠，她想要解脱，想要逃离，当她跃入水中，现实的世界正远离她的时候，她找到了真正的归宿。</p>\n<p>本书无声告白，乍一看还以为真的是告白。Everything I never told you是本书的原名。莉迪亚自始至终都没有告诉父母她真正想要的，一味地答应毁了她的一生。谁不是这样呢，人总是充满幻想，可以以后活成自己想要的模样，但现实是，绝大部分都成为了别人眼中的“相同”。遵循自己内心的想法真的很难，但或许当你想着，人死了，总要留下点什么的时候，你或许就会多一点在意自己的想法了吧。</p>\n<p>以上这些，或许就是我想对你说的，但机会已经过去了，重新提起未免有些突兀，当然，我也不是很想分享给你，因为你不会去理会，或许我这辈子，只能和自己去分享读过的书了吧。对你，我真的不知道该怎么办，真的。</p>\n<p>和莉迪亚一样，他们没有真正的朋友。</p>\n","site":{"data":{}},"excerpt":"<p>别让人生从你身旁溜走<br>断断续续看了将近一个月，最后还是在图书馆完成了本书的阅读。</p>","more":"本怀着期待的心情，告诉她所有的故事的情节，但当我接起电话，才发现，我很难去梳理出一条简单的逻辑线给她讲清楚所有的故事梗概，或许，她永远都不会理解吧。</p>\n<p>我认为书里描绘了两个重点，一个是相同，而另一个，是不同。</p>\n<p>詹姆斯，作为第一批到达美国的中国人，皮肤，眼睛的颜色，服饰都与当地人格格不入，而且詹姆斯的父母都是蓝领，干着詹姆斯不愿提及的工作。一心想要寻求“相同”的詹姆斯努力学习，教育孩子一定要融入集体，找到小伙伴，可终其一生，还逃不过一句：中国佬找不到中国了。</p>\n<p>玛丽琳是美国出生的正牌美国人，接受着相同的学校教育，家庭教育。从小就被母亲教育要做好饭，照顾好未来丈夫，孩子的她内心深处其实是排斥这些东西的。她想要获得自己的生活，不愿成为人们眼中相同的女人。即使是有了孩子，她也愿意远离孩子和丈夫，为了完成自己的梦想。</p>\n<p>就是这么两个人生道路完全不同的人，走到了一起。或许是詹姆斯想要寻求融入，而玛丽琳想要寻求不同罢了。冥冥中，有些事情就已开始改变。他们有三个孩子，内斯，莉迪亚和汉娜。作为家里的大女儿，莉迪亚寄托了母亲太多的期待，即使是违背了自己的意愿，当母亲从离家出走到回到家的那一刻，莉迪亚知道了，自己一定要听母亲的，为了她不再离开这个家。慢慢的，莉迪亚身上的担子越来越多，生物，物理，母亲根本没有了解真正的莉迪亚，只是在心中构想了一个自己希望的莉迪亚罢了。当詹姆斯知道了这一切有些奇怪并告诉莉迪亚要融入集体的时候，一切都晚了。由于注意力的转移，身为老大的内斯可以沉浸在自己的世界中，即使这个世界并没有被父母所关心。他明白这个家庭的问题并一心想要逃离，但他还是爱莉迪亚的，了解她，照顾她。但，当内斯去了哈佛，没有了家庭的羁绊，他就像破茧而出的蝴蝶，不再回头看望自己遗留下的东西，而是展开翅膀迎接新的生活。作为家中唯一了解莉迪亚的人，他走了。莉迪亚没有了依靠，她想要解脱，想要逃离，当她跃入水中，现实的世界正远离她的时候，她找到了真正的归宿。</p>\n<p>本书无声告白，乍一看还以为真的是告白。Everything I never told you是本书的原名。莉迪亚自始至终都没有告诉父母她真正想要的，一味地答应毁了她的一生。谁不是这样呢，人总是充满幻想，可以以后活成自己想要的模样，但现实是，绝大部分都成为了别人眼中的“相同”。遵循自己内心的想法真的很难，但或许当你想着，人死了，总要留下点什么的时候，你或许就会多一点在意自己的想法了吧。</p>\n<p>以上这些，或许就是我想对你说的，但机会已经过去了，重新提起未免有些突兀，当然，我也不是很想分享给你，因为你不会去理会，或许我这辈子，只能和自己去分享读过的书了吧。对你，我真的不知道该怎么办，真的。</p>\n<p>和莉迪亚一样，他们没有真正的朋友。</p>"},{"title":"痛苦的MARL(一)","date":"2019-07-04T12:00:02.000Z","thumbnail":"https://images.unsplash.com/photo-1434030216411-0b793f4b4173?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n# 多智能体强化学习(一) 基础知识与博弈\n<!--more-->\n## 1. 引言\n1. 多智能体通过和环境进行交互获取奖励值来学习改善自己的策略，其重点区别于单 agent 强化学习。\n2. 算法收敛性与每个 agent 的最优策略相关，其最优策略又与空间中其他的 agent 相关联。\n3. 联结动作:每个智能体当前动作组合而成的多智能体系统当前时刻的动作\n$$\n     A_t = [a_{1 ,t},a_{2 ,t},...,a_{n ,t}]^T \n$$\n其中$a_{i,t}$表示第 i 个智能体在时刻 t选取的动作\n## 2. 博弈论\n由于多 agent 之间涉及到合作和竞争关系，引入博弈的概念。\n### 1. 矩阵博弈\n$$\n    (n,A_1,A_2,...,A_n,R_1,R_2,...,R_n)\n$$\n其中 n 为 agent 数量，$A_i$为第 i 个 agent 的 action 集合，$R_i$为奖励函数，其值与空间中所有的 agent 的 action 集都有关系\n    Target: 寻找纯策略或者混合策略 st 其收益虽大\n#### 1. 纳什均衡\n给定其他玩家继续采用纳什均衡策略而该玩家无法通过改变其自身策略获得更大回报的所有玩家策略的集合，即\n$$\n    V_i(\\pi_1^*,...,\\pi_i^*,...,\\pi_n^*) \\geq V_i(\\pi_1^*,...,\\pi_i,...,\\pi_n^*)\n$$\n其中 $V_i(.)$ 表示玩家 i 在给定玩家策略下的期望回报，其含义为$\\sum$用户 i 在联合动作下所获得回报乘以每个用户采用纳什均衡策略下选择该动作的概率，\n$\\pi_i$表示玩家 i 在策略空间$\\prod_i$中选择的任一策略(可以理解为概率)\n#### 2. 严格纳什均衡\n大于等于公式严格成立\n#### 3. 完全混合策略\nDefinition: The strategy that agent choose specific action based on possibity of all actions.\nPossibities of all actions ara more than 0 percentage.\n在猜硬币博弈中，只要用户 50%的概率选择正面，50%的概率选择反面，才能获得最大收益。如果按照纯策略一直选择正面，则对方会知道并选择让自己一直收益的情况（一直正面或反面），无法达到最大收益\n#### 4. 纯策略\n在囚徒困境博弈中，agent 在任何情况下都选择同样的行为，也就是向警官坦白，这时候无论对方怎么选择，自己都是 reward 和都是最大的。\n### 2. agent在矩阵博弈中的纳什均衡\n其奖励矩阵为\n$$\n    \\begin{bmatrix}\n    r_{11}&r_{12} \\\\ \n    r_{21}&r_{22} \n    \\end{bmatrix}\n$$\n其中行表示行 agent，列表式列 agent，其下角标表示行列 agent 所采取的动作联结。\n#### 5. 零和博弈\n每玩一局游戏，都有一个玩家会赢而另一个玩家会输。两个玩家为完全竞争关系，\n#### 6. 一般和博弈\n任何类型的矩阵博弈\n### 3. 多智能体强化学习策略\n引入他妈的随机博弈：多智能体多个状态，是马尔科夫决策过程和矩阵博弈的过程。\n\n","source":"_posts/痛苦的MARL-一.md","raw":"---\ntitle: 痛苦的MARL(一)\ndate: 2019-07-04 20:00:02\ntags: [RL, Python]\ncategories: [MARL]\nthumbnail: https://images.unsplash.com/photo-1434030216411-0b793f4b4173?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n# 多智能体强化学习(一) 基础知识与博弈\n<!--more-->\n## 1. 引言\n1. 多智能体通过和环境进行交互获取奖励值来学习改善自己的策略，其重点区别于单 agent 强化学习。\n2. 算法收敛性与每个 agent 的最优策略相关，其最优策略又与空间中其他的 agent 相关联。\n3. 联结动作:每个智能体当前动作组合而成的多智能体系统当前时刻的动作\n$$\n     A_t = [a_{1 ,t},a_{2 ,t},...,a_{n ,t}]^T \n$$\n其中$a_{i,t}$表示第 i 个智能体在时刻 t选取的动作\n## 2. 博弈论\n由于多 agent 之间涉及到合作和竞争关系，引入博弈的概念。\n### 1. 矩阵博弈\n$$\n    (n,A_1,A_2,...,A_n,R_1,R_2,...,R_n)\n$$\n其中 n 为 agent 数量，$A_i$为第 i 个 agent 的 action 集合，$R_i$为奖励函数，其值与空间中所有的 agent 的 action 集都有关系\n    Target: 寻找纯策略或者混合策略 st 其收益虽大\n#### 1. 纳什均衡\n给定其他玩家继续采用纳什均衡策略而该玩家无法通过改变其自身策略获得更大回报的所有玩家策略的集合，即\n$$\n    V_i(\\pi_1^*,...,\\pi_i^*,...,\\pi_n^*) \\geq V_i(\\pi_1^*,...,\\pi_i,...,\\pi_n^*)\n$$\n其中 $V_i(.)$ 表示玩家 i 在给定玩家策略下的期望回报，其含义为$\\sum$用户 i 在联合动作下所获得回报乘以每个用户采用纳什均衡策略下选择该动作的概率，\n$\\pi_i$表示玩家 i 在策略空间$\\prod_i$中选择的任一策略(可以理解为概率)\n#### 2. 严格纳什均衡\n大于等于公式严格成立\n#### 3. 完全混合策略\nDefinition: The strategy that agent choose specific action based on possibity of all actions.\nPossibities of all actions ara more than 0 percentage.\n在猜硬币博弈中，只要用户 50%的概率选择正面，50%的概率选择反面，才能获得最大收益。如果按照纯策略一直选择正面，则对方会知道并选择让自己一直收益的情况（一直正面或反面），无法达到最大收益\n#### 4. 纯策略\n在囚徒困境博弈中，agent 在任何情况下都选择同样的行为，也就是向警官坦白，这时候无论对方怎么选择，自己都是 reward 和都是最大的。\n### 2. agent在矩阵博弈中的纳什均衡\n其奖励矩阵为\n$$\n    \\begin{bmatrix}\n    r_{11}&r_{12} \\\\ \n    r_{21}&r_{22} \n    \\end{bmatrix}\n$$\n其中行表示行 agent，列表式列 agent，其下角标表示行列 agent 所采取的动作联结。\n#### 5. 零和博弈\n每玩一局游戏，都有一个玩家会赢而另一个玩家会输。两个玩家为完全竞争关系，\n#### 6. 一般和博弈\n任何类型的矩阵博弈\n### 3. 多智能体强化学习策略\n引入他妈的随机博弈：多智能体多个状态，是马尔科夫决策过程和矩阵博弈的过程。\n\n","slug":"痛苦的MARL-一","published":1,"updated":"2019-11-16T12:11:54.838Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkqs002gk3x6brzb4k98","content":"<h1 id=\"多智能体强化学习-一-基础知识与博弈\"><a href=\"#多智能体强化学习-一-基础知识与博弈\" class=\"headerlink\" title=\"多智能体强化学习(一) 基础知识与博弈\"></a>多智能体强化学习(一) 基础知识与博弈</h1><a id=\"more\"></a>\n<h2 id=\"1-引言\"><a href=\"#1-引言\" class=\"headerlink\" title=\"1. 引言\"></a>1. 引言</h2><ol>\n<li>多智能体通过和环境进行交互获取奖励值来学习改善自己的策略，其重点区别于单 agent 强化学习。</li>\n<li>算法收敛性与每个 agent 的最优策略相关，其最优策略又与空间中其他的 agent 相关联。</li>\n<li>联结动作:每个智能体当前动作组合而成的多智能体系统当前时刻的动作<br>$$<br>  A_t = [a_{1 ,t},a_{2 ,t},…,a_{n ,t}]^T<br>$$<br>其中$a_{i,t}$表示第 i 个智能体在时刻 t选取的动作<h2 id=\"2-博弈论\"><a href=\"#2-博弈论\" class=\"headerlink\" title=\"2. 博弈论\"></a>2. 博弈论</h2>由于多 agent 之间涉及到合作和竞争关系，引入博弈的概念。<h3 id=\"1-矩阵博弈\"><a href=\"#1-矩阵博弈\" class=\"headerlink\" title=\"1. 矩阵博弈\"></a>1. 矩阵博弈</h3>$$<br> (n,A_1,A_2,…,A_n,R_1,R_2,…,R_n)<br>$$<br>其中 n 为 agent 数量，$A_i$为第 i 个 agent 的 action 集合，$R_i$为奖励函数，其值与空间中所有的 agent 的 action 集都有关系<br> Target: 寻找纯策略或者混合策略 st 其收益虽大<h4 id=\"1-纳什均衡\"><a href=\"#1-纳什均衡\" class=\"headerlink\" title=\"1. 纳什均衡\"></a>1. 纳什均衡</h4>给定其他玩家继续采用纳什均衡策略而该玩家无法通过改变其自身策略获得更大回报的所有玩家策略的集合，即<br>$$<br> V_i(\\pi_1^<em>,…,\\pi_i^</em>,…,\\pi_n^<em>) \\geq V_i(\\pi_1^</em>,…,\\pi_i,…,\\pi_n^*)<br>$$<br>其中 $V_i(.)$ 表示玩家 i 在给定玩家策略下的期望回报，其含义为$\\sum$用户 i 在联合动作下所获得回报乘以每个用户采用纳什均衡策略下选择该动作的概率，<br>$\\pi_i$表示玩家 i 在策略空间$\\prod_i$中选择的任一策略(可以理解为概率)<h4 id=\"2-严格纳什均衡\"><a href=\"#2-严格纳什均衡\" class=\"headerlink\" title=\"2. 严格纳什均衡\"></a>2. 严格纳什均衡</h4>大于等于公式严格成立<h4 id=\"3-完全混合策略\"><a href=\"#3-完全混合策略\" class=\"headerlink\" title=\"3. 完全混合策略\"></a>3. 完全混合策略</h4>Definition: The strategy that agent choose specific action based on possibity of all actions.<br>Possibities of all actions ara more than 0 percentage.<br>在猜硬币博弈中，只要用户 50%的概率选择正面，50%的概率选择反面，才能获得最大收益。如果按照纯策略一直选择正面，则对方会知道并选择让自己一直收益的情况（一直正面或反面），无法达到最大收益<h4 id=\"4-纯策略\"><a href=\"#4-纯策略\" class=\"headerlink\" title=\"4. 纯策略\"></a>4. 纯策略</h4>在囚徒困境博弈中，agent 在任何情况下都选择同样的行为，也就是向警官坦白，这时候无论对方怎么选择，自己都是 reward 和都是最大的。<h3 id=\"2-agent在矩阵博弈中的纳什均衡\"><a href=\"#2-agent在矩阵博弈中的纳什均衡\" class=\"headerlink\" title=\"2. agent在矩阵博弈中的纳什均衡\"></a>2. agent在矩阵博弈中的纳什均衡</h3>其奖励矩阵为<br>$$<br> \\begin{bmatrix}<br> r_{11}&amp;r_{12} \\<br> r_{21}&amp;r_{22}<br> \\end{bmatrix}<br>$$<br>其中行表示行 agent，列表式列 agent，其下角标表示行列 agent 所采取的动作联结。<h4 id=\"5-零和博弈\"><a href=\"#5-零和博弈\" class=\"headerlink\" title=\"5. 零和博弈\"></a>5. 零和博弈</h4>每玩一局游戏，都有一个玩家会赢而另一个玩家会输。两个玩家为完全竞争关系，<h4 id=\"6-一般和博弈\"><a href=\"#6-一般和博弈\" class=\"headerlink\" title=\"6. 一般和博弈\"></a>6. 一般和博弈</h4>任何类型的矩阵博弈<h3 id=\"3-多智能体强化学习策略\"><a href=\"#3-多智能体强化学习策略\" class=\"headerlink\" title=\"3. 多智能体强化学习策略\"></a>3. 多智能体强化学习策略</h3>引入他妈的随机博弈：多智能体多个状态，是马尔科夫决策过程和矩阵博弈的过程。</li>\n</ol>\n","site":{"data":{}},"excerpt":"<h1 id=\"多智能体强化学习-一-基础知识与博弈\"><a href=\"#多智能体强化学习-一-基础知识与博弈\" class=\"headerlink\" title=\"多智能体强化学习(一) 基础知识与博弈\"></a>多智能体强化学习(一) 基础知识与博弈</h1>","more":"<h2 id=\"1-引言\"><a href=\"#1-引言\" class=\"headerlink\" title=\"1. 引言\"></a>1. 引言</h2><ol>\n<li>多智能体通过和环境进行交互获取奖励值来学习改善自己的策略，其重点区别于单 agent 强化学习。</li>\n<li>算法收敛性与每个 agent 的最优策略相关，其最优策略又与空间中其他的 agent 相关联。</li>\n<li>联结动作:每个智能体当前动作组合而成的多智能体系统当前时刻的动作<br>$$<br>  A_t = [a_{1 ,t},a_{2 ,t},…,a_{n ,t}]^T<br>$$<br>其中$a_{i,t}$表示第 i 个智能体在时刻 t选取的动作<h2 id=\"2-博弈论\"><a href=\"#2-博弈论\" class=\"headerlink\" title=\"2. 博弈论\"></a>2. 博弈论</h2>由于多 agent 之间涉及到合作和竞争关系，引入博弈的概念。<h3 id=\"1-矩阵博弈\"><a href=\"#1-矩阵博弈\" class=\"headerlink\" title=\"1. 矩阵博弈\"></a>1. 矩阵博弈</h3>$$<br> (n,A_1,A_2,…,A_n,R_1,R_2,…,R_n)<br>$$<br>其中 n 为 agent 数量，$A_i$为第 i 个 agent 的 action 集合，$R_i$为奖励函数，其值与空间中所有的 agent 的 action 集都有关系<br> Target: 寻找纯策略或者混合策略 st 其收益虽大<h4 id=\"1-纳什均衡\"><a href=\"#1-纳什均衡\" class=\"headerlink\" title=\"1. 纳什均衡\"></a>1. 纳什均衡</h4>给定其他玩家继续采用纳什均衡策略而该玩家无法通过改变其自身策略获得更大回报的所有玩家策略的集合，即<br>$$<br> V_i(\\pi_1^<em>,…,\\pi_i^</em>,…,\\pi_n^<em>) \\geq V_i(\\pi_1^</em>,…,\\pi_i,…,\\pi_n^*)<br>$$<br>其中 $V_i(.)$ 表示玩家 i 在给定玩家策略下的期望回报，其含义为$\\sum$用户 i 在联合动作下所获得回报乘以每个用户采用纳什均衡策略下选择该动作的概率，<br>$\\pi_i$表示玩家 i 在策略空间$\\prod_i$中选择的任一策略(可以理解为概率)<h4 id=\"2-严格纳什均衡\"><a href=\"#2-严格纳什均衡\" class=\"headerlink\" title=\"2. 严格纳什均衡\"></a>2. 严格纳什均衡</h4>大于等于公式严格成立<h4 id=\"3-完全混合策略\"><a href=\"#3-完全混合策略\" class=\"headerlink\" title=\"3. 完全混合策略\"></a>3. 完全混合策略</h4>Definition: The strategy that agent choose specific action based on possibity of all actions.<br>Possibities of all actions ara more than 0 percentage.<br>在猜硬币博弈中，只要用户 50%的概率选择正面，50%的概率选择反面，才能获得最大收益。如果按照纯策略一直选择正面，则对方会知道并选择让自己一直收益的情况（一直正面或反面），无法达到最大收益<h4 id=\"4-纯策略\"><a href=\"#4-纯策略\" class=\"headerlink\" title=\"4. 纯策略\"></a>4. 纯策略</h4>在囚徒困境博弈中，agent 在任何情况下都选择同样的行为，也就是向警官坦白，这时候无论对方怎么选择，自己都是 reward 和都是最大的。<h3 id=\"2-agent在矩阵博弈中的纳什均衡\"><a href=\"#2-agent在矩阵博弈中的纳什均衡\" class=\"headerlink\" title=\"2. agent在矩阵博弈中的纳什均衡\"></a>2. agent在矩阵博弈中的纳什均衡</h3>其奖励矩阵为<br>$$<br> \\begin{bmatrix}<br> r_{11}&amp;r_{12} \\<br> r_{21}&amp;r_{22}<br> \\end{bmatrix}<br>$$<br>其中行表示行 agent，列表式列 agent，其下角标表示行列 agent 所采取的动作联结。<h4 id=\"5-零和博弈\"><a href=\"#5-零和博弈\" class=\"headerlink\" title=\"5. 零和博弈\"></a>5. 零和博弈</h4>每玩一局游戏，都有一个玩家会赢而另一个玩家会输。两个玩家为完全竞争关系，<h4 id=\"6-一般和博弈\"><a href=\"#6-一般和博弈\" class=\"headerlink\" title=\"6. 一般和博弈\"></a>6. 一般和博弈</h4>任何类型的矩阵博弈<h3 id=\"3-多智能体强化学习策略\"><a href=\"#3-多智能体强化学习策略\" class=\"headerlink\" title=\"3. 多智能体强化学习策略\"></a>3. 多智能体强化学习策略</h3>引入他妈的随机博弈：多智能体多个状态，是马尔科夫决策过程和矩阵博弈的过程。</li>\n</ol>"},{"title":"痛苦的MARL(三)","date":"2019-07-04T13:09:52.000Z","thumbnail":"https://images.unsplash.com/photo-1434030216411-0b793f4b4173?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"# 多智能体强化学习入门（三）——MFMARL算法（Mean Field Multi-Agent RL）\n<!--more-->\n**Idea**:将传统的多智能体算法（每个智能体都需考虑其他所有智能体的动作以及状态得到联合动作值函数）替换成一种近似假设（其他所有智能体对其产生的作用可以用一个均值替代）--MFT 平均场理论\nBased on MFT, there are two basic algoritms: MFQ & MFAC. （分别是对 Q learning 和 AC 算法的改进）\n## 1. Mean Field MARL\n**Idea**: 将 Q 函数中的参数调整为只包含邻居之间相互作用的形式：\n$$\n    Q_j(s,a)=\\frac{1}{N_j}\\sum _{k\\epsilon N_{(j)}}Q_j(s,a_j,a_k)\n$$\n其中$N_j$表示邻居节点个数，状态信息 s 为全局信息。\n\n### 1. Mean Field 近似\n\n\n\n\n### 2. 算法设计\nMF-Q + MF-AC Algorithm\n\n#### 1. MF-Q\n\n\n\n\n#### 2. MFAC\n","source":"_posts/痛苦的MARL-三.md","raw":"---\ntitle: 痛苦的MARL(三)\ndate: 2019-07-04 21:09:52\ntags: [RL, Python]\ncategories: [MARL]\nthumbnail: https://images.unsplash.com/photo-1434030216411-0b793f4b4173?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n# 多智能体强化学习入门（三）——MFMARL算法（Mean Field Multi-Agent RL）\n<!--more-->\n**Idea**:将传统的多智能体算法（每个智能体都需考虑其他所有智能体的动作以及状态得到联合动作值函数）替换成一种近似假设（其他所有智能体对其产生的作用可以用一个均值替代）--MFT 平均场理论\nBased on MFT, there are two basic algoritms: MFQ & MFAC. （分别是对 Q learning 和 AC 算法的改进）\n## 1. Mean Field MARL\n**Idea**: 将 Q 函数中的参数调整为只包含邻居之间相互作用的形式：\n$$\n    Q_j(s,a)=\\frac{1}{N_j}\\sum _{k\\epsilon N_{(j)}}Q_j(s,a_j,a_k)\n$$\n其中$N_j$表示邻居节点个数，状态信息 s 为全局信息。\n\n### 1. Mean Field 近似\n\n\n\n\n### 2. 算法设计\nMF-Q + MF-AC Algorithm\n\n#### 1. MF-Q\n\n\n\n\n#### 2. MFAC\n","slug":"痛苦的MARL-三","published":1,"updated":"2019-11-16T12:11:45.819Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkqt002jk3x695uv7qke","content":"<h1 id=\"多智能体强化学习入门（三）——MFMARL算法（Mean-Field-Multi-Agent-RL）\"><a href=\"#多智能体强化学习入门（三）——MFMARL算法（Mean-Field-Multi-Agent-RL）\" class=\"headerlink\" title=\"多智能体强化学习入门（三）——MFMARL算法（Mean Field Multi-Agent RL）\"></a>多智能体强化学习入门（三）——MFMARL算法（Mean Field Multi-Agent RL）</h1><a id=\"more\"></a>\n<p><strong>Idea</strong>:将传统的多智能体算法（每个智能体都需考虑其他所有智能体的动作以及状态得到联合动作值函数）替换成一种近似假设（其他所有智能体对其产生的作用可以用一个均值替代）–MFT 平均场理论<br>Based on MFT, there are two basic algoritms: MFQ &amp; MFAC. （分别是对 Q learning 和 AC 算法的改进）</p>\n<h2 id=\"1-Mean-Field-MARL\"><a href=\"#1-Mean-Field-MARL\" class=\"headerlink\" title=\"1. Mean Field MARL\"></a>1. Mean Field MARL</h2><p><strong>Idea</strong>: 将 Q 函数中的参数调整为只包含邻居之间相互作用的形式：<br>$$<br>    Q_j(s,a)=\\frac{1}{N_j}\\sum <em>{k\\epsilon N</em>{(j)}}Q_j(s,a_j,a_k)<br>$$<br>其中$N_j$表示邻居节点个数，状态信息 s 为全局信息。</p>\n<h3 id=\"1-Mean-Field-近似\"><a href=\"#1-Mean-Field-近似\" class=\"headerlink\" title=\"1. Mean Field 近似\"></a>1. Mean Field 近似</h3><h3 id=\"2-算法设计\"><a href=\"#2-算法设计\" class=\"headerlink\" title=\"2. 算法设计\"></a>2. 算法设计</h3><p>MF-Q + MF-AC Algorithm</p>\n<h4 id=\"1-MF-Q\"><a href=\"#1-MF-Q\" class=\"headerlink\" title=\"1. MF-Q\"></a>1. MF-Q</h4><h4 id=\"2-MFAC\"><a href=\"#2-MFAC\" class=\"headerlink\" title=\"2. MFAC\"></a>2. MFAC</h4>","site":{"data":{}},"excerpt":"<h1 id=\"多智能体强化学习入门（三）——MFMARL算法（Mean-Field-Multi-Agent-RL）\"><a href=\"#多智能体强化学习入门（三）——MFMARL算法（Mean-Field-Multi-Agent-RL）\" class=\"headerlink\" title=\"多智能体强化学习入门（三）——MFMARL算法（Mean Field Multi-Agent RL）\"></a>多智能体强化学习入门（三）——MFMARL算法（Mean Field Multi-Agent RL）</h1>","more":"<p><strong>Idea</strong>:将传统的多智能体算法（每个智能体都需考虑其他所有智能体的动作以及状态得到联合动作值函数）替换成一种近似假设（其他所有智能体对其产生的作用可以用一个均值替代）–MFT 平均场理论<br>Based on MFT, there are two basic algoritms: MFQ &amp; MFAC. （分别是对 Q learning 和 AC 算法的改进）</p>\n<h2 id=\"1-Mean-Field-MARL\"><a href=\"#1-Mean-Field-MARL\" class=\"headerlink\" title=\"1. Mean Field MARL\"></a>1. Mean Field MARL</h2><p><strong>Idea</strong>: 将 Q 函数中的参数调整为只包含邻居之间相互作用的形式：<br>$$<br>    Q_j(s,a)=\\frac{1}{N_j}\\sum <em>{k\\epsilon N</em>{(j)}}Q_j(s,a_j,a_k)<br>$$<br>其中$N_j$表示邻居节点个数，状态信息 s 为全局信息。</p>\n<h3 id=\"1-Mean-Field-近似\"><a href=\"#1-Mean-Field-近似\" class=\"headerlink\" title=\"1. Mean Field 近似\"></a>1. Mean Field 近似</h3><h3 id=\"2-算法设计\"><a href=\"#2-算法设计\" class=\"headerlink\" title=\"2. 算法设计\"></a>2. 算法设计</h3><p>MF-Q + MF-AC Algorithm</p>\n<h4 id=\"1-MF-Q\"><a href=\"#1-MF-Q\" class=\"headerlink\" title=\"1. MF-Q\"></a>1. MF-Q</h4><h4 id=\"2-MFAC\"><a href=\"#2-MFAC\" class=\"headerlink\" title=\"2. MFAC\"></a>2. MFAC</h4>"},{"title":"痛苦的MARL(二)","date":"2019-07-04T12:26:52.000Z","thumbnail":"https://images.unsplash.com/photo-1434030216411-0b793f4b4173?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"# 多智能体强化学习(二) 基础算法（MiniMax-Q，NashQ，FFQ，WoLF-PHC）\n<!--more-->\n## 1. 引言\n再多智能体强化学习中，需要多 agent 在与环境交互过程中不断学习每个状态的奖励值 Q函数，再通过 Q函数来学习得到最优纳什策略。\n**合理性**（rationality）是指在对手使用一个恒定策略的情况下，当前智能体能够学习并收敛到一个相对于对手策略的最优策略。\n\n**收敛性**（convergence）是指在其他智能体也使用学习算法时，当前智能体能够学习并收敛到一个稳定的策略。通常情况下，收敛性针对系统中的所有的智能体使用相同的学习算法。\n\n## 2. Minimax-Q算法\n**Condition**: 两个玩家的零和随机博弈(eg.抛硬币)\n**Idea**: 利用 Qlearning 的方法更新Q值\n**Algorithm**:\n![avatar](https://pic2.zhimg.com/80/v2-e907b291d3ec2e6dd62c96a86b4fd171_hd.jpg)\n\n## 3. Nash Q-Learning算法\n**Condition**: 多个玩家的一般和博弈(完全对抗博弈、完全合作博弈以及二者的混合博弈)\n**Idea**: 使用二次规划求解纳什均衡点\n**Algorithm**:\n![avatar](https://pic4.zhimg.com/v2-5d50dc1f2ad874c22f10d5e796f64347_r.jpg)\n通过算法可以得知，在更新 Q 值时，取代了传统的期望奖励 V 函数，这里用了 Nash 函数进行了更新,需要观测其他所有智能体的动作 $a_i$ 与奖励值 $r_i$\n\n## 4. Friend-or-Foe Q-Learning算法\n**Condition**: 一个智能体i，将其他所有智能体分为两组，一组为i的friend帮助i一起最大化其奖励回报，另一组为i的foe对抗i并降低i的奖励回报，因此对每个智能体而言都有两组。这样一个n智能体的一般和博弈就转化为了一个两智能体的零和博弈\n**Idea**: 将剩余 agent 进行分组，在纳什均衡策略求解中，传统的所有 action 替换为了帮助自己的 action 和敌人的 action\nAlgorithm:\n![avatar](https://pic1.zhimg.com/80/v2-2f4cff250568ca25853f1bc8e23e3b54_hd.jpg)\n为了更新 Q 值，每个智能体需要在每一步观测其他所有friend与foe的执行动作。\n\n## 5. WoLF Policy Hill-Climbing算法\n**Condition**: 每个智能体只用保存自己的动作来完成学习任务,个人认为为了避免前面三个算法带来的维度灾难问题，因为每个 agent 都需要存储所有 agent 的动作集。\n**Idea**: \n**WolF**:当智能体做的比期望值好的时候小心缓慢的调整参数，当智能体做的比期望值差的时候，加快步伐调整参数。\n**PHC**:一种单智能体在稳定环境下的一种学习算法。该算法的核心就是通常强化学习的思想，增大能够得到最大累积期望的动作的选取概率。该算法具有合理性，能够收敛到最优策略。其算法流程如下\n**PHC Algorithm**:\n![avatar](https://pic4.zhimg.com/80/v2-8420ec197cb0516076725645a1359ab3_hd.jpg)\n**WOLF+PHC Algorithm**:\n通过PHC算法进行学习改进策略,收敛性没有得到证明。\n![avatar](https://pic2.zhimg.com/80/v2-a549b9cfd895898e7a4cc74d7432ce55_hd.jpg)\n","source":"_posts/痛苦的MARL-二.md","raw":"---\ntitle: 痛苦的MARL(二)\ndate: 2019-07-04 20:26:52\ntags: [RL, Python]\ncategories: [MARL]\nthumbnail: https://images.unsplash.com/photo-1434030216411-0b793f4b4173?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n# 多智能体强化学习(二) 基础算法（MiniMax-Q，NashQ，FFQ，WoLF-PHC）\n<!--more-->\n## 1. 引言\n再多智能体强化学习中，需要多 agent 在与环境交互过程中不断学习每个状态的奖励值 Q函数，再通过 Q函数来学习得到最优纳什策略。\n**合理性**（rationality）是指在对手使用一个恒定策略的情况下，当前智能体能够学习并收敛到一个相对于对手策略的最优策略。\n\n**收敛性**（convergence）是指在其他智能体也使用学习算法时，当前智能体能够学习并收敛到一个稳定的策略。通常情况下，收敛性针对系统中的所有的智能体使用相同的学习算法。\n\n## 2. Minimax-Q算法\n**Condition**: 两个玩家的零和随机博弈(eg.抛硬币)\n**Idea**: 利用 Qlearning 的方法更新Q值\n**Algorithm**:\n![avatar](https://pic2.zhimg.com/80/v2-e907b291d3ec2e6dd62c96a86b4fd171_hd.jpg)\n\n## 3. Nash Q-Learning算法\n**Condition**: 多个玩家的一般和博弈(完全对抗博弈、完全合作博弈以及二者的混合博弈)\n**Idea**: 使用二次规划求解纳什均衡点\n**Algorithm**:\n![avatar](https://pic4.zhimg.com/v2-5d50dc1f2ad874c22f10d5e796f64347_r.jpg)\n通过算法可以得知，在更新 Q 值时，取代了传统的期望奖励 V 函数，这里用了 Nash 函数进行了更新,需要观测其他所有智能体的动作 $a_i$ 与奖励值 $r_i$\n\n## 4. Friend-or-Foe Q-Learning算法\n**Condition**: 一个智能体i，将其他所有智能体分为两组，一组为i的friend帮助i一起最大化其奖励回报，另一组为i的foe对抗i并降低i的奖励回报，因此对每个智能体而言都有两组。这样一个n智能体的一般和博弈就转化为了一个两智能体的零和博弈\n**Idea**: 将剩余 agent 进行分组，在纳什均衡策略求解中，传统的所有 action 替换为了帮助自己的 action 和敌人的 action\nAlgorithm:\n![avatar](https://pic1.zhimg.com/80/v2-2f4cff250568ca25853f1bc8e23e3b54_hd.jpg)\n为了更新 Q 值，每个智能体需要在每一步观测其他所有friend与foe的执行动作。\n\n## 5. WoLF Policy Hill-Climbing算法\n**Condition**: 每个智能体只用保存自己的动作来完成学习任务,个人认为为了避免前面三个算法带来的维度灾难问题，因为每个 agent 都需要存储所有 agent 的动作集。\n**Idea**: \n**WolF**:当智能体做的比期望值好的时候小心缓慢的调整参数，当智能体做的比期望值差的时候，加快步伐调整参数。\n**PHC**:一种单智能体在稳定环境下的一种学习算法。该算法的核心就是通常强化学习的思想，增大能够得到最大累积期望的动作的选取概率。该算法具有合理性，能够收敛到最优策略。其算法流程如下\n**PHC Algorithm**:\n![avatar](https://pic4.zhimg.com/80/v2-8420ec197cb0516076725645a1359ab3_hd.jpg)\n**WOLF+PHC Algorithm**:\n通过PHC算法进行学习改进策略,收敛性没有得到证明。\n![avatar](https://pic2.zhimg.com/80/v2-a549b9cfd895898e7a4cc74d7432ce55_hd.jpg)\n","slug":"痛苦的MARL-二","published":1,"updated":"2019-11-16T12:11:48.867Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkqv002nk3x68r1118i9","content":"<h1 id=\"多智能体强化学习-二-基础算法（MiniMax-Q，NashQ，FFQ，WoLF-PHC）\"><a href=\"#多智能体强化学习-二-基础算法（MiniMax-Q，NashQ，FFQ，WoLF-PHC）\" class=\"headerlink\" title=\"多智能体强化学习(二) 基础算法（MiniMax-Q，NashQ，FFQ，WoLF-PHC）\"></a>多智能体强化学习(二) 基础算法（MiniMax-Q，NashQ，FFQ，WoLF-PHC）</h1><a id=\"more\"></a>\n<h2 id=\"1-引言\"><a href=\"#1-引言\" class=\"headerlink\" title=\"1. 引言\"></a>1. 引言</h2><p>再多智能体强化学习中，需要多 agent 在与环境交互过程中不断学习每个状态的奖励值 Q函数，再通过 Q函数来学习得到最优纳什策略。<br><strong>合理性</strong>（rationality）是指在对手使用一个恒定策略的情况下，当前智能体能够学习并收敛到一个相对于对手策略的最优策略。</p>\n<p><strong>收敛性</strong>（convergence）是指在其他智能体也使用学习算法时，当前智能体能够学习并收敛到一个稳定的策略。通常情况下，收敛性针对系统中的所有的智能体使用相同的学习算法。</p>\n<h2 id=\"2-Minimax-Q算法\"><a href=\"#2-Minimax-Q算法\" class=\"headerlink\" title=\"2. Minimax-Q算法\"></a>2. Minimax-Q算法</h2><p><strong>Condition</strong>: 两个玩家的零和随机博弈(eg.抛硬币)<br><strong>Idea</strong>: 利用 Qlearning 的方法更新Q值<br><strong>Algorithm</strong>:<br><img src=\"https://pic2.zhimg.com/80/v2-e907b291d3ec2e6dd62c96a86b4fd171_hd.jpg\" alt=\"avatar\"></p>\n<h2 id=\"3-Nash-Q-Learning算法\"><a href=\"#3-Nash-Q-Learning算法\" class=\"headerlink\" title=\"3. Nash Q-Learning算法\"></a>3. Nash Q-Learning算法</h2><p><strong>Condition</strong>: 多个玩家的一般和博弈(完全对抗博弈、完全合作博弈以及二者的混合博弈)<br><strong>Idea</strong>: 使用二次规划求解纳什均衡点<br><strong>Algorithm</strong>:<br><img src=\"https://pic4.zhimg.com/v2-5d50dc1f2ad874c22f10d5e796f64347_r.jpg\" alt=\"avatar\"><br>通过算法可以得知，在更新 Q 值时，取代了传统的期望奖励 V 函数，这里用了 Nash 函数进行了更新,需要观测其他所有智能体的动作 $a_i$ 与奖励值 $r_i$</p>\n<h2 id=\"4-Friend-or-Foe-Q-Learning算法\"><a href=\"#4-Friend-or-Foe-Q-Learning算法\" class=\"headerlink\" title=\"4. Friend-or-Foe Q-Learning算法\"></a>4. Friend-or-Foe Q-Learning算法</h2><p><strong>Condition</strong>: 一个智能体i，将其他所有智能体分为两组，一组为i的friend帮助i一起最大化其奖励回报，另一组为i的foe对抗i并降低i的奖励回报，因此对每个智能体而言都有两组。这样一个n智能体的一般和博弈就转化为了一个两智能体的零和博弈<br><strong>Idea</strong>: 将剩余 agent 进行分组，在纳什均衡策略求解中，传统的所有 action 替换为了帮助自己的 action 和敌人的 action<br>Algorithm:<br><img src=\"https://pic1.zhimg.com/80/v2-2f4cff250568ca25853f1bc8e23e3b54_hd.jpg\" alt=\"avatar\"><br>为了更新 Q 值，每个智能体需要在每一步观测其他所有friend与foe的执行动作。</p>\n<h2 id=\"5-WoLF-Policy-Hill-Climbing算法\"><a href=\"#5-WoLF-Policy-Hill-Climbing算法\" class=\"headerlink\" title=\"5. WoLF Policy Hill-Climbing算法\"></a>5. WoLF Policy Hill-Climbing算法</h2><p><strong>Condition</strong>: 每个智能体只用保存自己的动作来完成学习任务,个人认为为了避免前面三个算法带来的维度灾难问题，因为每个 agent 都需要存储所有 agent 的动作集。<br><strong>Idea</strong>:<br><strong>WolF</strong>:当智能体做的比期望值好的时候小心缓慢的调整参数，当智能体做的比期望值差的时候，加快步伐调整参数。<br><strong>PHC</strong>:一种单智能体在稳定环境下的一种学习算法。该算法的核心就是通常强化学习的思想，增大能够得到最大累积期望的动作的选取概率。该算法具有合理性，能够收敛到最优策略。其算法流程如下<br><strong>PHC Algorithm</strong>:<br><img src=\"https://pic4.zhimg.com/80/v2-8420ec197cb0516076725645a1359ab3_hd.jpg\" alt=\"avatar\"><br><strong>WOLF+PHC Algorithm</strong>:<br>通过PHC算法进行学习改进策略,收敛性没有得到证明。<br><img src=\"https://pic2.zhimg.com/80/v2-a549b9cfd895898e7a4cc74d7432ce55_hd.jpg\" alt=\"avatar\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"多智能体强化学习-二-基础算法（MiniMax-Q，NashQ，FFQ，WoLF-PHC）\"><a href=\"#多智能体强化学习-二-基础算法（MiniMax-Q，NashQ，FFQ，WoLF-PHC）\" class=\"headerlink\" title=\"多智能体强化学习(二) 基础算法（MiniMax-Q，NashQ，FFQ，WoLF-PHC）\"></a>多智能体强化学习(二) 基础算法（MiniMax-Q，NashQ，FFQ，WoLF-PHC）</h1>","more":"<h2 id=\"1-引言\"><a href=\"#1-引言\" class=\"headerlink\" title=\"1. 引言\"></a>1. 引言</h2><p>再多智能体强化学习中，需要多 agent 在与环境交互过程中不断学习每个状态的奖励值 Q函数，再通过 Q函数来学习得到最优纳什策略。<br><strong>合理性</strong>（rationality）是指在对手使用一个恒定策略的情况下，当前智能体能够学习并收敛到一个相对于对手策略的最优策略。</p>\n<p><strong>收敛性</strong>（convergence）是指在其他智能体也使用学习算法时，当前智能体能够学习并收敛到一个稳定的策略。通常情况下，收敛性针对系统中的所有的智能体使用相同的学习算法。</p>\n<h2 id=\"2-Minimax-Q算法\"><a href=\"#2-Minimax-Q算法\" class=\"headerlink\" title=\"2. Minimax-Q算法\"></a>2. Minimax-Q算法</h2><p><strong>Condition</strong>: 两个玩家的零和随机博弈(eg.抛硬币)<br><strong>Idea</strong>: 利用 Qlearning 的方法更新Q值<br><strong>Algorithm</strong>:<br><img src=\"https://pic2.zhimg.com/80/v2-e907b291d3ec2e6dd62c96a86b4fd171_hd.jpg\" alt=\"avatar\"></p>\n<h2 id=\"3-Nash-Q-Learning算法\"><a href=\"#3-Nash-Q-Learning算法\" class=\"headerlink\" title=\"3. Nash Q-Learning算法\"></a>3. Nash Q-Learning算法</h2><p><strong>Condition</strong>: 多个玩家的一般和博弈(完全对抗博弈、完全合作博弈以及二者的混合博弈)<br><strong>Idea</strong>: 使用二次规划求解纳什均衡点<br><strong>Algorithm</strong>:<br><img src=\"https://pic4.zhimg.com/v2-5d50dc1f2ad874c22f10d5e796f64347_r.jpg\" alt=\"avatar\"><br>通过算法可以得知，在更新 Q 值时，取代了传统的期望奖励 V 函数，这里用了 Nash 函数进行了更新,需要观测其他所有智能体的动作 $a_i$ 与奖励值 $r_i$</p>\n<h2 id=\"4-Friend-or-Foe-Q-Learning算法\"><a href=\"#4-Friend-or-Foe-Q-Learning算法\" class=\"headerlink\" title=\"4. Friend-or-Foe Q-Learning算法\"></a>4. Friend-or-Foe Q-Learning算法</h2><p><strong>Condition</strong>: 一个智能体i，将其他所有智能体分为两组，一组为i的friend帮助i一起最大化其奖励回报，另一组为i的foe对抗i并降低i的奖励回报，因此对每个智能体而言都有两组。这样一个n智能体的一般和博弈就转化为了一个两智能体的零和博弈<br><strong>Idea</strong>: 将剩余 agent 进行分组，在纳什均衡策略求解中，传统的所有 action 替换为了帮助自己的 action 和敌人的 action<br>Algorithm:<br><img src=\"https://pic1.zhimg.com/80/v2-2f4cff250568ca25853f1bc8e23e3b54_hd.jpg\" alt=\"avatar\"><br>为了更新 Q 值，每个智能体需要在每一步观测其他所有friend与foe的执行动作。</p>\n<h2 id=\"5-WoLF-Policy-Hill-Climbing算法\"><a href=\"#5-WoLF-Policy-Hill-Climbing算法\" class=\"headerlink\" title=\"5. WoLF Policy Hill-Climbing算法\"></a>5. WoLF Policy Hill-Climbing算法</h2><p><strong>Condition</strong>: 每个智能体只用保存自己的动作来完成学习任务,个人认为为了避免前面三个算法带来的维度灾难问题，因为每个 agent 都需要存储所有 agent 的动作集。<br><strong>Idea</strong>:<br><strong>WolF</strong>:当智能体做的比期望值好的时候小心缓慢的调整参数，当智能体做的比期望值差的时候，加快步伐调整参数。<br><strong>PHC</strong>:一种单智能体在稳定环境下的一种学习算法。该算法的核心就是通常强化学习的思想，增大能够得到最大累积期望的动作的选取概率。该算法具有合理性，能够收敛到最优策略。其算法流程如下<br><strong>PHC Algorithm</strong>:<br><img src=\"https://pic4.zhimg.com/80/v2-8420ec197cb0516076725645a1359ab3_hd.jpg\" alt=\"avatar\"><br><strong>WOLF+PHC Algorithm</strong>:<br>通过PHC算法进行学习改进策略,收敛性没有得到证明。<br><img src=\"https://pic2.zhimg.com/80/v2-a549b9cfd895898e7a4cc74d7432ce55_hd.jpg\" alt=\"avatar\"></p>"},{"title":"追风筝的人","originContent":"","toc":false,"date":"2019-08-11T02:32:11.000Z","thumbnail":"https://images.unsplash.com/photo-1520111453936-54e59fb3bbd4?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60","_content":"\n寒假书单3\n生活在一个等级分明的地方，究竟是什么滋味\n<!--more-->\n故事的发展很像是一个人的救赎，甚至书中的某些片段都与电影《穿条纹睡衣的男孩》极为相似-宗教和种族对于一群人一生的影响。坦诚来讲，我对于伊斯兰文化了解的少之又少，这本书对于我来说也算是科普性质的书籍了。如果你对于伊斯兰教感兴趣的话，不妨去阅读一番，全书时长近7个小时，耐着性子读下去吧。\n\n“也许每个人心中都有一个风筝，无论它意味着什么，让我们勇敢的追”——翻译 李继宏","source":"_posts/追风筝的人.md","raw":"---\ntitle: 追风筝的人\ntags: []\noriginContent: ''\ncategories:\n  - 旧的文\ntoc: false\ndate: 2019-08-11 10:32:11\nthumbnail: https://images.unsplash.com/photo-1520111453936-54e59fb3bbd4?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60\n---\n\n寒假书单3\n生活在一个等级分明的地方，究竟是什么滋味\n<!--more-->\n故事的发展很像是一个人的救赎，甚至书中的某些片段都与电影《穿条纹睡衣的男孩》极为相似-宗教和种族对于一群人一生的影响。坦诚来讲，我对于伊斯兰文化了解的少之又少，这本书对于我来说也算是科普性质的书籍了。如果你对于伊斯兰教感兴趣的话，不妨去阅读一番，全书时长近7个小时，耐着性子读下去吧。\n\n“也许每个人心中都有一个风筝，无论它意味着什么，让我们勇敢的追”——翻译 李继宏","slug":"追风筝的人","published":1,"updated":"2019-11-15T12:50:24.232Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3h9fkqz002qk3x62g583kur","content":"<p>寒假书单3<br>生活在一个等级分明的地方，究竟是什么滋味</p>\n<a id=\"more\"></a>\n<p>故事的发展很像是一个人的救赎，甚至书中的某些片段都与电影《穿条纹睡衣的男孩》极为相似-宗教和种族对于一群人一生的影响。坦诚来讲，我对于伊斯兰文化了解的少之又少，这本书对于我来说也算是科普性质的书籍了。如果你对于伊斯兰教感兴趣的话，不妨去阅读一番，全书时长近7个小时，耐着性子读下去吧。</p>\n<p>“也许每个人心中都有一个风筝，无论它意味着什么，让我们勇敢的追”——翻译 李继宏</p>\n","site":{"data":{}},"excerpt":"<p>寒假书单3<br>生活在一个等级分明的地方，究竟是什么滋味</p>","more":"<p>故事的发展很像是一个人的救赎，甚至书中的某些片段都与电影《穿条纹睡衣的男孩》极为相似-宗教和种族对于一群人一生的影响。坦诚来讲，我对于伊斯兰文化了解的少之又少，这本书对于我来说也算是科普性质的书籍了。如果你对于伊斯兰教感兴趣的话，不妨去阅读一番，全书时长近7个小时，耐着性子读下去吧。</p>\n<p>“也许每个人心中都有一个风筝，无论它意味着什么，让我们勇敢的追”——翻译 李继宏</p>"}],"PostAsset":[],"PostCategory":[{"post_id":"ck3h9fkoq0008k3x6380e7cmw","category_id":"ck3h9fkoi0004k3x6ev2y7w9i","_id":"ck3h9fkp2000gk3x67deqfptr"},{"post_id":"ck3h9fkoa0001k3x6afec9xy3","category_id":"ck3h9fkoi0004k3x6ev2y7w9i","_id":"ck3h9fkp6000kk3x69mxq1rin"},{"post_id":"ck3h9fkof0003k3x6cdge1dot","category_id":"ck3h9fkoi0004k3x6ev2y7w9i","_id":"ck3h9fkp9000ok3x61vw76d2f"},{"post_id":"ck3h9fkom0006k3x6dxk7gvwr","category_id":"ck3h9fkp2000hk3x6am4r4lst","_id":"ck3h9fkpm000wk3x61crnfrvm"},{"post_id":"ck3h9fkos000ak3x66ymxesnp","category_id":"ck3h9fkp2000hk3x6am4r4lst","_id":"ck3h9fkpr0013k3x67vc2dkut"},{"post_id":"ck3h9fkoy000dk3x627zrb3yj","category_id":"ck3h9fkp2000hk3x6am4r4lst","_id":"ck3h9fkpv0019k3x6ejmreva9"},{"post_id":"ck3h9fkpp0010k3x6cmm76s10","category_id":"ck3h9fkp2000hk3x6am4r4lst","_id":"ck3h9fkq3001ck3x654boailr"},{"post_id":"ck3h9fkp1000fk3x615f93njx","category_id":"ck3h9fkpq0012k3x68b19bdbi","_id":"ck3h9fkq5001gk3x6chizahjb"},{"post_id":"ck3h9fkpu0016k3x64yt5fm89","category_id":"ck3h9fkp2000hk3x6am4r4lst","_id":"ck3h9fkq7001jk3x6c2e1diq5"},{"post_id":"ck3h9fkq2001bk3x62iiycm5u","category_id":"ck3h9fkoi0004k3x6ev2y7w9i","_id":"ck3h9fkqa001ok3x6gp9afkyx"},{"post_id":"ck3h9fkp6000jk3x67ri6cao0","category_id":"ck3h9fkpq0012k3x68b19bdbi","_id":"ck3h9fkqb001qk3x677c30hq1"},{"post_id":"ck3h9fkq3001dk3x6582u6jnj","category_id":"ck3h9fkoi0004k3x6ev2y7w9i","_id":"ck3h9fkqe001uk3x6h09sbe0n"},{"post_id":"ck3h9fkq6001hk3x64iz2fpnt","category_id":"ck3h9fkp2000hk3x6am4r4lst","_id":"ck3h9fkqi001xk3x6762uh8yv"},{"post_id":"ck3h9fkp8000nk3x6aiekfdg6","category_id":"ck3h9fkpq0012k3x68b19bdbi","_id":"ck3h9fkql0021k3x69nrk7b01"},{"post_id":"ck3h9fkpe000rk3x6c8wjhr0y","category_id":"ck3h9fkpq0012k3x68b19bdbi","_id":"ck3h9fkqm0024k3x6781f9ue3"},{"post_id":"ck3h9fkqe001vk3x67h9l2h2y","category_id":"ck3h9fkoi0004k3x6ev2y7w9i","_id":"ck3h9fkqp0028k3x6h5lqgro7"},{"post_id":"ck3h9fkpg000tk3x64vqxcifk","category_id":"ck3h9fkpq0012k3x68b19bdbi","_id":"ck3h9fkqq002bk3x65d7c02x7"},{"post_id":"ck3h9fkql0022k3x64ttv3rml","category_id":"ck3h9fkoi0004k3x6ev2y7w9i","_id":"ck3h9fkqr002fk3x65iqub2g5"},{"post_id":"ck3h9fkqn0025k3x6dl04biwb","category_id":"ck3h9fkoi0004k3x6ev2y7w9i","_id":"ck3h9fkqt002ik3x61dnd9ema"},{"post_id":"ck3h9fkqp0029k3x62eox2lot","category_id":"ck3h9fkoi0004k3x6ev2y7w9i","_id":"ck3h9fkqu002kk3x6g9qcd2w6"},{"post_id":"ck3h9fkqq002ck3x6cxxt6xny","category_id":"ck3h9fkoi0004k3x6ev2y7w9i","_id":"ck3h9fkqz002pk3x6evtfe74y"},{"post_id":"ck3h9fkqz002qk3x62g583kur","category_id":"ck3h9fkoi0004k3x6ev2y7w9i","_id":"ck3h9fkr1002vk3x6136ufxkb"},{"post_id":"ck3h9fkqs002gk3x6brzb4k98","category_id":"ck3h9fkqu002lk3x6c90w8hdt","_id":"ck3h9fkr2002zk3x68b7hanua"},{"post_id":"ck3h9fkqt002jk3x695uv7qke","category_id":"ck3h9fkqu002lk3x6c90w8hdt","_id":"ck3h9fkr20031k3x61bwt10ld"},{"post_id":"ck3h9fkqv002nk3x68r1118i9","category_id":"ck3h9fkqu002lk3x6c90w8hdt","_id":"ck3h9fkr30034k3x64uc5g70h"}],"PostTag":[{"post_id":"ck3h9fkp1000fk3x615f93njx","tag_id":"ck3h9fkp7000lk3x65yne3tjz","_id":"ck3h9fkpt0015k3x6czb01rl1"},{"post_id":"ck3h9fkp1000fk3x615f93njx","tag_id":"ck3h9fkpj000uk3x6evq9brta","_id":"ck3h9fkpu0017k3x6f885cwv8"},{"post_id":"ck3h9fkp6000jk3x67ri6cao0","tag_id":"ck3h9fkp7000lk3x65yne3tjz","_id":"ck3h9fkq6001ik3x63h7uawmd"},{"post_id":"ck3h9fkp6000jk3x67ri6cao0","tag_id":"ck3h9fkpj000uk3x6evq9brta","_id":"ck3h9fkq8001lk3x627pl41w5"},{"post_id":"ck3h9fkp8000nk3x6aiekfdg6","tag_id":"ck3h9fkp7000lk3x65yne3tjz","_id":"ck3h9fkqi001wk3x64bg3db96"},{"post_id":"ck3h9fkp8000nk3x6aiekfdg6","tag_id":"ck3h9fkpj000uk3x6evq9brta","_id":"ck3h9fkqk001zk3x67lri9jjf"},{"post_id":"ck3h9fkpe000rk3x6c8wjhr0y","tag_id":"ck3h9fkp7000lk3x65yne3tjz","_id":"ck3h9fkqm0023k3x63gn55ivc"},{"post_id":"ck3h9fkpe000rk3x6c8wjhr0y","tag_id":"ck3h9fkpj000uk3x6evq9brta","_id":"ck3h9fkqn0026k3x68z8kdbu1"},{"post_id":"ck3h9fkpg000tk3x64vqxcifk","tag_id":"ck3h9fkp7000lk3x65yne3tjz","_id":"ck3h9fkqq002ak3x6asiu9n7r"},{"post_id":"ck3h9fkpg000tk3x64vqxcifk","tag_id":"ck3h9fkpj000uk3x6evq9brta","_id":"ck3h9fkqr002dk3x67rpz4o71"},{"post_id":"ck3h9fkpr0014k3x6geouat0i","tag_id":"ck3h9fkqo0027k3x67bk7evyi","_id":"ck3h9fkqt002hk3x64ntiac8g"},{"post_id":"ck3h9fkq7001kk3x61pge47tx","tag_id":"ck3h9fkqo0027k3x67bk7evyi","_id":"ck3h9fkqy002ok3x6eoem8y47"},{"post_id":"ck3h9fkqs002gk3x6brzb4k98","tag_id":"ck3h9fkqu002mk3x6g6xj92q5","_id":"ck3h9fkr1002tk3x65a0g58va"},{"post_id":"ck3h9fkqs002gk3x6brzb4k98","tag_id":"ck3h9fkpj000uk3x6evq9brta","_id":"ck3h9fkr1002uk3x6gk4v0jw2"},{"post_id":"ck3h9fkqt002jk3x695uv7qke","tag_id":"ck3h9fkqu002mk3x6g6xj92q5","_id":"ck3h9fkr2002yk3x68aq9fpe9"},{"post_id":"ck3h9fkqt002jk3x695uv7qke","tag_id":"ck3h9fkpj000uk3x6evq9brta","_id":"ck3h9fkr20030k3x6dsou1rap"},{"post_id":"ck3h9fkqv002nk3x68r1118i9","tag_id":"ck3h9fkqu002mk3x6g6xj92q5","_id":"ck3h9fkr30032k3x6hwho741m"},{"post_id":"ck3h9fkqv002nk3x68r1118i9","tag_id":"ck3h9fkpj000uk3x6evq9brta","_id":"ck3h9fkr30033k3x64nli6w55"}],"Tag":[{"name":"NLP","_id":"ck3h9fkp7000lk3x65yne3tjz"},{"name":"Python","_id":"ck3h9fkpj000uk3x6evq9brta"},{"name":"JS","_id":"ck3h9fkqo0027k3x67bk7evyi"},{"name":"RL","_id":"ck3h9fkqu002mk3x6g6xj92q5"}]}}